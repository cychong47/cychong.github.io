<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>homelab on Keep calm and write something</title><link>https://cychong47.github.io/categories/homelab/</link><description>Recent content in homelab on Keep calm and write something</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 13 Apr 2021 11:26:01 +0900</lastBuildDate><atom:link href="https://cychong47.github.io/categories/homelab/index.xml" rel="self" type="application/rss+xml"/><item><title>Install kubernetes on mini3</title><link>https://cychong47.github.io/post/2021/2021-04-13-install-kubernetes-on-mini3/</link><pubDate>Tue, 13 Apr 2021 11:26:01 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-04-13-install-kubernetes-on-mini3/</guid><description>mini1에서 mini3로의 이전을 준비 중. 기존에 mini3에는 재미삼아 k3s를 설치해 놓았는데 왠지 새로운 설정 방식을 알아야 할 필요가 있나 하는 생각이 들어 이전처럼 다시 vanilla kubernetes 를 설치하기로 했다. minkkube처럼 VM을 만들어야 설치가 되는 것도 아니고 그냥 host OS에 설치하면 되니까 설치도 간단하고(물론 바이너리 하나 설치하면 되는 k3s와는 비교하기 어렵지만) 부하를 감당하기 어려운 정도의 CPU도 아니라서.
Installing kubeadm | Kubernetes
# /etc/modules-load.d/k8s.conf br_netfilter # /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 $ sudo sysctl —-system Install Containerd as a Container Runtime docker를 CRI로 사용하는 것은 곧 deprecated예정이니까 containerd를 사용해 보자.</description></item><item><title>Replace NodePort with ClsuterIP - Thx to Traefik</title><link>https://cychong47.github.io/post/2021/2021-03-31-change-nodeport-to-clusterip/</link><pubDate>Sat, 03 Apr 2021 22:00:00 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-03-31-change-nodeport-to-clusterip/</guid><description>Traefik을 이용한 Ingress/Ingress Controller를 이용해서 nginx 기반 Pod를 cluster 외부에서 접속할 수 있도록 설정했는데 곰곰히 생각해 보니 그렇다면 nginx service에 굳이 NodePort를 사용해야 하나 라는 생각이 들었다. 이제 외부로부터의 요청은 든든한 Traefik이 처리해 줄 테니 직접 각 pod가 서비스를 NodePort를 이용해서 외부에 오픈할 필요가 없어 보였다.
이를 위해 기존에 사용하던 nginx의 value 파일을 다음과 같이 수정했다. NodePort를 위해 필요했던 정보들이 사라지고, 수신하고 싶은 Port만 지정하면 되니설정 파일이 무척 깔끔해졌다.
service: # type: NodePort # targetPort: 80 # container app.</description></item><item><title>Setup Ingress with Traefik</title><link>https://cychong47.github.io/post/2021/2021-03-31-setup-ingress-with-traefik/</link><pubDate>Wed, 31 Mar 2021 23:00:00 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-03-31-setup-ingress-with-traefik/</guid><description>Ingress Controller 를 설치(Helm으로 Traefik 설치하기)했으니 이제 Ingress를 설정해서 실제 cluster 외부로부터의 http/https 메시지를 nginx pod에 전달되게 해 본다.
Ingress Ingress는 Cluster 외부에서 접근하는 http/https request에 대한 라우팅을 제어하는 기능을 제공한다. Ingress | Kubernetes
ingress.yaml 파일을 다음과 같이 작성한다. . 아래는 두 가지 rule을 설정하고 있는데 host가 ‘mini1’이고, URL path가 /ost면 podcast-nginx라는 서비스로 전달하게 하는 것과 host는 상관없이 path가 /ost면 역시 같은 podcast-nginx로 보내는 것이다.
kind: Ingress apiVersion: extensions/v1beta1 metadata: name: &amp;quot;test&amp;quot; namespace: default spec: rules: - host: mini1 http: paths: - path: /ost backend: serviceName: podcast-nginx servicePort: 8099 - http: paths: - path: /ost backend: serviceName: podcast-nginx servicePort: 8099 Kubectl 명령을 이용해 적용해 본다.</description></item><item><title>Helm으로 Traefik 설치하기</title><link>https://cychong47.github.io/post/2021/2021-03-30-install-traefik-with-helm/</link><pubDate>Tue, 30 Mar 2021 09:00:00 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-03-30-install-traefik-with-helm/</guid><description>지금 집에 있는 서버(mac mini 2009)에서 nginx를 이용해서 블로그를 호스팅하는데 port를 구분해서 외부에 노출하고 있다. 외부에서의 &amp;gt;접근을 위해 NodePort를 사용하고, 각 nginx instance는 서로 다른 port를 이용하고 있는데 port번호가 아니라 URL 경로를 이용해서 서로 다른 서비스를 이용할 수 있는 reverse proxy 기능을 사용하면 좀 더 깔끔할 듯 하다. Kubernetes에서는 ingress와 ingress controller를 이용해서 이 reverse proxy를 구현할 수 있다고 한다. Kubernetes에서는 ingress는 기본적으로 제공하는 object 지만, ingress controller는 제공하고 있지 않아, 별도로 설치해야 한다.</description></item><item><title>Install cockpit - linux server manager</title><link>https://cychong47.github.io/post/2021/2021-03-04-install-cockpit/</link><pubDate>Thu, 04 Mar 2021 22:06:00 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-03-04-install-cockpit/</guid><description>$ sudo apt install -y cockpit sssd-dbus $ sudo ufw allow 9090/tcp ; sudo systemctl start cockpit` $ ss -tunlp |grep 9090 tcp LISTEN 0 4096 *:9090 *:* CPU load 정보가 주기적으로 100%까지 튀네. 거의 10초 단위로. 뭘까 여러 개의 리눅스 서버가 있는 경우 한 곳에 추가해서 single glass of pane을 만들 수도 있다. 추가된 서버들은 dashboard에서 drop list로 보여지므로 원하는 대상을 선택</description></item><item><title>Change the server IP address of k3s</title><link>https://cychong47.github.io/post/2021/2021-03-03-change-the-server-ip-address-of-k3s/</link><pubDate>Wed, 03 Mar 2021 13:17:28 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-03-03-change-the-server-ip-address-of-k3s/</guid><description>How to change IP address of k3s By default, as k3s operates in the local host, it is not possible to connect from other host.
To get the server Ip address,
$ kubectl config view --raw |grep server server: https://127.0.0.1:6443 The listening server IP address can be specified by giving parameter in running the k3s binary.
K3s configuration is on /etc/systemd/system/k3s.service
$ cat /etc/systemd/system/k3s.service [Unit] Description=Lightweight Kubernetes Documentation=https://k3s.io Wants=network-online.target After=network-online.target [Install] WantedBy=multi-user.</description></item><item><title>Use the Secret and ConfigMaps</title><link>https://cychong47.github.io/post/2020/2020-10-19-use-the-secret-and-configmaps/</link><pubDate>Mon, 19 Oct 2020 14:21:03 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-10-19-use-the-secret-and-configmaps/</guid><description>Use the Secret and ConfigMaps $ cat my-secret.yaml apiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque stringData: WSO2_CLOUD_ORG_KEY: &amp;quot;mycompany&amp;quot; WSO2_CLOUD_EMAIL: &amp;quot;sample-email@wso2.com&amp;quot; WSO2_CLOUD_PASSWORD: &amp;quot;password&amp;quot; $ kubectl apply -f my-secret.yaml secret/mysecret created From Using Kubernetes Secrets as Environment Variables
spec: containers: - env: - name: WSO2_CLOUD_ORG_KEY valueFrom: secretKeyRef: name: mysecret key: WSO2_CLOUD_ORG_KEY ... apiVersion: v1 kind: Secret metadata: name: my-tokens type: Opaque stringData: pinboard_key: &amp;#34;FIXME&amp;#34; pocket_consumer_key: &amp;#34;FIXME&amp;#34; pocket_access_token: &amp;#34;FIXME&amp;#34; slack_api_token: &amp;#34;FIXME&amp;#34; slack_events_token: &amp;#34;FIXME&amp;#34; slack_verification_token: &amp;#34;FIXME&amp;#34; slack_signing_secret: &amp;#34;FIXME&amp;#34; telegram_token: &amp;#34;FIXME&amp;#34; telegram_api_id: &amp;#34;FIXME&amp;#34; telegram_api_hash: &amp;#34;FIXME&amp;#34; $ kubectl apply -f my-tokens.</description></item><item><title>How to make cronjob to support timezone</title><link>https://cychong47.github.io/post/2020/2020-10-19-how-to-fix-no-timezone-support-of-cronjob/</link><pubDate>Mon, 19 Oct 2020 14:16:45 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-10-19-how-to-fix-no-timezone-support-of-cronjob/</guid><description>Problem CronJob이 지정된 시간에 잘 동작했는 지 확인해 본 결과 이상한 점을 발견했다.
오후 2시 32분에 CronJob 의 동작을 확인했는데 이전에 실행된 시간이 4시간 32분 전이라고, 즉 새벽 1시가 아니라 오전 10시에 실행이 되었다는 나오는 것이다.
$ date Sat Oct 10 14:32:36 KST 2020 $ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE pocket-stat 0 1 * * * False 0 4h32m 14h 혹시 10시를 1시로 잘못 설정했나 하고 kubectl describe cronjob 명령으로 확인해 봤지만 schedule 정보는 정상적으로 설정되어 있었다는.</description></item><item><title>주기적으로 실행되는 앱은 CronJob으로</title><link>https://cychong47.github.io/post/2020/2020-10-09-cronjob-in-kubernetes/</link><pubDate>Fri, 09 Oct 2020 02:00:00 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-10-09-cronjob-in-kubernetes/</guid><description>만일 job을 일정 주기 혹은 특정 시간에 실행시키려면 CronJob resource를 만들어 사용하면 된다.
Job과 CronJob간의 관계는? CronJob에 대한 설명에 따르면 CronJob정의에 기술한 특정 시간이 되면 CronJob이 Job을 실행한다고. 그리고 그 Job이 Pod를 실행한다.
그럼 Job을 위한 resource 정의와 CronJob을 위한 resource 정의를 각각 정의해야 하나? 그렇지는 않은 듯. CronJob의 정의 파일을 보면 JobTemplate 항목이 Job에서 볼 수 있는 Template과 유사한 container spec 등을 가지고 있다. 물론 CronJob 에서만 유효한 schedule spec 등을 추가로 가지고 있긴 하지만.</description></item><item><title>일회성 앱은 Deployment가 아닌 Job으로</title><link>https://cychong47.github.io/post/2020/2020-10-09-job-instead-of-deployment/</link><pubDate>Fri, 09 Oct 2020 01:00:00 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-10-09-job-instead-of-deployment/</guid><description>한 번 실행되면 데몬 처럼 계속해서 동작하는 앱이 아니라 필요한 일을 수행하고 종료되는 앱도 있다. 실행된 시점에 필요한 일을 수행하고 종료하는 형태로 예를 들면 특정 위치에 있는 파일을 처리하고 종료한다거나, 실행된 시점에 외부 서비스에서 필요한 정보를 가져와 어딘가 저장하는 등의 일을 하는. 이런 종류의 앱을 kubernetes에서 Deployment로 배포한 경우 해당 앱은 자신이 해야 할 일을 정상적으로 수행하고 종료되지만, kubernetes scheduler 입장에서는 해당 container가 (의도하지 않게) 종료된 것으로 판단하여 다시 복구하는 절차를 수행한다.</description></item><item><title>Upgrade Kubernetes 1 18 2</title><link>https://cychong47.github.io/post/2020/2020-05-07-upgrade-kubernetes-1-18-2/</link><pubDate>Sat, 01 Aug 2020 22:52:47 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-05-07-upgrade-kubernetes-1-18-2/</guid><description>Upgrade kubernetes to 1.18.2
Note etcd might be need to be upgrade
cychong@mini1:~$ sudo kubeadm upgrade apply v1.18.2 [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [preflight] Running pre-flight checks. [upgrade] Running cluster health checks [upgrade/version] You have chosen to change the cluster version to &amp;quot;v1.18.2&amp;quot; [upgrade/versions] Cluster version: v1.</description></item><item><title>Deploy nginx with helm</title><link>https://cychong47.github.io/post/2020/2020-07-02-deploy-nginx-with-helm/</link><pubDate>Thu, 02 Jul 2020 23:58:41 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-07-02-deploy-nginx-with-helm/</guid><description>우선 docker로 실행한 nginx container를 종료시키고
cychong@mini1:~/work/helm-chart-github$ docker ps -a |grep nginx a66786635c60 nginx &amp;quot;/docker-entrypoint.…&amp;quot; 7 minutes ago Up 7 minutes k8s_nginx_my-nginx-77596b9fc6-7txns_default_44840d63-b496-4a58-9e18-83e503c6d2cf_0 85c85322ea59 k8s.gcr.io/pause:3.1 &amp;quot;/pause&amp;quot; 7 minutes ago Up 7 minutes k8s_POD_my-nginx-77596b9fc6-7txns_default_44840d63-b496-4a58-9e18-83e503c6d2cf_0 5be06dc3b184 nginx &amp;quot;nginx -g 'daemon of…&amp;quot; 2 weeks ago Up 2 weeks 0.0.0.0:8099-&amp;gt;80/tcp podcast 2812c510a5b6 nginx &amp;quot;nginx -g 'daemon of…&amp;quot; 2 weeks ago Up 2 weeks 0.0.0.0:80-&amp;gt;80/tcp sosa0sa cychong@mini1:~/work/helm-chart-github$ docker stop 5be06dc3b184 5be06dc3b184 nginx를 구동시킬 helm chart 준비</description></item><item><title>Upgrade kubernetes to 1.16.1</title><link>https://cychong47.github.io/post/2019/upgrade-kubernetes/</link><pubDate>Mon, 07 Oct 2019 15:37:14 +0900</pubDate><guid>https://cychong47.github.io/post/2019/upgrade-kubernetes/</guid><description>cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update [sudo] password for cychong: Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease Hit:5 http://dl.google.com/linux/chrome/deb stable Release Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB] Get:13 http://archive.</description></item><item><title>Setup kubernetes in a single host</title><link>https://cychong47.github.io/post/2019/setup-kubernetes-with-a-single-host/</link><pubDate>Mon, 23 Sep 2019 15:03:13 +0900</pubDate><guid>https://cychong47.github.io/post/2019/setup-kubernetes-with-a-single-host/</guid><description>Replace microk8s with kubernetes in mini1
remove micro.k8s with snap command cychong@mini1:~$ sudo snap remove microk8s Save data of snap &amp;quot;microk8s&amp;quot; in automatic snapshot set microk8s removed cychong@mini1:~$ setup kubernetes Reference : https://phoenixnap.com/kb/install-kubernetes-on-ubuntu
cychong@mini1:~$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.15.3 cychong@mini1:~$ kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5c98db65d4-r468f 0/1 Pending 0 2m3s &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; kube-system coredns-5c98db65d4-wcm2n 0/1 Pending 0 2m3s &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; kube-system etcd-mini1 1/1 Running 0 79s 192.</description></item></channel></rss>