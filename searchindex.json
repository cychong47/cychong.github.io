{"categories":[{"title":"Book","uri":"https://cychong47.github.io/categories/book/"},{"title":"TIL","uri":"https://cychong47.github.io/categories/til/"}],"posts":[{"content":"Wordpress 블로그를 hugo로 바꾼 김에 ghost 블로그도 hugo로 이사하기로 결심했다.\nGhost 정말 애증이 담긴\u0026hellip;\nGhost가 1.0이 되기 전에 markdown 기반의 블로그 툴을 찾는 과정 에서 발견해서 0.9 버전인가 부터 사용해 왔다. Ghost가 node 기반이라 생전 처음 듣는 node를 OS X에 설치해보고, docker for OS X이 나와서 docker로 실행해 오다, docker-compose 도 써 보고, Ansible 로 deploy도 해보고. 그러다 2019년에는 kubernetes hands-on을 해 볼 겸해서 리눅스에서 microk8s를 설치해서 ghost도 k8s로 실행해 봈다. 그리고 k8s에서 기본처럼 사용되는 SW 배포/관리 툴인 helm도 hands-on을 해 보고 싶어서 helm chart로 ghost도 배포해 보고. 횟수로 치면 대략 2016년 정보 부터 같은데 그간 Ghost는 1.0을 거쳐 2.0 그리고 지금은 3.0까지 업데이트가 된 상태이다.\n처음에 Ghost에 끌렸던 이유는 markdown 기반이라는 점이 컸는데, 본격적으로 markdown을 기반으로 글을 쓰는 blog 툴이라는 점. 그리고 그때도 그랬지만, wordpress가 blog 외에 다양한 형태의 CMS(Contents Management System)으로 개발되다 보니 blog만 돌리기에는 too much하다는 느낌을 지울 수 없었다. Ghost가 sqlite를 backend DB로 사용할 수 있는 것과 달리 wordpress는 MySql등의 DB를 반드시 사용해야 한다는 점도 8GB의 리눅스 박스에서 돌리기엔 부담이 벅차서 메모리 부족으로 에러가 나기도 했다는\u0026hellip;\nGhost에서 hugo로 이전해야겠다는 마음을 먹게 한 가장 큰 이유는 Ghost의 editor때문이 아닌가 싶다. 초기에는 정말 간단한 형태의 text editor 였는데, 시간이 지나면서 점점 복잡한 형태의 editor로 바뀌었는데 내겐 오히려 적응하는 것이 쉽지 않았다. 그냥 markdown 문법 몇 가지만 익혀서 사용하면 될 듯 한데 그걸 WIGWYG 형태로 지원하다 보니 오히려 내겐 번거로운 절차가 되어 버렸다.\n어차피 Ghost blog에 올린 글들은 markdown으로 정리했던 내용이 대부분인 터라 그냥 향후에 platform 에 대한 의존성을 줄이는 셈 치고 Ghost에서 한 발 물러서기로 했다.\nHugo 를 이용한 사이트를 만드는 것도 아직 익숙하지 않아서 살짝 헤매긴 했지만, 더 큰 문제는 Ghost에 있는 글들을 어떻게 옮길 것인가 하는. 개발자 사이에서는 Hugo를 이용한 블로그를 쓰는 경우가 적지 않지만 Ghost를 사용하다 Hugo로 이전하는 경우는 그렇게 많아 보이지 않았다. 구글링을 해 보면 대부분 GhostToHugo라는 golang으로 작성된 앱을 이용해서 데이터를 전환했다는 경우가 많았다. 그래도 나도 같은 툴을 시도해 봤는데 왠걸 잘 안된다. golang 문법을 모르지만, 에러가 난 부분을 보면 file IO로 보이는데 잘 이해가 안된다. 간단하게 디버그 코드를 추가해서 확인해 보려고 해도 이상하게 내가 수정한 코드가 실행이 안되는. 아마도 이건 golang의 빌드 체계를 몰라서 그런 듯.\n또 다시 구글링을 해서 찾는 방법은 누군가 PHP로 작성한 스크립트인데 역시나 안된다. 워낙 코드가 간단하긴 한데 문제는 문제가 왜 발생하는 지 전혀 감을 못 잡겠다는\u0026hellip; 근데 그 간단한 코드를 보니 대략 어떻게 하고 있구나 하는 감이 잡혔다. 그래서 이번 기회에 그냥 스크립트를 직접 작성해 보자 하고 졸린 눈을 부비고 코드를 작성했다. mobiledoc 문법으로 되어 있는 블로그 본문을 제외한 부분은 대충 원하는 형태로 동작하도록 했는데 mobiledoc의 문법이 또 달라서 이걸 markdown으로 변경하는 것도 은근 시간이 필요한 작업으로 보였다. 그러다 다시 구글링을 mobiledoc to markdown을 주제로 하다 찾은 글이 바로 이 글 Migrating From Ghost to Hugo (Again) 이다. 2017년에 작성된 글인데 무려 내가 하고 싶었던, 내가 헤매고 있었던 부분이 모두 구현된 변환 스크립트였다. 거기에 내가 몇 줄을 사용해서 구현한 기능을 단 한 줄로 pythonic 한 코드로 깔끔하게 작성한 걸 보고 좌절감을 또\u0026hellip; ;\n지난 번 wordpress를 이전한 hugo는 Mainroad theme을 사용했는데 ghost 를 이전한 hugo는 pure를 선택했다. 둘 다 깔끔한데, hugo의 단점으로 보이는 것 중 하나가 theme 간에 대략적인 통일성은 있는데 그렇다고 기본적인 걸 모두 엄격하게 지키는 게 아니라 theme 마다 hugo configuration 파일(config.toml 혹은 config.yaml)의 내용을 모두 바꿔야 한다. 그리고 md 파일을 두는 위치도 content 아래에서는 각 theme마다 다르게 처리하고 있어 지금도 mainroad theme은 post를 사용하고, pure theme은 posts를 사용한다. (이 점도 내가 아직 hugo의 구조를 제대로 이해하지 못해서 그럴 수도 있다 물론\u0026hellip;)\n두 개 theme에서 공히 없는 기능은 monthly archive 목록을 sidebar에서 보여주는 거. 특히 journal 형태로 가족 블로그에서 아쉬운 기능이다. 특정 연도에 있던 일을 보고 싶을 때가 많은데 mainroad theme 뿐만 아니라 다른 hugo theme에서도 이런 기능이 흔하지는 않다. 아마도(?) hugo를 사용하는 사람들이 대부분 기술적인 내용을 남기는 tech blogger여서 그런게 아닌가 싶은데 나로서는 아쉬운 부분이다. 이 기능은 꼭 필요하다는 생각이 들어 시간 날 때마다 찾아봐야겠다.\n이번에 Ghost에서 hugo로 옮긴 블로그는 github.io에 호스팅을 해보기로 했다. wordpress에서 이전한 hugo 블로그처럼 직접 nginx container를 이용해서 호스팅해도 되는데, 그냥 이번에는 그렇게 해보려고 한다. 거기에 netify도 연동해서 글을 쓰면 자동으로 글이 github.io에 호스팅에 반영되는 것 까지 해보려고. 실은 이건 wordpress에서 이전한 hugo 블로그에도 필요한 기능인데 netify가 제공하는 한 개의 블로그에 sosa0sa.com 도메인을 넘겨버리면 집 mac mini 서버로 redirect하는 것이 어려워져서 제약이 생길 것 같아 고민 중이다. 그건 좀 써 보면서 생각을 해 보기로\u0026hellip;\nFarewell Ghost~\n Migrating from Ghost to Hugo - Why Bother? Moving from Ghost to Hugo https://blog.viktoradam.net/2019/03/28/netlify-hugo/  ","id":0,"section":"posts","summary":"Wordpress 블로그를 hugo로 바꾼 김에 ghost 블로그도 hugo로 이사하기로 결심했다. Ghost 정말 애증이 담긴\u0026hellip; Ghost가 1.0이 되기 전에 markdown 기반의 블로","tags":["ghost","hugo"],"title":"Migrate Ghost to Hugo","uri":"https://cychong47.github.io/2020/06/migrate-ghost-to-hugo/","year":"2020"},{"content":"Wordpress 에서 hugo로 이사한 후 첫번째 시도. Hugo theme은 harbor를 사용하고, site 호스팅 방법은 nginx docker를 사용. (이상하게 nginx를 helm으로 띄우는 게 간단하지 않네)\nClone repogistry for raw blog data cychong15:migration_to_hugo cychong$ git clone https://github.com/cychong47/sosa0sa.git Cloning into 'sosa0sa'... warning: You appear to have cloned an empty repository.  Setup hugo inside of the git repository cychong15:migration_to_hugo cychong$ hugo new site sosa0sa Error: /Users/cychong/workspace/migration_to_hugo/sosa0sa already exists and is not empty. See --force. cychong15:migration_to_hugo cychong$ hugo new site sosa0sa --force Congratulations! Your new Hugo site is created in /Users/cychong/workspace/migration_to_hugo/sosa0sa. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \u0026quot;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026quot; command. 2. Perhaps you want to add some content. You can add single files with \u0026quot;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026quot;. 3. Start the built-in live server via \u0026quot;hugo server\u0026quot;. Visit https://gohugo.io/ for quickstart guide and full documentation.  Maybe not good to enforce to do something.\ncychong15:sosa0sa cychong$ tree -f . ├── ./archetypes │ └── ./archetypes/default.md ├── ./config.toml ├── ./content ├── ./data ├── ./layouts ├── ./static └── ./themes 6 directories, 2 files  Add Theme cychong15:sosa0sa cychong$ cd themes/ cychong15:themes cychong$ ls cychong15:themes cychong$ git submodule add https://github.com/matsuyoshi30/harbor.git harbor Cloning into '/Users/cychong/workspace/migration_to_hugo/sosa0sa/themes/harbor'... remote: Enumerating objects: 213, done. remote: Counting objects: 100% (213/213), done. remote: Compressing objects: 100% (142/142), done. remote: Total 739 (delta 111), reused 134 (delta 55), pack-reused 526 Receiving objects: 100% (739/739), 7.90 MiB | 4.50 MiB/s, done. Resolving deltas: 100% (349/349), done.  Copy example config.toml Default config.toml from harbor theme git repo which is a little bit different from that of the exampleSite directory of theme (themes/harbor/exampleSite/config.toml)\ntheme = \u0026quot;harbor\u0026quot; baseurl = \u0026quot;https://example.com/\u0026quot; title = \u0026quot;Hugo Themes\u0026quot; paginate = 3 languageCode = \u0026quot;en\u0026quot; DefaultContentLanguage = \u0026quot;en\u0026quot; enableInlineShortcodes = true footnoteReturnLinkContents = \u0026quot;^\u0026quot; # Optional # If you use googleAnalytics, you set top-level options in config.toml to the beginning of the config file like other top-level options. googleAnalytics = \u0026quot;UA-XXXXXXXX-XX\u0026quot; # and disqus too. disqusShortName = \u0026quot;yourdisqusshortname\u0026quot; [Author] name = \u0026quot;Hugo Author\u0026quot; [outputs] section = [\u0026quot;JSON\u0026quot;, \u0026quot;HTML\u0026quot;] [[params.nav]] identifier = \u0026quot;about\u0026quot; name = \u0026quot;About\u0026quot; icon = \u0026quot;fas fa-user fa-lg\u0026quot; url = \u0026quot;/about/\u0026quot; weight = 3 [[params.nav]] identifier = \u0026quot;tags\u0026quot; name = \u0026quot;Tags\u0026quot; icon = \u0026quot;fas fa-tag fa-lg\u0026quot; url = \u0026quot;tags\u0026quot; weight = 3 [[params.nav]] identifier = \u0026quot;categories\u0026quot; name = \u0026quot;Category\u0026quot; icon = \u0026quot;fas fa-folder-open fa-lg\u0026quot; url = \u0026quot;categories\u0026quot; weight = 3 [[params.nav]] identifier = \u0026quot;search\u0026quot; name = \u0026quot;Search\u0026quot; icon = \u0026quot;fas fa-search fa-lg\u0026quot; url = \u0026quot;search\u0026quot; weight = 3 [[params.nav]] identifier = \u0026quot;archives\u0026quot; name = \u0026quot;Archives\u0026quot; icon = \u0026quot;fas fa-archive fa-lg\u0026quot; url = \u0026quot;archives\u0026quot; weight = 3 [params.logo] url = \u0026quot;icon.png\u0026quot; # static/images/icon.png width = 50 height = 50 alt = \u0026quot;Logo\u0026quot;  Update a few things baseurl = \u0026quot;https://sosa0sa.com/\u0026quot; title = \u0026quot; sosa0sa.com\u0026quot; paginate = 5  Put markdown files under the content directory (venv) cychong15:sosa0sa cychong$ tree -d content/ -L 2 content/ └── post ├── 2003 ├── 2004 ├── 2005 ├── 2006 ├── 2007 ├── 2008 ├── 2009 ├── 2010 ├── 2011 ├── 2012 ├── 2013 ├── 2014 ├── 2015 ├── 2016 ├── 2017 ├── 2018 ├── 2019 └── 2020 19 directories  Put image files under the static files cychong15:static cychong$ tree -d -L 2 . └── images ├── 2002 ├── 2003 ├── 2004 ├── 2005 ├── 2006 ├── 2007 ├── 2008 ├── 2009 ├── 2010 ├── 2011 ├── 2012 ├── 2013 ├── 2014 ├── 2015 ├── 2016 ├── 2017 ├── 2018 ├── 2019 └── 2020 20 directories  Customize theme head.html Copy themes/harbor/layouts/partials/head.htmlto layouts/partials/head.html\nAnd change the css filename to use from dark.css to main.css\n(venv) cychong15:sosa0sa cychong$ diff themes/harbor/layouts/partials/head.html layouts/partials/head.html 14c14 \u0026lt; \u0026lt;link id=\u0026quot;dark-mode-theme\u0026quot; rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ .Site.BaseURL }}css/dark.css\u0026quot; /\u0026gt; --- \u0026gt; \u0026lt;link id=\u0026quot;dark-mode-theme\u0026quot; rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ .Site.BaseURL }}css/main.css\u0026quot; /\u0026gt;  Create HTML files (venv) cychong15:sosa0sa cychong$ hugo | EN -------------------+------- Pages | 3706 Paginator pages | 1096 Non-page files | 0 Static files | 6354 Processed images | 0 Aliases | 550 Sitemaps | 1 Cleaned | 0 Total in 5964 ms  (venv) cychong15:sosa0sa cychong$ tree -d -L 1 public/ public/ ├── archives ├── categories ├── css ├── fontawesome ├── fonts ├── images ├── js ├── page ├── post ├── src └── tags 11 directories  (venv) cychong15:sosa0sa cychong$ du -hs public/ 1.8G\tpublic/  Setup nginx docker - To Go cychong@mini1:~$ helm repo add nginx-stable https://helm.nginx.com/stable \u0026quot;nginx-stable\u0026quot; has been added to your repositories cychong@mini1:~$ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \u0026quot;nginx-stable\u0026quot; chart repository Update Complete. ⎈ Happy Helming!⎈  cychong@mini1:~/work$ helm install nginx nginx-stable/nginx-ingress NAME: nginx LAST DEPLOYED: Sun May 31 08:58:59 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The NGINX Ingress Controller has been installed.  Deploy nginx with customized values.yaml https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/charts/ingress-nginx/values.yaml\n파일을 받아 필요한 내용을 수정한 후 사용\nTry with docker Copy the default nginx configuration file and change to listen 0.0.0.0 rather than 127.0.0.1\nroot@e364ef9bb706:/etc/nginx# cat conf.d/default.conf server { listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} }  cychong@mini1:~$ docker run --name nginx -p80:80 -v /home/cychong/work/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro -v /home/cychong/Documents/hugo/:/usr/share/nginx/html -d nginx ce4d05fb3895a825ac8fee1723c3b7417c281e035b9bebeff91aa73e3749d317 cychong@mini1:~$ docker ps -a |grep nginx ce4d05fb3895 nginx \u0026quot;nginx -g 'daemon of…\u0026quot; 35 seconds ago Up 33 seconds 0.0.0.0:80-\u0026gt;80/tcp nginx  Stop the wordpress and mysql dockers cychong@mini1:~$ docker ps -a |grep wordpress 18203ecb1459 wordpress \u0026quot;docker-entrypoint.s…\u0026quot; 3 months ago Up 5 days 0.0.0.0:80-\u0026gt;80/tcp wordpress cychong@mini1:~$ docker stop wordpress wordpress cychong@mini1:~$ docker stop mysql mysql  Setup Hugo docker for hosting generated Static files cychong@mini1:~$ docker pull tarampampam/hugo:latest latest: Pulling from tarampampam/hugo df20fa9351a1: Pull complete 6da297b993f4: Pull complete ec2cc2aeaf82: Pull complete Digest: sha256:878b09a81c0594482a2c8291ea587b3b4b262069b64b0af0838d50438711926c Status: Downloaded newer image for tarampampam/hugo:latest docker.io/tarampampam/hugo:latest   https://github.com/matsuyoshi30/harbor https://hahafamilia.github.io/howto/hugo-staticgen/ Installation with Helm Helm chart 목록 nginx의 chart를 보려면 github.com/kubernetes 에 있는 해당 패키지의 charts 디렉토리를 확인한다 nginx configuration The most downloaded hugo docker image hugo 사용의 기본적인 절차를 간략하게 잘 요약한 글  ","id":1,"section":"posts","summary":"Wordpress 에서 hugo로 이사한 후 첫번째 시도. Hugo theme은 harbor를 사용하고, site 호스팅 방법은 nginx docker를 사용. (이상하게 nginx를 helm","tags":["wordpress","nginx","hugo"],"title":"Migrate wordpress to hugo","uri":"https://cychong47.github.io/2020/05/hugo-seutp-with-git/","year":"2020"},{"content":"https://devblogs.nvidia.com/building-accelerated-5g-cloudran-at-the-edge/\nMellanox ConnectX-6 Dx SmartNIC exceeds stringent industry-standard timing specifications for eCPRI-based RANs by ensuring clock accuracy of 16ns or less\n5T for 5G enables packet-based, ethernet RANs to provide precise time-stamping of packets for delivering highly accurate time references to 5G fronthaul and backhaul networks.\n 5T-for-5G, or time-triggered transmission technology for telco\n https://news.developer.nvidia.com/new-real-time-smartnic-technology-5t-for-5g/\n  Real-time transmission hardware acceleration: 5T-for-5G simplifies time synchronization and data transmission across servers, GPUs, radios, and baseband units in wireless network rollouts, making 5G rollouts easier and more efficient.\n  Precise time stamping: It supports IEEE 1588v2 PTP for precise timing synchronization.\n  Highest clock accuracy: It ensures extremely precise timing accuracy within 16 ns, adhering to the stringent ITU-T G8273.2 standard.\n  eCPRI windowing: It supports precise transmission of eCPRI packets within the O-RAN specified timing window.\n  ASAP2 time-based flow engine: It allows packet time stamping and time-bound packet steering using Mellanox ASAP2.\n  Highly efficient: 5T-for-5G enables more accurate time synchronization than software solutions and lower costs and power consumption than traditional FPGA-based solutions, enabling efficient CloudRAN and edge rollouts.\n  NVIDIA EGX–ready: Developers can create GPU-based CloudRAN solutions with the NVIDIA Aerial SDK that use precise timing without investing in expensive and proprietary FPGA solutions.\n  https://www.youtube.com/watch?v=rxLejojuMjM\u0026amp;feature=youtu.be\nGPUDirect Remote Direct Memory Access (RDMA) store data by eliminating unnecessary duplicates and decreasing latency. By reducing the back and forth with the CPU memory, GPUDirect saves computation cycles for memory access.\nHeader/data split functionality With cuVNF, you have the header/data split functionality that allows agile packet filtering.\nO-RAN format identification feature does faster packet flow steering based on the MAC address\ncuVNF EGX A100 edge server platform ConnectX-6 with 5T-for-5G\nLinks  CUDA CUDA download and additional resources such as training, open source packages and etc https://news.developer.nvidia.com https://developer.nvidia.com/nvidia-aerial-sdk-early-access-program  ","id":2,"section":"posts","summary":"https://devblogs.nvidia.com/building-accelerated-5g-cloudran-at-the-edge/\nMellanox ConnectX-6 Dx SmartNIC exceeds stringent industry-standard timing specifications for eCPRI-based RANs by ensuring clock accuracy of 16ns or less\n5T for 5G enables packet-based, ethernet RANs to provide precise time-stamping of packets for delivering highly accurate time references to 5G fronthaul and backhaul networks.\n 5T-for-5G, or time-triggered transmission technology for telco\n https://news.developer.nvidia.com/new-real-time-smartnic-technology-5t-for-5g/\n  Real-time transmission hardware acceleration: 5T-for-5G simplifies time synchronization and data transmission across servers, GPUs, radios, and baseband units in wireless network rollouts, making 5G rollouts easier and more efficient.","tags":["DPDK","vran","nvidia","gpu","cuphy","cubb","cuvnf","connectX-5","RMDA"],"title":"NVIDIA vRAN Solution","uri":"https://cychong47.github.io/2020/05/nvidia-vran-solution/","year":"2020"},{"content":"말썽쟁이(?) wordpress 블로그가 또 문제를 일으켰다.\n이번에도 로그인이 안되는 현상인데 지난 번과는 다른 에러 메시지가 나온다. 즉 지난 번 해결책은 소용이 없을 거라는 불길한 예감이.\n로그인 계정 자체가 없다는 이 어이없는 상황.\n그래서 지난 번에 유용하게 사용했던 phpmyadmin을 이용해서 DB 정보를 확인해봤다. (다행히 MySql, wordpress 와 함께 실행시켜놓은 phpmyadmin container가 동작하고 있어서 지난 번과 같이 8181 포트로 접속하면 된단. 다만 로그인 암호를 기억하지 못하고 있는 나 대신 Safari가 기억하고 있어서 그냥 접속했다는)\n뭔가 이상하다.\n #1812 - Tablespace is missing for table wordpress_db.wp_users.\n 이게 무슨 말인가 하고 구글링을 해 보니 DB 파일에 문제가 생겨서 그렇다고. 이걸 해결하려면 이전에 백업한 DB 파일이 있어야 한다는 청천벽력 같은 말. 거기에 전에 DB를 모두 restore하는 방식으로 해결했다는 글이 보인다. ERROR 1812 (HY000): Tablespace is missing for table in MYSQL\n Solution We must have backup for restore, We have taken on Sunday, deletion of TEST2 happen on Monday.\n 음.. 이러면 백업된 시점 이후에 변경된 내용은 모두 잃어버린다는 것 같은데\n다른 글에서는 일단 db 파일에 문제가 생긴 경우(파일이 없거나, 파일 퍼미션이 정상이 아닌에도 동일한 문제가 발생할 수 있다고. How to fix error “1812 Tablespace is missing for table XXXX”\n  Table files have the wrong ownership/permissions The table file is misplaced The data file is corrupted or deleted   만일 idb 파일에 문제가 생긴 경우라면 문제가 생긴 파일만 백업 본으로 교체하거나 파일 권한을 수정하면 간단하게 해결이 될 거고, SQL DB 전체에 대한 거라면 역시나 기존 DB를 지우고 백업된 걸로 복원을 해야 한다고\n If the backups are stored as .ibd files, we copy the table files into the database folder and set the right permissions. Everything usually works fine from that point. On the other hand, if it’s in the SQL format, we drop the current database, and restore the full database from backup. This method will create fresh entries in the System tables, and build proper linkages.\n 그나마 이건 백업 본이 있을 때나 하는 이야기고\u0026hellip;\n그래서 mysql container에 접속해서 확인해 보니 과연 위에서 에러난 table 파일만 찾을 수 없다. 아무리 봐도 wordpress 버전 업그레이드를 하면서 일부 파일에 문제가 생긴 듯\u0026hellip;\ncychong@mini1:~$ sudo docker ps -a |grep mysql [sudo] password for cychong: faafa54b9184 mysql:8 \u0026quot;docker-entrypoint.s…\u0026quot; 2 months ago Up 2 days 3306/tcp, 33060/tcp mysql cychong@mini1:~$ sudo docker exec -it faafa54b9184 /bin/bash root@faafa54b9184:/# find . -name *.ibd find: './proc/1/map_files': Permission denied ./var/lib/mysql/wordpress_db/wp_options.ibd ./var/lib/mysql/wordpress_db/wp_postmeta.ibd ./var/lib/mysql/wordpress_db/wp_posts.ibd ./var/lib/mysql/wordpress_db/wp_usermeta.ibd ./var/lib/mysql/wordpress_db/wp_comments.ibd ./var/lib/mysql/wordpress_db/wp_commentmeta.ibd ./var/lib/mysql/wordpress_db/wp_terms.ibd ./var/lib/mysql/wordpress_db/wp_term_taxonomy.ibd ./var/lib/mysql/wordpress_db/wp_term_relationships.ibd ./var/lib/mysql/mysql.ibd ./var/lib/mysql/sys/sys_config.ibd  하지만 내 문제는 백업된 SQL이 파일이 없다는 거. 가진 건 XML 형태 뿐. 이걸로 어떻게 고칠 수 없을까?\n일단 wp_users 외 다른 table에는 문제가 없는 각 table 별로 확인을 해보니(phpmyadmin에서 각 table별로 클릭해 보면 확인 가능) termmeta와 links도 같은 에러가 있다. 첩첩산중이네.\n아무래도 인터넷에 많이 있는 해결책으로는 내 문제를 해결할 수 없는 듯하다. 직접 문제를 해결해야 할 듯.\nTable을 새로 만들어 보자 기존에 백업된 걸로 복원하는 방식을 사용할 수 없다면 새로 만드는 수 밖에. 다행히 posts table이 아니고 일단 로그인 문제는 users table만 관계된 듯 하니 문제가 된 table을 직접 만들어 보기로 했다. 구글링을 해서 users table의 구조(schema)를 찾아 보니 2019년 3월 29일에 작성된 이 글 이 있는데 문제는 1년 전에 작성된 이 글에 있는 내용이 최신 구조와 같은 지 판단하기 어렵다는. 그래서 추가로 확인해 보니 앞 글 보다 더 최근에 작성된 다른 글 에서는 조금 다른 형태라고 설명이 되어 있다. 예를 들면 user_pass가 64가 아니라 255비트로 늘어난 걸로. 아무래도 직접 wordpress 코드를 보고 파악하는게 낫겠다.(나중에 깨달았지만, 내가 사용하는 wordpress가 최신 버전이 아닌데 최신 코드를 보고 작업하는 게 맞는 거 였을까 싶은\u0026hellip;)\nwordpress.org에서 wordpress 소스 코드를 받아 보기로.\ncychong15:workspace cychong$ wget https://wordpress.org/latest.tar.gz  wp-admin/includes/schema.php파일에 DB table을 만드는 코드가 있는 듯 한데 다음과 같이 정의되어 있다.\n\t// Single site users table. The multisite flavor of the users table is handled below. $users_single_table = \u0026quot;CREATE TABLE $wpdb-\u0026gt;users ( ID bigint(20) unsigned NOT NULL auto_increment, user_login varchar(60) NOT NULL default '', user_pass varchar(255) NOT NULL default '', user_nicename varchar(50) NOT NULL default '', user_email varchar(100) NOT NULL default '', user_url varchar(100) NOT NULL default '', user_registered datetime NOT NULL default '0000-00-00 00:00:00', user_activation_key varchar(255) NOT NULL default '', user_status int(11) NOT NULL default '0', display_name varchar(250) NOT NULL default '', PRIMARY KEY (ID), KEY user_login_key (user_login), KEY user_nicename (user_nicename), KEY user_email (user_email) ) $charset_collate;\\n\u0026quot;;  (이것도 Single site인 경우와 Multi site 인 경우가 다른 듯 한데, 일단 난 single site인 걸로)\n이제 구조를 알았으니 phpmyadmin을 이용해서 직접 DB에 users table을 추가하기로\n고장난 집부터 부수기 일단 문제가 된 users table을 삭제하고, 새로 만들기로\n그 다음 insert 메뉴를 통해 새로 users table을 추가해 본다.\n위 Schema에 있는 대로 각 항목별 필드 이름, 타입(int, varchar or datetime) 등을 고르고, varchar 타입인 경우 길이 지정하고. user_registered 항목의 default 값이 0000-00-00 00:00:00으로 되어 있는데 이렇게 하면 에러가 난다.\n구글링해보니 mysql 버전(설정?)에 따라 허용하지 않는 경우가 있다고. 내 경우는 허용하지 않는 상황인 듯. 그래서 그냥 1970-01-01로 변경\n참고로 오른쪽 아래 있는 \u0026ldquo;Preview SQL\u0026rdquo; 을 클릭하면 실제로 수행될 SQL 명령을 볼 수 있다. 이걸 통해 위 php 코드에 있는 SQL 유사한 명령처럼 나오는 지 비교하면 편하다(예를 들면 not null 이나 auto_increment 등은 옵션이 눈에 띄지 않는데 각각 NULL, A.I 선택 버튼을 클릭한 후 SQL 명령을 확인해서 옵션을 제대로 골랐는 지 파악할 수 있다)\n이제 명시적으로 정의해야 하는 필드 들은 모두 추가하고, ID를 primary key로 지정하는 건 알겠는데 나머지 3개 항목 user_login_key, user_nicename, user_email을 KEY형태로 하는 건 어떻게 해야 하는 지 모르겠다. 각 항목별 옵션에 primary key 외에 그냥 key로 지정하는 건 없는 듯한데\u0026hellip; 그래서 추가 검색해 보니 역시나 다른 옵션으로 보였던 INDEX를 사용하는 거 였다.\n나머지 항목들도 모두 추가\nusers table을 생성했으니 이제 실제 사용자 정보를 추가해 본다.\n자 이제 제대로 복구했는지 wordpress admin 페이지에 접속해 보면\n드.디.어.\nDB 망가진 지 몇 달만에 복구하는데 성공했다. 아직 다른 2개 table도 남아있긴 하지만 일단 로그인이 되니 좀 낫겠지.\n백업!\n백업! 백업!\n중요하다. 중요해.\n","id":3,"section":"posts","summary":"말썽쟁이(?) wordpress 블로그가 또 문제를 일으켰다. 이번에도 로그인이 안되는 현상인데 지난 번과는 다른 에러 메시지가 나온다. 즉 지난 번 해결책은 소용이 없을 거라는 불","tags":["wordpress","mysql","troubleshooting","database","recovery"],"title":"WordPress 로그인 불가 문제 해결","uri":"https://cychong47.github.io/2020/05/recover-broken-users-table/","year":"2020"},{"content":"내게 권한이 있다면\n이런 글을 쓴 적이 있었네. 우연히 ghost 블로그에 이전 글들이 2개씩 존재하는 걸 발견해서 중복된 글을 지우는 과정에서 이런 글을 썼다는 걸 알아냈다. 중복 글은 아마도 ghost 버전을 2에서 3으로 올리는 과정이나 복구하는 과정에서 발생한 듯 한데. 그 덕에 각 글들이 실제로 작성된 날짜정보는 사라지고 가장 오래된 글도 2년 전(2018) 정도로 나오는데 실제 내용은 2014년 글도 있다는.\n덕분에 이 글을 언제 썼는 지, 그 당시 어떤 일을 하고 있었는 지는 정확하지 않지만 글을 읽다 보니 어렴풋이 왜 이런 생각을 그때 했는 지 알겠다 싶다. 그간 많은 일이 있었고, 글의 제목에 있는 대로 \u0026lsquo;권한\u0026rsquo;을 갖거나 위임받아 운영한 적이 있었으니 그 결과를 하나씩 따져본 후 각 항목별로 O, X를 구분해 봤다. 관련 업무를 하지 않아 실행(혹은 시도)해 보지 못한 항목은 -로 구분했다. 적어도 정보를 excel로 관리하던 행태는 피한 듯 하다. 나름 자부심을 가지고 있는 건(아무도 알아주지 않지만) 십 수년 전에 시도했던 것과 같이 회사에 wiki를 제대로 활용해서 업무를 진행한 덕에 엑셀 사용을 최소화하고, 관련된 사람들이 쉽게 정보를 공유하고, 찾을 수 있도록 wiki를 기반으로 일을 진행했다. 덕분에 검색이 가능한 CMS 환경을 갖췄지만, 한 가지 아쉬운 점은 페이지 수가 많다보니 실제로 가치가 큰 정보를 찾는 게 쉽지 않았다는 점이다. tag(confluence wiki에서는 label이라고 부르는) 사용을 잘 활용하면 되었을 텐데 이 부분에 대해서는 아쉬움이 남는다.\n그래도 생각보다 O로 생각되는 항목이 많으니 나름 재밌는, 나름 의미있는 일을 했다는 생각이 드네.\n[O] 우선 할 것은 모든 과제의 진행상황을 투명하게 볼 수 있는 시스템만들기\n[O] 엑셀로 관리하고 있는 정보에 대해 최적의 대안을 찾아 엑셀 사용을 최소화 하기\n[O] 파일 서버에 단순히 모으고 있는 자료를 DB화. 적어도 하나의 과제에 관련된 문서를 한눈에 볼 수 있게 하고, 검색이 가능하도록 변경\n[O] File based DB 시스템 대체 방안. 필요하다면 기존 요구사항만 기존 담당자들로부터 받고, 새로운 생각을 가진 사람들에게 대안을 제안하도록\n[-] Code Coverage 100% 같은 비효율적인 업무 없애기\n[O] Inventory 정보 투명화. 어떤 실험 자산을 어떻게 사용하고 있는지, 부서간 공유.\n[O] 분야별 정보 공유할 수 있는 공간 만들고, 정보 공유 독려. 무슨무슨 TF니 WG를 만들기 보다 스스로 정보를 공유하도록 만들기(보다 구체적인 방안 필요)\n메일을 통한 정보 공유 최소화. 메일과 같은 휘발성 매체가 아닌(적어도 사내에서는 휘발성이 높음) CMS에 기록해서 이력 관리가 쉽도록\n[O] 모든 공유 정보는 CMS에 기록(위키 등)\n[-] Unit Test 강화. 불필요한 코드 삭제 유도\n[-] 비현실적이고, 불합리한 무리한 패키지 개발 계획 조정. 1년에 최대 2개만 개발\n[-] SIT단계 이후 진행되는 pre-SIT 같은 바보같은 업무 없앰\n[-] TC 개수 관리 같은 의미없는 숫자기반 관리 지양\n[O] 아침 8시 회의 같은 어이없는 회의 금지\n[-] SE Lab 강화.\n[-] 모 부서와의 전쟁. 미개하고, 무례하고, 개념없는 놈들.\n[O] 비효율적인 문서 작성 기반의 업무 보고 대안 강구.\n[?] 부서 혹은 부문 별 wish list 관리. 각 부서는 제기된 요청사항에 대해 검토 후 선정된 결과에 대해 기능 구현/개선. 단 선정 내용에 대해 필히 공유(그렇지 않으면 의미 있는 것보다는 쉬운 것을 선정할 수 있으므로)\n","id":4,"section":"posts","summary":"내게 권한이 있다면 이런 글을 쓴 적이 있었네. 우연히 ghost 블로그에 이전 글들이 2개씩 존재하는 걸 발견해서 중복된 글을 지우는 과정에서 이런 글을 썼다는 걸 알아냈다. 중","tags":[],"title":"내게 권한이 있다면 - 그 이후","uri":"https://cychong47.github.io/2020/05/if-i-have-authority-5-years-later/","year":"2020"},{"content":"지난 2016년 난생 처음으로 자발적으로 부서를 옮긴 후에 경험한 것들.\n그 전의 십수년간에는 해보지 않은 많은 새로운 경험들을 가질 수 있었다. 주변의 도움 덕에. 특히 날 믿어주는 지인 덕에 이런 새로운 경험을 해 봐서 재밌었다.\n 팀으로 일하기 Agile practice 해보기. Scrum meeting, Daily meeting, 회고 등 재밌게 일하기 의미를 가지며 일하기 의미있는 TF하기 Leading(TF, 파트) 외국 연구소, 사업자 직접 만나서 대화하기 정보를 입수해 가공해서 잘 전달하기 정보를 집중해서 관리하는 사이트 구축하기 사람들 독려하기 주간 리포트를 통해 업무 진행 공유하기 정치 맛 보기(이건 좀 힘들었네) 새로운 분야의 일 - Bearer Processing, OAM, MAC, PHY, 가상화 인프라 구축 - OpenStack, container 상용 솔류션 도입 - DB, Container platform 신기술을 컴파일해서 우리 것에 적용방안 찾기 (가상화 TF) 전화 영어로 일하기 밤 늦은 시간에 사업자마 해외 연구소와 콜하기 전략적으로 판단하기 (무조건 아는 걸 다 이야기하면 안되는) 팀 빌드의 중요성 옆에서 보기 다른 사람 평가하기 회사 평가 시스템 이해(TO는 생각보다 많이 적다, 연봉 캡, 동기부여의 수단은 별로 없다) 아는 것과 남들 특히 다른 생각을 가진 사람들을 설득하는 것이 어떤 지 배우기 영어로 업무하기. 외국 업체나 해외연구소 혹은 외국 인력과 함께 일하기 해외 연구소와 함께 일하기. Wiki등을 이용하여 협업하고, 주간 콜을 통해 업무 상황 공유. 사내 정치 맛 보기  그 전의 십수년간 경험한 것보다 훨씬 많은, 다양한 일들을 짧은 시간 동안 경험한 듯. 덕분에 새로운 사람들도 많이 만날 수 있었고, 이전과 다른 입장에서 일할 수 있는 기회도 가졌다. 그 전에는 SW architecture 측면에서 가장 아래쪽에 가까운 분야를 했다면, 그것보다는 보다 높은 layer의 업무도 해보고, 극단적으로 사업자와 대화를 하는 상당히 높은 게층의 일(계급이 아니라\u0026hellip;)도 해보고, 무형의 결과물을 만들어내는 일도 잠시나마 해 봤다.\n그리고 앞으로는\u0026hellip;?\n","id":5,"section":"posts","summary":"지난 2016년 난생 처음으로 자발적으로 부서를 옮긴 후에 경험한 것들. 그 전의 십수년간에는 해보지 않은 많은 새로운 경험들을 가질 수 있었다. 주변의 도움 덕에. 특","tags":["life"],"title":"새로운 경험 들","uri":"https://cychong47.github.io/2020/05/new-things-in-last-4-years/","year":"2020"},{"content":"리얼하다 조승연\nLunch or Happy Hour 뭔가 약속을 잡아야 할 때 점심 시간 혹은 저녁 업무 종료 후 저녁 식사 시간 전(Happy Hour, 5-7pm) 때 약속을 주로 잡는다고. 그래야 별도 개인 시간 낭비를 안하고, 저녁의 경우 필요하면 저녁 약속 을 핑계로 이야기를 끊을 수 있어서 주로 이렇게 한다고 한다.\n 이메일로 할 수 있는 걸 전화로 하지 않고, 전화로 할 수 있는 걸 만나서 하지 않는다.  뉴욕의 사업자는 대부분 이민자 출신이라 길거리에서 생존을 배워와서 \u0026lsquo;실행해서 결과를 도출해 보기 전까지는 무엇도 알 수 없다\u0026rsquo;고 생각.\n 일을 할 거면 당장 시작해서, 실패를 해도 빠르게 해보고 보완을 하든지 그만두든지 해야지, 일을 시작하기 전에 논의를 길게 하는 것은 쓸데없는 추측을 불러일으켜 추진력만 떨어뜨린다고 생각\n이게 Lean Startup 이라고  군더더기를 빼고 고강도로 업무에 임해 필요한 일을 마친 후 가질 수 있는 그들이 즐기는 Downtime이라는 개념.\n할 때는 하고, 안 할 때는 안 한다 늘 긴장하고 있는 게 아니라 집중해서 해야 할 때는 집중하고, 그렇지 않을 때는 relax.\n우리는 쉴 때 제대로 쉬고 있는가? 그리고 일할 때는 제대로 일하고 있는가?\n어중간한 상태에서 의미없는 피로에 피폭되고 있는 것은 아닌가?\n 뉴욕을 통해 우리가 한 가지 배울 수 있는 것은, 40세가 되건 60세가 되건 새로운 도전을 할 수 있는 무대가 되어주는 사회, 그리고 새로운 도전에 나선 사람에게 단체로 \u0026lsquo;철이나 들라\u0026rsquo;며 끌끌 혀를 차는 대신, 새하얀 스케치북을 들려주며 용기를 북돋아주는 분위기에는 가격을 매길 수 없다는 것이다.\n  He is a New Yorker. He has to earn it\n \u0026lsquo;One little, Two little Three little Indian\u0026rsquo; 송은 아메리카 원주민의 땅을 잔혹하게 빼앗은 커스타드 장군 시대의 것. 죽인 인디안 수를 자랑하는 인종차별적인 내용\n 필드에서 치열한 경쟁을 거쳐 살아남은 뉴요커는 실질적인 사회생활 능력을 정말로 중요시한다는 것 말이다. 이를 가리켜 미국인은 흔히 \u0026lsquo;Life Skills\u0026rsquo;라고 부른다. 인생의 맛과 멋을 스스로 터득하고, 누구 앞에서나 당당하게 자기 주장을 펴며, 자기 시간과 스트레스를 스스로 관리할 수 있고, 자기가 내린 결정의 이유를 알고 그 결과를 예측할 수 있는 사람은 어떤 환경에서도 살아남을 수 있다는 것을 뉴요커는 치열한 20세기를 겪으면서 뼈저리게 터득했다.\n  \u0026lsquo;공부를 시킨다\u0026rsquo;가 아니라 \u0026lsquo;알아서 공부할 줄 알고 험한 세상을 헤쳐나갈 수 있는 영리한 아이를 만든다\u0026rsquo;를 목표로 영유아기에 집중적인 교육 투자를 하기 때문에 이와 관련된 시장의 규모가 엄청나게 크다. 미국인이 \u0026lsquo;discipline\u0026rsquo;이라고 부르는 자기 통제력은 다른 문화에 대한 존중과 더불어 뉴요커 교육 철학의 두 번째 축이다.\n  책에서 머리를 떼지 않고 공부만 하느라 어른이 되었는데도 낯선 곳에서 스스로 길 하나를 찾지 못하고, 새로운 사람과 말을 트지도 못하며, 자기가 먹을 음식조차 스스로 만드지 못하는 어른이 되지 않도록 철저히 훈련을 시키는 것이ㅏㄷ. 앞에서 행복의 지름길은 경제적 자립이라고 말한 것과도 상통한다. 그래서 뉴요커는 부자라고 하더라도 이민자의 마인드를 자녀에게 계승시키려고 하는 것 같다.\n 영화 \u0026lsquo;\u0026rsquo; 중\n I am not going to tell the story the way it happened\nI am going to tell it the way I remember it\n ","id":6,"section":"posts","summary":"리얼하다 조승연 Lunch or Happy Hour 뭔가 약속을 잡아야 할 때 점심 시간 혹은 저녁 업무 종료 후 저녁 식사 시간 전(Happy Hour, 5-7pm) 때 약속을 주로 잡는다고. 그래야 별도 개인 시간 낭","tags":["Book"],"title":"(책) 리얼하다","uri":"https://cychong47.github.io/2019/12/book-so-real/","year":"2019"},{"content":"https://github.com/huangyuzhang/Fizzy-Theme\n오늘 우연히 발견한 ghost theme. 중국 친구가 만든 것 같은데 꽤 괜찮다. 검색 기능에 필요한 Content API key 등만 Site Header에 추가하면 검색 기능을 이용할 수 있고, TOC도 지원이 된다는. 특히 중국 친구가 만든 거라 그런지 한글 검색도 잘 지원된다.\n한 동안 이 테마로 지내면 될 듯.\n","id":7,"section":"posts","summary":"https://github.com/huangyuzhang/Fizzy-Theme 오늘 우연히 발견한 ghost theme. 중국 친구가 만든 것 같은데 꽤 괜찮다. 검색 기능에 필요한 Content API key 등만 Site Header에 추가하면 검색 기능을 이용할 수 있고, TOC도 지원","tags":["ghost-theme"],"title":"Ghost theme 변경 - Fizzy","uri":"https://cychong47.github.io/2019/12/change-ghost-theme-fizzy/","year":"2019"},{"content":"","id":8,"section":"posts","summary":"","tags":[],"title":"Tag Archive","uri":"https://cychong47.github.io/2019/12/tag-archive/","year":"2019"},{"content":"","id":9,"section":"posts","summary":"","tags":[],"title":"Post Archive","uri":"https://cychong47.github.io/2019/12/post-archive/","year":"2019"},{"content":"swap을 사용하지 못하는 kubenertes를 사용해서 ghost pod/container를 구동하니 메모리가 부족하다고 종료되어 버린다.\n확인해 보니 서버로 사용하고 있는 mac mini 2009에 장착된 RAM이 4G였다. 흠\u0026hellip;\n인터넷에서 mac mini 2009의 HW 사양을 찾아 보니 DDR3 1066 MHz라고. 그리고 다른 블로그를 찾아 보니 그 보다 나중에 나온 더 높은 클럭의 RAM을 실장해도 동작하는 데는 문제가 없단다. 다만 지금은 사용하지 않는 DDR3 제품이라 구하는 게 문제일 듯. 하지만 혹시나 하고 예전에 모아둔 메모리 더미를 뒤져보니 딱 맞는 메모리가 있었다. 1066 MHz에 4G짜리 2개. 정말 안성맞춤.\n이제 kubernetes를 이용해서 ghost를 실행하고, docker를 이용해서 mysql과 wordpress를 실행해도 비정상 종료되지 않는다. 하지만 메모리 상황을 보면 간당간당하긴 하네.\n$ free -h total used free shared buff/cache available Mem: 7.5G 2.8G 170M 33M 4.6G 4.5G Swap: 0B 0B 0B  오늘 PC를 교체받은 회사 친구가 받은 노트북에 실장된 메모리가 32G던데 참 격세지감이다.\n저기서 buff/cache가 왜 이렇게 큰 지 좀 확인해 봐야겠다.\n간만에 뜯는 거라(예전에는 항상 ifixit 사이트를 보고 했는데 이젠 예전의 기억을 더듬어가면서 작업하긴 했지만) 그래도 딱 필요한 (블로그 글)[https://centerone.tistory.com/entry/맥미니-메모리램-업그레이드-Mac-mini-Late-2009MC238KHA])을 찾을 수 있어 큰 도움이 되었다.\n","id":10,"section":"posts","summary":"swap을 사용하지 못하는 kubenertes를 사용해서 ghost pod/container를 구동하니 메모리가 부족하다고 종료되어 버린다. 확인해 보니 서버","tags":["Mac mini 2009"],"title":"Mac mini 2009 upgrade","uri":"https://cychong47.github.io/2019/11/mac-mini-2009-upgrade/","year":"2019"},{"content":"중요한 일은\n 생각을 기반으로 함. 기계적으로 대응 불가 소통이 따름. 조직의 일은 혼자 할 수 없으므로 결정이 수반되야 함. 길이 하나가 아닌 까닭 실행이 따름. 결정만으로 결과가 오는 것이 아님  52시간법은 일하는 시간에 제약이 가해지는 것이다. 충분한 시간을 투자해서 결과를 얻어내던 방식에서 달라져야 한다.\n직장 생활에서 반드시 익혀야 할 기술은 \u0026lsquo;생각을 정리하여 말이나 글로 표현하는 기술\u0026rsquo;\n일 때문에 일을 하는 것이 아니라 성과를 위해 일을 하는 것이다.\nWBS(Work Breakdown Structure)\n","id":11,"section":"posts","summary":"중요한 일은 생각을 기반으로 함. 기계적으로 대응 불가 소통이 따름. 조직의 일은 혼자 할 수 없으므로 결정이 수반되야 함. 길이 하나가 아닌 까닭 실행이 따름. 결정만으","tags":["Book"],"title":"사무력","uri":"https://cychong47.github.io/2019/11/samuryeog/","year":"2019"},{"content":" 부제 1. pod가 동작하지 않을때 원인 찾기 부제 2. helm upgrade 명령을 이용하여 업데이트 하기 부제 3. sqlite를 이용해서 ghost.db 직접 수정하기  values.yaml에 명시되어 있는 ghost docker image의 버전 정보를 2.31.0에서 3.0.2 최신 버전으로 업데이트 후 아래 명령어로 업데이트\n$ helm upgrade --debug my-ghost ghost-with-helm [debug] Created tunnel using local port: '45263' [debug] SERVER: \u0026quot;127.0.0.1:45263\u0026quot; REVISION: 6 RELEASED: Tue Nov 5 22:25:19 2019 CHART: ghost-0.1.0 USER-SUPPLIED VALUES: {} COMPUTED VALUES: affinity: {} env: node_env: production url: http://sosa0sa.com:2368 fullnameOverride: \u0026quot;\u0026quot; image: pullPolicy: Always registry: docekr.io repository: ghost tag: 3.0.2  Helm upgrade는 완료되었지만 ghost 블로그가 접속이 되지 않는다. 상태를 확인해 보니\n$ kubectl get pod NAME READY STATUS RESTARTS AGE my-ghost-795c6d674f-jb6t2 0/1 CrashLoopBackOff 4 3m6s sctp-7c94d9b5c9-wsjnd 1/1 Running 2 28d $ kubectl describe pod my-ghost-795c6d674f-jb6t2 ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled \u0026lt;unknown\u0026gt; default-scheduler Successfully assigned default/my-ghost-795c6d674f-jb6t2 to mini1 Normal Started 5m32s (x2 over 6m1s) kubelet, mini1 Started container ghost Warning Unhealthy 5m29s (x2 over 5m59s) kubelet, mini1 Readiness probe failed: Get http://10.244.51.112:2368/: dial tcp 10.244.51.112:2368: connect: connection refused Warning Unhealthy 5m26s (x2 over 5m56s) kubelet, mini1 Liveness probe failed: Get http://10.244.51.112:2368/: dial tcp 10.244.51.112:2368: connect: connection refused Warning Unhealthy 5m9s (x4 over 5m48s) kubelet, mini1 Readiness probe failed: HTTP probe failed with statuscode: 500 Warning Unhealthy 5m6s (x4 over 5m46s) kubelet, mini1 Liveness probe failed: HTTP probe failed with statuscode: 500 Normal Killing 5m6s (x2 over 5m36s) kubelet, mini1 Container ghost failed liveness probe, will be restarted Normal Pulling 5m6s (x3 over 6m6s) kubelet, mini1 Pulling image \u0026quot;ghost:3.0.2\u0026quot; Normal Pulled 5m2s (x3 over 6m2s) kubelet, mini1 Successfully pulled image \u0026quot;ghost:3.0.2\u0026quot; Normal Created 5m2s (x3 over 6m2s) kubelet, mini1 Created container ghost Warning BackOff 63s (x10 over 3m35s) kubelet, mini1 Back-off restarting failed container  my-ghost로 시작하는 pod가 제대로 실행되지 않아 반복해서 재시동 되었지만 제대로 동작하지 않아 결국 실패했다.\nGhost update! 쉽게 될 리가 없지 pod 에서 발생하는 로그를 분석해서 ghost가 제대로 실행되지 않는 이유를 알아보기로 했다. Container의 로그를 인하기 위해 kubectl logs 명령어를 사용한다.\n만일 pod에 여러 개의 container가 있는 경우 pod 명 뒤에 contaienr 명을 지정한다. 자세한 내용은 kubectl logs -h 로 확인해 본다.\n$ kubectl logs my-ghost-795c6d674f-jb6t2 [2019-11-05 13:41:48] ERROR The currently active theme \u0026quot;simply\u0026quot; is invalid. The currently active theme \u0026quot;simply\u0026quot; is invalid. Error ID: 03c2e4b0-ffd2-11e9-9543-b7dca11c112e Details: checkedVersion: 3.x name: simply-godofredoninja path: /var/lib/ghost/content/themes/simply version: 0.1.1 errors: - fatal: true level: error rule: The v0.1 API and \u0026lt;code\u0026gt;ghost.url.api()\u0026lt;/code\u0026gt; JavaScript helper have been removed. details: The v0.1 API \u0026amp; Public API Beta have been removed, along with the \u0026lt;code\u0026gt;public/ghost-sdk.min.js\u0026lt;/code\u0026gt; file \u0026amp; the \u0026lt;code\u0026gt;ghost.url.api()\u0026lt;/code\u0026gt; helper.\u0026lt;br\u0026gt;All code relying on the v0.1 API must be upgraded to use the \u0026lt;a href=\u0026quot;https://ghost.org/faq/upgrades/\u0026quot; target=_blank\u0026gt;new API\u0026lt;/a\u0026gt;. regex: failures: - ref: assets/scripts/main.js code: GS060-JS-GUA ---------------------------------------- ThemeValidationError: The currently active theme \u0026quot;simply\u0026quot; is invalid. at ThemeValidationError.GhostError (/var/lib/ghost/versions/3.0.2/core/server/lib/common/errors.js:10:26) at new ThemeValidationError (/var/lib/ghost/versions/3.0.2/core/server/lib/common/errors.js:40:20) at validationSuccess (/var/lib/ghost/versions/3.0.2/core/frontend/services/themes/index.js:34:48) at tryCatcher (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromise0 (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/promise.js:649:10) at Promise._settlePromises (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/promise.js:729:18) at _drainQueueStep (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/async.js:93:12) at _drainQueue (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/async.js:86:9) at Async._drainQueues (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/async.js:102:5) at Immediate.Async.drainQueues [as _onImmediate] (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/async.js:15:14) at runCallback (timers.js:705:18) at tryOnImmediate (timers.js:676:5) at processImmediate (timers.js:658:5) [2019-11-05 13:41:52] INFO Ghost is running in production... [2019-11-05 13:41:52] INFO Your site is now available on http://sosa0sa.com:2368/ [2019-11-05 13:41:52] INFO Ctrl+C to shut down [2019-11-05 13:41:52] INFO Ghost boot 9.265s [2019-11-05 13:41:53] ERROR \u0026quot;GET /\u0026quot; 500 70ms [error.hbs] Missing helper: \u0026quot;foreach\u0026quot; ---------------------------------------- Error: [error.hbs] Missing helper: \u0026quot;foreach\u0026quot; at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/helper-missing.js:19:13) at eval (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:6:95) at Object.prog [as fn] (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:229:12) at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/if.js:19:22) at Object.eval [as main] (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:20:32) at main (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:176:32) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:179:12) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/compiler.js:526:21) at renderTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:490:13) at render (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:526:5) at renderIt (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:588:18) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:611:11 at parseLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:471:7) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:577:7 at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:565:14 at FSReqWrap.readFileAfterClose [as oncomplete] (internal/fs/read_file_context.js:53:3) [2019-11-05 13:42:00] ERROR \u0026quot;GET /\u0026quot; 500 14ms [error.hbs] Missing helper: \u0026quot;foreach\u0026quot; ---------------------------------------- Error: [error.hbs] Missing helper: \u0026quot;foreach\u0026quot; at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/helper-missing.js:19:13) at eval (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:6:95) at Object.prog [as fn] (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:229:12) at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/if.js:19:22) at Object.eval [as main] (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:20:32) at main (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:176:32) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:179:12) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/compiler.js:526:21) at renderTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:490:13) at render (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:526:5) at renderIt (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:588:18) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:611:11 at parseLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:471:7) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:577:7 at getSourceTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:551:16) at compileFile (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:573:5) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:660:12 at ExpressHbs.loadDefaultLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:296:44) at ExpressHbs.___express (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:648:8) at View.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/view.js:135:8) at tryRender (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/application.js:640:10) at Function.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/application.js:592:3) at ServerResponse.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/response.js:1012:7) at _private.ThemeErrorRenderer (/var/lib/ghost/versions/3.0.2/core/server/web/shared/middlewares/error-handler.js:188:9) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:71:5) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at _private.prepareError (/var/lib/ghost/versions/3.0.2/core/server/web/shared/middlewares/error-handler.js:70:5) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:71:5) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) [2019-11-05 13:42:03] ERROR \u0026quot;GET /\u0026quot; 500 26ms [error.hbs] Missing helper: \u0026quot;foreach\u0026quot; ---------------------------------------- Error: [error.hbs] Missing helper: \u0026quot;foreach\u0026quot; at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/helper-missing.js:19:13) at eval (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:6:95) at Object.prog [as fn] (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:229:12) at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/if.js:19:22) at Object.eval [as main] (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:20:32) at main (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:176:32) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:179:12) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/compiler.js:526:21) at renderTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:490:13) at render (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:526:5) at renderIt (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:588:18) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:611:11 at parseLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:471:7) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:577:7 at getSourceTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:551:16) at compileFile (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:573:5) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:660:12 at ExpressHbs.loadDefaultLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:296:44) at ExpressHbs.___express (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:648:8) at View.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/view.js:135:8) at tryRender (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/application.js:640:10) at Function.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/application.js:592:3) at ServerResponse.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/response.js:1012:7) at _private.ThemeErrorRenderer (/var/lib/ghost/versions/3.0.2/core/server/web/shared/middlewares/error-handler.js:188:9) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:71:5) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at _private.prepareError (/var/lib/ghost/versions/3.0.2/core/server/web/shared/middlewares/error-handler.js:70:5) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:71:5) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) [2019-11-05 13:42:03] WARN Ghost has shut down [2019-11-05 13:42:03] WARN Your site is now offline  에러 로그를 보니 기존에 ghost 2.x에서 사용하던 theme simply 가 ghost 3.0과 호환이 되지 않아서 그런 듯 한다.\nghost theme 파일들은 PV(Persistent Volume)로 마운트 되는 디렉토리에 있는데 문제를 해결할 해결책을 생각해 보면\n theme simply를 수정해서 ghost 3.0과 호환되게 만든다. theme simpy 대신 ghost 3.0과 호횐되는 기본 casper 3.0 theme을 사용한다.  첫번째 옵션은 ghost theme에 대한 연구(?)가 필요해서 보다 쉬운 두 번째 방법으로 시도해 보기로 한다. ghost 3.0과 함께 발표된 기본 theme 인 casper 3.0을 사용하도록 변경하면 되는데 문제는 theme을 변경할 수 있는 화면도 ghost가 정상적으로 실행된 경우에 접근할 수 있는 설정 화면에 있다는 거.\n그렇지만 아마도 ghost가 사용하는 theme 정보가 어딘가 파일에 저장되어 있을 듯 하니 그걸 변경하면 해결할 수 있을 듯 하다.\nghost.db 파일을 직접 수정해서 theme 변경 https://blog.tylerbuchea.com/customizing-ghost/ 그리고 https://www.ghostforbeginners.com/change-ghost-theme-from-command-line/ 를 본 ghost가 동작하는데 사용하는 설정 정보들이 ghost.db에 저장되어 있는 듯 하다. 그리고 sqlite로 저장된 이 파일을 직접 수정할 수 도 있는 듯.\nPV로 마운트하는 ghost의 content/data 디렉토리에 있는 ghost.db 파일을 sqlite 툴로 열어본다. 설정에 관련된 내용은 settings 테이블에 저장된 듯 하다.\n$ sqlite3 ghost.db SQLite version 3.22.0 2018-01-22 18:45:57 Enter \u0026quot;.help\u0026quot; for usage hints. sqlite\u0026gt; .tables actions permissions_apps api_keys permissions_roles app_fields permissions_users app_settings posts apps posts_authors brute posts_meta integrations posts_tags invites roles members roles_users members_stripe_customers sessions members_stripe_customers_subscriptions settings migrations tags migrations_lock users mobiledoc_revisions webhooks permissions sqlite\u0026gt; select * FROM settings; ... 59929168a13f9a00014e67da|title|Another|blog|2016-09-20 14:03:55|1|2017-11-21 14:58:13|1 59929168a13f9a00014e67db|description|Thoughts, stories and ideas.|blog|2016-09-20 14:03:55|1|2017-11-21 14:58:13|1 ...  https://www.ghostforbeginners.com/change-ghost-theme-from-command-line/ 글을 참조하여 현재 사용하고 있는 theme을 가리키는 key인 activeTheme을 찾아보지만 2016 년 글이라 그런지 activeTheme이라는 key는 존재하지 않는다. DB scheme가 변경된 듯 하다. 하지만activeTheme이 아닌 유사한 이름인 active_theme 을 찾을 수 있다.\nsqlite\u0026gt; SELECT * FROM settings where key = 'active_theme'; 59929168a13f9a00014e67eb|active_theme|simply|theme|2017-08-15 06:15:04|1|2019-03-20 14:49:09|1  active_theme 키 값을 확인해 보니 문제가 되는 바로 그 simply임을 확인할 수 있다.\n값 변경은 update 명령을 이용해서 변경할 수 있다. 역시 위 글 참조\nsqlite\u0026gt; update settings set value='casper' where key = 'active_theme'; sqlite\u0026gt; SELECT * FROM settings where key = 'active_theme'; 59929168a13f9a00014e67eb|active_theme|casper|theme|2017-08-15 06:15:04|1|2019-03-20 14:49:09|1  sqlite3 종료는 ctrl + d로.\n이제 다시 pod의 상태를 확인해 보면 정상적으로 pod가 실행되고 있음을 확인할 수 있다.\n$ kubectl get pods NAME READY STATUS RESTARTS AGE my-ghost-795c6d674f-jb6t2 1/1 Running 22 60m sctp-7c94d9b5c9-wsjnd 1/1 Running 2 28d  웹 브라우저로 URL 접속하니 정상적으로 동작한다. 문제 해결\u0026hellip;\n","id":12,"section":"posts","summary":"부제 1. pod가 동작하지 않을때 원인 찾기 부제 2. helm upgrade 명령을 이용하여 업데이트 하기 부제 3. sqlite를 이용해서 ghost.db 직접 수정하기 values.yaml에 명","tags":["ghost","kubernetes","troubleshooting","sqlite"],"title":"Upgrade ghost to v3.0","uri":"https://cychong47.github.io/2019/11/upgrade-ghost-to-v3-0/","year":"2019"},{"content":"helm 명령을 입력했는데 다음과 같은 에러 메시지를 내면서 실행을 거부한다.\n$ helm ls snap-confine has elevated permissions and is not confined but should be. Refusing to continue to avoid permission escalation attacks  에러 메시지를 찾아보니 보안 관련된 내용이 이슈라고 다음과 같이 하면 해결된다.\n$ sudo systemctl enable --now apparmor.service Synchronizing state of apparmor.service with SysV service script with /lib/systemd/systemd-sysv-install. Executing: /lib/systemd/systemd-sysv-install enable apparmor  하지만 이제는 helm의 client와 server 버전이 맞지 않다는 에러\n$ helm ls Error: incompatible versions client[v2.15.1] server[v2.14.3]  해결책은 helm server 버전을 client와 같은 버전으로 변경하면 된다고.\n$ helm init --upgrade $HELM_HOME has been configured at /home/cychong/.helm. Tiller (the Helm server-side component) has been updated to gcr.io/kubernetes-helm/tiller:v2.15.1 .  Reference\n https://github.com/ubuntu/microk8s/issues/249 https://kubernetes.io/docs/tutorials/clusters/apparmor/ Helm: Incompatible versions between client and server  ","id":13,"section":"posts","summary":"helm 명령을 입력했는데 다음과 같은 에러 메시지를 내면서 실행을 거부한다. $ helm ls snap-confine has elevated permissions and is not confined but should be. Refusing to continue to avoid permission escalation attacks 에러 메시지를 찾아보니 보안 관련된 내용","tags":["troubleshooting","helm"],"title":"What if helm command refuse to execute","uri":"https://cychong47.github.io/2019/11/what-if-helm-command-refuses/","year":"2019"},{"content":"mini1 리붓 후 ghost 접속이 안됨.\ndocker를 직접 실행시키는 wordpress는 정상적으로 실행\n그래서 kubectl get svc 명령을 치니 접속이 안된다고.\n$ ps -ef |grep kube cychong 7461 2486 0 23:26 pts/0 00:00:00 grep --color=auto kube $ service kubelet status ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: activating (auto-restart) (Result: exit-code) since Mon 2019-11-04 23:26:47 KST; 5s ago Docs: https://kubernetes.io/docs/home/ Process: 7664 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=255 Main PID: 7664 (code=exited, status=255)  $ journalctl -xeu kubelet Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.418274 8695 server.go:773] Client rotation is on, will bootstrap in background Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.427223 8695 certificate_store.go:129] Loading cert/key pair from \u0026quot;/var/lib/kubelet/pki/kubelet-clien Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.580296 8695 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified. defaulti Nov 04 23:28:32 mini1 kubelet[8695]: F1104 23:28:32.580915 8695 server.go:271] failed to run Kubelet: running with swap on is not supported, please disa Nov 04 23:28:32 mini1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a Nov 04 23:28:32 mini1 systemd[1]: kubelet.service: Failed with result 'exit-code'. Nov 04 23:28:42 mini1 systemd[1]: kubelet.service: Service hold-off time over, scheduling restart. Nov 04 23:28:42 mini1 systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 30. -- Subject: Automatic restarting of a unit has been scheduled -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- Automatic restarting of the unit kubelet.service has been scheduled, as the result for -- the configured Restart= setting for the unit. Nov 04 23:28:42 mini1 systemd[1]: Stopped kubelet: The Kubernetes Node Agent. -- Subject: Unit kubelet.service has finished shutting down -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- Unit kubelet.service has finished shutting down. Nov 04 23:28:42 mini1 systemd[1]: Started kubelet: The Kubernetes Node Agent. -- Subject: Unit kubelet.service has finished start-up -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- Unit kubelet.service has finished starting up. -- -- The start-up result is RESULT. Nov 04 23:28:42 mini1 kubelet[8795]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet's Nov 04 23:28:42 mini1 kubelet[8795]: Flag --resolv-conf has been deprecated, This parameter should be set via the config file specified by the Kubelet's -- Nov 04 23:28:42 mini1 kubelet[8795]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet's Nov 04 23:28:42 mini1 kubelet[8795]: Flag --resolv-conf has been deprecated, This parameter should be set via the config file specified by the Kubelet's -- Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.907863 8795 server.go:410] Version: v1.16.1 Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.908251 8795 plugins.go:100] No cloud provider specified. Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.908283 8795 server.go:773] Client rotation is on, will bootstrap in background Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.917653 8795 certificate_store.go:129] Loading cert/key pair from \u0026quot;/var/lib/kubelet/pki/kubelet-clien Nov 04 23:28:43 mini1 kubelet[8795]: I1104 23:28:43.073234 8795 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified. defaulti Nov 04 23:28:43 mini1 kubelet[8795]: F1104 23:28:43.073886 8795 server.go:271] failed to run Kubelet: running with swap on is not supported, please disa Nov 04 23:28:43 mini1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a Nov 04 23:28:43 mini1 systemd[1]: kubelet.service: Failed with result 'exit-code'. lines 1947-1986/1986 (END)  찾아보니 docker가 정상적으로 실행 중인지 확인해 보라고.\n하지만 정상적으로 동작 중\n$ systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2019-11-04 23:25:40 KST; 7min ago Docs: https://docs.docker.com Main PID: 5285 (dockerd) Tasks: 59 CGroup: /system.slice/docker.service ├─5285 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ├─5586 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 80 -container-ip 172.17.0.3 -container-port 80 └─5598 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8181 -container-ip 172.17.0.4 -container-port 80 Nov 04 23:25:35 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:35.378057010+09:00\u0026quot; level=warning msg=\u0026quot;Your kernel does not support swap memory limit\u0026quot; Nov 04 23:25:35 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:35.378125944+09:00\u0026quot; level=warning msg=\u0026quot;Your kernel does not support cgroup rt period\u0026quot; Nov 04 23:25:35 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:35.378148389+09:00\u0026quot; level=warning msg=\u0026quot;Your kernel does not support cgroup rt runtime\u0026quot; Nov 04 23:25:35 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:35.378414322+09:00\u0026quot; level=info msg=\u0026quot;Loading containers: start.\u0026quot; Nov 04 23:25:36 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:36.163613079+09:00\u0026quot; level=info msg=\u0026quot;Default bridge (docker0) is assigned with an IP address 172 Nov 04 23:25:39 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:39.843337707+09:00\u0026quot; level=info msg=\u0026quot;Loading containers: done.\u0026quot; Nov 04 23:25:40 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:40.046412649+09:00\u0026quot; level=info msg=\u0026quot;Docker daemon\u0026quot; commit=9013bf583a graphdriver(s)=overlay2 ve Nov 04 23:25:40 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:40.047017959+09:00\u0026quot; level=info msg=\u0026quot;Daemon has completed initialization\u0026quot; Nov 04 23:25:40 mini1 dockerd[5285]: time=\u0026quot;2019-11-04T23:25:40.109258901+09:00\u0026quot; level=info msg=\u0026quot;API listen on /var/run/docker.sock\u0026quot; Nov 04 23:25:40 mini1 systemd[1]: Started Docker Application Container Engine.  범인은 아니 문제에 대한 설명은 에러 메시지에 있을 확률이 가장 높으니 위 systemctl status kubelet의 결과를 찬찬히 살펴보니 swap에 대한 내용이 눈에 띈다.\n그래서 바로 해결 시도.\n$ sudo swapoff -a [sudo] password for cychong: cychong@mini1:~$ systemctl status kubelet ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Mon 2019-11-04 23:48:43 KST; 2s ago Docs: https://kubernetes.io/docs/home/ Main PID: 18121 (kubelet) Tasks: 11 (limit: 4306) CGroup: /system.slice/kubelet.service └─18121 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/l Nov 04 23:48:43 mini1 kubelet[18121]: I1104 23:48:43.741976 18121 remote_image.go:50] parsed scheme: \u0026quot;\u0026quot; Nov 04 23:48:43 mini1 kubelet[18121]: I1104 23:48:43.742008 18121 remote_image.go:50] scheme \u0026quot;\u0026quot; not registered, fallback to default scheme Nov 04 23:48:43 mini1 kubelet[18121]: I1104 23:48:43.742038 18121 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/var/run/dockershim.sock Nov 04 23:48:43 mini1 kubelet[18121]: I1104 23:48:43.742058 18121 clientconn.go:577] ClientConn switching balancer to \u0026quot;pick_first\u0026quot; Nov 04 23:48:44 mini1 kubelet[18121]: E1104 23:48:44.424387 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/kubelet.go:459: Failed to list *v1.Node Nov 04 23:48:44 mini1 kubelet[18121]: E1104 23:48:44.428655 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/kubelet.go:450: Failed to list *v1.Serv Nov 04 23:48:44 mini1 kubelet[18121]: E1104 23:48:44.429959 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:46: Failed to list Nov 04 23:48:45 mini1 kubelet[18121]: E1104 23:48:45.425295 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/kubelet.go:459: Failed to list *v1.Node Nov 04 23:48:45 mini1 kubelet[18121]: E1104 23:48:45.429648 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/kubelet.go:450: Failed to list *v1.Serv Nov 04 23:48:45 mini1 kubelet[18121]: E1104 23:48:45.430623 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:46: Failed to list  우연치 않게 회사에서도 비슷한 문제가 있었는데 그것도 swap이 원인이었다는\u0026hellip;\n","id":14,"section":"posts","summary":"mini1 리붓 후 ghost 접속이 안됨. docker를 직접 실행시키는 wordpress는 정상적으로 실행 그래서 kubectl get svc 명령을 치니 접속이 안된다고. $ ps -ef |grep kube cychong 7461 2486 0","tags":["kubernetes","troubleshooting","kubelet"],"title":"kubelet이 실행되지 않을때","uri":"https://cychong47.github.io/2019/11/what-if-kubelet-is-not-started/","year":"2019"},{"content":"Check if SCTP is supported by creating SCTP service https://blog.aweimeow.tw/enable-sctp-in-kubernetes-cluster/\ncychong@mini1:~/work/sctp$ cat service.yaml apiVersion: v1 kind: Service metadata: name: sctp spec: selector: app: sctp ports: - protocol: SCTP port: 9999 targetPort: 30001  cychong@mini1:~/work/sctp$ kubectl create -f service.yaml The Service \u0026quot;sctp\u0026quot; is invalid: spec.ports[0].protocol: Unsupported value: \u0026quot;SCTP\u0026quot;: supported values: \u0026quot;TCP\u0026quot;, \u0026quot;UDP\u0026quot;  Enable SCTP in running kubernetes cluster https://stackoverflow.com/questions/55909512/how-to-configure-already-running-cluster-in-kubernetes\n Basically you must pass this flag to kube-apiserver. How you can do that depends on how you set up the cluster. If you used kubeadm or kubespray then you should edit file /etc/kubernetes/manifests/kube-apiserver.yaml and add this flag somewhere under \u0026ldquo;command\u0026rdquo; field (somewhere between other flags). After that kube-apiserver pod should be restarted automatically. If not - you can kill it by hand.\n Add --feature-gates=SCTPSupport=True to /etc/kubernetes/manifest/kube-apiserver.yaml\n - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key - --feature-gates=SCTPSupport=True image: k8s.gcr.io/kube-apiserver:v1.16.1  Restart kube-apiserver. Just kill it and wait restarted\ncychong@mini1:/etc/kubernetes$ ps -ef |grep kube-api root 21846 21824 9 00:02 ? 00:00:24 kube-apiserver --advertise-address=192.168.1.100 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --feature-gates=SCTPSupport=True cychong 29605 13731 0 00:06 pts/1 00:00:00 grep --color=auto kube-api cychong@mini1:/etc/kubernetes$ sudo kill -SIGHUP 21846 cychong@mini1:/etc/kubernetes$ ps -ef |grep kube-api root 30272 30246 79 00:07 ? 00:00:06 kube-apiserver --advertise-address=192.168.1.100 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --feature-gates=SCTPSupport=True cychong 30644 13731 0 00:07 pts/1 00:00:00 grep --color=auto kube-api  Check if SCTP service is supported cychong@mini1:~/work/sctp$ kubectl create -f service.yaml service/sctp created  Check iptables cychong@mini1:~/work/sctp$ sudo iptables -L -n |grep 9999 REJECT sctp -- 0.0.0.0/0 10.98.74.252 /* default/sctp: has no endpoints */ sctp dpt:9999 reject-with icmp-port-unreachable  Check SCTP by creating sample SCTP-server First delete manullay created service\ncychong@mini1:~/work/sctp$ kubectl delete svc sctp service \u0026quot;sctp\u0026quot; deleted  Install helm chart from https://github.com/aweimeow/sctp-server. This helm chart will deploy a pod which has python based SCTP server.\ncychong@mini1:~/work/sctp$ git clone https://github.com/aweimeow/sctp-server Cloning into 'sctp-server'... remote: Enumerating objects: 17, done. remote: Total 17 (delta 0), reused 0 (delta 0), pack-reused 17 Unpacking objects: 100% (17/17), done. cychong@mini1:~/work/sctp$ helm install -n sctp sctp-server NAME: sctp LAST DEPLOYED: Tue Oct 8 00:12:01 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Deployment NAME READY UP-TO-DATE AVAILABLE AGE sctp 0/1 0 0 3s ==\u0026gt; v1/Namespace NAME STATUS AGE sctp Active 4s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE sctp-7c94d9b5c9-wsjnd 0/1 Pending 0 1s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE sctp NodePort 10.108.218.164 \u0026lt;none\u0026gt; 9999:30001/SCTP 4s NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026quot;{.spec.ports[0].nodePort}\u0026quot; services sctp) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026quot;{.items[0].status.addresses[0].address}\u0026quot;) echo http://$NODE_IP:$NODE_PORT  Check the pod and service\ncychong@mini1:~/work/sctp$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 29d my-ghost NodePort 10.105.125.54 192.168.1.100 2368:32326/TCP 11d sctp NodePort 10.108.218.164 \u0026lt;none\u0026gt; 9999:30001/SCTP 2m42s cychong@mini1:~/work/sctp$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES my-ghost-5f6578fd76-lb7xc 1/1 Running 41 11d 10.244.51.82 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; sctp-7c94d9b5c9-wsjnd 1/1 Running 0 2m55s 10.244.51.90 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;  From the host, check if SCTP server is reachable from the host\ncychong@mini1:~/work/sctp$ ncat --sctp mini1 30001 Howdy! What's your name? Memphis Ncat: Connection reset by peer. cychong@mini1:~/work/sctp$  TODO - client in Pod and server in outside cluster Reference  Enabled SCTP in Kubernetes Cluster - aweimeow SCTP-server docker image - aweimeow Python sctp module - server side SCTP-server Helm Chart - aweimeow SCTP support in Openshift maybe be from 4.3 https://discuss.kubernetes.io/t/sctp-support-for-version-1-12-1/3203/8  ","id":15,"section":"posts","summary":"Check if SCTP is supported by creating SCTP service https://blog.aweimeow.tw/enable-sctp-in-kubernetes-cluster/\ncychong@mini1:~/work/sctp$ cat service.yaml apiVersion: v1 kind: Service metadata: name: sctp spec: selector: app: sctp ports: - protocol: SCTP port: 9999 targetPort: 30001  cychong@mini1:~/work/sctp$ kubectl create -f service.yaml The Service \u0026quot;sctp\u0026quot; is invalid: spec.ports[0].protocol: Unsupported value: \u0026quot;SCTP\u0026quot;: supported values: \u0026quot;TCP\u0026quot;, \u0026quot;UDP\u0026quot;  Enable SCTP in running kubernetes cluster https://stackoverflow.com/questions/55909512/how-to-configure-already-running-cluster-in-kubernetes\n Basically you must pass this flag to kube-apiserver. How you can do that depends on how you set up the cluster.","tags":["kubernetes","sctp"],"title":"Enable SCTP in kubernetes","uri":"https://cychong47.github.io/2019/10/enable-sctp-in-kubernetes/","year":"2019"},{"content":"cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update [sudo] password for cychong: Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease Hit:5 http://dl.google.com/linux/chrome/deb stable Release Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB] Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [254 kB] Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 48x48 Icons [197 kB] Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 64x64 Icons [453 kB] Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2468 B] Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [7916 B] Get:18 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [526 kB] Get:19 http://archive.ubuntu.com/ubuntu bionic-security/main Translation-en [176 kB] Get:20 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [38.5 kB] Get:21 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 48x48 Icons [17.6 kB] Get:22 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 64x64 Icons [41.5 kB] Get:23 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [611 kB] Get:24 http://archive.ubuntu.com/ubuntu bionic-security/universe Translation-en [203 kB] Get:25 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [42.2 kB] Get:26 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 48x48 Icons [16.4 kB] Get:27 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 64x64 Icons [111 kB] Get:28 http://archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2464 B] Fetched 3467 kB in 27s (128 kB/s) Reading package lists... Done Building dependency tree Reading state information... Done 41 packages can be upgraded. Run 'apt list --upgradable' to see them. cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-cache policy kubeadm kubeadm: Installed: 1.15.3-00 Candidate: 1.16.1-00  cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-get install -y kubeadm=1.16.1-00 \u0026amp;\u0026amp; sudo apt-mark hold kubeadm Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: libllvm7 Use 'sudo apt autoremove' to remove it. The following packages will be upgraded: kubeadm 1 upgraded, 0 newly installed, 0 to remove and 40 not upgraded. Need to get 8764 kB of archives. After this operation, 4062 kB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.16.1-00 [8764 kB] Fetched 8764 kB in 6s (1489 kB/s) (Reading database ... 237550 files and directories currently installed.) Preparing to unpack .../kubeadm_1.16.1-00_amd64.deb ... Unpacking kubeadm (1.16.1-00) over (1.15.3-00) ... Setting up kubeadm (1.16.1-00) ... kubeadm set on hold. cychong@mini1:~/work/ghost-with-helm-x$ kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;16\u0026quot;, GitVersion:\u0026quot;v1.16.1\u0026quot;, GitCommit:\u0026quot;d647ddbd755faf07169599a625faf302ffc34458\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2019-10-02T16:58:27Z\u0026quot;, GoVersion:\u0026quot;go1.12.10\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade plan [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/versions] Latest stable version: v1.16.1 [upgrade/versions] Latest version in the v1.15 series: v1.15.4 Components that must be upgraded manually after you have upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.15.4 Upgrade to the latest version in the v1.15 series: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.15.4 Controller Manager v1.15.3 v1.15.4 Scheduler v1.15.3 v1.15.4 Kube Proxy v1.15.3 v1.15.4 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.10 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.15.4 _____________________________________________________________________ Components that must be upgraded manually after you have upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.16.1 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.16.1 Controller Manager v1.15.3 v1.16.1 Scheduler v1.15.3 v1.16.1 Kube Proxy v1.15.3 v1.16.1 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.15-0 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.16.1 _____________________________________________________________________  failed cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade apply v1.16.1 [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to \u0026quot;v1.16.1\u0026quot; [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-scheduler. [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [upgrade/prepull] Failed prepulled the images for the control plane components error: the prepull operation timed out To see the stack trace of this error execute with --v=5 or higher  retry cychong@mini1:~$ sudo kubeadm upgrade apply v1.16.1 [sudo] password for cychong: [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to \u0026quot;v1.16.1\u0026quot; [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [upgrade/prepull] Prepulling image for component kube-apiserver. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026quot;v1.16.1\u0026quot;... Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 [upgrade/etcd] Upgrading to TLS for etcd Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa [upgrade/staticpods] Preparing for \u0026quot;etcd\u0026quot; upgrade [upgrade/staticpods] Renewing etcd-server certificate [upgrade/staticpods] Renewing etcd-peer certificate [upgrade/staticpods] Renewing etcd-healthcheck-client certificate [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/etcd.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/etcd.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: d96090bab45a5dababb3c3015960926b [apiclient] Found 1 Pods for label selector component=etcd [upgrade/staticpods] Component \u0026quot;etcd\u0026quot; upgraded successfully! [upgrade/etcd] Waiting for etcd to become available [upgrade/staticpods] Writing new Static Pod manifests to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests306281752\u0026quot; [upgrade/staticpods] Preparing for \u0026quot;kube-apiserver\u0026quot; upgrade [upgrade/staticpods] Renewing apiserver certificate [upgrade/staticpods] Renewing apiserver-kubelet-client certificate [upgrade/staticpods] Renewing front-proxy-client certificate [upgrade/staticpods] Renewing apiserver-etcd-client certificate [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-apiserver.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-apiserver-mini1 hash: 01800dd11dfbda441372caf7cbf8aa39 [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component \u0026quot;kube-apiserver\u0026quot; upgraded successfully! [upgrade/staticpods] Preparing for \u0026quot;kube-controller-manager\u0026quot; upgrade [upgrade/staticpods] Renewing controller-manager.conf certificate [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-controller-manager.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-controller-manager-mini1 hash: e12d193633dcf11f6095d89ee58c45a9 [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component \u0026quot;kube-controller-manager\u0026quot; upgraded successfully! [upgrade/staticpods] Preparing for \u0026quot;kube-scheduler\u0026quot; upgrade [upgrade/staticpods] Renewing scheduler.conf certificate [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-scheduler.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 Static pod: kube-scheduler-mini1 hash: bf9014e67294b0df0bc373fd7024ced7 [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component \u0026quot;kube-scheduler\u0026quot; upgraded successfully! [upload-config] Storing the configuration used in ConfigMap \u0026quot;kubeadm-config\u0026quot; in the \u0026quot;kube-system\u0026quot; Namespace [kubelet] Creating a ConfigMap \u0026quot;kubelet-config-1.16\u0026quot; in namespace kube-system with the configuration for the kubelets in the cluster [kubelet-start] Downloading configuration for the kubelet from the \u0026quot;kubelet-config-1.16\u0026quot; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \u0026quot;/var/lib/kubelet/config.yaml\u0026quot; [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026quot;v1.16.1\u0026quot;. Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven't already done so.  Upgrade calico from v3.8 to v3.9 kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml configmap/calico-config unchanged customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node configured clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node configured serviceaccount/calico-node unchanged deployment.apps/calico-kube-controllers configured serviceaccount/calico-kube-controllers unchanged  앗. 서브넷 변경하는 걸 깜빡\ncychong@mini1:~$ wget https://docs.projectcalico.org/v3.9/manifests/calico.yaml --2019-10-07 23:49:13-- https://docs.projectcalico.org/v3.9/manifests/calico.yaml Resolving docs.projectcalico.org (docs.projectcalico.org)... 104.248.78.23, 2604:a880:2:d0::21e9:b001 Connecting to docs.projectcalico.org (docs.projectcalico.org)|104.248.78.23|:443... connected. HTTP request sent, awaiting response... v200 OK Length: 20648 (20K) [application/x-yaml] Saving to: ‘calico.yaml’ calico.yaml 0%[ ] 0 --.-KB/s icalico.yaml 100%[=============================================================\u0026gt;] 20.16K 123KB/s in 0.2s c2019-10-07 23:49:14 (123 KB/s) - ‘calico.yaml’ saved [20648/20648]  Change CALICO_IPV4POOL_CIDR\n- name: CALICO_IPV4POOL_CIDR value: \u0026quot;10.201.0.0/24\u0026quot;  Upgrade kubelet and kubectl cychong@mini1:~$ sudo apt-mark unhold kubelet kubectl \u0026amp;\u0026amp; sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y kubelet=1.16.1-00 kubectl=1.16.1-00 \u0026amp;\u0026amp; sudo apt-mark hold kubelet kubectl Canceled hold on kubelet. Canceled hold on kubectl. Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://dl.google.com/linux/chrome/deb stable Release Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:5 https://download.docker.com/linux/ubuntu bionic InRelease Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Hit:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Hit:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease Reading package lists... Done Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: libllvm7 Use 'sudo apt autoremove' to remove it. The following packages will be upgraded: kubectl kubelet 2 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. Need to get 29.9 MB of archives. After this operation, 7179 kB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.16.1-00 [9234 kB] Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.16.1-00 [20.7 MB] Fetched 29.9 MB in 6s (4899 kB/s) (Reading database ... 237550 files and directories currently installed.) Preparing to unpack .../kubectl_1.16.1-00_amd64.deb ... Unpacking kubectl (1.16.1-00) over (1.15.3-00) ... Preparing to unpack .../kubelet_1.16.1-00_amd64.deb ... Unpacking kubelet (1.16.1-00) over (1.15.3-00) ... Setting up kubelet (1.16.1-00) ... Setting up kubectl (1.16.1-00) ... kubelet set on hold. kubectl set on hold.  cychong@mini1:~$ sudo systemctl restart kubelet cychong@mini1:~$  Check the status cychong@mini1:~$ kubectl get nodes NAME STATUS ROLES AGE VERSION mini1 Ready master 29d v1.16.1  Reference\n https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/  ","id":16,"section":"posts","summary":"cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update [sudo] password for cychong: Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease Hit:5 http://dl.google.com/linux/chrome/deb stable Release Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB]","tags":["kubernetes"],"title":"Upgrade kubernetes","uri":"https://cychong47.github.io/2019/10/upgrade-kubernetes/","year":"2019"},{"content":"하나의 Helm chart를 이용하여 여러 개의 pod를 설치 하는 nested chart 인 경우 각각의 pod에 대한 CPU requirement는 각 subchart의 values.yaml에 resources 항목에 기술하면 된다.\n아래는 ONAP중 closed loop control에서 Data collection을 담당하는 DCAE의 SW들을 kubernets에 배포하기 위해 만들어진 차트들이다. 다음과 같이 8개의 chart들로 구성되어 있고,\n$ tree -d oom/kubernetes/dcaegen2/charts/ -L 1 oom/kubernetes/dcaegen2/charts/ ├── dcae-bootstrap ├── dcae-cloudify-manager ├── dcae-config-binding-service ├── dcae-deployment-handler ├── dcae-healthcheck ├── dcae-policy-handler ├── dcae-redis └── dcae-servicechange-handler 8 directories  각각의 subchart는 각자의 values.yaml 파일을 가지고 있다.\ncychong@mini1:~/work/oom/kubernetes/dcaegen2$ find . -name values.yaml ./charts/dcae-redis/values.yaml ./charts/dcae-deployment-handler/values.yaml ./charts/dcae-servicechange-handler/charts/dcae-inventory-api/values.yaml ./charts/dcae-servicechange-handler/values.yaml ./charts/dcae-policy-handler/values.yaml ./charts/dcae-healthcheck/values.yaml ./charts/dcae-config-binding-service/values.yaml ./charts/dcae-bootstrap/values.yaml ./charts/dcae-cloudify-manager/values.yaml ./values.yaml  dcae-redis chart의 values.yaml 파일을 보면 다음과 같이 CPU, memory에 대한 요구사항을 기술하고 있다.\n# Resource Limit flavor -By Default using small flavor: small # Segregation for Different environment (Small and Large) resources: small: limits: cpu: 2 memory: 2Gi requests: cpu: 1 memory: 1Gi large: limits: cpu: 4 memory: 4Gi requests: cpu: 2 memory: 2Gi unlimited: {}  ","id":17,"section":"posts","summary":"하나의 Helm chart를 이용하여 여러 개의 pod를 설치 하는 nested chart 인 경우 각각의 pod에 대한 CPU requirement는 각 subchart의 values.","tags":["helm","nested-chart","subchart","resources","cpu"],"title":"Convention on impose core requirements","uri":"https://cychong47.github.io/2019/09/convention-on-impose-core-requirements/","year":"2019"},{"content":"multipass?  Multipass is a lightweight VM manager for Linux, Windows and macOS. It\u0026rsquo;s designed for developers who want a fresh Ubuntu environment with a single command. It uses KVM on Linux, Hyper-V on Windows and HyperKit on macOS to run the VM with minimal overhead. It can also use VirtualBox on Windows and macOS. Multipass will fetch images for you and keep them up to date.\nSince it supports metadata for cloud-init, you can simulate a small cloud deployment on your laptop or workstation.\n https://github.com/CanonicalLtd/multipass\nLinux 외에 Windows 그리고 Mac OS를 지원하는 multipass를 사용하면 virtualbox를 사용하지 않고도 OS X에서 VM을 쉽게 만들어 linux 기반의 환경을 구성할 수 있다.\n아래 예에서는 OS X에서 multipass를 이용해서 Linux(Ubuntu) VM을 생성하고, kubernetes를 설치해 본다.\ninstall multipass with brew mbpr15:~ cychong$ brew cask install multipass Updating Homebrew... ... ==\u0026gt; Satisfying dependencies ==\u0026gt; Downloading https://github.com/CanonicalLtd/multipass/releases/download/v0.8.0/multipass-0.8.0+mac-Darwin.pkg ==\u0026gt; Downloading from https://github-production-release-asset-2e65be.s3.amazonaws.com/114128199/8489a680-ac9c-11e9-99 ######################################################################## 100.0% ==\u0026gt; Verifying SHA-256 checksum for Cask 'multipass'. ==\u0026gt; Installing Cask multipass ==\u0026gt; Running installer for multipass; your password may be necessary. ==\u0026gt; Package installers may write to any location; options such as --appdir are ignored. Password: installer: Package name is multipass installer: Installing at base path / installer: The install was successful. 🍺 multipass was successfully installed!  Multipass multipass find mbpr15:~ cychong$ multipass find Image Aliases Version Description snapcraft:core core16 20190819 Snapcraft builder for Core 16 snapcraft:core18 20190820 Snapcraft builder for Core 18 16.04 xenial 20190814 Ubuntu 16.04 LTS 18.04 bionic,lts 20190813.1 Ubuntu 18.04 LTS  Create VM multipass launch mbpr15:~ cychong$ multipass launch --name vm --mem 4G --disk 20G --cpus 2 Launched: vm  list VMs mbpr15:~ cychong$ multipass list Name State IPv4 Image vm Running 192.168.64.2 Ubuntu 18.04 LTS  execute command in VM from host mbpr15:~ cychong$ multipass exec vm -- uname -a Linux vm 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux  login to VM mbpr15:~ cychong$ multipass shell vm Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-58-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Sun Aug 25 20:26:01 KST 2019 System load: 0.0 Processes: 101 Usage of /: 5.1% of 19.21GB Users logged in: 0 Memory usage: 3% IP address for enp0s2: 192.168.64.2 Swap usage: 0% 0 packages can be updated. 0 updates are security updates. To run a command as administrator (user \u0026quot;root\u0026quot;), use \u0026quot;sudo \u0026lt;command\u0026gt;\u0026quot;. See \u0026quot;man sudo_root\u0026quot; for details. multipass@vm:~$  Setup a single node kubernetes cluster multipass@vm:~$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - OK  multipass@vm:~$ sudo add-apt-repository \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026quot; Get:1 https://download.docker.com/linux/ubuntu bionic InRelease [64.4 kB] Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:5 https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages [7889 B] Get:6 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [485 kB] Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [8570 kB] Get:9 http://security.ubuntu.com/ubuntu bionic-security/main Translation-en [165 kB] Get:10 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [4976 B] Get:11 http://security.ubuntu.com/ubuntu bionic-security/restricted Translation-en [2476 B] Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [598 kB] Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe Translation-en [199 kB] Get:14 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [4004 B] Get:15 http://security.ubuntu.com/ubuntu bionic-security/multiverse Translation-en [2060 B] Get:16 http://archive.ubuntu.com/ubuntu bionic/universe Translation-en [4941 kB] Get:17 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [151 kB] Get:18 http://archive.ubuntu.com/ubuntu bionic/multiverse Translation-en [108 kB] Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [712 kB] Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main Translation-en [259 kB] Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [11.9 kB] Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted Translation-en [4156 B] Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [999 kB] Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe Translation-en [306 kB] Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [6636 B] Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse Translation-en [3556 B] Get:27 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [2512 B] Get:28 http://archive.ubuntu.com/ubuntu bionic-backports/main Translation-en [1644 B] Get:29 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [4000 B] Get:30 http://archive.ubuntu.com/ubuntu bionic-backports/universe Translation-en [1856 B] Preparing to unpack .../1-aufs-tools_1%3a4.9+20170918-1ubuntu1_amd64.deb ... Unpacking aufs-tools (1:4.9+20170918-1ubuntu1) ... Selecting previously unselected package cgroupfs-mount. Preparing to unpack .../2-cgroupfs-mount_1.4_all.deb ... Unpacking cgroupfs-mount (1.4) ... Selecting previously unselected package containerd.io. Preparing to unpack .../3-containerd.io_1.2.6-3_amd64.deb ... Unpacking containerd.io (1.2.6-3) ... Selecting previously unselected package docker-ce-cli. Preparing to unpack .../4-docker-ce-cli_5%3a19.03.1~3-0~ubuntu-bionic_amd64.deb ... Unpacking docker-ce-cli (5:19.03.1~3-0~ubuntu-bionic) ... Selecting previously unselected package docker-ce. Preparing to unpack .../5-docker-ce_5%3a19.03.1~3-0~ubuntu-bionic_amd64.deb ... Unpacking docker-ce (5:19.03.1~3-0~ubuntu-bionic) ... Selecting previously unselected package libltdl7:amd64. Preparing to unpack .../6-libltdl7_2.4.6-2_amd64.deb ... Unpacking libltdl7:amd64 (2.4.6-2) ... Setting up aufs-tools (1:4.9+20170918-1ubuntu1) ... Setting up containerd.io (1.2.6-3) ... Created symlink /etc/systemd/system/multi-user.target.wants/containerd.service → /lib/systemd/system/containerd.service. Processing triggers for ureadahead (0.100.0-21) ... Setting up cgroupfs-mount (1.4) ... Processing triggers for libc-bin (2.27-3ubuntu1) ... Processing triggers for systemd (237-3ubuntu10.25) ... Setting up libltdl7:amd64 (2.4.6-2) ... Processing triggers for man-db (2.8.3-2ubuntu0.1) ... Setting up docker-ce-cli (5:19.03.1~3-0~ubuntu-bionic) ... Setting up pigz (2.4-1) ... Setting up docker-ce (5:19.03.1~3-0~ubuntu-bionic) ... Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /lib/systemd/system/docker.service. Created symlink /etc/systemd/system/sockets.target.wants/docker.socket → /lib/systemd/system/docker.socket. Processing triggers for ureadahead (0.100.0-21) ... Processing triggers for libc-bin (2.27-3ubuntu1) ... Processing triggers for systemd (237-3ubuntu10.25) ...  multipass@vm:~$ sudo swapoff -a multipass@vm:~$ sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab  multipass@vm:~$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https \u0026amp;\u0026amp; curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:3 https://download.docker.com/linux/ubuntu bionic InRelease Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Reading package lists... Done Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: grub-pc-bin Use 'sudo apt autoremove' to remove it. The following NEW packages will be installed: apt-transport-https 0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded. Need to get 1692 B of archives. After this operation, 153 kB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 apt-transport-https all 1.6.11 [1692 B] Fetched 1692 B in 1s (2906 B/s) Selecting previously unselected package apt-transport-https. (Reading database ... 60304 files and directories currently installed.) Preparing to unpack .../apt-transport-https_1.6.11_all.deb ... Unpacking apt-transport-https (1.6.11) ... Setting up apt-transport-https (1.6.11) ... OK  multipass@vm:~$ echo \u0026quot;deb http://apt.kubernetes.io/ kubernetes-xenial main\u0026quot; | sudo tee -a /etc/apt/sources.list.d/kubernetes.list \u0026amp;\u0026amp; sudo apt-get update deb http://apt.kubernetes.io/ kubernetes-xenial main Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:3 https://download.docker.com/linux/ubuntu bionic InRelease Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Get:6 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [8993 B] Get:7 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [28.9 kB] Fetched 37.9 kB in 2s (15.3 kB/s) Reading package lists... Done  multipass@vm:~$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https \u0026amp;\u0026amp; curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:3 https://download.docker.com/linux/ubuntu bionic InRelease Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Reading package lists... Done Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: grub-pc-bin Use 'sudo apt autoremove' to remove it. The following NEW packages will be installed: apt-transport-https 0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded. Need to get 1692 B of archives. After this operation, 153 kB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 apt-transport-https all 1.6.11 [1692 B] Fetched 1692 B in 1s (2906 B/s) Selecting previously unselected package apt-transport-https. (Reading database ... 60304 files and directories currently installed.) Preparing to unpack .../apt-transport-https_1.6.11_all.deb ... Unpacking apt-transport-https (1.6.11) ... Get:3 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.15.3-00 [20.2 MB] Get:4 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.15.3-00 [8763 kB] Get:5 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.15.3-00 [8248 kB] Fetched 52.9 MB in 27s (1972 kB/s) Selecting previously unselected package conntrack. (Reading database ... 60308 files and directories currently installed.) Preparing to unpack .../0-conntrack_1%3a1.4.4+snapshot20161117-6ubuntu2_amd64.deb ... Unpacking conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ... Selecting previously unselected package cri-tools. Preparing to unpack .../1-cri-tools_1.13.0-00_amd64.deb ... Unpacking cri-tools (1.13.0-00) ... Selecting previously unselected package kubernetes-cni. Preparing to unpack .../2-kubernetes-cni_0.7.5-00_amd64.deb ... Unpacking kubernetes-cni (0.7.5-00) ... Selecting previously unselected package socat. Preparing to unpack .../3-socat_1.7.3.2-2ubuntu2_amd64.deb ... Unpacking socat (1.7.3.2-2ubuntu2) ... Selecting previously unselected package kubelet. Preparing to unpack .../4-kubelet_1.15.3-00_amd64.deb ... Unpacking kubelet (1.15.3-00) ... Selecting previously unselected package kubectl. Preparing to unpack .../5-kubectl_1.15.3-00_amd64.deb ... Unpacking kubectl (1.15.3-00) ... Selecting previously unselected package kubeadm. Preparing to unpack .../6-kubeadm_1.15.3-00_amd64.deb ... Unpacking kubeadm (1.15.3-00) ... Setting up conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ... Setting up kubernetes-cni (0.7.5-00) ... Setting up cri-tools (1.13.0-00) ... Setting up socat (1.7.3.2-2ubuntu2) ... Setting up kubelet (1.15.3-00) ... Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service. Setting up kubectl (1.15.3-00) ... Processing triggers for man-db (2.8.3-2ubuntu0.1) ... Setting up kubeadm (1.15.3-00) ...  multipass@vm:~$ sudo kubeadm init --pod-network-cidr=10.201.0.0/24 --token-ttl 0 ... multipass@vm:~$ mkdir -p $HOME/.kube multipass@vm:~$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config multipass@vm:~$ sudo chown $(id -u):$(id -g) $HOME/.kube/config  multipass@vm:~$ kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5c98db65d4-ksh4p 0/1 Pending 0 21m \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-nvvzg 0/1 Pending 0 21m \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-vm 1/1 Running 0 20m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-vm 1/1 Running 0 20m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-vm 1/1 Running 0 20m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-b8qf2 1/1 Running 0 21m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-vm 1/1 Running 0 20m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;  install calico multipass@vm:~$ wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml --2019-08-25 21:26:00-- https://docs.projectcalico.org/v3.8/manifests/calico.yaml Resolving docs.projectcalico.org (docs.projectcalico.org)... 206.189.73.52, 2604:a880:2:d0::21e9:c001 Connecting to docs.projectcalico.org (docs.projectcalico.org)|206.189.73.52|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20628 (20K) [application/x-yaml] Saving to: ‘calico.yaml’ calico.yaml 100%[==============================================\u0026gt;] 20.14K 93.2KB/s in 0.2s 2019-08-25 21:26:02 (93.2 KB/s) - ‘calico.yaml’ saved [20628/20628]  Change CALICO_IPV4POOL_CIDR\n - name: CALICO_IPV4POOL_CIDR value: \u0026quot;10.201.0.0/24\u0026quot;  multipass@vm:~$ kubectl apply -f calico.yaml configmap/calico-config unchanged customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node configured serviceaccount/calico-node unchanged deployment.apps/calico-kube-controllers unchanged serviceaccount/calico-kube-controllers unchanged  multipass@vm:~$ kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system calico-kube-controllers-65b8787765-5rftm 1/1 Running 0 3m57s 192.168.141.65 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system calico-node-dtbhl 1/1 Running 0 44s 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-ksh4p 1/1 Running 0 25m 192.168.141.66 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-nvvzg 1/1 Running 0 25m 192.168.141.67 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-vm 1/1 Running 0 24m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-vm 1/1 Running 0 24m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-vm 1/1 Running 0 24m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-b8qf2 1/1 Running 0 25m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-vm 1/1 Running 0 25m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;  multipass@vm:~$ kubectl taint nodes --all node-role.kubernetes.io/master- node/vm untainted  Install calicoctl https://docs.projectcalico.org/v3.5/usage/calicoctl/install\nmultipass@vm:~$ curl -O -L https://github.com/projectcalico/calicoctl/releases/download/v3.5.8/calicoctl multipass@vm:~$ chmod +x calicoctl multipass@vm:~$ ./calicoctl get profiles Failed to create Calico API client: no etcd endpoints specified multipass@vm:~$ kubectl apply -f \\ \u0026gt; https://docs.projectcalico.org/v3.5/getting-started/kubernetes/installation/hosted/calicoctl.yaml pod/calicoctl created multipass@vm:~$ kubectl exec -ti -n kube-system calicoctl -- /calicoctl get profiles -o wide error: unable to upgrade connection: container not found (\u0026quot;calicoctl\u0026quot;)  multipass@vm:~$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-65b8787765-5rftm 1/1 Running 0 10m kube-system calico-node-dtbhl 1/1 Running 0 7m46s kube-system calicoctl 0/1 CreateContainerConfigError 0 38s kube-system coredns-5c98db65d4-ksh4p 1/1 Running 0 33m kube-system coredns-5c98db65d4-nvvzg 1/1 Running 0 33m kube-system etcd-vm 1/1 Running 0 32m kube-system kube-apiserver-vm 1/1 Running 0 31m kube-system kube-controller-manager-vm 1/1 Running 0 31m kube-system kube-proxy-b8qf2 1/1 Running 0 33m kube-system kube-scheduler-vm 1/1 Running 0 32m  multipass@vm:~$ kubectl describe pod calicoctl --namespace=kube-system Name: calicoctl Namespace: kube-system Priority: 0 Node: vm/192.168.64.2 Start Time: Sun, 25 Aug 2019 21:35:02 +0900 Labels: \u0026lt;none\u0026gt; Annotations: kubectl.kubernetes.io/last-applied-configuration: {\u0026quot;apiVersion\u0026quot;:\u0026quot;v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Pod\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;calicoctl\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;kube-system\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;containers\u0026quot;:[{\u0026quot;command... Status: Pending IP: 192.168.64.2 Containers: calicoctl: Container ID: Image: calico/ctl:v3.5.8 Image ID: Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; Command: /bin/sh -c while true; do sleep 3600; done State: Waiting Reason: CreateContainerConfigError Ready: False Restart Count: 0 Environment: ETCD_ENDPOINTS: \u0026lt;set to the key 'etcd_endpoints' of config map 'calico-config'\u0026gt; Optional: false Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-w2l7q (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: default-token-w2l7q: Type: Secret (a volume populated by a Secret) SecretName: default-token-w2l7q Optional: false QoS Class: BestEffort Node-Selectors: beta.kubernetes.io/os=linux Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 72s default-scheduler Successfully assigned kube-system/calicoctl to vm Normal Pulling 71s kubelet, vm Pulling image \u0026quot;calico/ctl:v3.5.8\u0026quot; Normal Pulled 57s kubelet, vm Successfully pulled image \u0026quot;calico/ctl:v3.5.8\u0026quot; Warning Failed 3s (x6 over 57s) kubelet, vm Error: Couldn't find key etcd_endpoints in ConfigMap kube-system/calico-config Normal Pulled 3s (x5 over 57s) kubelet, vm Container image \u0026quot;calico/ctl:v3.5.8\u0026quot; already present on machine  delete kubenetes cluster multipass@vm:~$ kubectl drain vm --delete-local-data --force --ignore-daemonsets node/vm cordoned WARNING: ignoring DaemonSet-managed Pods: kube-system/calico-node-dtbhl, kube-system/kube-proxy-b8qf2; deleting Pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet: kube-system/calicoctl evicting pod \u0026quot;coredns-5c98db65d4-nvvzg\u0026quot; evicting pod \u0026quot;calico-kube-controllers-65b8787765-5rftm\u0026quot; evicting pod \u0026quot;calicoctl\u0026quot; evicting pod \u0026quot;coredns-5c98db65d4-ksh4p\u0026quot; pod/calicoctl evicted pod/coredns-5c98db65d4-nvvzg evicted pod/calico-kube-controllers-65b8787765-5rftm evicted pod/coredns-5c98db65d4-ksh4p evicted node/vm evicted multipass@vm:~$ sudo kubeadm reset [reset] Reading configuration from the cluster... [reset] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [reset] WARNING: Changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted. [reset] Are you sure you want to proceed? [y/N]: y [preflight] Running pre-flight checks [reset] Removing info for node \u0026quot;vm\u0026quot; from the ConfigMap \u0026quot;kubeadm-config\u0026quot; in the \u0026quot;kube-system\u0026quot; Namespace W0825 21:46:06.943208 4603 removeetcdmember.go:61] [reset] failed to remove etcd member: error syncing endpoints with etc: etcdclient: no available endpoints .Please manually remove this etcd member using etcdctl [reset] Stopping the kubelet service [reset] Unmounting mounted directories in \u0026quot;/var/lib/kubelet\u0026quot; [reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki] [reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf] [reset] Deleting contents of stateful directories: [/var/lib/etcd /var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes] The reset process does not reset or clean up iptables rules or IPVS tables. If you wish to reset iptables, you must do so manually. For example: iptables -F \u0026amp;\u0026amp; iptables -t nat -F \u0026amp;\u0026amp; iptables -t mangle -F \u0026amp;\u0026amp; iptables -X If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar) to reset your system's IPVS tables. The reset process does not clean your kubeconfig files and you must remove them manually. Please, check the contents of the $HOME/.kube/config file. multipass@vm:~$ sudo rm -rf /var/etcd  Reference multipass  https://multipass.run https://github.com/CanonicalLtd/multipass OS X에서 multipass를 이용하여 microk8s 환경 구성 Create a single node Kubernetes cluster on Ubuntu 18.04.1 (Bionic Beaver) with kubeadm https://docs.projectcalico.org/v3.8/getting-started/kubernetes/ k8s 설치 상세 절차 private helm repository 구성하기-조대협  ","id":18,"section":"posts","summary":"multipass? Multipass is a lightweight VM manager for Linux, Windows and macOS. It\u0026rsquo;s designed for developers who want a fresh Ubuntu environment with a single command. It uses KVM on Linux, Hyper-V on Windows and HyperKit on macOS to run the VM with minimal overhead. It can also use VirtualBox on Windows and macOS. Multipass will fetch images for you and keep them up to date. Since it supports metadata","tags":["Vmware","ubuntu","multipass"],"title":"Install VM with multipass on OS X","uri":"https://cychong47.github.io/2019/09/install-vm-with-multipass/","year":"2019"},{"content":"Replace microk8s with kubernetes in mini1\nremove micro.k8s with snap command cychong@mini1:~$ sudo snap remove microk8s Save data of snap \u0026quot;microk8s\u0026quot; in automatic snapshot set microk8s removed cychong@mini1:~$  setup kubernetes Reference : https://phoenixnap.com/kb/install-kubernetes-on-ubuntu\ncychong@mini1:~$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.15.3  cychong@mini1:~$ kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5c98db65d4-r468f 0/1 Pending 0 2m3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-wcm2n 0/1 Pending 0 2m3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-mini1 1/1 Running 0 79s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-mini1 1/1 Running 0 76s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-mini1 1/1 Running 0 72s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-rzpkc 1/1 Running 0 2m4s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-mini1 1/1 Running 0 82s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;  Install Calico cychong@mini1:~$ wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml --2019-09-08 21:53:13-- https://docs.projectcalico.org/v3.8/manifests/calico.yaml Resolving docs.projectcalico.org (docs.projectcalico.org)... 178.128.115.5, 2400:6180:0:d1::575:a001 Connecting to docs.projectcalico.org (docs.projectcalico.org)|178.128.115.5|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20628 (20K) [application/x-yaml] Saving to: ‘calico.yaml’ calico.yaml 100%[====================================================================================\u0026gt;] 20.14K --.-KB/s in 0.08s 2019-09-08 21:53:14 (240 KB/s) - ‘calico.yaml’ saved [20628/20628]  Change CALICO_IPV4POOL_CIDR\n - name: CALICO_IPV4POOL_CIDR value: \u0026quot;10.201.0.0/24\u0026quot;  cychong@mini1:~$ kubectl apply -f calico.yaml configmap/calico-config created customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created clusterrole.rbac.authorization.k8s.io/calico-node created clusterrolebinding.rbac.authorization.k8s.io/calico-node created daemonset.apps/calico-node created serviceaccount/calico-node created deployment.apps/calico-kube-controllers created serviceaccount/calico-kube-controllers created  cychong@mini1:~$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-65b8787765-7nmjw 1/1 Running 0 3m26s kube-system calico-node-8spzh 1/1 Running 0 3m26s kube-system coredns-5c98db65d4-r468f 1/1 Running 0 7m33s kube-system coredns-5c98db65d4-wcm2n 1/1 Running 0 7m33s kube-system etcd-mini1 1/1 Running 0 6m49s kube-system kube-apiserver-mini1 1/1 Running 0 6m46s kube-system kube-controller-manager-mini1 1/1 Running 0 6m42s kube-system kube-proxy-rzpkc 1/1 Running 0 7m34s kube-system kube-scheduler-mini1 1/1 Running 0 6m52s  cychong@mini1:~$ kubectl get nodes NAME STATUS ROLES AGE VERSION mini1 Ready master 11m v1.15.3 cychong@mini1:~$ kubectl describe node mini1 Name: mini1 Roles: master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/arch=amd64 kubernetes.io/hostname=mini1 kubernetes.io/os=linux node-role.kubernetes.io/master= Annotations: kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock node.alpha.kubernetes.io/ttl: 0 projectcalico.org/IPv4Address: 192.168.1.100/24 projectcalico.org/IPv4IPIPTunnelAddr: 10.244.51.64 volumes.kubernetes.io/controller-managed-attach-detach: true CreationTimestamp: Sun, 08 Sep 2019 21:49:54 +0900 Taints: node-role.kubernetes.io/master:NoSchedule Unschedulable: false  To use the master node as a worker node at the same time cychong@mini1:~$ kubectl taint nodes --all node-role.kubernetes.io/master- node/mini1 untainted cychong@mini1:~$ kubectl describe node mini1 Name: mini1 Roles: master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/arch=amd64 kubernetes.io/hostname=mini1 kubernetes.io/os=linux node-role.kubernetes.io/master= Annotations: kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock node.alpha.kubernetes.io/ttl: 0 projectcalico.org/IPv4Address: 192.168.1.100/24 projectcalico.org/IPv4IPIPTunnelAddr: 10.244.51.64 volumes.kubernetes.io/controller-managed-attach-detach: true CreationTimestamp: Sun, 08 Sep 2019 21:49:54 +0900 Taints: \u0026lt;none\u0026gt; Unschedulable: false  install helm with snap cychong@mini1:~$ sudo snap install helm --classic [sudo] password for cychong: helm 2.14.3 from Snapcrafters installed  if Kubelet is not started after reboot Disable swap\ncychong@mini1:~$ sudo swapoff -a cychong@mini1:~$ sudo systemctl status kubelet ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Sun 2019-09-08 22:34:24 KST; 1s ago Docs: https://kubernetes.io/docs/home/ Main PID: 16565 (kubelet) Tasks: 11 (limit: 4306) CGroup: /system.slice/kubelet.service └─16565 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --cgroup-dr  helm init cychong@mini1:~$ sudo helm init --history-max 200 $HELM_HOME has been configured at /home/cychong/.helm. Error: error installing: Post https://192.168.1.100:6443/apis/extensions/v1beta1/namespaces/kube-system/deployments: dial tcp 192.168.1.100:6443: connect: connection refused  Fix the Kubelet issue(due to the swap),\ncychong@mini1:~$ sudo helm init --history-max 200 $HELM_HOME has been configured at /home/cychong/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation  Instal ghost with Helm - failed cychong@mini1:~$ sudo helm search ghost NAME CHART VERSION\tAPP VERSION\tDESCRIPTION stable/ghost\t7.2.1 2.30.2 A simple, powerful publishing platform that allows you to...  Helm은 기본적으로 maridb를 사용하고 있으므로 values.yaml 파일을 override 해서 helm을 사용해야 한다. 문제는\nHelm install failed - “no available release name” cychong@mini1:~/work/ghost-with-helm$ sudo helm install -f values.yaml stable/ghost Error: no available release name found  해결책 : https://scriptcrunch.com/helm-error-no-available-release/\ncychong@mini1:~/work/ghost-with-helm$ kubectl get deployment --all-namespaces NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE kube-system calico-kube-controllers 1/1 1 1 24h kube-system coredns 2/2 2 2 25h kube-system tiller-deploy 1/1 1 1 24h cychong@mini1:~/work/ghost-with-helm$ kubectl delete deployment tiller-deploy -n kube-system deployment.extensions \u0026quot;tiller-deploy\u0026quot; deleted cychong@mini1:~/work/ghost-with-helm$ kubectl get deployment tiller-deploy --all-namespaces error: a resource cannot be retrieved by name across all namespaces cychong@mini1:~/work/ghost-with-helm$ sudo helm init --service-account=tiller $HELM_HOME has been configured at /home/cychong/.helm. Warning: Tiller is already installed in the cluster. (Use --client-only to suppress this message, or --upgrade to upgrade Tiller to the current version.)  cychong@mini1:~/work/ghost-with-helm$ kubectl create -f rbac-config.yaml serviceaccount/tiller created clusterrolebinding.rbac.authorization.k8s.io/tiller created  reference  https://www.linode.com/docs/applications/containers/kubernetes/how-to-install-apps-on-kubernetes-with-helm/ https://phoenixnap.com/kb/install-kubernetes-on-ubuntu  ","id":19,"section":"posts","summary":"Replace microk8s with kubernetes in mini1 remove micro.k8s with snap command cychong@mini1:~$ sudo snap remove microk8s Save data of snap \u0026quot;microk8s\u0026quot; in automatic snapshot set microk8s removed cychong@mini1:~$ setup kubernetes Reference : https://phoenixnap.com/kb/install-kubernetes-on-ubuntu cychong@mini1:~$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.15.3 cychong@mini1:~$ kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5c98db65d4-r468f 0/1 Pending 0 2m3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;","tags":["kubernetes","calico","setup"],"title":"Setup kubernetes in a single host","uri":"https://cychong47.github.io/2019/09/setup-kubernetes-with-a-single-host/","year":"2019"},{"content":"ghost를 설치한 지 몇 년이 지났는데 그 동안 여러 가지 방법으로 Ghost 운용 환경을 구축해왔다.\nHost 환경, Docker, Ansible, kubernetes 에 이어 이번은 5번째 시즌인데 Helm Chart 를 시용해서 설치해 보는 것이다. 처음 시작은 helm repository에 있는 공식(?) 공개된 helm chart를 이용하여 values.yaml 파일만 내 환경에 맞게 변경해서 사용하려던 것이었는데 아쉽게 아직은 그렇게 하기 힘든 것으로 보여 직접 helm chart를 만들어서 사용하고 있다. 이 문서는 그 과정을 기술한 것으로 향후 공식 helm chart를 활용할 수 있는 때가 오면 시즌 6에 해당하는 글을 또 쓸 듯 하다.\nPV PV(Persistent Volume을 만드는 건 Helm의 역할이 아닌 듯. 대부분의 Helm Chart는 필요한 PVC(Persistent Volume Claim)은 정의하고 있어도 PV 생성에 대한 책임은 지고 있지 않은 듯 하다.\nghost-pv.yaml kind: PersistentVolume apiVersion: v1 metadata: name: ghost-pv labels: type: local spec: storageClassName: manual capacity: storage: 12Gi accessModes: - ReadWriteOnce hostPath: path: \u0026quot;/home/cychong/Dropbox/Apps/ghost/content\u0026quot;  Kubectl 명령을 이용하여 직접 PV 생성한다.\ncychong@mini1:~/work$ kubectl create -f ghost-in-k8s/ghost-pv.yaml persistentvolume/ghost-pv created cychong@mini1:~/work$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv 12Gi RWO Retain Available manual 8s  다음은 helm을 이용해서 ghost를 deploy한다.\n처음 helm을 이용해서 손쉽게 ghost를 설치할 수 있다는 걸 알고( How to Install Apps on Kubernetes with Helm ) 부푼 기대감을 가지고 설치해 봤는데 아쉽게 github에 있는 건 mariadb를 backend DB로 사용하는 형태였다. Sqlite를 backend로 해서 가볍게 개인 블로그를 운용하고 있는 입장에서는 이걸 위해 mariadb를 사용하기는 배보다 배꼽이 더 큰 상황이 아닌가 싶어 mariadb를 사용하지 않고 ghost를 설치할 수 있는 지 helm chart를 살펴봤다. 그런데 아무리 봐도 mariadb 혹은 별도의 외부 DB가 없으면 제대로 동작하지 않는(ghost를 deploy할 수 없는) 듯 해 보였다. https://github.com/helm/charts/issues/16989 에도 issue를 올렸는데 반응을 보인 한 명이 별 문제 없을 것 같은데 라고 하길래 현상을 자세히 적어줬지만 그 다음부터는 감감무소식이라. 오픈 소스가 원래 그런 거 지만\u0026hellip; 다들 문제가 없는 건지 내가 하는 것처럼 ghost + kubernetes + helm + sqlite 의 조합으로 사용을 안하는 건지\u0026hellip;\n결국 목마른 사람이 우물을 판다고 이전에 직접 만들어서 사용했던 YAML 파일 들을 이용해서 직접 Helm chart를 만들어 보기로 마음 먹었다. 겸사겸사 이러다 보면 Helm chart의 복잡한(?) 문법도 어쩔 수 없이 조금은 이해할 수 밖에 없는 상황이 되지 않을까 하고\n접근 방법은 Helm chart의 convention과는 조금 다르지만 근본적으로 결국 deployment, service 등의 조합으로 이루어지는 거라 일단 잘(적어도 내가 원하는 형태대로) 동작하는 YAML 파일들 과 helm create 명령을 통해 만들어진 기본 형태의 파일들과 비교해 가면서 기존 YAML 파일들의 내용을 helm chart에 반영해서 제대로 된 동작하는 helm chart를 만들기로 했다. 제대로의 기준 중 하나는 helm이 추구하는 것과 같이 배포 site와 무관한 내용은 YAML이나 template 파일들에 정의하고 배포 site별로 다를 수 있는 내용은 values.yaml 파일에 정의하는 것이다. 이를 테면 블로그 URL등을 이전에는 deployment.yaml파일에 직접 정의했지만 이번에는 values.yaml에 정의하고 이 값을 참조하도록 했다.\n처음 helm을 사용해 보는 거라 쉽게 되지는 않았다. 밤 늦게 퇴근해서 뭔가를 한다는 건 정말 힘든 일이었고, 주말에 어쩌다 시간이 나면 시도해 보는 건데 이마저도 제대로 집중해서 보질 못하니. 그렇게 trial \u0026amp; error를 통해 만든 ghost helm chart를 github repo 에 올렸다. 참고로 이 repo에 있는 내용은 새로 ghost를 만드는 경우에도 잘 동작하는 지는 확인하지 못했다. 기존 sqlite DB파일을 가지고 있는 내 동작 환경에서만 확인해 본 거라 아직은 얼마나 범용성을 가지고 있는 지는 잘 모르겠다. 그렇게 하려면 완전히 새로운 환경에서 해 봐야 하는데 내 코가 석자라 그건 나중에 시간이 나면\u0026hellip;\n이 helm chart를 이용해 ghost를 설치하는 과정은 다음과 같다.\nhelm chart를 ghost-with-helm 이라는 디렉토리에 만들었다.\n$ tree -l ghost-with-helm ghost-with-helm ├── Chart.yaml ├── README.md ├── charts ├── templates │ ├── NOTES.txt │ ├── _helpers.tpl │ ├── deployment.yaml │ ├── ingress.yaml │ ├── pvc.yaml │ ├── service.yaml │ └── tests │ └── test-connection.yaml └── values.yaml  참고로 ingress.yaml은 아직 사용하지 않고 직접 NodePort를 이용해서 처리하고 있다. 이 부분은 향후 개선할 점 중 하나.\nhelm chart의 values.yaml을 맞게 고친 후 설치한다.\ncychong@mini1:~/work$ helm install --name my-ghost ghost-with-helm NAME: my-ghost LAST DEPLOYED: Sun Sep 22 21:39:34 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Deployment NAME READY UP-TO-DATE AVAILABLE AGE my-ghost 0/1 1 0 0s ==\u0026gt; v1/PersistentVolumeClaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ghost-pvc Bound ghost-pv 12Gi RWO manual 1s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-djd2g 0/1 Pending 0 0s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE my-ghost NodePort 10.97.215.158 \u0026lt;none\u0026gt; 2368:30025/TCP 1s NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026quot;{.spec.ports[0].nodePort}\u0026quot; services my-ghost) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026quot;{.items[0].status.addresses[0].address}\u0026quot;) echo http://$NODE_IP:$NODE_PORT  helm install 명령을 내리면 chart로 생성된 application과 관련된 resource 들 pod, service, PVCs 등의 상태가 한번에 모두 확인된다. Pod는 명령을 내리자 마자 상태를 조회한 거라 STATUS가 아직 Pending 상태로 나온다. kubectl 명령으로 pod의 상태를 다시 확인해 본다.\ncychong@mini1:~/work$ kubectl get pod my-ghost-5f6578fd76-djd2g NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-djd2g 1/1 Running 0 2m43s  Pod의 STATUS가 정상적으로 RUNNING으로 출력된다. 이제 pod는 정상적으로 deploy가 된 상태인데 Service를 NodePort 타입으로 지정한 경우 Host에서 접속하려면 실제 pod가 listening하는 것과 다른 port를 사용하므로 위 NOTES에 있는 대로 실제로 서비스에 할당된 port 정보를 확인해야 한다.\ncychong@mini1:~/work$ export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026quot;{.spec.ports[0].nodePort}\u0026quot; services my-ghost) cychong@mini1:~/work$ export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026quot;{.items[0].status.addresses[0].address}\u0026quot;) cychong@mini1:~/work$ echo http://$NODE_IP:$NODE_PORT http://192.168.1.100:30025  이번에 할당된 port는 30025다. 이제 NODE_IP와 NODE_PORT값을 이용해서 해당 주소에 접속하면 정상적으로 ghost 화면이 나온다.\n이 port 정보를 이용해서 공유기의 port forwarding 규칙에 추가한다. 외부에서 sosa0sa.com:2368로 접슨 시 실제 ghost 가 실행된 mini1의 내부 IP로 포워딩 하되 port 번호를 30025로 변환해서(NAPT) 전달하도록 변경한 후 접속해 본다.\nOn-premise 환경에서 kubernetes를 사용하는 경우 LoadBalancer를 별도로 설치하지 않고 외부와 통신하기 위해 사용하는 NodePort는 이렇게 service를 deploy할 때마다 port가 바뀌는 문제가 존재한다. 내 경우 공유기의 port forwarding을 이용해서 블로그에 접속할 수 있도록 하고 있어 매번 공유기의 port forwarding 규칙을 고쳐야 하므로 개선이 필요하다(포트 값을 고정값으로 할당하거나, Ingress Controller혹은 MetalLB등을 사용하여 NodePort가 아닌 LoadBalancer 타입으로 변경할 예정이다)\nhelm-test cychong@mini1:~/work/ghost-with-helm$ helm test my-ghost RUNNING: my-ghost-test-connection PASSED: my-ghost-test-connection  Port Number NodePort를 사용하면 해당 서비스를 위한 30000에서 32767 사이의 포트 번호가 할당된다. 그런데 위와 같이 port와 TargetPort를 지정하면 위 30000번대 포트 외에 의도한 포트로도 접근이 가능하다.\ncychong@mini1:~/work/ghost-with-helm$ echo $(kubectl get --namespace default -o jsonpath=\u0026quot;{.spec.ports[0].nodePort}\u0026quot; services my-ghost) 32326 cychong@mini1:~/work/ghost-with-helm$ sudo netstat -atnp |grep kube-proxy [sudo] password for cychong: tcp 0 0 127.0.0.1:10249 0.0.0.0:* LISTEN 18392/kube-proxy tcp 0 0 192.168.1.100:2368 0.0.0.0:* LISTEN 18392/kube-proxy tcp 0 0 192.168.1.100:49778 192.168.1.100:6443 ESTABLISHED 18392/kube-proxy tcp6 0 0 :::32326 :::* LISTEN 18392/kube-proxy tcp6 0 0 :::10256 :::* LISTEN 18392/kube-proxy  위 내용을 보면 my-ghost 서비스에 할당된 NodePort 32326 외에 TargetPort인 2368이 그대로 보이는 것을 알 수 있다.\nUpgrade Helm Chart에 변경이 있는 경우에는 upgrade 명령을 이용한다. 만일 value 파일에 변화가 있는 경우에는 전체를 다시 deploy하는 듯 하다. 아래는 targetPort 값을 임시로 다른 값으로 변경해서 upgrade 했다 다시 원복한 경우다.\ncychong@mini1:~/work$ helm upgrade --debug my-ghost ghost-with-helm [debug] Created tunnel using local port: '44111' [debug] SERVER: \u0026quot;127.0.0.1:44111\u0026quot; REVISION: 5 RELEASED: Thu Sep 26 01:06:32 2019 CHART: ghost-0.1.0 USER-SUPPLIED VALUES: {} ... Release \u0026quot;my-ghost\u0026quot; has been upgraded. LAST DEPLOYED: Thu Sep 26 01:06:32 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Deployment NAME READY UP-TO-DATE AVAILABLE AGE my-ghost 1/1 1 1 18m ==\u0026gt; v1/PersistentVolumeClaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ghost-pvc Bound ghost-pv 12Gi RWO manual 18m ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-lb7xc 1/1 Running 0 18m ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE my-ghost NodePort 10.105.125.54 192.168.1.100 2368:32326/TCP 18m  Troubleshooting 동일한 helm release 이름을 다시 사용하려면 삭제한 helm release를 재사용하려면 delete 외에 delete —purge 옵션으로 삭제할 것\ncychong@mini1:~/work$ helm install --name my-ghost ghost-with-helm Error: a release named my-ghost already exists. Run: helm ls --all my-ghost; to check the status of the release Or run: helm del --purge my-ghost; to delete it cychong@mini1:~/work$ helm ls cychong@mini1:~/work$ helm ls -A Error: unknown shorthand flag: 'A' in -A cychong@mini1:~/work$ helm ls --all my-ghost NAME REVISION\tUPDATED STATUS CHART APP VERSION\tNAMESPACE my-ghost\t1 Sun Sep 22 21:36:42 2019\tDELETED\tghost-0.1.0\t1.0 default cychong@mini1:~/work$ helm del --purge my-ghost release \u0026quot;my-ghost\u0026quot; deleted  helm delete 후 PV 연결이 안되는 경우 한번 Release를 생성한 후 삭제한 경우 PVC가 제대로 할당되지 않는 현상이 있다. 이 경우 PV를 삭제한 후 다시 Helm install을 수행한다.\ncychong@mini1:~/work$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv 12Gi RWO Retain Bound default/ghost-pvc manual 13m cychong@mini1:~/work$ helm ls helm delete NAME REVISION\tUPDATED STATUS CHART APP VERSION\tNAMESPACE my-ghost\t1 Sun Sep 22 21:39:34 2019\tDEPLOYED\tghost-0.1.0\t1.0 default cychong@mini1:~/work$ helm delete --purge my-ghost release \u0026quot;my-ghost\u0026quot; deleted cychong@mini1:~/work$ helm ls cychong@mini1:~/work$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv 12Gi RWO Retain Released default/ghost-pvc manual 14m  이 상태에서 다시 helm install을 수행하면\ncychong@mini1:~/work$ helm install --name my-ghost ghost-with-helm NAME: my-ghost LAST DEPLOYED: Sun Sep 22 21:53:40 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Deployment NAME READY UP-TO-DATE AVAILABLE AGE my-ghost 0/1 1 0 1s ==\u0026gt; v1/PersistentVolumeClaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ghost-pvc Pending manual 1s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-kddlg 0/1 Pending 0 1s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE my-ghost NodePort 10.96.105.207 \u0026lt;none\u0026gt; 2368:32615/TCP 1s NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026quot;{.spec.ports[0].nodePort}\u0026quot; services my-ghost) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026quot;{.items[0].status.addresses[0].address}\u0026quot;) echo http://$NODE_IP:$NODE_PORT  cychong@mini1:~/work$ kubectl describe pod my-ghost-5f6578fd76-kddlg Name: my-ghost-5f6578fd76-kddlg Namespace: default Priority: 0 Node: \u0026lt;none\u0026gt; Labels: app.kubernetes.io/instance=my-ghost app.kubernetes.io/name=ghost pod-template-hash=5f6578fd76 Annotations: \u0026lt;none\u0026gt; Status: Pending … Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 26s (x2 over 87s) default-scheduler pod has unbound immediate PersistentVolumeClaims  이 경우 다시 PV를 삭제하고 새로 PV를 정의한 후 helm install을 실행해야 한다.\ncychong@mini1:~/work$ helm ls helm del NAME REVISION\tUPDATED STATUS CHART APP VERSION\tNAMESPACE my-ghost\t1 Sun Sep 22 21:53:40 2019\tDEPLOYED\tghost-0.1.0\t1.0 default cychong@mini1:~/work$ helm del --purge my-ghost release \u0026quot;my-ghost\u0026quot; deleted cychong@mini1:~/work$ kubectl delete -f ghost-in-k8s/ghost-pv.yaml persistentvolume \u0026quot;ghost-pv\u0026quot; deleted cychong@mini1:~/work$ kubectl create -f ghost-in-k8s/ghost-pv.yaml persistentvolume/ghost-pv created cychong@mini1:~/work$ helm install --name my-ghost ghost-with-helm NAME: my-ghost LAST DEPLOYED: Sun Sep 22 21:56:42 2019 NAMESPACE: default STATUS: DEPLOYED … cychong@mini1:~/work$ kubectl get pod NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-k5xcs 1/1 Running 0 50s  ","id":20,"section":"posts","summary":"ghost를 설치한 지 몇 년이 지났는데 그 동안 여러 가지 방법으로 Ghost 운용 환경을 구축해왔다. Host 환경, Docker, Ansible, kubernetes 에 이어 이번은 5번째 시즌인데 Helm Chart 를 시용해서 설치해","tags":["ghost","kubernetes","helm","github"],"title":"Ghost Season 5 - Helm","uri":"https://cychong47.github.io/2019/09/ghost-season-5-helm/","year":"2019"},{"content":"간혹 아니 자주 블루투스로 연결한 마우스가 너무 반응이 느리다. 맥이 이상한 가 싶어 트랙패드를 만져보면 전혀 반응 속도에 이상이 없다.\n인터넷을 뒤져보니 Wifi 2.5GHz와 블루투스가 간섭을 일으켜서 그런다고. 가장 간단한 해결책은 2.5GHz인데, 설명서에 있는 대로 2.5GHz에 대해 Radio Enable 를 꺼도 여전히 AP list에 나온다. 그러다 우연히 본 옵션이 \u0026ldquo;Bluetooth coexistence\u0026rdquo;. 5GHz에 대해서는 이 옵션이 없는 걸 보니 뭔가 영향을 줄 것 같다. 일단 옵션을 Enable로 변경.\nLet\u0026rsquo;s see what happens. 5분 정도 지난 아직까지는 마우스 움직임이 둔해지는 현상이 없네. 왠지 느낌이 좋네.\n","id":21,"section":"posts","summary":"간혹 아니 자주 블루투스로 연결한 마우스가 너무 반응이 느리다. 맥이 이상한 가 싶어 트랙패드를 만져보면 전혀 반응 속도에 이상이 없다. 인터넷을 뒤져보니 Wifi 2.5G","tags":[],"title":"Wifi 2.5GHz bluetooth coexist","uri":"https://cychong47.github.io/2019/08/wifi-5ghz-bluetooth-coexistence/","year":"2019"},{"content":"Getting started with Calico on Kubernetes   Calico를 사용하는 경우 kubelet의 실행 옵션 중 --network-plugin=cni와 같이 변경된다.\n  kube-controller-manager의 실행 옵션 중 --allocate-node-cidrs=false 로 역시 변경된다. 이는 CNI(여기서는 Calico의 IPAM)에서 IP 주소를 할당하기 때문\n  Pod 내 route table에서는 host의 link local address를 default route로 사용한다.\n  Pod가 갖는 eth0 interface는 root(혹은 default) namespace에 존재하는 \u0026lsquo;cali\u0026rsquo;로 시작하는 interface와 veh pair 관계를 갖는다.\n veth pairs는 아래 설명과 같이 서로 연결된 두 개의 interface를 의미하는데 한쪽으로 들어가면 연결된 다른 인터페이스로 나온다. 즉 pod의 eth0 interface를 통해 패킷을 전송하면 host의 cali interface로 나와 커널의 라우팅 혹은 iptable 처리를 받는다. https://www.fir3net.com/Networking/Terms-and-Concepts/virtual-networking-devices-tun-tap-and-veth-pairs-explained.html     What goes in one end will come out the other.\n Calico and Kubernetes Series 1 to 4 kubernetes를 설치하는 방법부터 Calico 설치 그리고 sample application을 이용해서 calico를 이용한 전반적인 네트워킹을 친절하고 상세하게 설명.\n k8s 설치 방법 : kubeadm을 이용해서 설치할 수 있다.  https://kubenetes.io/docs/setup/independent/install-kubeadm sudo systemctl start docker ; sudo systemctl enable docker Virtualbox 등을 사용해서 설치하는 경우 최소 core 2개 이상은 할당해야 함. 그렇지 않으면 kubeadm 실행할 때 core 부족을 이유로 에러 발생. 추가로 swap 도 꺼야 함 sudo swapoff -a Ubuntu 에 kubenetes 설치하는 것은 (https://www.linuxtechi.com/install-configure-kubernetes-ubuntu-18-04-ubuntu-18-10/ 참고.   master node를 worker node로 사용하려면 \u0026lsquo;kubectl taint\u0026rsquo; 명령을 사용하면 된다  kubectl taint nodes --all node-role,kubernetes.io/master-   일반 사용자도 kubectl 을 사용하게 하려면 /etc/kubenetes/admin.conf' 사용자 계정 아래 $HOME/.kube/config` 파일로 복사하고 권한을 사용자로 주면 된다.  sudo cp -i /etc/kubenetes/admin.conf $HOME/.kube/config ; sudo chown $(id -u):$(id -g) $HOME/.kube/config   Calico 관련 설정 내용을 확인하려면 kube-system namespace에서 동작하고 있는 calicoctl pod의 calicoctl 을 사용한다.  kubectl exec -ti -n kube-system calicoctl -- /calicoctl get profiles -o wide kubectl exec -ti -n kube-system calicoctl -- /calicoctl get -o yaml ippool  nat-outging: true container에서 외부로 향하는 패킷 중 목적지가 calico CIDR에 속하지 않는 경우 NAT를 수행한다는 의미. 자세한 내용은 iptables -L -t nat -n 명령에서 확인할 수 있음   ippool을 추가하려면 kind: ipPool을 갖는 yaml 파일을 만들어 calico 명령으로 적용한다.  calicoctl pod에서 실행해야 하는데 yaml 파일을 해당 pod 내에서 만들어서 적용해야 하므로 calicoctl pod에 ssh로 접속한 후 YAML 파일 만들어 calicoctl create -f XXX.yaml 명령으로 적용한다.   2개 이상의 ippool을 만든 경우 특정 pod가 특정 subnet에서 ip를 할당받도록 하려면 annotation 을 이용해서 pod 생성시 calico subnet을 지정한다.  annotations: \u0026quot;cni.projectcalico.org/ipv4pools\u0026quot;: \u0026quot;[\\\u0026quot;10.91.1.0/24\\\u0026quot;]\u0026quot;     다목적 시험용 sshd pod는 이걸 사용  kubectl run sushi-1 --image=rastasheep/ubuntu-sshd:16.04 단 2017년 글이라 그런지 kubectl run 대신 kubectl create를 사용하라고 경고가 나온다 추가로 패키지를 몇 개 설치할 섯. apt-get update ; apt-get install iproute2 inetutils-ping traceroute   container내 eth0 interface의 IP는 /32로 host의 cali로 시작하는 veth pair 관계를 갖는다.  pod내에서 ip -d link 명령의 결과에 나오는 interface 이름 정보를 통해 Veth pair 인터페이스가 어떤 것인지 확인할 수 있다. 예를 들어 pod 내에서 확인한 정보가 eth0@if5면 이 pod의 eth0는 host에서 5번째 interface라는 것을 알 수 있다.   특정 pod가 위치할 node를 지정하기 위해 node에 label을 지정하려면  kubectl label nodes NODE-NAME node_id=NODE-LABEL   Calico의 bop 기능을 사용하려면 \u0026ldquo;kind: bgpPeer\u0026quot;인 YAML 파일을 만들어 적용한다. (calicoctl pod 내에서 작업)  calicoctl create -f bgp.yaml calicoctl get -o yaml bgppeer calicoctl node status 여러 노드들이 동일한 bgp 정보를 adversize하여 특정 pod의 subnet이 여러 node에서 수신하도록 외부에 adversize될 수도 있음. 확인 필요    ","id":22,"section":"posts","summary":"Getting started with Calico on Kubernetes Calico를 사용하는 경우 kubelet의 실행 옵션 중 --network-plugin=cni와 같이 변경된다. kube-contr","tags":["container","kubernetes","cni","calico","network"],"title":"Calico CNI (draft)","uri":"https://cychong47.github.io/2019/08/calico-cni-1/","year":"2019"},{"content":"IEEE 1588: What’s the difference between a Boundary Clock and Transparent Clock?\nIEEE 1588 2002  Original standard Ordinary Clock : GrandMaster of Slave. Always a single port Boundary Clock  clock node that has two or more ports (router or switch) One port as a slave clock, The remaining ports are master clock for other nodes. BC recovers the time of day within the slave clock and relays it as a reference to the mater clock function    1PPS  Pulse-Per-Second https://www.iqdfrequencyproducts.com/media/pg/1589/1495630251/gps-do.pdf  Holdover time  Time to maintain the accuracy during the GPS is not locked  OXCO vs. TCXO  Oven Controlled Oscillator  ensure 8 microseconds of holdover from 8 to 24 hours,   https://www.eetimes.com/document.asp?doc_id=1278627# TCXO(Temperature-Compensated Crystal Oscillator)  ","id":23,"section":"posts","summary":"IEEE 1588: What’s the difference between a Boundary Clock and Transparent Clock?\nIEEE 1588 2002  Original standard Ordinary Clock : GrandMaster of Slave. Always a single port Boundary Clock  clock node that has two or more ports (router or switch) One port as a slave clock, The remaining ports are master clock for other nodes. BC recovers the time of day within the slave clock and relays it as a reference to the mater clock function    1PPS  Pulse-Per-Second https://www.","tags":["til"],"title":"Boundary Clock","uri":"https://cychong47.github.io/2019/07/boundary-clock/","year":"2019"},{"content":"Install microk8s MicroK8s - Fast, Light, Upstream Developer Kubernetes\n설치는 위 링크에 있는 공식 홈페이지에 있는 대로 snap 명령어 하나로 간단하게 설치할 수 있다.\ncychong@mini1:~$ sudo snap install microk8s --classic 2019-05-18T09:43:53+09:00 INFO Waiting for restart... microk8s v1.14.1 from Canonical✓ installed  설치된 microk8s의 정보를 확인하려면 snap info microk8s\ncychong@mini1:~$ sudo snap info microk8s name: microk8s summary: Kubernetes for workstations and appliances publisher: Canonical✓ contact: \u0026lt;https://github.com/ubuntu/microk8s\u0026gt; license: unset description: | MicroK8s is a small, fast, secure, single node Kubernetes that installs on just about any Linux box. Use it for offline development, prototyping, testing, or use it on a VM as a small, cheap, reliable k8s for CI/CD. It's also a great k8s for appliances - develop your IoT apps for k8s and deploy them to MicroK8s on your boxes. commands: - microk8s.config - microk8s.ctr - microk8s.disable - microk8s.enable - microk8s.inspect - microk8s.istioctl - microk8s.kubectl - microk8s.reset - microk8s.start - microk8s.status - microk8s.stop services: microk8s.daemon-apiserver: simple, enabled, active microk8s.daemon-apiserver-kicker: simple, enabled, active microk8s.daemon-containerd: simple, enabled, active microk8s.daemon-controller-manager: simple, enabled, active microk8s.daemon-etcd: simple, enabled, active microk8s.daemon-kubelet: simple, enabled, active microk8s.daemon-proxy: simple, enabled, active microk8s.daemon-scheduler: simple, enabled, active snap-id: EaXqgt1lyCaxKaQCU349mlodBkDCXRcg tracking: stable refresh-date: today at 09:44 KST channels: stable: v1.14.1 2019-04-18 (522) 214MB classic candidate: v1.14.1 2019-04-15 (522) 214MB classic beta: v1.14.1 2019-04-15 (522) 214MB classic edge: v1.14.2 2019-05-17 (604) 217MB classic 1.15/stable: – 1.15/candidate: – 1.15/beta: – 1.15/edge: v1.15.0-alpha.3 2019-05-08 (578) 215MB classic 1.14/stable: v1.14.1 2019-04-18 (521) 214MB classic 1.14/candidate: v1.14.1 2019-04-15 (521) 214MB classic 1.14/beta: v1.14.1 2019-04-15 (521) 214MB classic 1.14/edge: v1.14.2 2019-05-17 (603) 217MB classic 1.13/stable: v1.13.5 2019-04-22 (526) 237MB classic 1.13/candidate: v1.13.6 2019-05-09 (581) 237MB classic 1.13/beta: v1.13.6 2019-05-09 (581) 237MB classic 1.13/edge: v1.13.6 2019-05-08 (581) 237MB classic 1.12/stable: v1.12.8 2019-05-02 (547) 259MB classic 1.12/candidate: v1.12.8 2019-05-01 (547) 259MB classic 1.12/beta: v1.12.8 2019-05-01 (547) 259MB classic 1.12/edge: v1.12.8 2019-04-24 (547) 259MB classic 1.11/stable: v1.11.10 2019-05-10 (557) 258MB classic 1.11/candidate: v1.11.10 2019-05-02 (557) 258MB classic 1.11/beta: v1.11.10 2019-05-02 (557) 258MB classic 1.11/edge: v1.11.10 2019-05-01 (557) 258MB classic 1.10/stable: v1.10.13 2019-04-22 (546) 222MB classic 1.10/candidate: v1.10.13 2019-04-22 (546) 222MB classic 1.10/beta: v1.10.13 2019-04-22 (546) 222MB classic 1.10/edge: v1.10.13 2019-04-22 (546) 222MB classic installed: v1.14.1 (522) 214MB classic  Enable services(microk8s) cychong@mini1:~$ sudo microk8s.enable dashboard registry dns Enabling dashboard secret/kubernetes-dashboard-certs created serviceaccount/kubernetes-dashboard created deployment.apps/kubernetes-dashboard created service/kubernetes-dashboard created service/monitoring-grafana created service/monitoring-influxdb created service/heapster created deployment.extensions/monitoring-influxdb-grafana-v4 created serviceaccount/heapster created configmap/heapster-config created configmap/eventer-config created deployment.extensions/heapster-v1.5.2 created dashboard enabled Enabling the private registry Enabling default storage class deployment.extensions/hostpath-provisioner created storageclass.storage.k8s.io/microk8s-hostpath created Storage will be available soon Applying registry manifest namespace/container-registry created persistentvolumeclaim/registry-claim created deployment.extensions/registry created service/registry created The registry is enabled Enabling DNS Applying manifest service/kube-dns created serviceaccount/kube-dns created configmap/kube-dns created deployment.extensions/kube-dns created Restarting kubelet DNS is enabled  서비스 상태는 microk8s.status로 확인 가능\ncychong@mini1:~$ sudo microk8s.status [sudo] password for cychong: microk8s is running addons: jaeger: disabled fluentd: disabled gpu: disabled storage: enabled registry: enabled ingress: disabled dns: enabled metrics-server: disabled prometheus: disabled istio: disabled dashboard: enabled  Basic kubectl commands Node 상태 확인 cychong@mini1:~$ sudo microk8s.kubectl get node NAME STATUS ROLES AGE VERSION mini1 Ready \u0026lt;none\u0026gt; 13m v1.14.1  namespace 상태 확인 cychong@mini1:~$ sudo microk8s.kubectl get namespace NAME STATUS AGE container-registry Active 179m default Active 3h2m kube-node-lease Active 3h2m kube-public Active 3h2m kube-system Active 3h2m   cychong@mini1:~$ sudo microk8s.kubectl get all NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 15m  모든 namespace를 보고 싶을 때\ncychong@mini1:~$ sudo microk8s.kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE container-registry pod/registry-7d65c894c-z5nv6 1/1 Running 0 12m kube-system pod/heapster-v1.5.2-5c5498f57c-wztz5 4/4 Terminating 0 12m kube-system pod/heapster-v1.5.2-6b5d7b57f9-4q9rd 4/4 Running 0 10m kube-system pod/heapster-v1.5.2-89b48dff-g9hqj 4/4 Terminating 0 10m kube-system pod/hostpath-provisioner-6d744c4f7c-gxksl 1/1 Running 0 12m kube-system pod/kube-dns-6bfbdd666c-t6f74 3/3 Running 0 12m kube-system pod/kubernetes-dashboard-6fd7f9c494-48dnz 1/1 Running 0 12m kube-system pod/monitoring-influxdb-grafana-v4-78777c64c8-c5jk4 2/2 Running 0 12m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE container-registry service/registry NodePort 10.152.183.138 \u0026lt;none\u0026gt; 5000:32000/TCP 12m default service/kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 15m kube-system service/heapster ClusterIP 10.152.183.196 \u0026lt;none\u0026gt; 80/TCP 12m kube-system service/kube-dns ClusterIP 10.152.183.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 12m kube-system service/kubernetes-dashboard ClusterIP 10.152.183.236 \u0026lt;none\u0026gt; 443/TCP 12m kube-system service/monitoring-grafana ClusterIP 10.152.183.146 \u0026lt;none\u0026gt; 80/TCP 12m kube-system service/monitoring-influxdb ClusterIP 10.152.183.137 \u0026lt;none\u0026gt; 8083/TCP,8086/TCP 12m NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE container-registry deployment.apps/registry 1/1 1 1 12m kube-system deployment.apps/heapster-v1.5.2 1/1 1 1 12m kube-system deployment.apps/hostpath-provisioner 1/1 1 1 12m kube-system deployment.apps/kube-dns 1/1 1 1 12m kube-system deployment.apps/kubernetes-dashboard 1/1 1 1 12m kube-system deployment.apps/monitoring-influxdb-grafana-v4 1/1 1 1 12m NAMESPACE NAME DESIRED CURRENT READY AGE container-registry replicaset.apps/registry-7d65c894c 1 1 1 12m kube-system replicaset.apps/heapster-v1.5.2-5c5498f57c 0 0 0 12m kube-system replicaset.apps/heapster-v1.5.2-6b5d7b57f9 1 1 1 10m kube-system replicaset.apps/heapster-v1.5.2-89b48dff 0 0 0 10m kube-system replicaset.apps/hostpath-provisioner-6d744c4f7c 1 1 1 12m kube-system replicaset.apps/kube-dns-6bfbdd666c 1 1 1 12m kube-system replicaset.apps/kubernetes-dashboard-6fd7f9c494 1 1 1 12m kube-system replicaset.apps/monitoring-influxdb-grafana-v4-78777c64c8 1 1 1 12m  System Pod 확인 namespace를 kube-system으로 지정하면 됨. namespace는 microk8s.kubectl get all --all-namespaces 명령의 출력에 나오는 NAMESPACE에서 알 수 있음\ncychong@mini1:~$ sudo microk8s.kubectl get pod No resources found. cychong@mini1:~$ sudo microk8s.kubectl get pod --namespace=kube-system NAME READY STATUS RESTARTS AGE heapster-v1.5.2-5c5498f57c-wztz5 4/4 Terminating 0 16m heapster-v1.5.2-6b5d7b57f9-4q9rd 4/4 Running 0 15m heapster-v1.5.2-89b48dff-g9hqj 4/4 Terminating 0 15m hostpath-provisioner-6d744c4f7c-gxksl 1/1 Running 0 16m kube-dns-6bfbdd666c-t6f74 3/3 Running 0 16m kubernetes-dashboard-6fd7f9c494-48dnz 1/1 Running 0 16m monitoring-influxdb-grafana-v4-78777c64c8-c5jk4 2/2 Running 0 16m  특정 pod에 대한 정보만 보고 싶을 때는 pod 명령 뒤에 pod name을 지정한다.\n``` cychong@mini1:~$ sudo microk8s.kubectl get pod kubernetes-dashboard-6fd7f9c494-48dnz --namespace=kube-system NAME READY STATUS RESTARTS AGE kubernetes-dashboard-6fd7f9c494-48dnz 1/1 Running 0 20m cychong@mini1:~$ sudo microk8s.kubectl get pod kubernetes-dashboard-6fd7f9c494-48dnz --namespace=kube-system -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kubernetes-dashboard-6fd7f9c494-48dnz 1/1 Running 0 19m 10.1.1.6 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;  Service 확인 cychong@mini1:~$ sudo microk8s.kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 33m cychong@mini1:~$ sudo microk8s.kubectl cluster-info [sudo] password for cychong: Kubernetes master is running at https://127.0.0.1:16443 Heapster is running at https://127.0.0.1:16443/api/v1/namespaces/kube-system/services/heapster/proxy KubeDNS is running at https://127.0.0.1:16443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy Grafana is running at https://127.0.0.1:16443/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy InfluxDB is running at https://127.0.0.1:16443/api/v1/namespaces/kube-system/services/monitoring-influxdb:http/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.  Example. Ngnix container replicaset을 만들고 service로 expose Deploy Lightweight Kubernetes with MicroK8s and Snap - Computing for Geeks\n# microk8s.kubectl run nginx --replicas 2 --image nginx deployment.apps/nginx created # microk8s.kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE nginx 2/2 2 2 39s # microk8s.kubectl get pods NAME READY STATUS RESTARTS AGE nginx-7db9fccd9b-7662b 1/1 Running 0 61s nginx-7db9fccd9b-87z6d 1/1 Running 0 61s # microk8s.kubectl expose deployment nginx --port 80 --target-port 80 \\ --type ClusterIP --selector=run=nginx --name nginx service/nginx exposed # microk8s.kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.152.183.1 443/TCP 27m nginx ClusterIP 10.152.183.54 80/TCP 104s # microk8s.kubectl delete deployment nginx deployment.extensions \u0026quot;nginx\u0026quot; deleted # microk8s.kubectl delete service nginx service \u0026quot;nginx\u0026quot; deleted  Setup Ghost Setup volume ghost의 DB를 sqlite3를 사용하고 있어 DB 파일이 저장될 위치인 공간을 node에 생성한다.\nvolume.yaml kind: PersistentVolume apiVersion: v1 metadata: name: ghost-pv-volume labels: type: local spec: storageClassName: manual capacity: storage: 12Gi accessModes: - ReadWriteOnce hostPath: path: \u0026quot;/home/cychong/Dropbox/Apps/ghost/content\u0026quot; cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl apply -f volume.yaml [sudo] password for cychong: persistentvolume/ghost-volume created cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-volume 12Gi RWO Retain Available manual 17s pvc-942cf467-7906-11e9-8f0b-00264a162bca 20Gi RWX Delete Bound container-registry/registry-claim microk8s-hostpath 28h  특정 volume 정보만 확인하려면 get pv 뒤에 volume 이름을 지정한다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv ghost-volume NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-volume 12Gi RWO Retain Available manual 24s  특정 volume 삭제하려면 delete pv [volume-name]을 사용한다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv-volume 12Gi RWO Retain Available manual 4s ghost-volume 12Gi RWO Retain Available manual 20m pvc-942cf467-7906-11e9-8f0b-00264a162bca 20Gi RWX Delete Bound container-registry/registry-claim microk8s-hostpath 28h cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl delete pv ghost-volume persistentvolume \u0026quot;ghost-volume\u0026quot; deleted cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv-volume 12Gi RWO Retain Available manual 112s pvc-942cf467-7906-11e9-8f0b-00264a162bca 20Gi RWX Delete Bound container-registry/registry-claim microk8s-hostpath 28h  Volume Claim volume-claim.yaml\nPod에서 PV를 사용하려면 PVC(Persistent Volume Claim)을 설정한다. 앞에서 본 volume.yaml과 유사하지만 requests를 통해 일정 크기(아래는 10G)를 요청한다.\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: ghost-pv-claim labels: type: local spec: storageClassName: manual accessModes: - ReadWriteOnce resources: requests: storage: 10Gi cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl apply -f volume-claim.yaml persistentvolumeclaim/ghost-pv-claim created  Claim 된 Volume의 상태 확인 get pv 명령으로 volume의 상태를 확인하면 이전에는 STATUS가 Available이었던 것이 Bound로 변경된 것을 알 수 있다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv ghost-pv-volume NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv-volume 12Gi RWO Retain Bound default/ghost-pv-claim manual 3m40s  get pvc 명령으로 확인하면 claim된 volume에 대한 정보를 확인할 수 있다.\ncychong@mini1:~$ sudo microk8s.kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ghost-pv-claim Bound ghost-pv-volume 12Gi RWO manual 146m  Deploy 이제 실제 container를 이용한 Pod를 구성한다.\nPod를 직접 생성하고 Container를 실행할 수도 있지만, 이 경우 Pod의 상태를 확인하여 다시 실행해 주는 kubernetes의 관리 기능을 이용할 수 없다.\ndeployment.yaml 동시에 하나의 ghost container만 띄우면 되므로 아래와 같이 replicas를 1로 지정한다.\n그 외 deploy할 때 항상 최신 docker image를 다운 받도록 imagePullPolicy를 Always 로 설정한다.\nContainer에 넘길 환경 변수 등은 env 항목을 통해 넘길 수 있고, 위에서 생성한 volume cliam을 ghost-content라는 이름으로 지정한 후 mountPath를 이용하여 container의 특정 위치에 마운트되도록 한다.\n즉 ghost-pv-volume → ghost-pv-claim → ghost-content→ ghost\napiVersion: apps/v1 kind: Deployment metadata: name: ghost labels: app: ghost spec: replicas: 1 selector: matchLabels: app: ghost template: metadata: labels: app: ghost spec: containers: - name: ghost image: ghost imagePullPolicy: Always ports: - containerPort: 2368 env: - name: url value: http://sosa0sa.com:2368 - name: NODE_ENV value: production volumeMounts: - mountPath: /var/lib/ghost/content name: ghost-content volumes: - name: ghost-content persistentVolumeClaim: claimName: ghost-pv-claim cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl apply -f deployment.yaml [sudo] password for cychong: deployment.apps/ghost created cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pods NAME READY STATUS RESTARTS AGE ghost-79b8c8979d-7m7fm 0/1 ContainerCreating 0 9s cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE ghost 0/1 1 0 71s  시간이 지나면 READY 상태가 1/1로 변경되고, AVAILABLE 값이 역시 0에서 1로 변경된다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pods NAME READY STATUS RESTARTS AGE ghost-79b8c8979d-7m7fm 1/1 Running 0 90s cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE ghost 1/1 1 1 92s  이제 Pod/container는 정상적으로 실행이 된 상태\n만일 ghost라고 명명된 Pod이 비정상 상태가 되면 자동으로 다른 Pod를 실행시킨다.\ncychong@mini1:~/work/ghost-in-k8s$ sudo microk8s.kubectl get pods NAME READY STATUS RESTARTS AGE default-http-backend-5769f6bc66-jpcfj 1/1 Terminating 0 27h ghost-79b8c8979d-7m7fm 1/1 Running 0 29h cychong@mini1:~/work/ghost-in-k8s$ sudo microk8s.kubectl delete pod ghost-79b8c8979d-7m7fm pod \u0026quot;ghost-79b8c8979d-7m7fm\u0026quot; deleted ^Z [1]+ Stopped sudo microk8s.kubectl delete pod ghost-79b8c8979d-7m7fm cychong@mini1:~/work/ghost-in-k8s$ bg [1]+ sudo microk8s.kubectl delete pod ghost-79b8c8979d-7m7fm \u0026amp; cychong@mini1:~/work/ghost-in-k8s$ sudo microk8s.kubectl get pod NAME READY STATUS RESTARTS AGE default-http-backend-5769f6bc66-jpcfj 1/1 Terminating 0 27h ghost-79b8c8979d-468d2 1/1 Running 0 76s ghost-79b8c8979d-7m7fm 1/1 Terminating 0 29h  위 예에서는 기존에 동작하고 있던 pod을 삭제하니(정상적으로 삭제가 되지 않아 STATUS가 Terminating 상태로 표시되고 있다. 확인 필요)\nkind: Pod or kind: deployment?\nPod를 직접 생성하는 yaml 파일을 만들어 사용할 수도 있지만 상용에서는 직접 pod를 만들기 보다 deployment를 통해 pod를 생성하고 pod를 관리한다.\nIn kubernetes what is the difference between a pod and a deployment?\nService ghost는 Cluster 외부에서 접속이 필요한 블로그 서비스이므로 외부에서 접속이 가능하도록 external IP를 가질 수 있게 service를 구성한다.\nservice.yaml apiVersion: v1 kind: Service metadata: name: ghost spec: type: LoadBalancer selector: app: ghost ports: - protocol: TCP port: 2368 targetPort: 2368  type:LoadBalancer를 적용하면 외부 통신에 대해 Load Balancer를 사용하여 자동으로 EXTERNAL-IP가 설정된다고 한다.\nhttps://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types\n LoadBalancer: Exposes the service externally using a cloud provider’s load balancer. NodePort and ClusterIP services, to which the external load balancer will route, are automatically created.\n How to install Kubernetes dashboard on external IP address?\n하지만 위 파일을 적용했는데 EXTERNAL-IP 정보가 pending으로 나온다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl apply -f service.yaml service/ghost created cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ghost LoadBalancer 10.152.183.119 \u0026lt;pending\u0026gt; 2368:30126/TCP 3s kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 32h  웹 브라우저를 이용해서 Cluster 외부에서 접속(ghost Pod가 deploy된 mini1 머신의 IP로 접속)을 시도해 보지만 접속이 안된다.\n아무래도 저 pending 상태로 나오는 게 이상한데 혹시나 하고 검색을 해 보니 역시나 저렇게 되면 외부에서 접속이 안된다고. 그 이유로 처음에 사용한 service 파일에서 사용된 LoadBalancer type이 microk8s에서는 지원되지 않기 때문이라고 한다. 추가로 load balancer를 설치해도 여전히 안된다고\u0026hellip;\n ktsakalozos commented on Nov 23, 2018 Hi @khteh , Kubernetes does not provide a loadbalancer. It is assumed that loadbalancers are an external component [1]. MicroK8s is not shipping any loadbalancer but even if it did there would not have been any nodes to balance load over. There is only one node so if you want to expose a service you should use the NodePort service type.\n microk8s does not support LoadBalancer nginx loadbalancer service EXTERNAL-IP is always in \u0026ldquo;pending\u0026rdquo; state · Issue #200 · ubuntu/microk8s\nkubernetes service external ip pending\nPublishing Service Type 변경 service.yaml 파일의 Publishing Service Type을 microk8s에서 지원되는 NodePort로 변경한 후 다시 appy한 후 다시 접속을 시도하지만 여전히 접속이 되지 않는다.\nService 수정해서 External IP 강제 지정 Node의 EXTERNAL-IP 정보가 여전히 빈칸으로 나온다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME mini1 Ready \u0026lt;none\u0026gt; 35h v1.14.1 192.168.1.100 \u0026lt;none\u0026gt; Ubuntu 18.04.2 LTS 4.15.0-48-generic containerd://1.2.5  원래(?) service 에서 NodePort 타입으로 지정하고 port 만 지정하면 Cluster 외부에서 접속이 되어야 하는데 이것 때문에 안되는 듯 하다.\n그래서 결국 임시로 service.yaml 수정해서 external IP를 강제로 지정했다. exteranlIPs이므로 배열 형태로 지정 한다.\napiVersion: v1 kind: Service metadata: name: ghost spec: type: NodePort externalTrafficPolicy : Local externalIPs : [192.168.1.100] selector: app: ghost ports: - protocol: TCP port: 2368 targetPort: 2368  변경된 service.yaml을 적용한 후 service 내용을 확인하면 EXTERNAL-IP 정보가 변경된 것을 확인할 수 있다.\ncychong@mini1:~/work/ghost-in-k8s$ sudo microk8s.kubectl get svc -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR ghost NodePort 10.152.183.119 192.168.1.100 2368:30126/TCP 4h54m app=ghost kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 37h \u0026lt;none\u0026gt;  이제 Cluster 외부에서도 node의 EXTERNAL-IP를 이용해서 접속할 수 있다.\nmetalLB를 사용하는 것이 대안일까? ingress 서비스를 enable하고, ngnix를 추가로 설치한다.\nhttps://kndrck.co/posts/microk8s_ingress_example/\ngithub 위에서 사용된 모든 YAML 파일은 아래 위치에서 확인할 수 있다.\ncychong47/ghost-in-k8s\n","id":24,"section":"posts","summary":"Install microk8s MicroK8s - Fast, Light, Upstream Developer Kubernetes 설치는 위 링크에 있는 공식 홈페이지에 있는 대로 snap 명령어 하나로 간단하게 설치할 수 있다. cychong@mini1:~$ sudo snap install microk8s --classic 2019-05-18T09:43:53+09:00 INFO Waiting for restart... microk8s v1.14.1 from Canonical","tags":["ghost","kubernetes","microk8s"],"title":"Setup Ghost in microk8s","uri":"https://cychong47.github.io/2019/05/setup-ghost-in-microk8s-2/","year":"2019"},{"content":"ghost blog를 구성해서 사용한 게 벌써 2014년 이다. 당시 0.x 버전 이었던 초반에는 얼마 못 가고 사라지지 않을까 걱정했는데 한참을 1.0버전을 발표하지 않더니 벌써 2.x 버전이다.\n그동안 내가 ghost 블로그를 운용하는 방식도 몇 번의 변화를 가졌다.\n시즌 1 - brew \u0026amp; tar-ball 처음에는 매뉴얼 대로 직접 Node.js와 ghost 소스를 이용해서 직접 OS X에 설치해서 운용했다.\n시즌 2 - Docker 그러다 Node.js 버전이 꼬이는 것도 그렇고, docker를 쓰면 ghost 버전이 새로 나왔을 때 편할 듯 해서 docker를 쓰는 방식으로 변경했다. 이 시점에 docker의 stateless 속성을 이용하고, 데이터의 백업도 고려해서 ghost content는 Dropbox에 두고, docker 실행할 때 volume으로 마운트 하는 방식을 사용했다. 그 당시 ghost보다 먼저 운용하고 있던 wordpress도 함께 docker로 실행 환경을 바꿨다. wordpess는 ghost와 달리 MySql을 필요로 해서 docker-compose를 이용해서 두 개의 container를 연동해서 실행했다.\n시즌 3 - Ansible로 remote deploy 이 당시에 ghost 블로그가 실행되는 mac mini 2011이 아닌 MacBookPro 2017에서 주로 작업을 하고 있던 터라 MacBookPro에서 mac mini에 로그인해서 작업하는 것도 귀찮아 원격(?)으로 ghost 업데이트를 하기 위해 ansible을 이용해서 ghost를 deploy 할 수 있게 했다.\n시즌 4 - Deploy with kubernetes docker, ansible로 실행 환경을 구성해 놓은 덕에 ghost와 wordpress를 기존에 Mac OS X의 docker for Mac을 사용하던 mini2 에서 Ubuntu를 설치한 mini1으로 별 다른 문제 없이 쉽게 옮길 수 있었다.\nDocker for Mac 보다 훨씬 안정적인 docker 덕에 아무런 문제 없이 쓰고 있었는데 괜히 kubernetes 환경으로 꾸며보고 싶었다. 개인 블로그라 특별한 장점이 있을까 싶긴 하지만, kubernetes 공부도 할 겸해서 바꿔보기로 했다. 눈으로만 익히고 입개발만 하기 보다는 직접 해보는 게 남는 게 많을 거라 내가 가진 환경에서 kubernetes를 운용할 수 있는 방법부터 찾아 봤다.\n내 환경\n집에 있는 머신 들은 다음과 같다.\n Mac mini1 2009 - Ubuntu 18.04 LTS. 현재 ghost, wordpress 블로그 운용 중 Mac mini2 2011 - OS X HP mini PC - Windows 10 MacBook Pro 2017 - OS X  kubernetes의 기본 환경 구성이 Master와 Node라 대개 2개의 머신을 기본으로 요구한다. 한 대의 머신으로도 kubernetes를 구성할 수 있는 MiniKube등이 있지만 VM을 기반으로 하는 거라 벌써 연식이 10년이 넘은 mini1에서 돌리기에는 부담이 되보였다. 그래서 Docker for Mac이 설치되어 있는 mini2를 master로 하고, mini1을 node로 사용하는 방법을 생각하고 시도해봤다. 하지만 아직 Docker for Mac은 node를 추가하는 건 지원하지 않는다고. 그럼 worker node를 mini2에서 돌려야 한다는 건데 굳이 다시 mini2으로 container 실행 환경을 돌리고 싶지는 않았다.\n그래서 mini2만으로 kubernetes를 구성할 수 있는 방법을 찾아 보다 microk8s를 적용해 보기로 했다. Canonical에서 공개한 kubernetes 실행 환경인데 local machine에서 실행할 수 있도록 경량화 한 것이 특정이라고 한다.\n It’s not elastic, but it is on rails. Use it for offline development, prototyping, testing, or use it on a VM as a small, cheap, reliable k8s for CI/CD. Makes a great k8s for appliances - develop your IoT apps for k8s and deploy them to MicroK8s on your boxes.\n 기본적인 설치는 snap 을 이용하는데 https://microk8s.io/ 페이지에 있는 명령을 이용하면 간단하게 kubernetes 환경 구성이 가능하다.\nGhost를 kubernetes에 설치하는 것이 내가 처음은 아닐 듯 해서 검색해 보니 How to run Ghost in Kubernetes 이런 글이 나왔다. 2018년 12월 글이라 크게 달라진 점은 없을 듯 해서 kubernetes.io의 글과 이 글을 이용해서 하나 하나 따라갔다. 결론적으로 내가 구성한 환경 역시 이 분이 작성하신 것과 큰 차이가 없지만 한가지 차이점 때문에 몇 시간을 헤매야 했다. 이글은 Digital Ocean 환경에서 제공하는 kubernetes를 이용하여 ghost를 구성했는데 내가 구성한 환경은 microk8s였다. 가장 큰 차이점 중 하나가 microk8s는 외부에 서비스를 expose할 때 사용할 수 있는 방식 중 LoadBalancer를 원하지 않는다는 점이다.\n자세한 설치기는 to be continued\u0026hellip;\n","id":25,"section":"posts","summary":"ghost blog를 구성해서 사용한 게 벌써 2014년 이다. 당시 0.x 버전 이었던 초반에는 얼마 못 가고 사라지지 않을까 걱정했는데 한참을 1.0버전을 발표하지 않더니 벌","tags":["ghost","kubernetes"],"title":"ghost deployment season 4","uri":"https://cychong47.github.io/2019/05/ghost-deployment-season-4/","year":"2019"},{"content":"Kubernetes Networks in google docs\n이거 보면 IPv6를 사용해야 하는 경우 선택할 수 있는 CNI는 Calico, Cillium, Contiv, Tungsten Fabric 정도로 좁혀지네\n","id":26,"section":"posts","summary":"Kubernetes Networks in google docs 이거 보면 IPv6를 사용해야 하는 경우 선택할 수 있는 CNI는 Calico, Cillium, Contiv, Tungsten Fabric 정도로 좁혀지네","tags":["kubernetes","cni"],"title":"Kubernetes Networks","uri":"https://cychong47.github.io/2019/05/kubernetes-networks/","year":"2019"},{"content":"https://zaverome.wordpress.com/2019/01/09/%EC%95%84%EB%A7%88%EC%A1%B4-3%EB%85%84-%EC%B6%9C%EA%B7%BC%EA%B8%B0-1-%ED%95%98%EB%A3%A8-%EC%9D%BC%EA%B3%BC-%EB%B0%8F-%EC%9A%94%EC%95%BD/\n인상적인 내용들\n 매일 하는 스탠드업 미팅(데일리 스크럼)은 오후 4시입니다.\n 오후 4시에 하는 데일리 미팅이라. 신기하다. 보통 오늘 할 일과, 이슈 등을 이야기하는 것이 잘 알려진 daily meeting의 practice인데 오후에 한다니. 아래 내용을 보면 야근도 안 한다는데. 흠.. 신기하네\n 아마존에서 일한 이래 일이 많아서 사무실에 늦게까지 남아 야근을 한 일은 한 번도 없습니다. 일년에 두 세번 정도 일이 좀 남아서 퇴근 후에 집에서 한 두시간 정도 일을 한 적은 있습니다.\n 어떻게 이게 가능할까? 정말 업무를, 과제를 팀 능력에 맞게 잘 계획해서?\n시장(?)이나 어떤 이유로 인해 빠른 개발을 요구받는 경우도 없나? 분명히 야근은 없다고 했는데. 아마도 B2B지만, 고객의 기능, 일정 요구에 맞춰서 개발을 진행하는 것이 아니라 우리 팀의 개발 일정에 맞게 진행해서 그런 것이 아닌가 싶다. 그게 아니라면 어떻게 가능할까??\n이런 걸 신기하다고 생각하는 나, 내가 속한 조직이 이상한 걸까? 아니면 저런 조직이 특이한 걸까? 지난 번에 샌프란시스코에서 본 후배도 비슷하게 일하는 걸 보면 아마존만 이상하거나 특이한 건 아닌 듯 한데. 그렇다고 내가 속한 조직만 그런 건 아니고 옆, 그 옆 그리고 그 옆옆 부서도 그런 걸 보면 적어도 내가 있는 건물에 있는 우리 회사는 대부분 저 아마존하고 다른 건 확실한데.\n 코드 리뷰에 열심히 참여할 수록 팀에서의 영향력이 증가합니다.\n 중요한 내용이네. 코드를 많이 알수록 팀의 업무를 많이 알게 되는 거라 그 만큼 할 수 있는 일이 많아진다는 뜻인 듯.\n 시니어 엔지니어일 수록 본인이 직접 코드를 작성하는 시간보다 아키텍쳐 리뷰, 디자인 리뷰, 코드 리뷰 등을 통해 간접적으로 코드를 작성하는 시간이 길어지게 됩니다. 참고로, 아마존의 최상위 엔지니어 등급인 프린시플 엔지니어들은 대부분의 시간을 문서 리뷰 혹은 멘토링에 할애한다고 합니다.\n 우리와는 다른 의미의 prinipal engineer. 아무튼 경력/경험이 많아질 수록 리뷰하는데 많은 시간을 보낸 다는 것. 우리 회사도 그렇기는 한 듯.\n 팀의 분위기는 스타트업과 비슷합니다. 신규 서비스이기 때문에 개발팀 스스로 요구사항을 정의하고, 사용자 패턴을 상상해 서비스를 만들어 나가고 있습니다.\n 글을 쓴 사람이 속한 팀 성격이 새로운 서비스를 만드는 팀이라서 그렇다고 하네. 여기서 말하는 서비스가 어떤 정도의 크기인지는 잘 모르겠지만, 새로운 캐시카우가 되길 바란다는 정도면 그래도 하나의 단독적인 서비스라고 생각이 되지만 우리 회사가 일하는 과제보다는 사이즈가 작지 않을까 하는 예상.\n 13 포인트가 한 사람이 한 스프린트에서 수행할 수 있는 최대 포인트로 상정하고 이에 기반해 팀 토론을 거쳐 사이즈를 예측합니다. 또한, 단일 이슈가 13포인트 이상이 되면 세부 이슈로 나눕니다.\n Sprint 주기를 2주라고 했는데 그럼 하나의 이슈가 2주일 짜리도 가능하다는 이야기인가? 그리고 여기서 말하는 13포인트는 어디서 나온 걸까? 피보나치 수에서 가져왔다고 하는데(scrum에서 흔히 사용하는 story point인 듯 하긴 하네, https://wormwlrm.github.io/2018/09/09/Scrum-tutorial-for-adapting-agile-methodologies.html, https://ko.popularhowto.com/estimating-end-of-scrum-projects-with-fibonacci-numbers-and-story-points) 좀 더 공부해 봐야 할 듯.\n 스프린트가 종료되면 각자가 해당 스프린트에서 완료한 작업을 간단히 시연합니다. 또한, 해당 스프린트 동안 잘 된일, 개선할 수 있는 일들을 논의하고, 액션 아이템을 도출합니다.\n 요즘 시연을 하는 게 별로 없었는데 다시 좀 활성화시키면 좋겠다. 다들 개발자다 보니 뭔가 동작하는 걸 만들면 조금 더 성취감을 느끼지 않을까?\n 아마존의 개발팀은 시니어 엔지니어와 매니저(팀장)가 이끈다고 볼 수 있습니다. 팀장과 시니어 엔지니어 모두 부장 정도의 레벨이라고 보면 될 것 같습니다. 이 중 시니어 엔지니어는 일을 ‘어떻게’ 할 것인지(컴포넌트 구성, 소프트웨어 디자인, 인터페이스 등)를 결정한다면, 매니저는 ‘무엇을’ 할 것인지를 결정합니다. 주로 일의 우선 순위 관리가 이에 해당하겠지요. 그렇기 때문에 매니저는 기술적인 구현에 거의 관여하지 않고, 시니어 엔지니어가 이를 주도합니다. 팀장의 큰 역할 중 하나는 팀내 개발자들의 ‘관리’입니다. 개별 개발자가 본인의 일을 잘 할 수 있도록 불필요한 일들을 치워 주거나, 다른 팀의 역할이 필요한 경우 해당 팀을 설득하거나 혹은 개발자가 성장할 수 있도록 적절한 일을 맡기는 등의 일입니다.\n 아무래도 난 매니저로서의 시니어 엔지니어가 그나마 더 가망이 있어 보이는데. 아직도 개발자 마인드가 크게 남아 있어 여전히 전략적으로 말하지 못하고(물어보면 신나서 아는 거 다 이야기하는 개발자 속성) 설득력있는 논리를 만드는 능력이 부족하다. 때(?)로는 만들어진 논리가 순리를 이기는 경우가 많은 데 아직도 \u0026lsquo;옳은 게 맞는 거다\u0026rsquo;라는 생각을 버리지 못한다.\n하지만 개발이던 매니징이던 다 잘하는 사람이 있는 걸 보면 그냥 이건 핑계일 뿐, 내 능력이 부족해서 그런거라\u0026hellip;\n오늘도 한숨 100번 하고\n","id":27,"section":"posts","summary":"https://zaverome.wordpress.com/2019/01/09/%EC%95%84%EB%A7%88%EC%A1%B4-3%EB%85%84-%EC%B6%9C%EA%B7%BC%EA%B8%B0-1-%ED%95%98%EB%A3%A8-%EC%9D%BC%EA%B3%BC-%EB%B0%8F-%EC%9A%94%EC%95%BD/ 인상적인 내용들 매일 하는 스탠드업 미팅(데일리 스크럼)은 오후 4시입니다. 오후 4시에 하는 데일리 미팅이라. 신기하다. 보통 오늘 할 일과, 이슈 등을 이야기","tags":["manager","amazon","scrum"],"title":"(펌글) 아마존 3년 출근기","uri":"https://cychong47.github.io/2019/05/amazon-daily-work/","year":"2019"},{"content":"최고령 Mac은 아니고 세 번째 고령 가장 오래된 Mac은 2005년에 구입한 Powerbook. PowerPc processor를 사용한 마지막 Apple의 laptop. 그 다음 오래된 것은 iMac 2007. 하지만 이 두 녀석들은 현재 꺼진 상태로 방치되고 있어, 현역은 Mac mini 2009라는. 당시에 리퍼를 구입했던 걸로 기억하는데 10년이 지난 2019년에도 유용하게 사용하고 있다는 게 너무 신기하다.\n한글 글꼴 Firefox 등에서 한글 글꼴이 없어 한글 페이지가 깨져서 나눔고딕을 설치 이것 저것 찾아보다 https://blog.inidog.com/p/20170131169 참고해서 한번에 해결했다.마지막 명령어 fc-cache -r 을 수행하는 도중 firefox의 한글 페이지에서 깨진 한글 글꼴이 예쁜 나눔고딕으로 변하는 모습은 감동(?)이었다\u0026hellip;\n# 폰트 설치 경로로 이동합니다. cd /usr/share/fonts/ # 나눔고딕 폰트 파일을 다운로드합니다. wget http://cdn.naver.com/naver/NanumFont/fontfiles/NanumFont_TTF_ALL.zip # 나눔고딕 폰트 파일의 압축을 해제합니다. unzip NanumFont_TTF_ALL.zip -d NanumFont # 사용이 끝난 압축파일을 삭제합니다. rm -f NanumFont_TTF_ALL.zip # 시스템 폰트 리스트를 갱신합니다. fc-cache -r  ","id":28,"section":"posts","summary":"최고령 Mac은 아니고 세 번째 고령 가장 오래된 Mac은 2005년에 구입한 Powerbook. PowerPc processor를 사용한 마지막 Apple의 laptop. 그 다음 오래된 것은 iMac 2007. 하지","tags":["Mac mini 2009","linux","ubuntu"],"title":"Install Ubuntu 18.04.1 in Mac mini 2009","uri":"https://cychong47.github.io/2019/02/install-ubuntu-18-04-1-in-mac-mini-2009/","year":"2019"},{"content":"https://doc.dpdk.org/guides-18.11/rel_notes/release_18_11.html\nNew Features Updated the C11 memory model version of the ring library. Added changes to decrease latency for architectures using the C11 memory model version of the ring library.\nOn Cavium ThunderX2 platform, the changes decreased latency by 27-29% and 3-15% for MPMC and SPSC cases respectively (with 2 lcores). The real improvements may vary with the number of contending lcores and the size of the ring.\nAdded support for device multi-process hotplug. Added support for hotplug and hot-unplug in a multiprocessing scenario. Any ethdev devices created in the primary process will be regarded as shared and will be available for all DPDK processes. Synchronization between processes will be done using DPDK IPC.\nAdded Event Ethernet Tx Adapter. Added event ethernet Tx adapter library that provides configuration and data path APIs for the ethernet transmit stage of an event driven packet processing application. These APIs abstract the implementation of the transmit stage and allow the application to use eventdev PMD support or a common implementation. Added Distributed Software Eventdev PMD.\nAdded Distributed Software Eventdev PMD. Added the new Distributed Software Event Device (DSW), which is a pure-software eventdev driver distributing the work of scheduling among all eventdev ports and the lcores using them. DSW, compared to the SW eventdev PMD, sacrifices load balancing performance to gain better event scheduling throughput and scalability.\nAdded Telemetry API. Added a new telemetry API which allows applications to transparently expose their telemetry in JSON via a UNIX socket. The JSON can be consumed by any Service Assurance agent, such as CollectD.\nRefer to https://doc.dpdk.org/guides-18.11/howto/telemetry.html\nKnown Issues AVX-512 support has been disabled for GCC builds [1] because of a crash [2]. This can affect native machine type build targets on the platforms that support AVX512F like Intel Skylake processors, and can cause a possible performance drop. The immediate workaround is to use clang compiler on these platforms. The issue has been identified as a GCC defect and reported to the GCC community [3]. Further actions will be taken based on the GCC defect result. [1]: Commit 8d07c82b239f (“mk: disable gcc AVX512F support”) [2]: https://bugs.dpdk.org/show_bug.cgi?id=97 [3]: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=88096\n","id":29,"section":"posts","summary":"https://doc.dpdk.org/guides-18.11/rel_notes/release_18_11.html\nNew Features Updated the C11 memory model version of the ring library. Added changes to decrease latency for architectures using the C11 memory model version of the ring library.\nOn Cavium ThunderX2 platform, the changes decreased latency by 27-29% and 3-15% for MPMC and SPSC cases respectively (with 2 lcores). The real improvements may vary with the number of contending lcores and the size of the ring.\nAdded support for device multi-process hotplug.","tags":["DPDK"],"title":"DPDK 18.11","uri":"https://cychong47.github.io/2019/01/dpdk-18-11/","year":"2019"},{"content":"p12 학교 학습 vs. 야생 학습  야생 학습은 대부분 자료에 한정이 없다.\n야생 학습은 대부분 명확한 평가가 없다.\n야생 학습은 대부분 정답이 없다.\n야생 학습은 대부분 목표가 불분명하고 바뀌기도 한다.\n 학습의 본질은 야생 학습에 더 가깝다고 생각. 현실 세계에서는 야생 학습이 더 많이 필요하다고 봅니다.\np23  구조화된 인터뷰(특별히 구조화된 행동중심적 인터뷰를 권함)와 실제 작업을 해보도록 하는 작업 샘플 테스트, 그리고 가능하다면 실제 업무를 주고 시험적으로 짧은 기간 동안 일을 해보게 하는 것 등을 권합니다.\n p30  그는 상당한 시간을 자기 환자를 확인하는 데에 보내면서, 진단 시에 자신이 무얼 생각하는 지 많은 기록을 하고, 자신이 얼마나 정확한 지 나중에 확인을 하더군요. 자신이 만든 이 부차적 단계가 그를 자신의 동료들로부터 차별화되는 중요한 점입니다.\n p31  일 년 회고를 할 때 항상 되짚어 보는 것 중 하나가 나 자신에게 얼마나 투자를 했나 하는 것입니다.\n자기계발이 왜 중요하나고 생각하냐면, 현재 나에게 무엇을 투자했느냐가 1년, 혹은 2년 후에 나를 결정한다고 느끼기 때문입니다.\n p33 작업 구분 Douglas Engelbart - 작업을 세 가지 수준으로 구분.\n A작업 : 원래 그 조직이 하기로 되어 있는 일을 하는 것 B작업 : A작업을 개선하는 것. 제품을 만드는 사이클에서 시간과 품질을 개선하는 것. 제품을 만드는 시스템을 잘 설계하는 것도 포함 C작업 : B작업을 개선하는 것. 개선 사이클 자체의 시간과 품질을 개선하는 것. 개선하는 인프라를 설계하는 것. 개선하는 능력을 개선하는 것   우리가 더 잘하는 것을 더 잘하게 될수록 우리는 더 잘하는 걸 더 잘 그리고 더 빨리 하게 될 것이다.\n Peter Senge\n A작업 : 겉으로 가장 잘 드러나는 수준으로 한 회사의 제품과 서비스의 개발, 생산, 판매와 관련이 있다. 그 회사의 사람과 자원의 대부분은 이 수준에 초점이 맞춰져 있다. B작업 : 회사가 자신의 제품과 서비스를 개발, 생산, 판매하는 걸 가능케 해주는 시스템과 프로세스를 설계하는 것과 관련 C작업 : 우리의 사고방식과 상호 작용 방법을 개선. C작업의 품질이 우리가 설계하는 시스템과 프로세스의 품질을 결정짓고, 나아가 우리가 제공하는 제품과 서비스의 품질을 결정짓는다.  p35 복리 조직이 일하는 구조  동일한 조직이 매달 동일한 수준의 결과를 만드는 것이 아니라 지난 달 보다 발전된 수준에서 결과물을 만들어 냄. 그 다음 달은 더 높은 수준에서 결과물을 만들어 냄.\n 매일 내가 더 나은 내가 되어 감. 복리의 효과. 지수적 증가\n지수적 팀 자기 자신을 곱해나가는 팀.\n부분의 합보다 전체가 크려면 시너지가 필요함. 상호 협력적으로 일하기.\n 가용 시간을 늘리고, 쓸데없이 낭비되는 시간을 줄이고, 잠자는 시간을 줄이는 것이 더하기적 사고라면, 집단의 지능을 높히는 것은 곱하기적 사고 . 집단의 지능을 높히면 모든 지적 활동의 효율이 좋아지기 때문에 전반적인 개선(B작업)이 일어나고, 특히나 개선 작업을 더 잘하게(C작업) 된다.\n  자신의 평소 투자하는 비용을 한번 살펴본다. B작업, C작업에 투자하는 것이 거의 없다면 후퇴하는 셈이 된다.\n   자신이 이미 갖고 있는 것들을 잘 활용한다. 새로운 것을 유입하는 데만 집중하지 말고. 책 권 수보다는 책에서 얻은 지식을 어떻게 활용하는 지 반성. 이미 가지고 있는 것들을 하이퍼링크로 서로 촘촘히 연결. 이미 습득한 지식, 기술, 경험 등을 서로 연결해서 시너지 효과가 나게 하고, 다른 영역 간을 넘나들기 수월하게 만들 것\n  외부 물질을 체화 주기적이 외부 자극. 단 재빨리 자기화.\n  자신을 개선하는 프로세스에 대해 생각 주기적으로 나의 A작업을 회고/반성. 나를 개선하는 과정(B 작업)을 어떻게 하면 개선할 수 있을 지 고민\n  피드백을 자주 받을 것 사이클 타임을 줄일 것. 일찍, 자주 실패할 것. 실패에서 학습할 것.\n  자신의 능력을 높여주는 도구와 환경을 점진적으로 만들 것 활용 가능한 환경/툴 등을 구축\n  p43  동일한 자극/조건이 주어졌을 때 누군가는 더 많은 학습과 성장의 기회를 찾고 오히려 그 조건을 자신에게 유리한 조건으로 생각하기도 한다.\n 인공지능에서 살아남으려면  독창성 : 주어진 주제나 상황에 대해 특이하거나 독창적인 생각을 해내기. 혹은 문제를 해결하는 창의적인 방법을 만들기 사회적 민감성 : 타인의 반응을 알아차리고 그 사람들이 왜 그렇게 반응하는 지 이해하기 협상 : 사람들을 화해시키고 서로 간의 차이를 조정하려고 노력 설득 : 다른 사람들이 마음이나 행동을 바꾸게 설득하기 타인을 돕고 돌보기   자신이 주로 하는 일이 남이 시킨 대로 혼자 프로그램을 만드는 것이라면 그런 스킬과 경력만 계속 쌓일 것입니다.\n  현재 자신의 업무 상황 속에서 창의적으로 그리고 사회적으로(다른 사람의 생각과 마음에 관심을 갖고 그들을 설득하고 협상하고 하는 것) 일하지 않는 기간이 계속된다면 결국 자신의 커리어에 막대한 손해가 될 수 있다는 점이다. 혼자서 딱 정해진 일만 할 수 있는 환경이 축복이 아니라 저주가 될 수 있다.\n p65 제자리걸음에서 벗어나기 작업 난이도 * 실력\n 지루함을 느끼는 경우(실력 \u0026gt; 난이도)  실력 낮추기 - 일부러 제약조건을 둠, 마우스 사용 불가. 디버거 안 쓰기 등 난이도를 높이기 - 요구 사항 상향, 안해도 되는 업무를 자신의 의지로 추가 - Job Crafting - 리펙토링, 자동화 테스트, 자신만의 도구 개발 등   불안함을 느끼는 경우 (난이도 \u0026gt; 실력)  실력 높이기 - 짝 프로그래밍, 도구 사용(좋은 디버거, 코드 분석툴 등), 난이도 낮추기 - 맡은 일의 가장 간단하면서 핵심적인 결과물을 첫번째 목표로 작업(What\u0026rsquo;s The Simpliest Thing That Could Possibly Work?)    p74  팀장들은 팀원의 상태를 파악하고 그들이 몰입으로 가게 도와주는 것 자체가 고도의 의도적 수련이 될 수 있다.\n  이상적으로는 그 사람의 실력에 맞는 난이도의 일을 나눠주는 걸 생각할 수 있겠지만 현실은 그렇게 딱딱 맞아떨어지지 않는다. 개개인이 자기 스스로 몰입 상태를 조정하는 능력을 키우게 도와주는 것이 더 바람직하지 않을까 싶습니다.\n p90 두 가지의 실무 문화 행동 -\u0026gt; 실수 -\u0026gt; 결과\n 실수 예방 : 행동 -\u0026gt; 실수 실수 관리 : 결과로부터 행동과 실수에 feedback   회사의 문화가 실수 에방보다 관리에 가까울수록 그 기업의 혁신 정도가 더 높다. 그리고 실수 관리 문화일 수록 회사의 수익성이 높아진다.\n  실수를 없으면 학습하지 못한다. 이는 학습이론의 기본. 실수 관리를 하는 문화일수록 학습을 더 잘한다.\n http://agile.egloos.com/5774862 실수 관리 문화를 위한 개인과 조직 수준에서 할 수 있는 구체적인 팁들\nhttp://agile.egloos.com/5822712 음의 생산성\np101  신뢰가 깨어져 있는 상태에서는 어떤 행동을 해도 악의적으로 보인다\n p102  뛰어난 소프트웨어 개발자일수록 타인과 인턴랙션에 더 많은 시간을 쓰며 https://www.researchgate.net/publication/225100027_What_we_have_learned_about_software_engineering_expertise\n 함께 p131 팀 vs. 작업 그룹 팀과 작업 그룹은 경영학에서는 다른 개념으로 사용.\n팀은 구성원간의 소통/협력 네트워크가 그물망에 가까운 반면,\n작업 그룹은 그 네트워크가 중앙(팀장)에서 뻣어나가는 불가사리형\n작업 불확실성이 높을수록 작업 그룹보다는 팀이 좋은 성과를 냄.\nBusiness 불확실성이 높아지면서 대부분 조직이 팀을 표방하게 되었지만, 스스로를 팀이라고 부르는 집단도 실상은 작업 그룹인 경우가 많다.\np116 소프트웨어 개발 비용    항목 내용 개선 효과     도구 SW 개발에 사용하는 모든 종류의 도구. 컴퓨터 모니터, 버그 트래커, IDE, 하향/구조적 개발 기법 2.97   사람 사람들의 능력과 경험 10.55   시스템 제품 자체의 복잡도, 요구되는 신뢰성, DB 크기, target의 변화 가능성, 스케줄 제약 25.76   관리 사람을 배정하고 작업 분배를 조정하고 위임하는 것. 작업 모니터링, 동기를 고취하는 것. 작업 조건/환경을 개선하는 것. 자원의 준비, 리스크를 일찍 확인하고 적절한 조치를 취하는 것. 요구사항과 설계 스펙이 비준되게 돕는 것 64.00    관리자들이 선호하는 개선 노력은 효과 와 정반대\n추상화  워드 커닝햄이 개발한 wikiwiki의 중요성은 그 기술에 있지 않습니다. 기술이 만들어낸 사회 구조의 변화가 기술이 이끌어 낼 사람들 간의 대화에 있습니다. 그리고 그 대화는 우리가 혼자서는 생각하지 못했던 것들을 만들게 해 줄 것입니다.\n p129 신뢰  신뢰 자산이 높은 조직은 커뮤니케이션 효율이나 생산성이 높다.\n신뢰를 쌓는 데 널리 사용되는 한 가지 방법은 투명성과 공유, 인터랙션이다.\n 그러나 단순히 공유하는 것만으로는 신뢰가 쌓이지 않는다. 최소 공유(share one) 혹은 최고 공유(share best)인 경우에는 오히려 신뢰도를 떨어뜨린다. 복수 공유(shared multiple) 방식으로 자신이 가진 것으로 모두 공유하면 피드백에 대한 부담도 적어지고, 수용감도 높아진다.\n설득  남을 설득하려면 논리성과 객관성에 대한 환상을 버려야 한다. 그래야 현실적으로 설득이 가능하다.\n내가 설득하고 싶은 상대를 자주 만나서 신뢰를 쌓고, 그 사람이 무엇을 중요하게 여기는지, 어떤 설명 방식을 선호하는 지 이해해야 한다.\n출발은 결국 내가 설득하려는 사람에게서 하는 것이다. 자료에서 출발하는 것이 아니다.\n 행동을 유도하는 대화 이것도 모르세요가 아니라 상대방의 개선 행동을 유도하는 대화\n\u0026lsquo;코치는 선수가 아니다\u0026rsquo;, 에릭 슈미트, 코치의 중요성\n구글이 밝힌 탁원할 팀의 비밀 구글 Aristole Project\n 팀에 누가 있는 지 보다 팀원들이 서로 어떻게 상호작용하고 자신의 일을 바라보는지가 훨씬 중요 5가지 성공적 팀의 특징. 그 중 압도적으로 높은 예측력을 보인 변수는 팀의 심리적 안정감(Psychological Safety) 팀 토론 등 특별히 공용된 활동을 통해 심리적 안정감을 개선할 수 있다.  Oxygen Project - 뛰어난 관리자의 특징을 찾는 연구(2008~)\ngTeam exercise, 10분간 5가지 성공적인 팀의 특징에 대해 팀원들이 답하고, 팀이 얼마나 잘하는지 요약 보고서를 보고 결과에 대해 면대면 토론을 하고, 팀이 개선하게 자원을 제공하는 것\n심리적 안전감\n 내가 이 일에서 실수를 하면 그걸로 비난을 받는 경우가 많다. 이 조직에서 남들에게 도움을 구하기가 어렵다. 내 관리자는 내가 전에 한 번도 해보지 않은 걸 해내는 방법을 배우거나 혹은 새로운 일을 맡도록 격려하는 경우가 많다. 내가 만약 다른 곳에서 더 나은 일을 구하려고 이 회사를 떠날 생각이 있다면 나는 그에 대해 내 관리자랑 이야기를 나눌 것이다. 내가 나의 관리자에게 문제를 제기하면 그는 내가 해결책을 찾도록 도와주는 일에 그다지 관심을 보이지 않는 경우가 많다.  심리적 안전감을 높이려면 어떻게 해야 할까\n 단순히 우리팀의 현상황에 대해 열린 대화를 시작하는 거만으로 변화가 시작될 수 있음 일상에서의 변확 생기고, 이런 것으로 신뢰가 조금씩 쌓이기 시작한다면, 위에서 나온 \u0026lsquo;특별히 고안된 활동\u0026rsquo;을 시도할 수 있다.  쾌속 학습 단순히 기술적 탁월함을 갖춘 사람보다는 학습 환경을 만들 수 있는 리더가 필요하다\n속도가 빠른 팀은(특히 리더가 중심이 되어) 새로운 수술 도입을 기술적 도전이라기보다 조직적 도전으로 받아들였다. 개개인이 새로운 기술을 획득해야 한다고 보지 않고, 함께 일하는 새로운 방법을 만들어야 한다고 생각했다. 속도라 빠른 팀은 심리적으로 보호가 되어 있다. 뭔가 새로운 것을 제안하고 시도하는 데에 열려 있었고, 실패에 관대했으며 잠재적 문제를 지적하고 실수를 인정하는 데에 부담을 느끼지 않았다.\n팀원들은 모두 팀 퍼포먼스를 높이기 위해 새로운 방식을 실험해 보는 걸 강조했다.\n속도가 빠른 팀은 도전 자체를 팀의 학습 능력에 대한 도전으로 받아들이고, 같이 학습해야 한다고 생각했다. 학습을 팀의 중요한 목표로 받아들였다.\n리더는 기회와 가능성, 큰 변화의 흐름에 동참하는 중요성과 즐거움을 강조\n반면 속도가 느리거나 낙오된 팀은 학습을 개인의 과제로 치부. 학습보다는 단기 퍼포먼스를 중요. 낙오의 위험성을 강조하고, 팀원들의 실력이 부족하다고 불평.\n애자일 고객에게 매일 가치를 전하라.  고객에게  우리의 진짜 고객은 누구인가?   매일  어덯게 점진적으로 가치를 전할 것인가? 어떻게 보다 일찍, 그리고 보다 자주 가치를 전할 것인가?   가치를  무엇이 가치인가? 지금 우리가 하고 있는 일이 정말 가치를 만드는 일인가? 지금 가장 높은 가치는 무엇인가? 비슷한 수준의 가치를 더 값싸게 전달하는 방법은?   전하라  가치를 우리가 갖고 있지 않고, 고객에게 정말 전달하고 있는가? 고객이 정말 가치를 얻고 있는가?    불확실성이 높을수록 빈도가 자주 있어야 한다.\np205 두려워도 중요한다면 시도해 봐야 하지 않을까? 전문가팀은 무섭고 두렵더라도 중요한 일이라면 그 일을 안하는 리스크를 인식하고 꾸준히 시도한다는 점에세 초보팀과 다르다.\np214 만일 ~ 하면 ~ 하라 자신이 관심 있는 분야에 \u0026ldquo;만약 ~하면 ~하라\u0026quot;라는 규칙이 있다면, 해당 분야는 \u0026lsquo;단순한 도메인\u0026rsquo;에 해당한다.\np216 애자일을 애자일스럽게 도입하기  도요타가 도요타일 수 있었떤 것은 칸반 같은 개별 best practice 가 아니라 그런 실천법들이 생겨날 수 있는 문화적 풍토와 생성적 과정 때문이었다. 우리가 배워야 할 것은 칸반 이면의 칸반이 나올 수 있었던 구조와 문화다.\n  애자일을 진행하는 가운데 가장 빈번히 빚어지는 폐단은?\n애자일을 반애자일적으로 진행하는 것. 에컨대 애자일은 불확실한 상황에 대한 접근법인데, 애자일을 도입할 때 확실성 위에서 진행하려고 한다면 문제가 된다.\n애자일 방법론을 도입할 때 뭘 해야 할지 명확하게 알려달라고 한다. 근데 그 모습은 전혀 애자일적이지 않다. 찾아가는 모습이 애자일이다. 어차피 방법론 도입이라는 것이 매우 불확실한 것이기 때문에 정답이 있을 수 없다.\n ","id":30,"section":"posts","summary":"p12 학교 학습 vs. 야생 학습 야생 학습은 대부분 자료에 한정이 없다. 야생 학습은 대부분 명확한 평가가 없다. 야생 학습은 대부분 정답이 없다. 야생 학습은 대부분 목표가 불","tags":["Book","agile","manager"],"title":"함께 자라기","uri":"https://cychong47.github.io/2018/12/grow-together/","year":"2018"},{"content":"http://sosa0sa.com:2368/use-jetpack-for-wordpress-5-0/ 의 연장선. Jetpack plugin의 최신 버전을 알아내서 자동으로 해당 바이너리 파일을 다운로드 받아 보자.\n몇 가지 module 을 사용하는데 필요한 module은 https://realpython.com/python-web-scraping-practical-introduction/ 을 참고해서 설치\n$ python3 -m venv venv $ . ./venv/bin/activate $ pip3 install requests BeautifulSoup4  webscrap.py from requests import get from requests.exceptions import RequestException from contextlib import closing from bs4 import BeautifulSoup from urllib.request import * ''' https://realpython.com/python-web-scraping-practical-introduction/ ''' def simple_get(url): \u0026quot;\u0026quot;\u0026quot; Attempts to get the content at `url` by making an HTTP GET request. If the content-type of response is some kind of HTML/XML, return the text content, otherwise return None. \u0026quot;\u0026quot;\u0026quot; try: with closing(get(url, stream=True)) as resp: if is_good_response(resp): return resp.content else: return None except RequestException as e: log_error('Error during requests to {0} : {1}'.format(url, str(e))) return None def is_good_response(resp): \u0026quot;\u0026quot;\u0026quot; Returns True if the response seems to be HTML, False otherwise. \u0026quot;\u0026quot;\u0026quot; content_type = resp.headers['Content-Type'].lower() return (resp.status_code == 200 and content_type is not None and content_type.find('html') \u0026gt; -1) def log_error(e): \u0026quot;\u0026quot;\u0026quot; It is always a good idea to log errors. This function just prints them, but you can make it do anything. \u0026quot;\u0026quot;\u0026quot; print(e) def download_file(base_url, filename): file_url = '%s/%s' %(base_url, filename) print(\u0026quot;Download %s\u0026quot; %(file_url)) try: from tqdm import tqdm except: urlretrieve(file_url, filename) return # use tqdm to display the progress but too slow file_response = get(file_url, stream=True) with open(filename, 'wb') as handle: for data in tqdm(file_response.iter_content()): handle.write(data)  Jetpack plugin 페이지에 있는 버전 정보를 이용해서 플러그인 다운로드 하기 tqdm은 progress를 보여주는 모듈인데 그냥 사용하면 속도가 너무 너무 느리다. 몇 초면 다운 받을 수 있는 파일을 1분에 걸쳐 받는\u0026hellip;\nget_jetpack.py from webscrap import * ''' https://realpython.com/python-web-scraping-practical-introduction/ https://stackoverflow.com/questions/22676/how-do-i-download-a-file-over-http-using-python ''' if __name__ == '__main__': jetpack_url='https://wordpress.org/plugins/jetpack/' jetpack_ver = None response = simple_get(jetpack_url) if response is not None: html = BeautifulSoup(response, 'html.parser') for i,l1 in enumerate(html.select('li')): if l1.text.strip().find(\u0026quot;Version:\u0026quot;) == 0: jetpack_ver = l1.text.strip().split()[1] break if jetpack_ver is not None: filename = 'jetpack.%s.zip' %jetpack_ver download_file(jetpack_url, filename)  ","id":31,"section":"posts","summary":"http://sosa0sa.com:2368/use-jetpack-for-wordpress-5-0/ 의 연장선. Jetpack plugin의 최신 버전을 알아내서 자동으로 해당 바이너리 파일을 다운로드 받아 보자. 몇 가지 module 을 사용하는데 필요한 module은 https://realpython.com/python-web-scraping-practical-introduction/ 을 참고해","tags":["Python","web-scrapping"],"title":"Get the latest jetpack plugin","uri":"https://cychong47.github.io/2018/12/get-the-latest-jetpack-plugin/","year":"2018"},{"content":"Wordpress 5.0부터 기본 editor가 ghost와 같이 block editor 로 변경됨. Markdown을 사용하려면 이전과 동일하게 Jetpack을 사용해야 하는데 docker에서 wordpress를 돌리고 있는 내 경우 ftp를 통한 plugin 설치가 안되다는\u0026hellip;\n직접 설치는 안되므로 해결 방안은 Jetpack을 따로 받아 설치한 후 docker volume으로 jetpack 디렉토리를 plugins 디렉토리 밑에 마운트 시키는 방법.\n이번 기회에 최신 버전을 받는 방법을 포함해서 정리 해 보자.\nJetpack의 최신 버전 확인 방법 https://wordpress.org/plugins/jetpack/ 을 방문하면 오른쪽 plugin 정보란에서 다음과 같이 최신 버전 정보를 확인할 수 있다.\nVersion: 6.8.1  download wget https://downloads.wordpress.org/plugin/jetpack.6.8.1.zip  다운 받은 jetpack 파일을 적당한 위치에 풀어준다. 내 경우는 wordpress/plugins/jetpack.\nattach to docker ansible을 사용하고 있는 내 경우 다음과 같이 볼륨을 지정한다.\n volumes: ... - \u0026quot;wordpress/plugins/jetpack:/var/www/html/wp-content/plugins/jetpack\u0026quot; ...  restart wordpress docker 끝\u0026hellip;\ntodo Jetpack의 최신 버전 정보를 읽어와서 해당 버전을 다운로드 하는 script를 만들어 봐야겠다. beautifulsoup을 사용하면 되지 않을까?\n","id":32,"section":"posts","summary":"Wordpress 5.0부터 기본 editor가 ghost와 같이 block editor 로 변경됨. Markdown을 사용하려면 이전과 동일하게 Jetpack을 사용해야 하는데 dock","tags":["wordpress","jetpack","markdown"],"title":"Use jetpack for wordpress 5.0","uri":"https://cychong47.github.io/2018/12/use-jetpack-for-wordpress-5-0/","year":"2018"},{"content":"Really good wiki adoption case in NASA\nhttp://enterprisemediawiki.github.io/slides/MeetingMinutes/#/\n","id":33,"section":"posts","summary":"Really good wiki adoption case in NASA\nhttp://enterprisemediawiki.github.io/slides/MeetingMinutes/#/","tags":["nasa","wiki","mediawiki"],"title":"How NASA uses a wiki to reduce email","uri":"https://cychong47.github.io/2018/11/how-nasa-uses-a-wiki-to-reduce-email/","year":"2018"},{"content":" 제품 책임자는 해결해야 할 문제가 무엇인지 제시합니다. 그리고 팀은 주어진 문제를 어떻게 해결할 지 결정하죠. 진정한 자율성이 있다면 팀의 일을 중복으로 확인할 필요가 없습니다. 그들이 결정하고 그들이 만들고 조직 모두가 결과를 확인합니다. 모두가 배우는 것이죠 개발팀은 1-2주에 해당하는 개발 주기를 거칠 때마다 제품 책임자와 함께 무엇을 완료해야 하는지 상의해야 합니다. 잘 \u0008작동하는 상태로 배포할 수 있는 피처들이 얼마나 \u0008되는지 구분합니다.\n  이렇게 팀이 일을 끝낸 이후 \u0026ldquo;작동하는 소프트웨어를 보여주세요\u0026quot;라고 요구하면 됩니다.\n  제품이 나아가야 할 목표를 함께 이해하는 자기 조직화된 팀을 만드는 것 또한 최고의 순간입니다.\n 반복적인 개발 주기\n 각 개발 주기를 사용할 수 있는 소프트웨어를 만드는 연습과정으로 여길 것 항상 무엇을 달성했는지 관찰할 것. 무엇이 일정을 지연시켰는지 기록하고 상황을 개선할 방법을 찾을 것 팀의 능력을 향상함으로써 조직 모두가 완벽하게 숙달할 때까지 나아갈 수 있다 제품이 나아가야 할 목표를 함께 이해하는 숙련된 자기 조직화 팀이 되는 것이 핵심  Five Card\n 각 에픽은 한 줄의 문장으로 설명할 수 있어야 함 각 에픽 카드를 3-5개의 작은 카드로 쪼갤 것. 각 카드는 구체적이고 비지니스 측면에서도 가차기 있어야 함. 기술적인 아이디어가 아닌 실제로 작동하는 피쳐여야 함  ","id":34,"section":"posts","summary":"제품 책임자는 해결해야 할 문제가 무엇인지 제시합니다. 그리고 팀은 주어진 문제를 어떻게 해결할 지 결정하죠. 진정한 자율성이 있다면 팀의 일을 중복으로 확인할 필요","tags":["Book"],"title":"(책) The nature of Software Development","uri":"https://cychong47.github.io/2018/10/caeg-the-nature-of-software-development/","year":"2018"},{"content":"자료 \u0026ldquo;등록\u0026rdquo;\n미팅 노트건 어떤 주제에 대한 정리 노트건 \u0026ldquo;등록\u0026quot;이란 단어를 만나면 \u0026ldquo;공식적\u0026quot;이고, \u0026ldquo;뭔가 부담스러운\u0026rdquo; 자료가 되는 것 같다.\n그래서 자료(라고 쓰고 그냥 \u0026lsquo;정보\u0026rsquo;라고 부른다) 공유가 안되는 것이 아닌가 싶다.\n누군가 눈을 부릅뜨고 있는 단상에 자료를 올리는 작업은 부담스럽다. 그런 문화/상황/환경/분위기부터 없어지면 좀 더 편하게 자료를 공유하지 않을까?\nGoogler 들은 많은 자료를 자사 협업 툴인 Google docs등에서 작업할 듯 하다. 우리와는 다른 \u0026ldquo;일하는 환경\u0026quot;과 \u0026ldquo;사람들의 생각\u0026quot;이 그런 정보의 공유를 가능케 하는 게 아닐까 싶다.\n더 많은 자료를 편하게 \u0026ldquo;jot down\u0026quot;하자!!!!\n","id":35,"section":"posts","summary":"자료 \u0026ldquo;등록\u0026rdquo; 미팅 노트건 어떤 주제에 대한 정리 노트건 \u0026ldquo;등록\u0026quot;이란 단어를 만나면 \u0026ldquo;공식적\u0026q","tags":[],"title":"없어졌으면 하는 말","uri":"https://cychong47.github.io/2018/10/untitled-3/","year":"2018"},{"content":"P40 업무 지시 -\u0026gt; 일을 맡아달라고 부탁\nP44 제조업에서는 정보 공유의 중요성이 높지 않다. 설계 -\u0026gt; 생산 분리 SW에서는 설계가 모든 상세 내역을 알 수 없고, 지속적인 변경 사항에 따른 변화를 모두 확인할 수 없다. 실리콘밸리에는 기획자라는 역할이 없다. 각자가 자신의 역할을 책임진다. 엔지니어 문화에서는 끊임없이 진화를 가정하고 시작한다. 아웃소싱은 설계 변경을 빠른 시간 내 반영하기 어려워 많이 사용하지 않는다.\n우리나라 기업 문화는 기술집약 제조업에 적합하다. Speed - Quality - Feature triangle\n 직원들 각자가 전문가로서 매일 크고 작은 결정을 내리고 꾸준히 소통하는 조직 우리가 만드는 게 고객이 원하는 것인가를 끊임없이 고민\n P55\n 내 레벨에 비추어 성과를 절대 평가 한다.\n 엔지니어링 매니저 : 엔지니어가 효율적으로 일할 수 있도록 뭘 배워야 하고, 다른 팀과 문제가 없는 지 확인하는 역할을 수행.\n위계 조직 : 너 아니어도 일할 사람 많아 역할 조직 각자가 주어진 일에 갖혀있지 않고, 전문성을 최대한 살려서 목표를 이루고자 노력\n역할조직 소통이 가장 필요\n하지만 회의는 치소화 \u0026lt;- 각자 독립적으로 작업 -\u0026gt; 혼자 일할 시간을 최대한 확보 필요\nP85 구글의 미션과 핵심가치 구글이 말하는 훌륭한 인재는 똑똑하고 열심히 일하는 사람이 아님\nP91 Over communication is always better than less communication 실시간 소통은 근무시간 내로 한정\n근무시간 이후의 이메일은 답장을 기대하지 않음 전화 회의\nWork-Life-Balance는 직원들을 위한 것이 아니라 직원들이 최고의 성과를 낼 수 있도록 하기 위함 -\u0026gt; 회사에도 이득\nWiki or Cloud document 개발 가이드 라인, 테스트 방법론, 개발 환경 설정 등\n1~2주 마다 1:1 대화 Are you happy? Do you have any issue? What is on your mind?\nManager는 개인의 발전을 위해 어떤 공부를 하고, 어떤 프로젝트를 하면 좋을 지 의견 제시\n5시 이후에는 회식 X. 모임에는 매니저가 주도하지 않음. BrownBag meeting (누런색 종이 봉투) 점심을 먹으며 논의\n혁신은 뛰어난 한 사람이 아니라 작은 성공들을 공유하면서 서로 자극을 주고 전달한 정보가 씨앗이 되어 점진적으로 만들어진다.\nP204 Wikipedia -\u0026gt; portmortem 시간순으로 정리 잘한 점, 못한 점, 운 좋았던 점 (실마리를 우연히 찾는 것은 잘한 점이 아니므로)\n개선책 포함 전체 공유 Action Item 포함\nP218 Tesla는 가장 큰 시장용 제품인 Tesla 3 가 아닌 RoadStar를 제일 먼저 출시함 -\u0026gt; 시장의 범위를 좁혀 점진적으로 개선해 나감 -\u0026gt; Agile\nAgile은 빠르게 하는 것이 아니다 Agile은 변화에 빠르게 변화할 수 있기 위함이지 단순히 개발을 빠르게 하기 위함이 아니다.\nDaily meeting에서 종종 Burndown chart를 보면서 논의 단 자세한 내용을 Daily meeting에서 논의하지 말 것. 자세한 내용은 다른 방법(위키나 jira등의 task management tool)을 통해 평소에 공유할 것. 진행한 업무에 대해 이슈가 있고, 도움이 필요하면 요청.\nSprint Planning 미팅을 금요일에 진행\n9시 이후 에는 개인시간을 보냄. 아이는 재우고, 회사 일을 하거나, 책을 보거나, 영화를 보거나 등\n","id":36,"section":"posts","summary":"P40 업무 지시 -\u0026gt; 일을 맡아달라고 부탁 P44 제조업에서는 정보 공유의 중요성이 높지 않다. 설계 -\u0026gt; 생산 분리 SW에서는 설계가 모든 상세 내역을 알 수 없고, 지속적인 변경 사","tags":["Book","agile","dev culture"],"title":"(책) 실리콘밸리를 그리다","uri":"https://cychong47.github.io/2018/09/silicon-valley-illustrated/","year":"2018"},{"content":"One day The Wordpress container does not work at all. docker ps로 확인하면 1분 주기로 restart를 반복하고 있다. 경험상 이건 wordpress 앱이 초기화 과정에서 문제가 있는 거라는 걸로 짐작된다. 로그를 확인해 보니 아래와 같은 에러만 출력.\n뭐가 문제일까 멀쩡히 잘 돌던 녀석들인데.\nmini2:html cychong$ docker logs -f f12c3b3a57ef ... Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22 MySQL Connection Error: (2006) MySQL server has gone away Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22 Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22 Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22 Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22 Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22 MySQL Connection Error: (2006) MySQL server has gone away Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22 MySQL Connection Error: (2006) MySQL server has gone away Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22 Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22  Let’s debug  하지만 뭔가 달라진 게 있으니 갑자기 문제가 발생했겠지.\n 하지만 좀처럼 실마리를 찾기가 어렵고 급한 서비스도 아니라서 제대로 파서 해결할 생각을 하지 않았다. 방문자도 없는 블로그인데 뭐 라는 생각에.\n그래도 책 읽을 때마다 책 제목을 적어두는 페이지가 이 블로그에 있어 책을 한 권 다 읽은 김에 시간을 내서 고쳐보기로 했다.\n이런 문제의 가장 쉬운 해결책 검색은 에러 메시지를 그대로 검색하는 것. 위 로그에 있는 에러 메시지 몇 가지를 넣어봤지만 쓸모있는 정보(해결책이나 실마리라도)가 담긴 글이 잘 나오질 않는다. 대부분 일반적인 mysql에 대한 에러 해결책인데 그런 문제는 아닌 듯 하고.\n이 전에 추측한 것이 그냥 wordpress container에서 mysql container로의 통신에 문제가 있는게 아닐까 싶었다. 마침 docker for mac을 edge 버전으로 사용하고 있어서 그런가 하는 생각도 들고. 그래서 docker for mac을 stable 버전으로 바꿔도 보고, mysql, wordoress container 삭제/생성을 수차례 반복했다. 하지만 백약이 무효였다.\nResolution 이것저것도 다 안되니 지푸라기라도 잡는 심정으로 mysql을 mariaDB등으로 바꿔볼까 라는 생각을 했다. 백업해 놓은 mysql db 파일은 mariaDB에 사용할 수 있는 걸까? 아니면 sqlite3로 바꿀까? 근데 이건 정보가 너무 없네. 몇 개 나오는 게 5-6년 전 내용이라 지금도 유요한 방법인 지 의심스러웠다.\n그러다 wordpress container의 초반에 나오는 로그를 이용해서 구글링을 해봤는데 마침 이런 글이 눈에 띄었다.\nWordpress latest does not works with mysql latest container · Issue #313 · docker-library/wordpress · GitHub\n바로 이거였다.\n MySQL 8 changed the password authentication method. You’re looking for the mysql_native_password plugin https://dev.mysql.com/doc/refman/8.0/en/native-pluggable-authentication.html So you’ll want to connect with mysql —default-auth=mysql_native_password -p Or you could use mysql 5.7\n mysql을 5.7 버전을 사용하거나 8버전을 사용하면서 인증 방식을 지정하면 된단다.\nDocker-compose를 사용하는 경우 이렇게 지정하면 된다고 한다.\n mysql: image: mysql:5.7 # or image: mysql:8 command: '--default-authentication-plugin=mysql_native_password'  Ansible을 사용해서 container를 만들고 있는 나도 그냥 똑같이 해 봤다.\n--- - hosts: mini2 tasks: - name: Start mysql docker_container: name: mysql image: mysql command: '--default-authentication-plugin=mysql_native_password'  docker-compose.yml 기준으로 옵션을 설명하고 있어 ansible에서도 같은 걸 사용하는 지 몰라 제대로 옵션이 적용되었는 지 확인해 보니 아래 Args에 있다\nmini2:html cychong$ docker inspect mysql [ { “Id”: “a6336d1ef9a428564ff91aff396d5fa60bfa4bff092980758fc656e303b24fb6”, “Created”: “2018-09-04T14:55:24.440551604Z”, “Path”: “docker-entrypoint.sh”, “Args”: [ “—default-authentication-plugin=mysql_native_password” ],  Finally container들을 실행시킨 후 다시 docker logs wordpress 명령으로 확인해 보니 이제 그 지긋지긋한 mysql 관련 에러가 보이지 않는다.\nComplete! WordPress has been successfully copied to /var/www/html AH00558: apache2: Could not reliably determine the server’s fully qualified domain name, using 172.17.0.3. Set the ‘ServerName’ directive globally to suppress this message AH00558: apache2: Could not reliably determine the server’s fully qualified domain name, using 172.17.0.3. Set the ‘ServerName’ directive globally to suppress this message [Tue Sep 04 14:55:54.842454 2018] [mpm_prefork:notice] [pid 1] AH00163: Apache/2.4.25 (Debian) PHP/7.2.9 configured — resuming normal operations  그리고 블로그 접속해 보니 정상적으로 동작. 덕분에 15년 째 유지하고 있는 블로그가 다시 살아났다 :-)\n","id":37,"section":"posts","summary":"One day The Wordpress container does not work at all. docker ps로 확인하면 1분 주기로 restart를 반복하고 있다. 경험상 이건 wordpress 앱이 초기화 과정에서 문제가 있는 거라는 걸로 짐작된다. 로그","tags":["container","wordpress","mysql","troubleshooting","blog"],"title":"Recover WordPress container","uri":"https://cychong47.github.io/2018/09/recovery-failed-wordpress-container/","year":"2018"},{"content":"Motivation P39\n 자신이나 다른 사람에게 동기를 부여하고 싶은 사람이라면 반드시 알아두어야 할 교훈이다. 결정권을 행사할 수 있는 일을 찾아내면 행동하려는 의지를 쉽게 불어일으킬 수 있기 때문이다.\n직접 결정할 수 있다는 생각이 우리를 흥분시킨다.\n Teams P71\n 구글 인력 자원국의 기본적인 목표는 구글 직원들이 직장에서의 삶을 조금이라도 더 행복하고 생산적으로 꾸려 가도록 유도하는 것이었다\n P72\n 산소 프로젝트 -\u0026gt; 훌륭한 관리자란?\n 훌륭한 코치이고, 권한을 위임하고, 시시콜콜한 문제를 따지지 않으며, 부하 직원의 성공과 행복에 관심을 드러내고, 결과를 중시하고, 정보를 경청하고 공유하며, 경력 개발을 지원하고, 분명한 비전과 전략을 직원들에게 제시하며, 해당 비즈니스에 대한 중요한 핵심 능력을 지니고 있다.   P75\n Aristoteles Project -\u0026gt; 훌륭한 팀의 조건\n 집단 규범 열정, 지원 충성심   P82\n 직원들에게 아이디를 불쑥 내뱉지 말고 구체화한 후 제시하라고 말한다. 논리적인 것처럼 보이지만 결국에는 팀원의 능력을 떨어뜨린다.\n리더들은 팀원들에게 자신의 생각을 자유롭게 말하라고 독려하고 팀원들은 자신의 약점까지도 숨김없이 드러낼 수 있다고 생각하며 반박과 경멸이 있을 까 두려워하지 않고 어떤 아이디어라도 제시할 수 있으며, 가혹한 비판을 자제하는 문화가 형성되어 있다.\n모든 규범이 유대감을 조성하는 동시에 팀원들에게 무엇이든 과감하게 시도해 보라고 독려하는 행위였다. 이 공통된 속성을 *“심리적 안전감”*이라고 칭함(에이미 에드먼슨) ‘위험한 것을 시도할 수 있는 안전한 공간이자 팀원이 공유하는 믿음’ 심리적 안정감은 상호 신뢰와 상호 존중으로 요약되는 팀 문화의 특징. 요컨데 팀원들이 자신의 본래 모습대로 편안하게 행동할 수 있는 팀 문화를 뜻한다.\n P98\n 훌륭한 팀의 두 가지 공통점\n 모든 팀원이 거의 같은 비율로 발언. ‘대화 차례 분배의 균등성’ 팀원들의 사회적 감수성이 평균적으로 높음(서로 상대의 감정을 헤아리는 감성적인 면을 보임)   P107\n Aristoteles Project의 결론 훌륭한 팀의 다섯가지 핵심 규범\n 팀원들은 자신에게 주어진 일이 중요하다고 굳게 믿어야 한다 팀원들은 자신에게 주어진 일이 조직 전체에는 물론 팀원 개개인에게도 중요하다고 믿어야 한다. 팀원들에게 팀의 분명한 목표와 개개인의 명확한 역할이 주어져야 한다 팀원들은 서로 신뢰할 수 있어야 한다 팀에 심리적 안전감이 있어야 한다.  심리적 안전감을 조성하기 위해서는 팀 리더가 적절한 행동의 본보기가 되어야 한다.\n 리더는 팀원의 말을 도중에 끊지 말아야 한다 리더는 팀원이 발언을 끝내면 그 내용을 요약함으로써 귀담아 듣고 있다는 사실을 입증해 보여야 한다 리더는 모르는 것을 모른다고 흔쾌히 인정해야 한다 리더는 회사에서 모든 팀원에게 적어도 한번 이상의 발언 기회를 주어야 한다 리더는 곤경에 빠진 팀원에게 좌절감을 털어놓도록 독려하고 팀원들에게 개인적인 비판을 삼가도록 유도해야 한다 리더는 팀 내의 갈등을 공개적인 토론을 통해 해소해야 한다   P113\n 론 마이클스는 이렇게 말했다 “내가 좋아하는 거요? 배우들이 어떤 꼭지를 완벽하게 연기해 내고, 그 꼭지를 쓴 작가들이 모니터 앞에 서서 서로 손바닥을 마주 치며 축하하고, 다음 차례를 기다리던 배우들도 깔깔대고 웃는 모습을 보면 정말 즐겁습니다. 다음번에는 등장인물들을 더 재미있게 꾸미는 방법을 고민하는 팀이 눈에 띄면 더더욱 즐겁지요. 팀 전체가 똑같은 것에서 일종의 영감을 받아 즐거워하면 모든 것이 제대로 돌아가고 있다는 뜻입니다. 그때는 팀원 전체가 서로 응원하고 팀원 개개인이 주인공이 된 듯한 기분일 테니까요” 득점 찬스에서 점수가 났을 때 덕아웃 분위기? 끝내기 안타를 친 야구팀의 덕아웃 분위기?\n Focus P144\n 당신이 책상에 앉아 수행하려는 일을 가능한 한 구체적으로 상상하는 습관을 길러라. 그럼 당신이 머릿속에 그린 이야기와 현실의 작은 차이를 찾아내기가 쉬워진다. Amazon Way에 있던 내용과 유사. 과제가 성공했을 때 신문에 낼 기사를 적어봐라\n P154\n 정보가 감당하기 힘들 정도로 너무 많이 유입되면 우리는 뭐가 중요한 지 제대로 파악하지 못합니다. 심성 모형(Mental Model)을 통해 상황에 대한 대비/준비\n P158\n 심성 모형은 끊임없이 휘몰아치는 정보의 소용돌이로부터 우리를 지켜 주는 기준점이라고 할 수 있다. 또한 우리가 관심을 어디에 두어야 하는 가를 결정하는데 도움을 준다. 심성 모형이 머리속에 있을 때 우리는 단순히 반응하는 데 그치지 않고 선체적으로 결정을 내릴 수 있다. 회의 중 갑자기 의견을 물었을 때 미리 준비하고 있지 않으면 엉뚱한 말을 할 수 있다.\n P159\n 무엇에 집중하고, 무엇을 무시해야 하는 지 정확히 판단하려면, 우리 삶을 이야기로 꾸미는 습관을 들여야 한다.\n자신의 주의력을 통제할 수 있어야 한다. 우리가 확고히 책임지는 심성 모형을 구축해야 한다. 자동차를 운전하며 출근할 때 일과를 머리속에 그려 본다. 회의실에 앉아있거나 점심 식사를 하려고 식당에 앉아 있는 동안에는 눈에 보이는 것을 구체적으로 묘사해 보고 그 의미까지 표현해 보라. 당신의 이론을 듣고 반박할 사람을 찾아보라 다음에는 어떤 일이 닥칠지 예상하는 습관을 길러라\n P160\n 중요한 것은 생각하는 힘이다. 우리가 생각하는 힘을 유지하는 한 절반은 성공한 것이다\n Goal Setting P178\n GE의 Smart Goal\n Specific Measurable Attainable Realistic Timeline 시야를 좁히고 즉각적인 결과를 얻는데 더 많은 시간을 할애한다.   Agile에서 매 sprint나 각 task에만 집중하면 동일한 문제가 발생하지 않을까? Sprint와 Task들은 Product 개발의 목표나 일정을 고려해서 수립해야 한다.\nP184\n 상대적으로 쉬운 과제를 선택하고 프로젝트를 어떻게든 마무리해야 한다는 강박관념에 시달릴 가능성이 크다. 스마트 목표에 집착하면 완료한 일을 업무 목록에서 지워 내는 것이 내가 올바른 방향으로 일하고 있는 지 의문을 품는 것보다 더 중요하다고 생각하는 사고 방식에 길들여진다\n P185\n Workout - GE 직원이면 누구라도 GE가 마땅히 추구해야 한다고 생각하는 목표를 제안할 수 있어야 한다. 관리자들은 어떤 제안이든 신속하게 때로는 그 즉시 가부간에 결정을 내려 줘야 했다. “우리는 관리자가 어떤 제안이라도 흔쾌히 인정해 주는 분위기를 조성하고 싶었습니다. 직원들로 하여금 먼저 목표를 원대하게 세우고 계획은 나중에 구체화하도록 유도하면 결국에는 더 크게 생각하지 않을까 여긴 겁니다”\n P187\n 당신이 성취 가능한 결과에 집중하라는 말을 반복해 듣는다면 성취 가능한 목표만을 생각할 것이고, 큰 꿈을 꾸지 않을 겁니다.\n P190\n 신간센 이야기. 일본 철도청장의 고속 철도에 대한 집요한 요구 덕에 신간센 개발. 경제 발전에 기여 구체적이고 성취 가능하며 시의적절한 목표를 설정하는데 그치지 않고 도전적인 목표를 찾아낼 수 있어야 한다. 도전적인 목표는 처음에는 어떻게 성취해야 할 지 모를 정도로 야심적인 목표를 뜻한다.\n P192\n 엔진 결함율 70% 감소 목표\n 재교육(엔진 이론 교육 등) 우수인력 채용 -\u0026gt; 자율권 보장. Flexible time, 직원 채용 방법까지변경 -\u0026gt; 팀구성권 부여. 유연사고 방식 지녀야 해서 직원 채용 방법 변경   P194\n 도전적인 목표\n 집단의 열망을 인위적으로 크게 높임 조직의 에너지를 극단적으로 끌어올림 실험과 혁신, 폭넓은 조사와 신명 나는 업무를 통해 탐색 학습을 유도할 수 있다  도전적인 목표가 지나치면 조직원들을 공황 상태에 몰아넣으며 성공이 불가능하다는 확신을 심어 줄 수 있다. 그래서 도전적인 목표가 조직원들에게 용기를 북돋아 주려면 때로는 스마크 목표와 병행될 필요가 있다.\n도전적인 목표가 단순한 열망을 넘어서려면, 아득한 목표를 일련의 현실적인 단기적 목적들로 변환하는 방법을 조직원들에게 보여주는 절제된 태도와 마음가짐이 필요하다.\n P196\n 원대하고 많은 생각이 필요한 보고서를 작성하는 대신 사소하고 하찮은 메일에 답장하며 많은 시간을 보내게 된다. 그렇게 하면 받은편지함을 깨끗하게 처리했다는 만족감을 얻기때문이다.\n P198\n 목표 설정 절차\n 도전적인 목표는 무엇인가? 구체적인 하위 목표는 무엇인가? 성공 여부를 어떻게 측정할 것인가? 이 하위 목표는 성취 가능한 것인가? 이 하위 목표는 현실적인가? 목표 성취를 위한 시간 계획표는 어떻게 되는가?   Managing Others P208\n 센티널(Sentinel)을 Agile 방식으로 개발\n P224\n 헌신을 중시한 기업일 수록 직원을 선발할 때 충분한 시간을 두고, 자기 주도적 능력이 뛰어난 사람을 찾으려 하기 때문에 중간 관리자가 적고, 조직에 군살이 없었습니다.\n P229\n 도요타 사장의 솔선수범이 직원들이 회사에 대한 신뢰와 심리적 안전감을 갖게 함\n P235\n 픽사 방법론 앞으로 디즈니에서는 누구도 다른 사람이 문제를 해결해 주기를 기다릴 필요가 없다는 점을 강조했다. 잘못된 곳을 직접 수선할 권한을 주지 않는다면 굳이 똑똑한 사람을 채용할 필요가 있겠는가\n핵심적인 특징\n 어떤 경우에나 의사 결정권이 문제를 가장 가까이서 경험하는 사람에게 위임되었다는 점 팀에 자주적 관리와 자주적 조직을 허용하는 동시에 협력을 독려하는 점 헌신과 신뢰 문화를 강조하는 점   P237\n 누구나 멋진 아이디어가 떠으려면 서슴없이 제안해야 하고, 프로젝트가 잘못된 방향으로 가고 있다는 생각이 들면 누구라도 중단을 선언할 수 있으며, 문제에 가장 가까이 있는 사람이 일차적으로 그 문제를 책임지고 해결하는 게 규칙이라고 알렸다\n Decision Making P281\n Bayesian cognition 베이즈 심리학 - 패턴을 직감하는 능력 Bayes’ rule - 자료가 지극히 적더라고 어떤 식으로든 추정한 후 우리가 세상에서 관찰한 결과를 바탕으로 그 추정을 조절하면 미래를 예측할 수 있다\n P295\n 확률적으로 생각하려면 미래를 다양한 관점에서 상상하고, 모순된 것처럼 보이는 현상들도 동시에 일어날 수 있다는 가능성을 열어 두며, 성공만이 아니라 실패까지 폭넓게 경험하고, 어떤 예측이 실현될 가능성을 가늠하는 직관력을 키워야 한다\n Innovation P327\n Spinning - 특에 박혀 프로젝트를 다른 관점에서 더 이상 보지 못할 때 스피닝이 일어난다\n P340\n 창의적 과정 창의성을 발휘하도록 지원하는 조건은 인위적으로 조성할 수 있다. 기존 개념들을 새로운 방식으로 결합하면 혁신을 이루어 낼 가능성이 더 높다는 것은 이미 잘 알려진 사실\n조직의 창의적 과정에서 생산성을 높이고 싶다면\n 당신 자신의 경험에 주목하라. 주변 현상을 당신이 어떻게 생각하고 어떻게 느끼는지 유심히 관찰해 보라. 그래야 상투적인 것과 진정한 통찰을 구분할 수 있다 당신이 뭔가를 창조하려고 할 때마다 스트레스와 두려움에 시달린다고 모든 것이 끝났다고 자책하고 좌절할 필요는 없다. 오히려 그런 두려움과 스테레스를 긍정적인 방향으로 활용하면 새로운 것을 찾아내는 융통성을 발휘할 수 있다. 창조적 과정에서 돌파구를 마련했을 때의 안도감은 지극히 달콤하지만 우리에게 다른 대안들을 무시하고 잊게 할 수도 있다는 걸 반드시 기억해야 한다. 우리가 지금 만들어 내고 있는 것으로부터 일정한 거리를 유지하는 게 중요하다. 하나의 아이디어가 경쟁적 관계에 있는 다른 아이디어들을 신속하게 몰아낸다.   Absorbing Data P347\n 자료는 변화를 유도할 수 있지만 그런 자료를 사용하는 방법을 교사가 아는 경우에만 가능하다 빅데이터와 유사(?) 데이터를 가공할 줄 알아야 데이터로부터 의미있는 정보를 찾을 수 있다는\n P349\n 구글과 인터넷을 통해 언제라도 충분한 정보를 확보할 수 있어 우리는 거의 모든 것에 대한 대답을 순식간에 찾아낼 수 있습니다. 하지만 사우스 애번데일은 대답을 찾는 것과 대답이 무엇을 뜻하는지 이해하는 것은 엄연히 다르다는 사실을 보여 주었지요\n P377\n 조직원들이 각자의 경험을 새로운 관점에서 접근하도록 지원하는 방법으로는 미리 정해진 일련의 질문표나 공학 설계 과정처럼 단계적 의사 결정 시스템을 가르치는 게 가장 효과적인 듯하다. 이 방법을 사용하면 이분법적 결정에 익숙한 뇌의 습관에서 벗어날 수 있다\n ","id":38,"section":"posts","summary":"Motivation P39 자신이나 다른 사람에게 동기를 부여하고 싶은 사람이라면 반드시 알아두어야 할 교훈이다. 결정권을 행사할 수 있는 일을 찾아내면 행동하려는 의지를 쉽게 불어일으","tags":["Book"],"title":"(책) 1등의 습관 Smarter, Faster, Better","uri":"https://cychong47.github.io/2018/09/smarter-faster-better/","year":"2018"},{"content":"","id":39,"section":"posts","summary":"","tags":[],"title":"Tags","uri":"https://cychong47.github.io/2018/09/tags/","year":"2018"},{"content":"팀원이 안전하다고 느끼는가?\n구글 * 지위에 연연하지 않음. * 누가 책임질 지 고민하지 않음 * 어려운 문제를 풀기 위해 모든 집단을 토론시킴  미사일리어 * 미국의 미사일기지 근무 군인들의 만족도가 크게 떨어짐 * 우리가 이어져 있나? * 우리에게 미래가 있나? * 우리는 안전한가?  피드백 * 기대치가 높다 * 당신이면 기대를 충분히 달성할 수 있을 있을 거라고 믿는다  경청하라. 또 경청하라 * 높은 자리에 오를수록 먼저 약점을 드러내라 * 불편한 목소리도 포용 * 구체적인 미래상 제시 * 공치사는 과장될수록 좋다 * 서로 부딪칠 수 있는 공간을 마련하라 * 각자의 목소리를 내게 하라. Toyota(Action Code), Pixar(Details), google, It’s your ship(해군 함장) * 벤폴트호를 타면 제일 좋은 점은? * 제일 마음에 들지 않는 점은? * If you’re captain, what do you change? * 하찮은 일일수록 솔선수범 * 샌드위치식 feedback은 피할 것 * 칭찬 - 질책 - 칭찬 X * 칭찬과 질책을 분리 * 유쾌한 분위기를 만들것  IDEO * 나를 제일 들뜨게 하는 것은? * 별로 들뜨게 하지 않는 이유는? * 이 프로젝트에서 개선하고 싶은 것은?  Google Laszlo Bock * Work rules * 지금 하는 일 중에 계속 하고 싶은 일은? * 좀 더 자주 하면 좋겠다고 생각하는 일은? * 내가 어떻게 해야 직원들이 효율적으로 일할 수 있을까?   협동을 부추기는 계기 배드 뉴스는 개인적으로 전달  #book\n","id":40,"section":"posts","summary":"팀원이 안전하다고 느끼는가? 구글 * 지위에 연연하지 않음. * 누가 책임질 지 고민하지 않음 * 어려운 문제를 풀기 위해 모든 집단을 토론시킴 미사일리어 * 미국의 미사","tags":["Book"],"title":"(책) 최고의 팀은 무엇이 다른가","uri":"https://cychong47.github.io/2018/08/the-secret-of-highly-successful-groups/","year":"2018"},{"content":"p15\n 사람들에게 제대로 집중해서 일을 하고자 할 때 어디로 갈거냐고 물었을 때 “사무실”이라고 답하는 사람은 별로 없다.혹은 “다른 직원들이 출근하기 전 아침 일찍” 또는 “다른 직원들이 퇴근하고 난 후의 사무실” 또는 “주말에 아무도 없는 사무실”\n p18\n 출퇴근 시간 1.5시간/하루 * 5일 * 4 * 11 month = 330 시간.400시간은 베이스캠프를 개발자들이 프로그래밍하는데 걸린 시간\n p22\n 엄청난 기술이 필요한 것은 아니다. 하지만 과거의 유산을 내려놓고 미래로 가는 배에 올라 탈 굳은 의지를 갖추어야만 한다.\n p24\n 동시적 협업에서 비동기 협업 체제로 바뀌는 것 원격근무가 아니더라도 시간대가 다른 부서와 협업하는 것만 해도 비동기 협업의 중요성이 높아진다. 동시성 협업은 극히 제한되고, 공간과 언어의 제약으로 인해 효율이 극히 낮아진다.\n p48\n 출근하지만, 막상 사무실에서는 마치 모두가 원격근무하는 것처럼 일을 한다. 이메일, 메시징앱으로 일하면서 혼자 일하는 시간을 달라고 한다. 출근길에 생각해 보자. 과연 오늘 사무실로 출근하는 것이 그럴 만한 가치가 있었나? 회사 업무를 살펴보라. 어떤 업무가 외부에서 일어나고 있는지, 또는 반대로 반드시 대면해서 해야 하는 업무가 어떤 것이 있는 지. 아마 생각보다 많은 업무가 원격으로 진행되고 있다는 것에 놀라게 될 것이다.\n p53\n 신뢰에 문제가 있다면, 그것은 채용 당시 의사결정에 문제가 있었다는 것을 뜻한다. 팀원 중 좋은 결과를 내지 못하거나, 스스로 일정관리와 업무량을 조절할 수 없는 사람과는 계속 일할 수 없다. 스스로 일정을 관리하고 조직에 의미 있는 기여를 하는 전문가와 일하기를 원한다. 관리자는 직원 옆에 진종일 붙어서 보모 역할을 하는 사람이 아니다.\n p55\n 리차드 브랜슨경은 원격근무에 대해 이렇게 말했다. “다른 사람들과 성공적으로 협업하려면 서로 신뢰가 있어야 한다. 관리감독이 없는 상황에서도 동료가 제 몫을 해낼 것이라는 믿음이 필요하다”\n p66\n 생산성에 대한 이야기를 할 때는 대기업을 예로 들지 않는 것이 현명하다.\n p72\n 최선의 문화는 사람들의 행동에서 나타나는 것이지, 사훈에 적는 문구가 아니다.신입사원들은 의사결정이 어떻게 이루어지는지, 회사가 어떤 것에 신경을 쓰는지, 문제를 어떻게 해결하는 지 등을 지켜보면서 문화를 익힌다. 원격근무를 하게 되면 기업문화란 사람 간의 사회적 교류를 통해서 만들어진다는 허상을 깨닫게 된다. 그리고 기업문화란 업무를 정의하고 실행하는 방법이라는 것을 알게 된다.\n p74\n Mail, Chat, call 등 긴급성에 따라 다른 방식으로 연락할 것\n p95\n 모든 정보를 공개하라.원격근무인 경우 발생하는 시차로 인한 정보 공유 문제를 해결하려면(4시간 시차가 있는 사람들에게 정보를 얻기 위해 4시간을 기다린다는 것은 말이 안되는 일) 가급적 모든 정보를 공개된 공간에 모아야 한다.\n p98\n 다양한 챗 채널을 사용.업무 뿐만 아니라 잡담용 채널 등도 사용하여 유대감을 만들 것. 이런 낭비가 필요하다\n p102\n 팀장보다 팀원을 속이기가 더 어렵다.다른 개발자들에게 정보가 모두 공개되면 거짓은 금방 들통 나기 마련이다.모두가 업무진행 상황을 공유할 때 좋은 결과가 나온다.\n p104\n “오늘 무슨 일을 했나요?라고 묻지 말고 ”오늘 한 일을 보여주세요”라고 묻자.업무결과물과 관계없는 나머지는 무시하면 된다.\n p120\n 매일 업무를 마치면서 스스로에게 질문해 보자. “오늘은 업무 성과가 좋았나?”\n p158\n 베이스캠프처럼 일감을 자동으로 관리하고 보고하는 시스템은 누가 무슨 일을 하는 지, 얼마나 걸리는 지 투명하게 보여준다.이런 시스템은 전통적인 사무실 업무환경에서 소외받던 조용하게 일 잘 하는 사람들을 돋보이게 한다. 원격근무 환경에서는 자신이 한 업무에 대해 자랑질을 하지 않아도 된다. 이미 모두에게 공개되어 있고 주의 깊게 살펴보고 있다. 일은 안하고 허풍만 떨다 보면 동료들 모두가 금방 그 사실을 알아챌 것이다.\n p161\n 글쓰기는 원격근무의 시작이다. 원격근무를 잘하려면 쓰기를 잘해야 한다.On Writing WellThe Elements of StyleRevising Prose\n p165\n 미니프로젝트는 의미 있는 일이라야 한다. 현재 회사가 가지고 있는 문제를 해결하는 과제여야 한다.\n p192\n 직원들에게 스스로 의사결정 권한을 주어라. 회사에 층층히 쌓인 관리자의 승인이 있어야만 의사결정을 할 수 있다면 회사에는 잘못된 사람들만 있는 것이다.사람들은 의사결정 내리기를 두려워한다. 왜냐면 그들은 처벌과 원망을 받을까 두렵기 때문이다. 이런 문화는 원격근무와 어울리지 않는다.직원들이 일하는데 필요한 것들을 쉽게 획득할 수 있도록 해야 한다. 하지만 대부분의 회사는 정확히 반대로 하고 있다.조직이 군과 관련되어 있거나, 일급비밀정보를 다루는 일이 아니라면 정보 접근을 제한하는 장벽들은 직원들이 업무를 하는데 방해가 될 뿐이다.\n p195\n 장기적으로 좋은 직원은 지속 가능한 업무를 하는 사람이다. 모자라지도, 넘치지도 않게 딱 적당히 일하는 것이 좋다. 우리 경험으로는 일주일에 40시간 정도가 평균적으로 적절했다.\n remote에 대해 다른 사람이 쓴 글\n","id":41,"section":"posts","summary":"p15 사람들에게 제대로 집중해서 일을 하고자 할 때 어디로 갈거냐고 물었을 때 “사무실”이라고 답하는 사람은 별로 없다.혹은 “다른 직원들이 출근하기 전 아침 일찍” 또","tags":["Book"],"title":"(책) 리모트","uri":"https://cychong47.github.io/2018/08/remote/","year":"2018"},{"content":"기대와는 많이 달랐던 책\u0026hellip;\n 인생은 바꿔 말하면 ‘시간’입니다. 그 시간을 보내는 ‘공간’이야말로 그 사람의 행복으로 이어집니다.\n ","id":42,"section":"posts","summary":"기대와는 많이 달랐던 책\u0026hellip; 인생은 바꿔 말하면 ‘시간’입니다. 그 시간을 보내는 ‘공간’이야말로 그 사람의 행복으로 이어집니다.","tags":["Book"],"title":"(책) 덴마크 사람들은 왜 첫 월급을 받으면","uri":"https://cychong47.github.io/2018/08/why-danish-bought-a-chair-with-the-first-time-salary/","year":"2018"},{"content":"31\n PO의 역할 A,B, C의 우선 순위를 결정하는 수동적인 역할 더 창의적으로 생각해보면 전혀 다른 D라는 일을 텅해 A,B, C의 문제를 한꺼번에 해결 할 수도. 사고의 폭이 넓으면 PO가 할 일은 무한정 많아지기도 한다.\n 관리자와 같은 입장인 듯. 2018년 8월 내가 갖는 고민, 상황에 딱 드러맞는 말.\n240\n 쿠팡 대표 이사, 김범석\n\u0026ldquo;제발 위에서 시키니까 한다는 소리 좀 하지 마세요. 그거 제가 제일 싫어하는 말이예요\u0026rdquo;\n\u0026ldquo;무엇이 옳고 합리적인지\u0026quot;를 묻는 것은 다양성을 존중하는 수평적인 조직문화의 토대가 될 수 있다. 좀 더 타당한 논리와 근거를 갖춘 의견을 우선시하는 분위기가 갖춰진다면 사람들이 자유롭게 자신의 주장을 펼치기가 더 쉬워질 것이다.\n 251\n 생각하는 바가 있으면 그냥 구현에 제약이 없다고 간주하고 비전을 제시\n 260\n 수평조직이라 권한을 위임받은 사람이 없다. 조직(원)간 설득과 협의를 통해 일을 진행해 나가야 한다.\n수직적인 조직에 비해 일 진행이 더디기도\u0026hellip;\n 289\n \u0026ldquo;어떻게 할까요?\u0026rdquo; \u0026ldquo;어떻게 해야 한다고 생각하세요?\u0026rdquo;\n 295\n \u0026ldquo;큰 배를 만들게 하고 싶으면 바다에 대한 동경을 심어줘라\u0026rdquo; 이렇게 하면 모든 이가 스스로 배 만드는 법을 찾을까? \u0026ldquo;그래서 배의 설계도는 대체 어디에 있나?\u0026rdquo;\n\u0026ldquo;큰 배를 만들면 나한테 무슨 이득이 있나?\u0026rdquo;\n ","id":43,"section":"posts","summary":"31 PO의 역할 A,B, C의 우선 순위를 결정하는 수동적인 역할 더 창의적으로 생각해보면 전혀 다른 D라는 일을 텅해 A,B, C의 문제를 한꺼번에 해결 할 수도. 사고의 폭이 넓으면","tags":["Book","agile","dev culture"],"title":"(책) 쿠팡 우리가 혁신하는 이유","uri":"https://cychong47.github.io/2018/08/coupang-the-reason-of-innovation/","year":"2018"},{"content":"p17 술과 구라를 즐기되 항상 혀를 조심하라. 어느 장소에서나 어느 주제에 대해서나 할 말을 다하는 자는 불행한 자이니 말하고 싶을 때마다 세 번을 더 깊이 들어라 특히 나이가 들어서는 혀를 잘 묶어두어야 한다. 고약한 늙은이 옆에는 사람이 없으니 외로움이 끝없으리라 배워서 알고 싶은 것을 다 쓰지 못하고 가는 것은 서운한 일이나\n친구는 들어주는 사람 곁에 모이는 것이니 하나를 말하고 둘을 들어라.\np27 여러분이 놓치고 있는 것이 있습니다. 바로 이 하얀 종이 말입니다. 인생에서, 비즈니스에서, 가정에서 개인적인 일에서나 공적인 일에서 우리는 바로 이 검은 점 하나와 같은 작은 실수와 실패 때문에 온통 마음이 심란해집니다. 그러나 중요한 것은 아무것도 그려져 있지 않은 이 하얀 여백입닏. 이곳이 바로 우리가 꿈을 그려 넣을 자리입니다.\np33 창의성의 시작은 질문으로부터 온다. 철학은 ‘만물의 근원은 무엇일까’를 묻는 질문에서부터 시작되었다. 답이 중요한 것이 아니다. 좋은 질문이 위대하다. 우리 교육의 가장 큰 문제는 질문할 수 있는 호기심과 자유의 힘을 빼앗은 것이다. 너무도 빨리 정말 알고 싶은 것들을 제쳐두고, 아직 절실하지 않은 세상의 대답들을 외우게 함으로써 질문의 힘을 죽여버린다.\n그러나 사회에 나오는 순간 학생들은 이 세상에 정답이란 애초에 없는 것임을 알게 된다. 그때그때 가능한 복수의 답들 중에서 하나를 선택하거나 몇 개의 가능한 답들을 융합해 새로운 답을 찾아내야 한다는 것을 깨닫는다. 답을 찾아가는 가장 중요한 과정은 적절하게 질문할 수 있는 힘이다. 질문이야말로 멋진 답으로 가는 마법의 길이다.\np37 ‘이보게, 세상에 뜻대로 안 되는 것이 열에 여덟아홉이라고 하지 않나. 그러니 뜯대로 되는 기분 좋은 일 한 둘을 늘 생각하고 그 일을 넓혀가시게. 그러면 삶이 즐겁지 않겠는가?”\np60 “일할 때는 가족 생각을 하고, 가족과 있을 때는 일을 생각하는 사람들은 아무것도 성취할 수 없다. 그들은 온전히 어느 순간도 즐기지 못한다. 단지 떠돌이일 뿐이다”\n지금, 여기에 모두 다 걸어라. 실천이 목표를 얻기 위한 수단이라 생각하지 마라. 실천은 지금을 즐기는 것이다. 즐기지 못하면 목표만 남고 삶은 사라진다.\np66 조지 버나드 쇼 “인생은 너 자신을 발견하고 찾아가는 것이 아니다. 네가 원하는 모습대로 너를 창조내는 것이다”\np85 태평스럽게 살 수 있다면 그나마 다행이다. 그러나 이제 그만한 소시민적 평화를 바라기 어렵게 되었다. 처음 시작한 직장에서 적당한 자부심을 느끼며 평생을 지낼 수 있는 이제 드문 은총이 되었따. 어디에도 적절한 자리가 없는 것이 지금의 40대다.\np86 안쪽 깊은 곳에 새로운 삶을 만들어갈 수 있는 힘이 남아있다.아직 며칠 더 절실하게 푸를 수 있고 뜨거울 수 있다. 살면서 한 가지의 흔적을 남길 수 있을 거라는 오만을 떨 수 있는 며칠이 남아 있다. 겸손한 가을이 오기까지 아직 조금의 시간이 있다. 참으로 작고 보잘것 없는 나라는 열매 속에 엄청난 에너지를 채워 넣을 수 있는 찬란한 여름의 며칠이 남아 있다. 그래서 이때는 모든 40대들에게 아주 절박한 시기다.\n변화는 절박함을 인식할 수 있는 능력이다. 절박함을 스슷로에게 설득시킬 수 있다면 변화의 반은 성공한다. 그러나 절실하지 못한 사람은 자기를 바꾸는데 성공할 수 없다….절실하다는 것은 것은 그것을 생존의 문제로 인식한다는 것을 뜻한다. 지금이 결단의 시기이며, 지금 시작하지 않으면 마지막 기회를 놓치고 말 것이라는 자기 암시이며 주술이다.\n40이 넘은 사람들에게 여름은 이제 며칠 안 남았다. 변화의 절박함을 인식할 수 있는 사람은 도움을 받을 수 있다. 그러나 절박하지 않은 사람은 누구도 도와줄 수 없다.\n절박함은 스스로 부여하는 것이다. 이 자발성은 변화가 무엇인지를 이해하는 것으로부터 온다. 변화는 움직임이다. 한 점에서 다른 한 점으로 움직여가는 것이다. 따럿 변화에는 한 순간에 적어도 두 개의 점이 필요하다. 지금 서 있는 곳과 도달할 목적지를 나타내는 두 개의 좌료를 찍을 수 있어야 한다.\np89 절박함은 그러므로 꿈이 있는 사람에게만 생겨난다. 현실과 꿈 사이의 간격에서 꿈을 향해 움직여갈 때 생겨난다. 현실밖에 없는 사람은 절박하지 않다. 그들에게 삶은 그저 지루하고 짜증스러운 반복과 연속일 뿐이다. 그들에게는 꿈, 즉 도달해야 할 점이 없다. 오직 현실이라는 한 점밖에 존재하지 않기 때문에 움직일 수 없다. 그래서 스스로의 변화는 불가능하다. 외부의 변화가 밀려오면 속수무책으로 당할 수밖에 없다. 그런가 하면 꿈밖에 없는 사람도 있다. 그들도 변화할 수 없다. 그들에게는 현실이 없기 때문에 ‘이룬다’는 개념도없다. 그저 취해서 살 뿐이다.\n변화에 성공하기 위해서는 늘 ‘또 하나의 점’이 필요하다. 그것도 스스로가 자발적으로 찍은 ‘또 하나의 점’이 중요하다. 스스로 찍지 못하면 대개의 경우, 다른 사람들이 찍어놓은 곳으로의 이행을 강요당하게 된다. 강요된 스피드로 강요된 곳을 향해 몰려가지 못하면 도태되거나 원하지 않는 곳에 도달하게 된다. 삶이 불만족스러운 것은 바로 이 비자발성에 기인한다.\n지금 서 있는 곳에서 꿈꾸는 곳으로의 이동은 힘든 과정이다. 그 간격을 극복하는 것은 산을 오륻르듯 높은 곳으로 움직여가는 것이기 때문에 많은 에너지를 필요하다. 힘은 밖에서 오지 않는다.. 그래서 힘은 안으로부터 온다.\n안으로부터 오는 힘은 단지 의지와 인내를 통해 얻어지는 것이 아니다. 참고 견디는 것은 고통스럽다. 자기 마음이 흐르는 대로 따름으로써 그 내면적 힘을 얻어낼 수 있다. 좋아하는 일을 하는 것은 즐거움이다. 수련과정에 포함되는 반복과 연습 그리고 땀은 자부심을 높여주고 행복하게 해준다.\np97 꿈을 이루려면 ‘꾸는’ 것만으로는 턱도 없다. 이 대목에서 우리는 시간의 문제를 해결해야 한다. 하루에 두 시간은 자신이 좋아하서 선택한 일에 써야 한다. .. 시간해서 6개월 이내에 스스로 변화를 감지하고 확신을 가지하면 하루에 적어도 두 시간은 써야 한다. 변화를 시작해서 6개월이 지나도록 변화로 인한 보람과 의미를 발견하지 못하게 되면 지칠 수 있다. 인간은 증거를 필요로 한다.\np105 삶을 꾸려가는 강령 7가지\n 생긴 대로 살아라 학생으로 계속 남아라. 과거를 그리워하거나 자랑하지 마라.  역사는 자랑하기 위해 있는 것이 아니다. 역사는 오늘의 문제를 풀기 위한 지혜로 존재하는 것이다. 과거에 기초에 정체성을 만들어내서는 안 된다. 잠재성 또한 나의 정체성을 결정해야 한다. 잠재성이란 발현되지 않았지만 이미 내가 갖고 있는 것들이다.   젊은 사람들과 밥그릇을 놓고 경쟁하자 마라 리스크를 지고 살아라.  예측된 위험을 피하지 마라. 모험이 없는 인생은 재미없다.   삶을 관조와 관찰로 대체하지 마라.  삶과 조금 격리되어 삶을 관조하는 조용한 옵저버가 되지 마라. 삶은 뜨거운 것이다. 살아봐야 삶이 된다.   자연과 하나가 되라.  인간관계를 부드럽게 하는 강령 7가지  사람을 있는 그대로 받아들여라. 부탁하지 않았다면 충고하려 하지 마라. 현재의 관점에서 이해하라.  과거는 우리가 어떤 사람을 판단하는 중요한 기준이다. 과거에 지나치게 많은 비중을 두지 않는 것이 좋다. 사람들에게는 많은 사연이 있고, 그때 그 상황헤 처하지 않고는 정확하게 이해하기 어렵다. 더욱이 사람은 변한다. 직접 경험한 것이 아니라면 소문과 풍문으로 다른 사람을 판단하는 것은 금물이다. 현재의 자세와 태도 그리고 전문성으로 판단하라.   성과보다 존재에 고마워하라.  칭찬을 할 때는 성과에 대한 칭찬보다는 그 사람의 존재에 대한 칭찬을 해주는 것이 효과적이다.   감정의 70퍼센트 정도는 표현하려고 애써라.  자기 감정의 3분의 2 정도는 자기답게 표현하는 비법을 터득할 필요가 있다. 나머지 3분의 1은 마음속에 묻어두는 것이 좋다. 묻어가는 법도 반드시 터득할 기술이다.   휴먼 네트워크를 만들어라. 들으면 친해진다. 묻고 잘 들어라.  자신이 떠드는 것보다 상대방의 말을 더 많이 듣는 것이 언제나 이문이 남는 거래다.    일에 대한 강령 7가지  의식적으로 문제의식을 가져라.  문제의식이 없으면 일은 단순 반복된다. 어제의 방식으로 오늘의 일이 처리되고, 내일의 일 역시 어제의 방식으로 처리될 것이다. 반복이 재생산될 때 개선과 혁신은 없다. 혁신의 능력 없이는 지식사회에서 성장하고 번영할 수 없다. 어제의 방식을 의심하라. 어제의 방식으로 오늘의 일을 처리하는 것을 퇴보라 생각하고 부끄러워하라.   실험하고 모색하라.  실패를 두려워하면 실험하기 어렵다. 실패는 아주 잘 배우느느 또 하나의 방법일 뿐이다.   알아주지 않아도 계속하라. 긍정적인 자긍심을 가져라.  자긍심은 자신을 좋아하는 마음이다. 남이 시키는 대로 하거나 하는 일에 대해 자신의 이유를 찾지 못하면서 자긍심을 가질 수 는 없다. 따라서 먼저 자신이 매일 하고 있는 일을 자신의 언오로 규정해보자.   자신만의 방식을 찾아라.  전문가의 세계에서 중요한 것은 차별성이다.   1인기업이라 생각하라. 자신의 지적 자산을 형상하라.  지적사회의 재산은 지식이다. 지식은 만들어져야 하고 저장되어야 하고 유통되어야 하며 활용되어야 한다. 매일 자신의 실험과 모색의 과정을 올려 회원들과 공유하도록 하라.    운이 좋아지는 강령 7가지  호의를 배풀어라. 잘난척 하지 않고 똑똑하게 보여라.  상대방의 말에 반박하고 싶거나 꼭 한마디 해주고 싶어 못 견딜 때는 의견을 말하기 전에 반드시 질문을 하라. 좋은 질문은 훌륭한 반복보다 훨씬 부드럽고 창조적이다. 답변이 부족하면 상대방이 스스로 무너지고 답변이 훌륭하면 당신은 황금같은 조언을 듣게 되는 것이다. 더욱이 당신은 꼭 필요한 대목에서 꼭 필요한 질문을 한 현명한 사람으로 기억될 것이다.   변명하거나 남에게 원망을 돌리지 마라.  일이 잘못된 책임을 다른 사람에게 전가하는 것은 쪽박을 깨는 바보짓이다. 결코, 책임으로부터 자유로워질 수도 없고, 비난을 전가한 상대방과 적이 될 뿐이다. 책임을 인정하되 주눅 들지 마라. 같은 실수를 하면 바보라고 스스로 비웃어줘라. 그러나 다른 실수를 하면 창조적 행위의 일환이라고 스스로 위로하라. 검증된 방식은 안전하나 보상도 적다. 새로운 바식의 모색은 실수를 동반하나 도약과 대박이 가능하다.   한 해 동안 꼭 하고 싶은 일을 한두 개 골라라. * 꼭 하고 싶은 일을 하면 인생이 즐겁다. 과거의 자신과 경쟁하라 .  자신의 과거와 경쟁하는 것은 적을 만들지 않고, 스스로 나아지는 방식이다. 가장 어려운 싸움은 자신과의 싸움이며 가장 가치 있는 진보는 자신의 어제보다 나아지는 것이다.   다른 사람에게 공을 돌려라. 복수하지 마라.  자기계발 강령 7가지  자신의 기질과 재능을 찾아내라. 노력의 8할을 자신의 특성에 집중하라. 하루 한두 시간의 해방구를 만들어라. 매일 해야 이룰 수 있다. 독학 없는 배움은 없다. 스승을 구하고 파트너를 찾아라. 기록하지 않는 것은 사라진다.  기록된 하루는 조금씩 다르지만 기록되지 않은 하루는 모두 같아 구별되지 않는다.    퇴직 강령  준비하라 자신에게 맞는 일을 유일한 방식으로 제공하라.  ‘뭘 하면 먹고 살 수 있을까’라는 생각에 빠지면 절대로 먹고 살 수 없다. ‘내가 잘할 수 있는 가슴 뛰는 일은 무엇일까’ 이 질문의 끈을 놓지 말아야 한다. 자신의 기질과 재능과 경험을 연결해 차별화하라. 그리고 그 일에 전력을 다하고 즐겨라.    p125 변화는 불행한 사람들의 주제다. ‘지금의 나’와 ‘내가 바라는 나’ 사이의 간격을 인식하는 불행한 자각으로부터 변화는 시작한다. 이 간격을 못 견디는 절박한 사람만이 이 길을 선택한다. 변화는 에너지를 많이 요구하는 작업이다. 자신에 대한 창조적 증오 없이는 이 에너지를 공급받을 곳이 마땅치 않다.\n그러나 변화가 더욱 매력적인 이유는 그것이 ‘내가 바라는 나’로 향하는 여정이기 때문이다.\n129 노동은 심심함을 이기는 아주 생산적인 일이긴 하지만, 노동이 바쁨을 만들어내면 우리는 석고처럼 된다. 바쁨은 새로움의 천적이다. 머리는 죽고 손발은 헉헉대는 것이 바로 바쁨의 모습이다. 바쁨은 전염성이 아주 강하다. 휴가조차 바쁘게 하고 쉼조차 바쁨으로 가득 채운다. 결국 심심한 것을 참을 수 없게 만든다. 사람들은 그렇게 해서 모두 똑같아지는 것같다.\np134 아이들이 커서 자신의 일에 몰두하게 되면, 가족 여행조차 함께하기 어렵기 때문에 아이들이 자라나는 십여 년 정도는 기쁨을 추억으로 간직할 수 있도록 해야 한다는 것이다. 여행은 사람들이 가장 좋아하는 기쁨 중의 하나다. … 그러나 중요한 것은 우선순위다.\np147 우리는 실패를 두려워한다. 그렇기 때문에 삶이라는 경기장에서 졸렬한 축구를 하는 것이다. 현란한 드리블도 멋진 패스도 강력한 슛도 해보지 못한 채, 그저 공을 기다리고 모처럼 공이 오면 내놓지 않으려 한다. 그 많은 시도, 그것을 실패라고 부르지 말자. 그 실패를 지금부터 시도라고 부르자.\np148 머리속에 남은 것이 없다면 독서 방식에 변화를 주어야 한다. 밑줄을 치면서 ㅇ릭자. 다 읽고 나서 밑줄 친 부분을 컴퓨터에 옮기면서 다시 음미하자. 강렬하게 다가오는 구절은 따로 떼어내 ‘나를 움직인 한마디’라는 파일에 넣어두자. 그리고 응용하자. PT에도 인용하고, 팸플릿을 만드 때도 인용하고, 편지 쓸 때도 인용하자. 그러면서 독서는 훨씬 흥미진진한 사상과 언어의 채집 과정이 된다. 모든 배움과 훈련은 그 과정에 대한 진화를 요구하며, 방식의 변화에 따라 효과는 급증하게 마련이다. 실패한 방법을 답습하면서 여전히 좋은 결과를 기대한다면 우둔한 것이다. 현명한 사람은 성공할 때까지 방법을 달리해본다.\np163 특히 재능이 많은 살마들은 한곳에 몰입하기 어렵다. 이 일도 좋아 보이고 저 일도 재밍ㅆ어 보이면 어떤 하나도 경지에 이르기 어려워진다. 하나에 전념하라. 이것이 바로 경영의 기초인 ‘선택과 집중’이다. 이때 유의할 점은 무엇을 선택하더라도 그 수준은 예술적 경지를 추구해야 한다는 것이다. 예술이란 사물을 더 잘 만드는 것이다. 예술은 필요를 넘어선다. 더할 수 없는 경지, 즉 완벽을 향해 나가야 한다. 그러면 그 일이 무엇이든 그 살마은 그 분야의 예술가가 된다. 예술이야말로 가장 화려한 변모의 체험이다.\np170 부지런하다는 것은 미덕이다. 분명하다. 그런데 나는 필요에 따라 이 금면을 몰아 쓰는 것이 전략적으로 훨씬 더 유용하다는 것을 깨닫게 되었다.\n똑같은 일을 반복하기 위해 매일 아주 많은 야근을 하고 있다면 그 부지런함은 격무를 몸으로 때우고 있다는 반증에 지나지 않는다. 끝없는 야근을 종료하려면 지금의 프로세스에 도전해야 한다. 새로운 프로세스는 다른 살마이 만들어주지 않는다. 내가 나서서 만들어내야 한다. 시키는 일을 마치는 것, 이것이 내 직무의 전부가 아니다. 내가 해야 할 일을 잘해내기 위해서 가장 좋은 ㅂ아법을 찾아내는 것 역시 내 직무의 영역이다. 바로 이런 인식의 고양이 주도적 리더십의 핵심이다. 이때 손발의 부지런함은 두뇌의 활동으로 확장되며, 매일 반복되는 저부가가치의 일이 일의 방식을 바꾸는 프로세스의 혁신 프로젝트로 전환된다.\n일을 잘하느냐 못하느냐의 기준에는 크게 네 가지 수준의 차원이 있다.\n 가장 초보적인 단계가 초보적 부지런함의 단계다. 성실한 초보의 단계. 노동의 차원 시키는 일, 즉 과업을 달성하는 새로운 방법을 찾아내는 차원. 프로세스 혁신. How. 일을 연결과 접속의 차원으로 인식하는 실험의 차원. 지금까지 해오던 일을 하는 대신 새로운 개념이 할 일을 찾아내는 차원. 일 자체는 전환. What. 가장 창의적인 집단의 구성원들이 지니는 자세. 일이 즐거움이 되는 놀이의 차원. 일이 예술의 경지에 이르는 차원. 일은 필요를 충족시키는 것이 아니라 영혼의 웰빙이 기여하는 수준에 도달.  p177 직장에서의 생활이 내가 깨어 있는 시간의 3분의 2를 차지한다는 간단한 을 사실을 각성.\n","id":44,"section":"posts","summary":"p17 술과 구라를 즐기되 항상 혀를 조심하라. 어느 장소에서나 어느 주제에 대해서나 할 말을 다하는 자는 불행한 자이니 말하고 싶을 때마다 세 번을 더 깊이 들어라 특히 나이가","tags":["Book"],"title":"(책) 나는 이렇게 될것이다.","uri":"https://cychong47.github.io/2018/07/i-am-going-to-be/","year":"2018"},{"content":"p21 사람들이 업무의 인간적인 측면보다 기술적인 측면에 주로 매달리는 가장 큰 이유는 기술적인 부분이 더욱 중요하기 때문이 아니라 거기에 매달리는 것이 훨씬 더 쉽기 때문이다.\np24 실수를 허용하지 않는 분위기는 직원들에게 방어적인 태도를 양산할 뿐이다. 즉 직원들로 하여금 실패할 것 같은 일은 아예 시도조차 하지 않게 만드는 것이다. 개발 프로세스를 체계화하려고 하거나 엄격한 방법론을 강요하면서, 팀원들이 확실한 성공을 보장할 수 없는 것들에 대해 중요한 결정들을 내리지 못하게 한다면 그들은 점점 더 소극적이고 방어적인 태도를 취한다. 실수를 허용하지 않는 분위기로 인해 평균적인 기술 수준은 약간 향상될지도 모르지만, 팀은 위기에 처하게 될 것이다.\np25 그들을 닦달해서 억지로 움직이게 할 수 있을지는 몰라도, 그들이 창의적이고 창조적이며 풍부한 사고를 하도록 만드는 것은 불가능하다. 사람들의 옆구리를 찔러서 단기 생산성을 올릴 수 있을지는 모르지만 장기적인 관점에서 그런 방법은 효과적이지 않다. 스스로의 동기가 아니라 상사가 강요한 동기에 의해 일한다는 사실만큼 직원들의 사기를 떨어뜨리는 것은 없을 것이다.\np28 사람들은 새로운 프로젝트의 가치를 주로 수치에 의존하는 경향이 있다. 팀원들이 얼마나 많은 코드들을 만들어 낼 수 있는 가 혹은 얼마나 많은 문헌 조사가 이루어졌는가에 대해서는 관심을 가지면서도, 팀웍 전체가 개발 과정에서 어떠한 역동적인 역할들을 담당하고 있는가에 대해서는 관심을 갖지 않는다.\np65 샤론은 천성적으로 뛰어난 관리자적 자질을 가진 사람들이 그렇듯이 다음 사실을 알고 있었다. “관리자가 진정 해야 하는 일은 사람들에게 일을 시키는 것이 아니라 그들이 일에 전념할 수 있는 환경을 만들어 주는 것이다”\np75 직원들이 근무 시간의 양을 늘이기 위해서라기보다는 근무 시간의 평균적인 질을 향상시키기 위해 초과근무라는 수단을 택한다는 것이다. (다른 사람이 없는 새벽이나 늦은 시간에 집중할 수 있어서)\np85 상위 집단의 업무 공간은 조용하고 프라이버시가 보장되며 불필요한 방해로부터 차단되어 있다.\np105 사람들이 진짜 일하는 시간은 바로 혼자서 일하는 때이기 때문이다.\np113 직원들은 매일 머리를 쓰는 작업을 하러 출근하는 것이다. 일터가 조금이라도 조용하고 차분해진다면 그들은 아무 조건없이 두뇌를 사용하여 자기 일을 열심히 할 수 있을 것이다.\np121 문제는 기술이 아니라 습관을 바꾸는 것에 있다.\np129 우뇌가 배경 음악을 듣느라 바쁘다면 창의적인 도약 과정이 생겨날 기회는 사라진다.\np141 사람들은 창문이 없는 집에서 산다는 것은 상상도 못하면서, 낮 시간의 대부분을 창문이 없는 사무실에서 보낸다.\np149  꼭 필요한 사람들을 뽑아라. 그들이 떠나지 않도록 행복하게 만들어라. 그들을 자유롭게 풀어 주어라.  p193 업무의 도전적 성격은 중요하다. 하지만 그 자체로 중요한 것은 아니다. 그것이 중요한 이유는 사람들이 함께 초점을 맞출 수 있게 하는 것들을 제공하기 때문이다. 도전은 함께함을 위한 도구일 뿐이다. 즐겁게 일하고 최대한의 능력을 발휘하는 최고이 작업 그룹에서, 팀의 상호 작용은 무엇보다도 중요하다. 그것이 바로 사람들이 끝까지 노력하고, 모든 것을 일에 투자하고, 엄청난 장애를 극복하는 이유이다.\np197 경영 위원회에서 이익의 증대를 위해 열을 올리고 있는 동안, 그 목표는 하부에서 일하는 사람들에게는 별로 큰 소득을 가져다 주지 않는 것이다. ‘십억 달러 수익성 증대’, ‘회사의 기록적인 분기 실적’과 같은 목표에 하위 직원들은 관심도 갖지 않는다. … 그들은 목적을 달성하는 기쁨을 함께 느끼며 공동의 성공을 위해 팀 내에 속해 있었다. 회사의 이익에 대한 관심을 환기시키는 것은 전혀 도움이 되지 않는다. 그것은 단지 성공을 사소하고 의미 없는 것으로 만들어 버렸다.\np220 관리자들이 팀에 대해 유일하게 신경 쓸 때는 팀을 깨려고 할 때 뿐이다.\np225 스파케티 회식. 바로 관리자가 팀원들이 함께 성공을 거둘 수 있는 작은 업무들을 끊임없이 제공한다는 것이다.\np241 팀 형성 기법을 갖고 있는 관리자들은 전체 업무를 부분적으로 완성하여 보여 줄 수 있는 것들로 나누려고 애쓴다…. 팀의 구성원들은 중간 확인 작업을 해야 할 때가 되면 준비하고 있다가 진짜 목표를 향해 전력질주할 것이다. 중간 확인 작업이 성공하면 다음 목표에 쓸 에너지는 재충전된다. 또한 그렇게 함으로써 팀은 서로 더욱 가깝게 느끼게 된다.\np310 존슨은 ‘신뢰는 하지만 의문을 제기하는 사람들’만이 변화에 진정으로 동참시킬 만한 유일한 집단이라고 주장한다. 이들을 설득할 때는 카드놀이를 할 때 처럼 논리를 따라서는 안된다. 이 의심의 양단에 서서 같은 편이 될지 안 될지 확실하지 않은 사람들은 기존의 방법보다 새로 도입할 방법이 엄청나게 나을 거라고 논리적으로 설득해 봐야 전혀 흔들리지 않을 것이다. 당신이 사람들에게 변화를 요구하려고 할때마다 항상 주문처럼 반복해서 말해야 할 것이 있다.\n 변화에 대한 사람들의 반응은 본질적으로 이성적인 것이 아니라 감정적인 것이다.\n 윌리엄 브리지스는 그의 저서 \u0026lt;변화 관리\u0026gt;에서 절대로 기존의 방식을 폄하하는 발언을 해서는 안된다고 말한다. 대신 우리는 기존의 체계를 새로운 변화를 일으키는 데 도움이 되는 것으로 치켜세워야 한다.\np313 낡은 현상태 -\u0026gt;(생소한 요소)-\u0026gt; 카오스 -\u0026gt;(생각의 변화)-\u0026gt; 실행과 융합 -\u0026gt; 새로운 현상태\n","id":45,"section":"posts","summary":"p21 사람들이 업무의 인간적인 측면보다 기술적인 측면에 주로 매달리는 가장 큰 이유는 기술적인 부분이 더욱 중요하기 때문이 아니라 거기에 매달리는 것이 훨씬 더 쉽기 때문","tags":["Book"],"title":"(책) 피플웨어","uri":"https://cychong47.github.io/2018/07/peopleware/","year":"2018"},{"content":"30 생산성의 증가가 오히려 일자리를 필요없게 만든다. 사람의 노동력을 대체할 것들이 등장하기 때문이다.\n31 지나친 생산성은 고용의 안정성을 해지며, 높아진 생산성만큼 사회와 경제가 성장하지 않으면 안 된든다는 압력으로 작용한다.\n33 거대한 생산성과 효율성을 바탕으로 하는 소비자 중심의 과소비 사회가 종말을 맞이하려고 한다. 과소비를 통해 외형이 성장하고, 이를 맞추기 위한 생산성의 독려와 일자리를 유지했던 성장의 순환 사이클이 그 동력을 잃고 있다.\n52 지식노동자의 주된 역할은 정보를 다루고, 찾아내며, 컴퓨터가 계산한 내용을 바탕으로 새로운 지식을 만들어 내고 분석하는 일이라 할 수 있다. 그러나 이러한 것들이 새로운 기술에 의해 대체가 가능해지는 미래에는 결국 판단과 비판적인 사고, 공감 등 기계로 대체하기 어려운 더욱더 새로운 기술이 필요하게 된다. 지식노동자가 비지니스를 어떻게 관리하고 운영하는지 알았다면, 인사이트 노동자나는 비지니스가 어떻게 그리고 왜 필요한 지에 대한 근본적인 의문에 답할 수 있어야 한다.\n62 “물질이 저의 인생을 의미 있게 만드는 데 아무런 도움이 되지 않는다는 결론에 도달했습니다”\n67 자신이 집에 돌아갈 때 어떤 마음을 가지고 가는지를 생각했다. 자존심이 상했거나 기분이 나쁜 날이면 집으로 돌아가 자녀들을 만났을 때 잘 대하기 어렵다. 반면 성취를 이루고 인정받은 날은 기분 좋게 가족들을 만날 것이고, 행복감을 느낄 것이다. 이처럼 그녀는 배우자이자 부모로서의 개개인의 역할과 긍정적인 여향에 대해 고민했고, 그렇기에 직장에서의 건강한 마인드는 가정, 그리고 결국은 사회를 이끄는 힘이 된다고 믿었다. 이러한 그녀의 시각은 크리스텐슨 교수에게도 관리와 경영의 소중함에 대해 다시 한 번 되새기게 했다.\n68 시간과 재능, 그리고 에너지를 어떻게 쓸 것인가에 대해서만 고민하지, 인생에 대한 목적에 대해서는 그 중요성을 놓치기 때문이다.\n70 반복되는 문제와 대응은 문화를 만들고, 관행과 본능에 따라 문화를 따르게 된다. MIT Edgar Shein 교수 아이가 어렸을 때 공감을 통해 문제를 해결하고, 부모를 존경하고, 옳은 일을 따라 결정을 내리는 문화를 형성하였다면, 자녀가 청소년기가 되었을 때 겪게 되는 통제의 어려움은 덜하게 될 것이다.\n73 기업가 Oliver Segovia HBR “ 행복은 내가 사랑하고, 잘하고, 세상이 원하는 것의 교차점에 있다. Happiness comes from the intersection of what you love, what you’re good at, and what the world needs”\n행복은 열심히 찾기만 한다고 미소 짓지 않는다. 역설적이게도 “행복해야 하는데”라는 걱정을 덜 하는 것이 가장 행복해지는 법이라는 말도 있다. 세상과 하나 되어 나 자신의 역할을 묵묵하게 수행하면서, 진정한 사회적 가치를 만들어 낼 때 내가 행복할 뿐만 아니라 세상에 행복을 전파하는 사람이 될 수 있다. 나 자신이 가장 잘할 수 있는 것을, 열정을 가지고, 사회적 가치로 만들어 낼 때 기회가 주어질 것이다.\n82 배워야 한다는 의무가 아닌, 호기심에서 시작된 학습은 그 효과가 이처럼 확연히 드러난다. “아이들은 스스로 학습 환경을 만들 수 있는 여견을 제공한다면, 누구나 스스로 배울 수 있습니다”\n##84 미래에는 결국 많은 사람과 소통하고 나누며 자신의 일을 행복하게 하는 사람이 성공한다.\n정보가 넘치는 세상이다. 아이들의 재능을 꽃피우게 할 방법과 이렇게 가지게 된 재능을 어떤 방식으로 자신들의 삶과 연결시킬 것인지에 대해 부모도 같이 고민할 수 있다. 이를 생업과 직업으로 연결시키기 위해서는 단순히 아이가 좋아하는 분야를 찾고 해당되는 재능을 찾는 것만으로는 안 될 것이다. 소통 능력이나 사회관계, 경제에 대한 개념, 또는 과학이나 수학 같은 것들이 필요할 수도 있다. 그렇다면 아이들은 자신의 꿈을 위해 공부해야 하는 당위성을 파악하게 되는 것이다.\n부모는 미래를 읽을 수 있는 혜안을 가지려는 노력을 게을리해서는 안 된다.\n92 수렴적 사고 (Covergent Thinking) 여러가지를 종합하고 분석하는 능력 발산적 사고 (Divergent Thinking) 엉뚱한 곳으로 튀는 경향 수렴적 사고와 발산적 사고를 자유롭게 전환하는 연습도 필요한데, 종종 새로운 정보를 과거의 정보나 지나간 아이디어와 결합시키거나 잠시 말도 안되는 엉뚱한 아이디어들을 계속 내놓다가 이를 정리하고 단단하게 만드는 작업을 반복하면 창의력을 키울 수 있다.\n94 자유롭게 노는 것을 좋아하는 아이들의 성향과 공부 습관을 기르는 것이 서로 다른 영역이기 때문에 아이들이 괴로워하고 고생하는 경우가 많다. 이럴 때 중요한 것은 부모와 선생님의 역할이다. 공부하는 습관을 가지도록 격려하고 도와주면서, 동시에 가끔씩 특별 프로글매이나 독특한 시도를 허용하며, 호기심을 자극할 수 있도록 지도하면 아이들은 훨씬 쉽게 창의력을 기르고 융합적 사고를 할 수 있게 된다. 또한 공부 과정에도 창의성을 발휘해 자신ㅇ만의일과와 공부 일정을 세우고, 공부할 학습지를 스스로 찾게 하는 것도 좋다. 이 과정을 실패하면, 공부하는 습관을 들이지 못하고 시간을 낭비하거나 자신의 미래에 대한 비전을 잃고 수동적으로 공부하는 등 잠재되어 있는 자신의 뛰어난 기량을 꽃피우지 못하게 된다.\n106 기본적으로 내놓기보다는 지키는 것에 익숙하며, 자신들이 원하는 것을 가져가려고만 하는 경우가 많다. 이런 기업이나 사람들은 네트워크에 참여하기 어렵고, 참여해도 적응하기 어렵다.\n이런 변화에 적응하는 것은 쉬운 일이 아니다. 그렇지만 비교적 위험성이 덜한 지식자산부터 내놓고, 조금씩 신뢰를 쌓아 나가는 것이 중요하다. 그리고 흐름의 네트워크를 통해 자연스럽게 해당 지식 자산의 가치가 상승하는 것을 관찰하면 이런 새로운 흐름의 원리를 파악할 수 있다. 네트워크의 신뢰도가 올라가고 참여자들도 보다 많은 것을 내놓기 시작하면 이 네트워크는 선순환의 고리를 돌기 시작할 것이다. 보다 높은 가치가 있는 지식이 공유되고, 이들이 결합하여 더 높은 부가가치를 가진 형태로 변화된다면 점진적 혁신이 이루어진다. 이렇게 한 단계 업그레이드한 지식자산은 또다시 공유되면서 새로운 발전의 원천이 될 수 있다. 세상의 변화 양상은 주입식으로 공부하고 개인이 지식을 많이 쌓아 나가는 것보다는, 지식과 경험을 공유하고 소통을 통해 그 가치를 높여 나가면서 실질적인 협업을 통해 눈에 보이는 성과를 창출하길 원한다. 이를 통해 지식과 경험의 흐름을 요구하고, 또 그런 능력을 가진 인재를 필요로 하고 있다.\n120 사람들은 일하지 않으면 논다고 생각한다. 그러나 놀이의 반대는 ’일’이 아니라 ‘우울’이다.\n140 아이들에게 추천하는 좋은 게임.\n 게임하는 시간에 제한. 온라인 게임은 시키지 않음.  게임의 완성도가 있으면서 명확한 끝이 있어 매일 적당한 시간을 투자해서 정복해 나가는 게임(젤다의 전설). 사용자가 자유롭게 게임 속 세계를 만들 수 있어 창의성과 성취감을 높일 수 있는 게임(마인크래프트). 가족들이 함께 몸을 쓰며 즐기는 게임(위) 역사에 대한 괏미을 고조시킬 수 있는 패키지 게임(에이지오브엠파이어)   아이들에게 틈틈이 게임을 어떻게 즐기고 있고, 어떤 면이 좋았는 지 질문.  세다가 다르고 세상의 규칙이 달라지고 있는데, 기성세대의 선입견만 가지고 모든을 것을 제약하려는 시도는 어쩌면 아이들을 편하게 관리하려는 어른들의 이기심에서 비롯된 것일 지 모른다. 본인들은 아이들을 이해하려고 노력하지 않으면서, 아이들이 말을 듣지 않고 게임만 한다고 한탄하고, 아이들을 죄인으로 만드는 법을 자꾸만 만드는 것이 과연 옳은 것인지 잘 생각해 볼 문제다.\n게임에 대한 부모들의 시각에 따라 게임을 대하는 아이들의 자세도 달라진다. 막는다고 막아지는 것도 아니다. 숨어서 몰래하거나 또는 억지로 참게 하기보다, 건강하게 즐기고 게임이 주는 유익을 누리는 방법을 찾을 때다.\n158 외국어 능력의 중요성을 아이들에게 각인시키는 것이다. 무엇보다 자신의 필요에 의해 외국어에 매진할 수 있도록 동기부여를 한다면, 그 열정에 의해 외국어 능력은 일취월장하게 되어 있다.\n외국 게임. 공부하지 않으면 안되는 게임으로 아이들의 학습을 유도. 세계사를 공부해야 게임을 잘할 수 있는 에이지오브엠파이어, 토탈워, 문명. 영문판을 사서 매일 시간 제한. 단 해당 게임을 마스터하기 위해 공부하는 시간에는 특별히 제한을 두지 않음. 그랬더니 아이들이 영어사전을 이용해서 매뉴얼과 인터넷에 공개된 다양한 외국어 사이트를 뒤지면서 자료를 찾았고, 이러한 과정을 통해 영어 공부를 두려워하지 않게 되었다.\n Stencil Works History Channel EBS 다큐멘터리  174  휴대폰과 PC, 게임과 인터넷 등은 정해진 시간만큼 이용하도록 한다. 매주 하루 반나절은 휴대폰과 PC, 게임과 인터넷을 하지 않는다. 부모와 아이들이 함께 산책하면서 진중하고도 소소한 이야기를 나눌 기회를 가진다. 한 달에 한 번은 가까운 공공도서관에 가서 책 속에 파묻혀 몇 시간을 보낸다. 일주일에 하루는 부모와 아이들이 함께 게임하는 시간을 가진다.  ","id":46,"section":"posts","summary":"30 생산성의 증가가 오히려 일자리를 필요없게 만든다. 사람의 노동력을 대체할 것들이 등장하기 때문이다. 31 지나친 생산성은 고용의 안정성을 해지며, 높아진 생산성","tags":["Book"],"title":"(책) 내 아이가 만날 미래","uri":"https://cychong47.github.io/2018/07/the-future-of-my-children/","year":"2018"},{"content":"42 우리는 통제할 수 있는 것에 초점을 맞추되, 통제할 수 없는 것에는 마음을 편히 먹어야 한다.\n44 이제는 불평도 하지 않고, 남을 탓하지도 않을거야. 내 앞에 놓인 세상을 거부할 게 아니라, 있는 그대로의 세상에 뛰어들어서 내가 통제할 수 있는 것부터 시작할 거야. 무슨 일을 할 수 있을 지 찾아봐야겠어.\n50 자신의 지금 위치가 어디이든, 영향력의 원이 얼마나 크든 그 원의 밖이 아닌 안에서 변화를 일으키려 노력하라. 어차피 손을 쓸 수도 없는 큰 그림을 분석하고 해부하는데 소중한 에너지를 쓰지 말라. 대신 그 시간과 에너지를 손을 쓸 수 있는 것, 즉 영향력의 원 안에 있는 것에 써라. 그러다 보면 영향력의 원이 알아서 커질 것이다.\n53 우리 발목을 잡는 것은 ‘시스템’이 아니라 우리 자신의 ‘인식의 결함’이다. 통제할 수 없는 외부의 사건에 정신이 팔리면 통제할 수 있는 삶의 결함을 보지 못한다. 우리가 고통스러운 것은 세상이 불완전하기 때문이 아니라, 개인의 시스템이 불완전하기 때문이라는 것을 알지 못한다. 개인의 시스템은 충분히 개선할 수 있는데도 말이다. 삶의 사소한 부분까지 깐깐하게 살펴보야만 성공과 마음의 평화, 즉 자유를 손에 넣을 수 있다.\n57 품질 좋은 상품이나 서비스, 능력있는 직원, 수익성은 그것을 창출하는 훌륭한 시스템의 결과물이지 시스템이 아니라는 것이다.\n101 회사 생활과 개인 생활을 뜯어고치는 작업이 왜 막막하기만 했는 지 알 수 있을 것 같다. 그것들을 감히 손댈 수 없는 ‘불가항력의 존재’라고 생각했기 때문이다. 그것들을 단순한 하부 시스템으로 분해해서 하나씩 최적화할 수 있다는 생각은 한 번도 해본 적이 없었던 것이다. 잘못된 구조를 고치는 게 아니라, 보이지도 않는 잘못된 구조에서 비롯되는 문제들을 처리하느라 급급했던 것이다.\n103 센트라텔에 처음으로 거둔 가장 큰 성공은 내부 커뮤니케이션 시스템을 완성한 것이다. 매순간 모든 직원이 다른 부서에서 무슨 일이 일어나고 있는지를 알 수 있게 되었다.\n직원 2명이 시스템 방법론과 그에 따른 문서화 작업을 받아들이지 못한 것이다.\n107 근무시간 줄이기\n5킬로그램 감량하기\n카페인 음료 섭취 줄이기\n일주일에 최소 4회 이상 운동하기\n몸에 좋은 음식 먹기\n물 많이 마시기\n당분과 염분 섭취 줄이기\n3개월마다 혈액 검사하기\n혈액 검사 결과에 따라 필요한 영양제 먹기 일주일에 최소 1회 친구들 만나기\n가족과 일대일로 마주하는 횟수 늘리기\n매일 최소 1시간 이상 독서하기\n일주일에 단행본 1권, 잡지 6권 읽기\n158  시스템을 개선하는 관점, 즉 밖에서 그리고 위에서 바라보는 관점을 몸에 익혀야 한다. 비지니스와 직장, 개인 생활에서의 목표를 구체적으로 정한다음, 문서로 작성한다. 그 목표를 달성하기 위해 활용할 방법을 간략히 정의한다. 이것이 전략 목표 설정서이다. 자신만의 종합 운영 원칙을 만들고, 그것을 의사 결정의 지침으로 삼는다. 개선할 수 있는 시스템에 대해 구체적으로 적는다. 이때 이미 존재하는 시스템과 새로 만들어야 할 시스템을 포함시킨다. 그 외의 것들은 버릴 각오를 한다. 각 시스템을 가장 기본적인 구성 요소로 분해한다. 비니지스와 직장의 경우에는 각 단게를 1-2-3 단계 형식으로 문서화한다. 시스템을 하나하나 살펴보면서 각 단계의 효율성을 높인다. 이때 최대한 단순함을 추구해야 한다. 필요하면 순서를 바꾸고, 단계를 추가하거나 뺀다. 각 시스템을 작업 절차서에 기록하여 비지니스나 직장에서 시스템을 계속 유지할 수 있도록 한다. 새로운 작업 절차를 추구하고, 정기적으로 관리해야 한다. 필요에 따라 조정할 수 있다.  ##198\n예외를 두지 말고 새로 마련한 절차서 모두를 시험해 보라. 절차서를 공개하기 전에 단계별 내용을 꼼꼼히 확인하고, 문제를 이해할 수 있는 직원에게 작성한 문서를 보여줘라.\n208 작업절차서는 상세하게 작성하되, 지나치지 않게 작성해야 한다. 원하는 결과를 계속 얻을 수 있을 정도로만 말이다. 그래서 현장을 모르는 일반인이 보고도 처리할 수 있을 수준이면 된다.\n211 당신은 불필요한 업무, 불필요한 정보에 집착하여 너무 많은 시간을 낭비하고 있지 않는가? 쓸모없는 세부적인 내용에 집중하고 있지 않은가?\n214 ‘당신이 무슨 말을 하건, 무슨 생각을 하건 상관없어! 중요한 건 ‘무엇을 하느냐’이지”\n219 직원들이 발전기 작동 과정에 대해 단계별로 ‘담당자 아니어도 이해할 수 있을 정도로’ 쉽게 작성해 두었다. 이 때문에 시험 운행할 때마다 늘 문서를 보고 가동한다. 흥미로운 점은 매달 시험 가동을 할 때마다 계속 작업 절차가 개선되었다는 점이다. 절차서는 살아 있는 생명체와도 같다. 급변하는 환경과 시험 가동 관리자의 개선안에 따라 계속 바뀌기 때문이다.\n227 POS(Point Of Sale) 방식.\n 꾸물대지 말라. 지금 당장 실행해서 일을 마무리하라. 그 일을 직접 하건 위임하건, 내던져 버리건 이란 실행하라. 일을 자동화하고, 체계화해서 개인적으로 해야 할 일을 줄여라.  230 멀티태스킹 또는 동시에 여러 개의 시스템이 기능하도록 만드는 것은 컴퓨터를 완벽하게 응용하는 것이지 사람이 하는 것이 아니다. 멀티태스킹은 컴퓨터에 맡겨라.\n249 오늘날의 기업 문화 속에서 모든 활동 영역이 효율성을 갈구하고 있지만, 실상 서비스의 질은 상당히 떨어진다… 하지만 당신이 시스템을 만들고 유지하는 일에 초점을 맞춘다면, 시스템은 일관적인 품질을 보장해 주기 때문에 탁월한 서비스를 제공하는 일이 쉬울 수 있다. 다시 한번 강조하지만 내부의 시스템을 만들고, 유지하고, 개선하는 일이 관리자의 주된 목표가 되어야 한다.\n","id":47,"section":"posts","summary":"42 우리는 통제할 수 있는 것에 초점을 맞추되, 통제할 수 없는 것에는 마음을 편히 먹어야 한다. 44 이제는 불평도 하지 않고, 남을 탓하지도 않을거야. 내 앞에 놓인 세상을","tags":["Book"],"title":"(책) 시스템의 힘","uri":"https://cychong47.github.io/2018/07/the-work-system/","year":"2018"},{"content":"꿈을 노트하라 꿈을 날짜와 함께 적어 놓으면 그것은 목표가 되고 목표를 잘게 나누면 그것은 계획인 되며, 그 계획을 실행에 옮기면 꿈을 이루게 되는 것이다.\np46 우리는 무거운 짐을 지고 살아간다. ‘등이 휠 것 같은 삶의 무게여’라는 가사도 있다. 내가 책임져야 할 가족과 도움을 필요로 한 친구들, 나에게 주어진 과중한 업무와 기대. 이 거추장스러운 짐들이 사실은 ‘내 인생의 날개’일 수도 있다.\np68 다른 사람과 한 약속을 지키는 것도 중요하지만 자기 자신과 한 약속을 지키는 것이 더 중요하다 세상과 타협하는 것도 위험하지만 자기 자신과 타협하는 것이 가장 위험하다\np75 누구나 할 수 있는 일이 아니라 나만이 할 수 있는 일을 계발해야 한다 언제든 대체 가능한 사람이 아니라 내가 아니면 안되는 능력을 가져야 한다는 것이다 세상은 네가 가진 그 한 가지의 재능을 인정할 것이다.\np79 우리가 정말 포기하는 이유는 불가능해서가 아니라 불가능할 것 같아서라고\n목표는 최고를 지향하되 계획은 최악을 가정하라\n함께 가라 빨기 가려거든 혼자 가라 멀리 가려거든 함께 가라 빨리 가려거든 직선으로 가라 멀리 가려거든 곡선으로 가라 외나무가 되려거든 혼자 서고 푸른 숲이 되려거든 함게 서라\n 인디언 속담  p125 진짜 실력은 보이지 않는 데서 나온다. 눈가림은 언제나 들통이 난다. 자신에게 진실하고, 최선을 다할 때 그 결과는 돌아오기 마련이다.\np149 자기만 생각하는 사람과 남을 배려하는 사람은 삶의 스케일이 다르다. 자신만 바라보면 ‘우물 안 개구리’가 되고, 다른 사람을 돌아보면 온 우주를 품게 된다.\np158 세상을 보는 눈\n사람을 유익하게 꾸짖고 그의 잘못을 깨우쳐주려고 할 때는 그가 어떤 방향에서 사물을 보는가를 관찰할 필요가 있다. 왜냐하면 그 방향에서 보면 대체로 옳기 때문이다. 그리고 그에게 옳은 점은 인정하되 그것이 어떤 면에서 틀렸는가를 보여줘야 한다. 그는 이에 만족을 느낄 것이다. 왜냐하면 자기가 틀린 것이 아니라 단지 모든 면을 보지 못했다는 것을 알게 되기 때문이다. -파스칼 \u0026lt;팡세\u0026gt; 중에서\n지금이라는 의미\n사람은 이미 흘려보낸 되돌릴 수 없는 시간을 못내 아쉬워하고 연연해하면서 가장 뜻 깊고, 가장 중요한 ‘지금’이라는 시간을 소흘히 한다.\n","id":48,"section":"posts","summary":"꿈을 노트하라 꿈을 날짜와 함께 적어 놓으면 그것은 목표가 되고 목표를 잘게 나누면 그것은 계획인 되며, 그 계획을 실행에 옮기면 꿈을 이루게 되는 것이다. p46 우리는 무거","tags":["Book"],"title":"(책) 지금 꿈꾸라, 사랑하라, 행복하라","uri":"https://cychong47.github.io/2018/07/just-now-dream-love-be-happy/","year":"2018"},{"content":"신호 - 보상 - 반복행동 - 열망\n 습관에 숨겨진 \u0026ldquo;열망\u0026quot;을 찾아야 한다. 담배를 습관적으로 피우는 사람도 담배를 피우는 이유가 니코틴 부족이 아니라 잠깐 동안의 여유를 주기 때문일 수 있다. 이때는 이 \u0026ldquo;여유\u0026quot;라는 열망을 담배가 아닌 산책 등으로 바꾸면 습관을 바꿀 수 있다. 이때 그 열망에 대한 \u0026ldquo;신호\u0026quot;와 \u0026ldquo;보상\u0026quot;을 알아야 한다. 그래서 담배가 주는 것과 유사한 담배껌, 팔굽혀 펴기, 스트레칭등의 새로운 반복행동을 선택하면 담배를 끊을 확률이 높아진다.\n 믿음\n 하느님이 아니더라도, 내 상황이 더 좋아질 거라는 믿음이 필요하다. 습관을 근절할 수는 없어도 바꿀 수는 있다. 또 \u0026lsquo;동일한 신호와 동일한 보상을 유지하면서 새로운 반복 행동을 더하라\u0026rsquo;는 습관 변화의 황금률을 사용하면 습관을 쉽게 바꿀 수 있는 것도 사실이다. 여기에 습관을 항구적으로 바꾸기 위해서는 변할 수 있다는 믿음이 필요하다.\n p151\n 폴 오닐 알코아를 변화시켜야 한다는 알았지만, 직원들에게 \u0026lsquo;명령\u0026rsquo;할 수는 없었죠. 명령을 받는다고 뇌가 작동하는 건 아니니까요. 그래서 처음에는 한 가지에 집중했습니다. 나쁜 습관 하나를 고칠 수 있다면 그에 따른 변화가 회사 전체에 파급될 것이라고 생각했습니다.\n p156\n 정부의 다른 분서를 분석할 때마다 정책의 성공과 실패를 구분 짓는 기준이 조직의 습관에 있다는 걸 확인할 수 있었습니다. 가장 효율적으로 운영되는 정부 기관들은 반복 행동의 중요성을 알고 있었습니다. 반면에 효율성이 떨어지는 기관들은 조직의 습관에 대해 고민하기는 커녕 \u0026lsquo;왜 조직원들이 명령을 따르지 않는가\u0026rsquo;라는 사실에만 골머리를 썩이는 사람들이 윗자리를 차지하고 있었습니다.\n p157\n 폴 오닐은 자신이 알코아의 최고 경영자가 되면 노동조합과 경영진 모두가 인정하는 것을 최우선 순위에 두어야 한다고 생각했다. 모든 조직원을 하나로 묶는 구심점, 또한 조직원들이 일하고 의사소통하는 방법을 바꿔 놓을 수 있는 수단을 그에게 안겨 줄 구심점이 무엇인지 알아내야 했다.\n p162\n 우리가 습관적으로 운동을 시작하면, 하다못해 일주일에 한 번씩이라도 운동을 시작하게 되면, 운동과 관계없는 삶의 다른 부분들까지 부지불식간에 바뀌기 시작한다. 운동을 시작하면 식습관이 좋아하지고, 생산성이 높아지는 경우가 대표적인 예다. 담배도 덜 피우고, 동료들과 가족들에 대한 인내심도 깊어진다. 신용 카드도 한층 절체해서 사용하고 스트레스도 덜 받는다고 한다. 저녁 식사를 함께하는 습관을 지닌 집안에서 자란 아이들은 숙제하는 능력이 뛰어나고 성적도 좋으며, 감정 조절도 잘하고 자신감이 넘친다. 매일 아침 자신의 손으로 침대를 정리하는 습관은 생산성, 행복 지수, 예산을 통제하는 절제력 등과 상관관계가 있다.\n p177\n 단번에 너무 많은 변화를 도모한 까닭에 하나도 제대로 해낼 수 없었던 것이다.\n p191\n 자제력이 강한 청소년이 지능 지수가 높은 청소년보다 학문적 성과가 높을 것이라 예측한다. 또한 꾸준히 성적이 향상될 확률이 높다. 따라서 지적 능력보다 자제력이 학문적 성과에 더 큰 영향을 미친다고 할 수 있다.\n p199\n 의지력은 무한한 것이 아니다. 다른 일에 의지력을 사용하면 그 만큼 의지력이 약해진다. (쿠기 먹지 말기 시험 + 문제 풀기)\n p202\n 아이들에게 피아노나 운동을 가르치는 게 무척 중요하다. 그 교육 자체가 아이를 훌륭한 음악가나 다섯 살배기 축구 스타로 만들지는 않는다. 하지만 피아오를 1시간 동안 연습하거나 운동장을 15바퀴 뛰는 방법을 어떻게든 습득하면 자신을 관리하는 힘을 키워 가기 시작한다. 다섯살에 축구공을 10분 동안 쫓아 다닐 수 있는 아이는 6학년이 되면 숙제를 제때 해낼 수 있게 된다.\n 의지력. 스타벅스. 하워드 슐츠.\n \u0026ldquo;너는 우리 집안에서 대학에 진학하는 첫 번째 사람이 될 거다.\u0026rdquo; \u0026ldquo;오늘 밤에는 어떻게 공부할 거니? 내일은 무엇을 할 거니? 시험 준비는 다 했니? 그런 독려와 질문 덕분에 나는 습관적으로 목표를 세우게 됐습니다. \u0026ldquo;만약 당신이 누군가에게 성공하는데 필요한 것을 갖고 있다고 말해 주면 당신 말이 맞다는 걸 그 사람이 입증해 보일 거라고 나는 정말 진심으로 믿습니다.\u0026rdquo;\n p216\n 자제력이 필요한 일을 하라는 요구를 받을 때 그 일을 개인적인 이유로 한다고 생각하면, 다시 말해서 그 일을 즐긴다고 생걱하거나 그 일ㄹ로 누군가를 돕기 때문에 선택받은 사람이란 기분이 들면 그 일이 훨씬 덜 힘듭니다. 반면에 아무런 자율권도 없이 명령에 무조건 따라야 한다면 의지력 근육이 훨씬 빨리 피로해집니다.\n p228\n 조직 내의 파괴적인 습관은 수많은 산업체와 기업에서도 찾아볼 수 있다. 그런 파괴적인 습관은 문화에 대해 생각하지 않는 리더들의 무관심에서 비롯된다. 그 때문에 파괴적인 습관이 어떤 방해도 받지 않고 독버섯처럼 자라난다. 제도적인 습관이 없는 조직은 없다. 제도적인 습관이 계획적으로 형성된 조직과, 그런 습관이 우연히 형성된 조직이 있을 뿐이다. 적절한 기회를 포착해서 활용할 줄 아는 리더들은 파괴적인 습관까지 바꿔 갈 수 있으며, 때로는 위기가 닥쳤을 때 올바른 습관이 형성되기도 한다.\n p230\n 대부분의 기업은 신중한 의사 결정에 근거해서 합리적인 선택을 하는 듯하지만 실제로 그렇게 운영되는 기업은 그리 많지 않다. 오히려 기업의 행태는 조직 내에서 오랫동안 지속된 습관에 영향을 받으며, 그것은 직원들의 독자적인 결정에서 흔히 드러나다.\n p248\n 이들의 공통점은 위기에서 가능성을 포착했다는 것이다. 혼란이 닥쳤을 때야말로 책임을 부여하고 한층 공평한 세력 균형을 조성하는 방향으로 조직의 습관을 바꿀 수 있는 적기이다. 위기에 직면하면 조직의 습관이 유연해지기 때문이다. 때로는 어렴풋이 나타나기 시작한 재앙에 대한 인식을 자극하는 것이 덮어두는 것보다 백번 낫다. 이런 점에서 위기는 무척 유익하다.\n p254\n 무신경과 나태함에 물든 제도적 습관으로 조직을 위험에 빠뜨릴 수 있는 휴전이 지배하는 기업에서도 이런 변화는 얼마든지 가능하다. 그렇다고 부정적인 습관에 물든 기업이 리더의 명령 하나로 변하지는 않는다. 현명한 경영자라면 위기의 순간을 포착해서 혹은 위기의식을 조장해서라도 \u0026lsquo;뭔가 변해야 한다\u0026rsquo;라는 의식을 심어 주며, 모든 조직원이 일상적으로 행하는 패턴을 점검하도록 유도해야 한다.\n p294\n YMCA 새로운 습관(이 경우에는 운동)을 팔기 위해서는 사람들이 이미 알고 좋아하는 것(친구를 사귀기 쉬운 곳으로 가려는 본능)으로 그 습관을 포장해야 한다.\n p302\n 첫번째 단계에서 사회 운동은 가까운 지인들 간의 우애와 강력한 연대감. 두번째 단계에서 사회 운동은 이웃과 집단을 하나로 묶는 약한 연대감과 공동체의 습관 덕분에 커져간다. 세번째 단계에서 사회 운동의 지도자들이 참여자들에게 새로운 습관을 심어준다. 변화된 정체성과 주인 의식을 잉태하는 새로운 습관의 영향으로 사회 운동은 지속된다.\n p330\n 어떤 생각이 구체화되어 공동체 넘어까지 확대되기 위해서는 자체의 추진력을 지녀야 한다. 이런 단계에 이르는 가장 확실한 방법은, 구성원들에게 자신의 힘으로 어디까지 갈 수 있는 지 생각해 내도록 유도하는 습관을 심어 주는 것이다.\n p366\n \u0026lsquo;거의 성공\u0026rsquo;이 그들에게 한 번 더 배팅 하도록 유도하는 습관을 자극하기 때문이다.\n p372\n 습관을 바꾸기 위해서는 습관을 바꾸겠다는 결심이 먼저 있어야 한다. 습관의 반복 행동을 유도하는 신호와 보상을 알아내고, 대안을 찾으려는 의식적인 노력이 있어야 한다. 우리에게 통제 수단이 있다는 걸 깨닫고, 그 통제 수단을 의식적으로 활용할 수 있어야 한다. 습관을 바꿀 수 있다고 깨닫는 순간부터 우리는 언제라도 습관을 바꿀 수 있고, 그 책임은 우리 자신에게 있다. 습관이 개조될 수 있다는 걸 깨닫는 순간, 습관의 힘을 파악하기가 한결 쉬워진다. 그때부터 남는 과제는 습관을 바꾸겠다고 결심하고 실천하는 것이다.\n p374\n 제임스는 결단을 내렸다. 그는 자신과 운명을 통제하고 더 나아질 수 있으며, 무엇이든 바꿀 수 있다는 자유 의지가 있다고 믿으면서 12개월을 보냈다. 그런 믿음이 사실이란 증거는 어디에도 없었다. 현실은 그렇지 않았지만 그는 변화가 가능하다고 믿었다. 내 자유 의지에 따른 첫 행동은 자유 의지를 믿는 것이었다.\n ","id":49,"section":"posts","summary":"신호 - 보상 - 반복행동 - 열망 습관에 숨겨진 \u0026ldquo;열망\u0026quot;을 찾아야 한다. 담배를 습관적으로 피우는 사람도 담배를 피우는 이유가 니코틴 부족이","tags":["Book"],"title":"(책) 습관의 힘","uri":"https://cychong47.github.io/2018/07/power-of-habit/","year":"2018"},{"content":"p215 우리 사회가 뭔가 단단히 헷갈리고 있다. 정치, 경제, 사회 전반에서 국가의 강력한 통졔를 바란다면 헌법부터 뜯어고쳐야 할 것이다. 일단 자유민주주의의 \u0026lsquo;자유\u0026rsquo;와 \u0026lsquo;민주\u0026rsquo;는 빼야 할 것 같으니까. 대만민국의 국가적 정체성부터 다시 생각해봐야 할 일이다. 공산주의가 싫어 자유주의를 주장하는 거라면 작은 정부를 지향해야 옳다. 그리고 그 작은 정부가 왜 시장에 대한 규제 철폐만 주장하고, 사상, 언론, 표현, 결사 등의 영역에서는 작은 소리만 있어도 사회가 불안정하고 무질서해진다며 통제하려고 하는 지 합리적인 이유를 내 놓아야 한다. 큰 정부에 대한 막연한 환상에서 일단 벗어나, 국가와 시민의 기본적인 관계에 대해서부터 다시 고민해 볼 일이다.\np217 우리에게 부족한 것은 바로 이것이다. 국가와 개인의 관계에 대한 기본적인 관점 말이다. 우리 사회가 여전히, 전방위적으로 큰 정부, 더 나아가 제왕적 대통령을 그리워하는 이유는 \u0026lsquo;국가는 어떤 경우에도 개인의 기본적인 자유와 보편적 인권을 억압해서는 안 된다\u0026rsquo;는 자유민주주의의 원리가 실현되는 사회를 체험해 본 적도 만들어본 적도 없기 때문이다. 그래서 그게 무엇인지 잘 모르기 때문이다. 자유민주주의 국가를 표방한 지 60년이 넘은 지금도 말이다.\np219 그렇다고 가난한 사람들도 걱정만 할 필요는 없다. 정말 정부가 99%의 서민이 아닌 1%의 부자를 위한 정치를 하고 있다고 생각된다면, 정부를 갈아치우면 된다. 그런 상황에서는 다행히 부자보다 서민이 압도적으로 많을 테니 말이다. 다수결이니 모든 사람은 한 표씩 행사할 수 있다. 불만이 있으면 규합하고 집결해 투표하면 된다.\np237 진보주의자들이 좀 더 해야 할 고민은 가령 이런 것들이다. 어떻게 하면 대중을 설득할 수 있을까, 어떻게 하면 그들의 삶이 어려움에 처해 있다는 것을 느끼게 할 수 있을까, 어떻게 하면 내가 바로 당신을 위해 이 말을 하고 있다는 것을 그들이 공감할 수 있을까 하는 것이다. 하지만 이들은 그런 것보다 어떤 게 더 정확한 진보의 관점인가, 어떻게 말하는 게 내가 진보임을 더 확실히 보여줄 수 있을까, 어떻게 해야 내가 아군으로부터 쭉정이 회색분자로 찍히지 않을까를 더 고민하는 것 같다. 이렇게 \u0026lsquo;그들만의 리고\u0026rsquo;에 머물러 있는 그들, 멀리서 그들을 바라보던 시민들의 발길은 이미 멀어진 지 오래다.\np251 우리는 아직도 시스템을 더 좋게 바꿔야 한다고, 바꿀 수 있다고 생각한다. 좌파든 우파든 마찬가지다. 흔들림을 느끼는 것은 바꿀 수 있는 힘이 있다는 것을 믿기 때문이다. 다만 우리는 아직 충분히 경험하지 못했다. 그저 분노를 분출만 하는 게 아니라 제도 안에서 그 분노를 조직화하고, 그 조직을 통해 서로 정정당당하게 대결해 승패를 가르고, 그 결과에 따라 타협하고 더 좋은 시스템을 향해 앞으로 나아가는 합리적 민주주의의 경험을 아직 충분히 갖고 있지 못하다.\n","id":50,"section":"posts","summary":"p215 우리 사회가 뭔가 단단히 헷갈리고 있다. 정치, 경제, 사회 전반에서 국가의 강력한 통졔를 바란다면 헌법부터 뜯어고쳐야 할 것이다. 일단 자유민주주의의 \u0026lsq","tags":["Book"],"title":"(책) 나는 다른 대한민국에서 살고 싶다","uri":"https://cychong47.github.io/2018/07/i-want-to-live-in-a-different-korea/","year":"2018"},{"content":"p39 자신이 정말 좋아하는 일을 만날 수만 있다면, 인생의 절반은 성공한 것이다. 끔찍이 좋아하는 일이라면 남들이 말려도 다시 덤벼들어야 한다.\n지금 내가 쌓고 있는 스펙이 과연 10년, 20년 후에도 계속 하고 싶은 일에 도움이 될까? 다시 한번 생각해 보라.\np47 부디 이 땅의 청춘들이 자신을 괴롭게 하는 스펙 쌓기에 매달리지 않기를 바란다. 고통의 순간이 가면 즐거움의 시간이 오리라는 보장을 누가 해줄 것인가? 지금 나를 가장 즐겁게 하는 일, 뜨겁게 나를 느낄 수 있는 일에 열정을 쏟아부어야 진정한 퍼플피플로 성장할 수 있다.\np57 후회할까봐 미리 걱정하는 일은 선택 자체를 방해한다. 해본 후회와 안 해본 후회는 근본적으로 다르다. 해본 후회는 후회하는 순간부터 점점 줄어들지만, 해보지 않은 후회는 점점 커질 뿐이다. 그러니 목표가 생기면 되돌아보지 말고 뛰어야 한다. 그러다가 목표에 도달하면 한번 뒤돌아보고 크게 웃으면 된다.\np71 디자인은 신제품 개발의 과정뿐 아니라 생활의 불편함을 해소해 나가는 과정이기도 하다. 우리는 현실을 바꾸기도 하지만 현실에 순응하는 경우가 더 많다. 이는 마치 문화와 같다. 제품의 형태가 바뀌면 그것을 사용하는 우리의 생활도 바뀌지만 한번 변한 것은 한동안 그 속에서 머물 수도 있기 때문이다. 하지만 이 세상의 모든 혁신은 불편함을 참지 못하고 새로운 것을 파고드는 태도에서 출발했음을 잊어서는 안 된다.\np77 누군가 나에게 \u0026ldquo;예전에는 차가운 머리만으로 돈을 벌었는데 이제는 따뜻한 마음 없이는 돈을 벌 수 없다\u0026quot;고 말했다. 이제는 철저히 사용자 중심적인 상품이 아니면 환영받을 수 없는 시대다. 정보는 상품보다 빠르게 유통되고 있으며, 사용자들은 어떤 것이 자신을 위한 최선의 선택인지 훨씬 쉽게 판단할 수 있게 되었다. 자신의 취향이 아닌, 상대를 위한 취향을 담은 따뜻한 마음과 배려, 그것이 혁신의 시작이자 끝이다. 성공의 기회를 잡기 위해서는 그 위력과 가능성에 집중해야 한다.\np100 피카소는 \u0026ldquo;모든 아이들은 아티스트로 태어난다. 다만, 그들을 아티스트로 지키는 것이 문제다\u0026quot;라고 말했다. 따라서 어린이들이 타고난 상상력을 유지하는 일은 교육의 기본이 되어야 한다.\np105 아무리 새로운 아이디어라도 생각에만 머무르는 것은 창의성이 아니다. 창의성은 보고, 듣고, 느낄 수 있는 행동이다. 창의성을 이론적 방식으로 교육하기가 힘든 이유가 바로 여기에 있다. 창의성은 발견하는 것이 아니라 생존경쟁을 통해서 살아남기 위한 노력으로 진화된다. 타고난 재능을 낭비하는 사람도 있고, 끊임없는 노력으로 창의성을 재창조하는 사람도 있다. 결국 승부는 노력의 차이로 만들어진다. 우리가 누군가를 앞선다는 것은 생각에만 그치지 않고 그것의 가치를 확장시킬 만한 실행에 들어갔다는 뜻이다.\np106 간디. \u0026ldquo;이 세상에 있어서는 안되는 6가지\u0026rdquo;. \u0026lsquo;원칙 없는 정치\u0026rsquo;, \u0026lsquo;희생 없는 종교\u0026rsquo;, \u0026lsquo;양심 없는 상술\u0026rsquo;. \u0026lsquo;인성 없는 과학\u0026rsquo;, \u0026lsquo;도덕 없는 쾌락\u0026rsquo;, \u0026lsquo;땀 없는 부\u0026rsquo;\np109 우리가 자신과 가족을 우해 돈을 벌던 직장은 그것이 블루칼라건 화이트칼라건, 서서히 기술이 대체해 나갈 것이다. 간디가 그토록 경계하던 \u0026lsquo;인성 없는 과학\u0026rsquo;의 시대가 오고 있는 것이다.\np112 인간의 창의력은 7세 때가 절정기라는 이야기를 들은 적이 있다. 이 이론이 사실이라면 참 슬픈 이야기다. 창의력으로 세상에 이바지해야 할 성인기에 근접할수록 창의력은 고갈되어 간다는 말이 아닌가? 아이들이 타고난 창의력을 잃어가는 배경에는 교육과 사회적 접촉이 절대적인 영향을 미치니 이 또한 아이러니다.\np116 구글 에릭 슈미트. 2012년 5월 보스턴 대학교 졸업식장에서 \u0026lsquo;하루 한 시간, 컴퓨터 화면을 꺼라\u0026rsquo; \u0026ldquo;기술에는 심장이 없다\u0026quot;는 점을 강조하면서 컴퓨터 화면을 끈 한 시간 동안 눈앞에 있는 친구와 동료, 가족들과 대화하고, 생각하고, 웃으라고 덧붙였다.\np118 마리사 메이어, \u0026ldquo;구글에서는 아이디어가 생기면 우선 시도합니다. 완벽을 찾을 때까지 기다리기보다 남보다 빨리 시작하고, 재해석하고, 발전시킵니다. 시장에서 원하는 모습으로 진화시키는 것입니다. 바로 이것이 구글식 혁신입니다\u0026rdquo;\np120 혁신이란 창조를 행동으로 옮기는 일이다. 행동이 따르지 않는 창조는 아무런 가치가 없다. 멋진 생각이 떠올랐다면 반드시 그것을 지나치지 말고 잡아서 구현할 방법을 찾아야 한다. 이런 습관이야말로 퍼플피플로 진화하기 위한 디딤돌이다. 결과가 어찌 될 것인지를 미리 걱정할 필요는 없다. 중요한 것은 자신이 원하고, 자신이 좋아하는 일이라면 지금 당장 나가서 그것을 실행하는 용기다.\np136 농경시대의 가축을 다루듯 고용인을 당근과 채찍으로 다루는 기업 문화는 이미 사라진 지 오래다. 정보화 시대를 지나 감성의 시대를 살아가는 우리에게 가장 큰 동기 부여는 일을 즐기는 과정에서 얻는 성취감이다.\np144 소통의 기술을 몸에 익히고 미래 사회에서 활발하게 성장해 나가기 위해서는 청소년기부터, 아니 그보다 이른 유,아동기에 가정 내에서부터 생각을 공유하고 의견을 주고받는 습관을 길러야 한다. 체 내의 혈액이 탁해지고 순환이 나빠지면 동맥경화에 걸리는 것처럼 상호 간의 소통이 막히면 우리 사회 역시 필요한 양분과 산소를 제때 공급받지 못하고 병들고 만다. 사람과 사람, 조직과 조직 사이의 혈액을 씽씽 건강하게 돌리기 이해 소통의 기술을 익혀보자.\np146 기업이 발전하기 위해서는 조직도를 피라미드가 아닌 원형으로 만들어야 한다. CEO가 원이 중심에 자리를 잡고 임직원들은 CEO의 주위를 채우며 점차 큰 원을 만든다. 이 원은 시간이 흐를수록 나무의 나이테처럼 확장해 나간다. 이것이 바로 창의적 기업환경이며, 영속적으로 성장할 수 있는 건강한 기업의 구조다.\np152 그렇다고 해서 지금 조직에 \u0026lsquo;메기\u0026rsquo;를 풀어높으면 많은 어려움에 봉착하게 될 것이다. 변화를 받아들여야 한다는 인식은 어느 정도 생겼다 하더라도 오래 묵혀온 구태를 일순간에 벗어던지기는 어렵기 때문이다. 이미 조직 내에서 자리를 잡고 있는 사람들은 타성에 젖어서 기존의 업무방식을 고수하려 할 것이다. 그들에게 변화란 불편하고 귀찮은 일일 뿐이다. 그러니 작은 일 하나라도 바꿔보려고 하면 여러 가지 어려움이 있을 수 밖에 없다.\n조직 내에서 변화를 주도하고 리더가 되어보겠다는 사람은 혼자서 뭔가를 할 때보다 더 큰 도전정신이 필요하다. 그러다 보면 \u0026lsquo;엉뚱한 사람\u0026rsquo;, \u0026lsquo;이상을 쫓는 사람\u0026rsquo;으로 비칠 수도 있다. 하지만 조직을 변화시키고 진보시키는 것은 바로 이런 사람들이다. 시간이 좀 걸리고, 이겨내야 할 난관은 많겠지만 결국은 그들이 리더가 될 것이다.\n남들보다 더 먼 미래를 준비하려면 타성에 젖어 눈앞의 변화만을 쫓는 사람이 아니라, 변화를 주도해 나갈 수 있는 인재가 되어야 한다. 이는 기업은 인재가 능력을 발휘할 수 있는 환경을 제공하고 우리는 절대로 포기하기 않고 새로운 것에 도전하는 협업이 있어야만 가능하다.\np155 매니저는 직위가 만들지만, 리더는 따르는 사람이 만든다. 아무리 높은 자리에 있어도 따르는 사람들이 없다면 리더라고 불릴 수 없다. 반대로 직위가 높지 않아도 따르는 사람들이 많다면 바로 그가 리더다.\np158 대기업도 이제는 구멍가게 운영하듯이 장사해야 한다. 고객 한 사람 한 사람에게 얼마나 성실하고 정확하게 메시지를 전달하느냐가 고객을 확보하는 승부터가 될 것이기 때문이다.\np176 사람도 기업도 끝없는 자기반성과 도전을 통해 변화를 만들지 못하면 도태될 수 밖에 없다. 급격히 변화하는 산업 환경에서 살아남고 나아가 리더가 되기 위해서는 변화를 이끌고 혁신을 주도해야만 한다. 그것이 자신의 일생을 디자인하는 길이고 우리 사회의 일원으로서 부여받은 일익을 담당하는 방법이다.\np179 \u0026lsquo;편안함이 보장된 삶\u0026rsquo;이라는 울타리를 뛰어넘어 한 치 앞도 볼 수 없는 미래에 도전하는 것은 누구에게나 두려운 일이다. 하지만 어떤 새도 알 속에서 하늘을 나는 법을 배울 수는 없다. 성공이란 누군가 알을 깨주길 기다리는 것이 아니라 스스로 알을 깨고 나는 법을 배우는 것이다. 당신은 과연 나는 법을 배우고 있는가?\np220 산업시대의 유물인 당근과 채찍만으론 더 이상 동기부여가 되지 않는다. 직장인들은 이제 유연한 시간개념, 자유롭게 선택할 수 있는 과제, 일하는 즐거움, 성과를 인정해주는 보상을 기대한다. 그러니 사람을 고용할 때는 돈을 위해 당신을 돕는 사람이 아니라 그 일을 사랑하는 사람을 찾아야 한다. 개인도 마찬가지다. 많은 취업 준비생들이 연봉 높은 대기업에 목을 매지만 \u0026lsquo;대기업\u0026rsquo; 자체는 절대 꿈이 될 수 없다. 날마다 즐겁게 출근하고 싶거든 아침에 눈을 떴을 때 가슴 뛰게 하는 일을 찾아야 한다. 그것이 퍼플피플의 기본 자세다.\np223 시간의 지배를 받는 사람은 마감일에 자신의 능력을 맞춘다. 이런 사람은 같은 일이라도 시간을 많이 주면 천천히 한다. 시간을 지배하는 사람은 마감일에 무관하게 자신의 능력대로 일을 마치고 또 다른 일을 찾는다. 누가 더 성공하겠는가?\n제대로 된 시간과 용역의 관리를 위해서라면 주어진 기한에 얾매여서는 안된다. 작업에 필요한 시간과 에너지는 필요한 만큼만 쓰면 된다. 주어진 일을 조금이라도 빠르게 처리하고 남은 시간과 에어지는 또 다른 중요한 일에 사용하는 것이 효율적이다. 퍼플피플은 프리랜서처럼 시간을 자유롭게 사용하는 일에 종사할 가능성이 높기 때문에 시간 관리야말로 가장 중요한 능력이라 할 수 있다. 시간을 지배하는 자가 세상을 얻을 것이다.\n231 정말 하고 싶은 일이 무엇일까를 찾는 과정은 결코 쉽지 않았을 것이다. 하지만 무슨 일이 있어도 꼭 지켜야 할 세 가지 조건을 세우고 나니 자신이 선택해야 할 갈이 보였다고 한다. 첫째, 일하기 전부터 마음이 설레야 한다. 둘째, 일하는 동안에는 반드시 행복해야 한다. 셋째, 일을 마치고 나면 다른 사람에게도 기쁨을 주어야 한다.\n","id":51,"section":"posts","summary":"p39 자신이 정말 좋아하는 일을 만날 수만 있다면, 인생의 절반은 성공한 것이다. 끔찍이 좋아하는 일이라면 남들이 말려도 다시 덤벼들어야 한다. 지금 내가 쌓고 있는 스펙","tags":["Book"],"title":"(책) 퍼플피플","uri":"https://cychong47.github.io/2018/07/purple-people/","year":"2018"},{"content":"8p\n  혼 : 가슴 벅차게 하는 비전이 사람을 움직인다. 창 : 끊임없이 \u0026ldquo;왜\u0026quot;라고 물어라, 그러면 열린다. 통 : 만나라, 또 만나라. 들어라 잘 들어라.   16p\n IBM, P\u0026amp;G, Cisco, CEMEX 이 기없들의 공통점은 무엇일까? 그렇다 공룡처럼 몸집이 큰 기업들이다. 공룡인데도 민첩하다. 한가지 공통점은 회사 전체가 보다 큰 가치, 가슴을 울렁이게 하는 원대한 비전을 공유한다는 사실이다. 하버드경영대학원의 로자베스모스 캔터 교수(Rosabeth Moss Kanter) \u0026ldquo;모든 직원이 보다 큰 가치를 공유하게 되면 일선에서 어떤 문제가 부딛쳐도, 혹은 본사로부터 아무리 떨어진 곳에서 일하더라도 자발적으로 문제의 해결을 주도하게 된다\u0026rdquo;\n 17p\n 손정의 소프트뱅크 회장은 비전의 중요성을 강조하면서 이렇게 말했다. \u0026ldquo;눈앞을 보기 때문에 멀미를 느끼는 것이다. 몇백 킬로미터 앞을 보라. 그곳은 잔잔한 물결처럼 평온하다. 나는 그런 장소에 서서 오늘을 지켜보고 사업을 하고 있기 때문에 전혀 걱정하지 않는다\u0026rdquo;\n 18p\n 현실에 만족하고 안주하는 순간, 창은 시들고 만다. 다른 사람들이 선택한 쉬운 길을 거부하고, 늘 \u0026ldquo;왜\u0026quot;라고 물으며 새롭고 어려운 길을 갈 때에야 비로소 창이 싹튼다. 창은 손이 진흙으로 더러워지는 것을 두려워하지 않는 실험정신이고, 실패를 찬양하는 도전정신이다.\n 33p\n 무언가 디지털화할 수 있는 것은 결국 공짜 버전이 나오고 만다. 결국 당신의 숙제는 어떻게 공짜와 경쟁할 수 있느냐는 것이다. 공짜 버전이 제공하지 못하는 것을 제공하라. \u0026lsquo;아이튠즈\u0026rsquo;가 제공한 것은 편리함이었다. 제품을 파는 시대에서 서비스를 파는 시대로 바뀌고 있다.\n 43p\n 많은 리더들이 \u0026lsquo;어떻게 하면 구성원들에게 동기를 부여해 스스로 일하게 만들 수 있을까?\u0026rsquo; 라는 문제를 고민한다. 돈은 결코 정답이 아니다. 물론 누구나 돈이 필요하긴 하지만, 돈으로 사람을 움직이는 데는 한계가 있는 법이다. 경영자라면 이해득실을 전부 버려도 포기해서는 안 되는 죽어도 지키고 싶은 무엇을 최소한 한 가지는 마음속 깊이 갖고 있어야 한다. 그래야 사람의 마음을 움직일 수 있다. 그것이 바로 철학이고 혼일 것이다. 혼은 \u0026lsquo;사람을 움직이는 힘\u0026rsquo;이다.\n 46p\n 나는 사람들이 어떻게 그렇게 사는 지 상상을 할 수 없어요. 내가 보기에 정말 미친 것 같거든요. 아무리 높은 연봉이라도 일상생활의 일부로서 즐거움이 없는 삶을 나는 살 수 없습니다. 자본주의 체계란 놀라울 정도로 못돼먹은 겁니다. 80%이상의 사람들이, 생계를 위해 하는 일에서 아무런 즐거움을 엊지 못한다고 합니다. 대부분 사람들의 인생이 그렇습니다. 정말 미쳤어요.\n 49p\n 케네디 토머스 \u0026lt;열정과 몰입의 방법, Intrinsic Motivation at work\u0026gt; 사람들은 4가지 조건이 충족될 경우 일에서 재미와 열정을 느낀다. 1. 자신이 가치있는 일을 하고 있다고 느낄 때 2. 그 일을 할 때 자신에게 선택권이 있다고 느낄 때 3. 그 일을 할 만한 기술과 지식이 있다고 느낄 때 4. 실제로 진보하고 있다고 느낄 때\n 51p\n 세계와 경쟁한다는 것이 진정 어떤 의미인지 알고 있는 지\u0026hellip;\n 66p\n 다른 사람들의 생각에 얽매이지 마십시오. 타인의 소리들이 여러분 내면의 진정한 목소리를 방해하지 못하게 하십시오. 그리고 가장 중요한 것은 여러분의 심장과 직관이 이끄는 대로 살아갈 수 있는 용기를 가지는 것입니다. 이미 여러분의 심장과 직관은 당신이 진짜로 원하는 것이 무엇인지를 알고 있습니다. 나머지는 다 부차적인 것입니다.\n 70p\n 나는 만약 어떤 일에서 재미와 즐거움을 더 이상 찾을 수 없다면 드디어 다른 일을 찾아야 할 때가 된 것이라고 믿는다. 행복하지 않게 시간을 보내기에는 인생이 너무 짧다. 아침에 일어나면서부터 스트레스를 견뎌야 하고, 비참한 기분으로 일터로 나간다면 삶에 대한 올바른 태도가 아니다.\n 72p\n 좋아하지 않는 직장이지만 그래도 계쏙 남아 일해야만 하는 사람에게는. 인생은 긍정적으로 바라보는 사람에게 문을 열어준다. 일을 하면서 만나게 되는 사람들과 함께 즐거움을 찾아야 한다.\n 73p\n \u0026lsquo;나는 골치 아프고 힘든 일이 잔쯕 있을 때는 그 일이 해결되었을 때의 기쁨을 생각하면서 출근합니다\u0026rdquo; 개인은 일의 주인이 되어야 한다. 그래야 진정한 성공을 맛볼 수 있다. 기업은 조직원을 일의 주인으로 만들어야 한다. 그것이 조직원과 기업이 함께 성장하는 길이다.\n 84p\n 돈으로는 사람을 움직일 수 없습니다. 사람을 움직이려면 마음 깊은 곳에서 타오르는 동기를 부여해야 합니다. 이를 위해서는 이윤을 뛰어넘는 숭고한 경영철학과 경영자의 인격이 필요합니다.\n 90p\n 중요한 사실은 내발적 동기가 외발적 동기보다 더 지속성이 있고, 더 좋은 결과를 가져오며, 더 큰 심리적 안정을 가져온다는 점이다. 내발적 동기의 경우, 활동에 집중하는 것 자체가 보상이 되므로 언제까지나 높은 동기가 부여될 수 있고, 활동이 계쏙 유지돼 자연스럽게 좋은 성과를 내게 된다. 92p \u0026lsquo;당근과 채찍\u0026rsquo; 전략으로 상징되는 전통적인 기업의 보상 시스템은 종업원이 스스로 일하려는 동기, 즉 내발적 동기를 오히려 꺾을 수 있다는 점이다.\n 95p\n 천이유천 이란 중국 속담을 새기기 다닌다고 했다. 하늘 위에 또 하늘이 있다는 뜻이다. \u0026ldquo;제 성격에는 자만의 DNA가 흐르고 있습니다. 조금만 방심해도 우쭐해지기 쉬운 성격이죠. 그래서 늘 자만하지 않도록 스스로를 일깨우고 조심하고 있습니다\u0026rdquo;\n 96p\n 첫째가 중국의 개혁 개방 둘째가 높은 목표를 세우고 그것을 실현하기 위해 늘 노력한 갓 셋째가 언제나 공부하는 것\n 96p\n 간부는 큰 엔진이고, 그 밖의 모든 직원들은 큰 엔진과 함께 돌아가는 작은 엔진이 되어야 합니다. 밑의 직원들이 엔진에 따라 움직이는 기어가 되어서는 절대로 안됩니다. 어떻게 하면 일을 더 잘할 수 있을 지 스스로 생각하게 만들어야 합니다. 이렇게 해야 원동력이 더 커지게 됩니다.\n 99p\n 마케팅 1.0 소비자 머리에 호소 2.0 감성에 호소 3.0 영혼에 호소. 환경에 신경 쓰고 사회에 좋은 일도 하는 회사라면 내게 특별히 무엇을 주지 않더라도 그냥 좋다.\n 104p\n 혼은 \u0026lsquo;사람을 움직이는 힘\u0026rsquo;이며 \u0026lsquo;내가 여기에 있어야 하는 이유\u0026rsquo;이고 \u0026lsquo;개인을 뛰어넘는 대의\u0026rsquo;이다. 혼은 우리를 움직이게 하고, 버티게 하고, 극복하게 하는 근본적인 힘.\n 119p\n 사람들의 태도와 정신을 바꾸는 것이 중요합니다. 처음에는 불편해도 스스로에게 강제하고 단계적으로 반복 훈련을 하면 습관이 됩니다. 습관은 들이기는 어렵지만 나중에는 자연스럽고 편안해지죠. 개인뿐 아니라 조직이나 기관도 이런 식으로 변해야 합니다.\n 127p\n 끊임없이 노력해야 하고 아주 작은 디테일까지 세심한 주의를 기울여야 하며, 리스크를 감수하더라도 실행에 옮겨야 한다.\n 129p\n 다니엘 핑크 우리가 왜 새로워지고 창조적이지 않으면 안되는 지. 1. 아시아 - 아시아의 신흥시장 인력이 급성장한 경우, 루틴한 업무는 일상재가 될 것이다. 남들이 하지 않는 창조적인 일을 하지 않으면 안 된다. 2. 자동화 - 기계와 소프트웨어가 인간의 노동과 두뇌를 대신해가고 있다. 컴퓨터가 대체할 수 없는 인간의 우뇌만이 할 수 있는 창조적인 일을 하지 않으면 안된다. 3. 풍요 - 생활이 풍족해지면서 사람들의 새로운 욕구를 충족시키는 창의성 있는 인재가 날로 중요해진다. 당장은 사람들이 필요하다고 느끼지 못하지만, 사람들의 잠재된 욕구를 충족시킬 수 있는 상품을 개발하는 역량이 중요하다.\n 136p\n 다니엘 핑크 이제 우리에게는 펙트들이 너무나 넘쳐난다. 그런 팩트들을 스토리로, 문맥으로 엮어내지 못하면 팩트는 증발된다.\n 139p\n 마에다 총장은 권위적 리더쉽고, 창조적 리더쉽을 제시 권위적 리더쉽 - 채찍 중시, 위계질서 중시, \u0026lsquo;예스 혹은 노\u0026rsquo;의 명쾌함 중시, 옳은 판단인지 따지기, 장군처럼 생각하기, 실수 회피, 제한된 피드백만의 허용 창조적 리더쉽 - 당근 중시, 네트워크 중시, \u0026lsquo;아마도\u0026rsquo;와 같은 모호함 인정, 현실적 판단인지 따지기, 예술가처럼 생각하기, 실수로부터의 학습 환영, 무제한적 비판 허용\n 144p\n 이처럼 창을 얻기 위해서는 마음이 열려 있어야 한다. 우리는 어떤 결정을 내리면 자신의 생각이 틀릴 수도 있다는 생각에에 대해 개방적으로 되기 어렵다. 자신의 결정의 근거를 부정하는 모든 사실에 대해 마음을 닫기 쉽다. 그러나 창을 얻기 위해서는 다른 사람의 충고와 비판에 열려 있어야 한다.\n 145p\n 소설가 베르나르 베르베르 \u0026lsquo;풍부하고 다양한 호기심은 타고 나는 것이지만, 그 이후에는 끊임없이 정보와 지식을 습득하는 노력이 필요합니다. 나는 날마다 배웁니다. 뭔가 새로운 것을 하지 않은 날에는 \u0026lsquo;시간을 잃어버렸다\u0026rsquo;고 여깁니다.\n 161p\n 아마존 베조스의 선택 기준 Regret minimization framework 자신이 여든 살이 되었을 때를 가정해서 인생을 뒤돌아 보았을 때 후회할 일을 가장 줄이는 방법을 생각.\n 164p\n 큰 생각을 하려면 자신을 색다른 경험에 수없이 노출시켜보라.\n 164p\n 무용가 트와일라 타프는 사전에서 단어를 찾을 때, 그 단어 바로 앞, 뒷 단어도 함께 읽는 다고. 다음 번에 좋은 아이디어가 어디에서 올지 모르기 때문에. 한 번에 성격이 다른 여러 작품을 동시에 하고, 한 작품이 끝나면 그와 전혀 성격이 다른 작품에 도전하는 것도 창조성을 유지하는 그녀만의 노하우\n 165p\n 우뇌형 인간의 5가지 조건. 다니엘 핑크 1. 디자인이란 언어를 익히라. 2. 스토리를 만들라 3. 큰 그림으로 생각하라 4. 공감하라 5. Play하라\n 168p\n 미국 속담 에 \u0026lsquo;평소 알고 있던 악마가 낫다\u0026rsquo;. 그만큼 사람들은 변화를 싫어하는 보수적 본성이 있다.\n 174p\n 지식 e 시즌 4. 경로 의존성(Path Dep endency) 한 번 일정한 경로에 의존하기 시작하면 나중에 그 경로가 비효율적이라는 것을 알고도 여전히 그 경로를 벗어나지 못한다는 사고의 관습\n 190p\n 실패한 사람이 무엇을 해야 할 지 생각하지 않으면, 실패를 반복할 수 밖에 없다. 실패의 원인과 과정을 깊이 있게 생각하지 않으면, 실패는 실패의 어머니일 뿐이다. 실패는 도전과 발전을 위해 그 원잉늘 분석하고 거기서 창조적인 아이디어를 도출해낼 때, 비로소 가치가 있는 것이다. 부주의아 오판으로 똑같은 실수를 연발하는 것은 절대 용서받을 수 없는 실패다.\n 195p\n 창은 혼을 노력과 근성으로 치환하는 과정이며 매일 새로워지는 일이고 익숙한 것과의 싸움이다. 어느 날 갑자기 찾아오는 것이 아니라 노력하고 도전하는 하루하루가 쌓여야 비로소 발현되는 것이 창이다.\n 239p\n 호리바 마사오 \u0026lt;남의 말을 듣기 마라\u0026gt; 나와 같이 일하는 사람은 나와 다른 생각을 갖고 있어야만 존재 가치가 있는 법이다. 나와 똑같은 생각을 가지고 있다면 차라리 그 월급을 내게 달라\n 244p\n 조직 내의 진정한 소통은 위에서 아래로 흐르는 탑다운의 일방적 방식으로는 결코 이룰 수 없다. 진정한 소통은 아래에서 위로, 오른쪽에서 왼쪽으로 360도 어느 쪽에서든 자유롭게 흐르는 것이다. 톱다운 커뮤니케이션은 조직 전체를 톱, 한 사람의 능력 안에 머물게 한다. 그러나 360도 커뮤니케이션은 구성원 모두가 아이디어와 능력을 발휘할 수 있게 함으로써 조직 역량에 한계가 없어진다.\n 245p\n 가와시마 기요시 혼다 전 사장 최근 2~3년간 내가 말한 사항들이 사내에서 8할이나 통과됐다. 6할이 넘으면 원맨 경영의 폐해가 나타나는 위험신호라고 하는데, 그렇다면 지금 혼다가 위험하다는 얘기가 아닌가?\n 246p\n 지난 20년간 조사한 수백 명의 관리자 중 70%는 보스의 일이 실패하리라는 것을 알면서도 피드백이나 충고를 하지 않은 것으로 나탔다. 직원이 경영자에게 문제를 제기할 정도면 가볍게 하는 말이 결코 아닐 것이기 때문이다. 물이 흐르지 못하면 고여서 썩기 마련이듯, 소통이 원할하지 못한 조직은 결국 문제가 발생하기 마련이다. 이것이 경영자가 직원들이 자유롭게 말할 수 있는 환경과 분위기를 조성해야 하는 이유다. 직원 또한 소신껏 자신의 의견을 개진해야 하는 이유다.\n 252p\n 포스코 정준양 회장 리더는 VIP가 되어야 한다. 리더라면 Vision을 제시할 수 있어야 하고, Insight 통찰력과 철학 Philosophy를 갖고 있어야 한다고 주장했다.\n 254p\n 1977년부터 1997년 사이에 태어난 N세대의 특징은 - 선택의 자유를 최고의 가치로 여기고 - 협업에 익숙하며 - 사실 여부를 늘 검증하려고 하고 - 재미와 스피드를 추구한다.\n 258p\n 사일로(Silo) 바이오기업 몬산토 휴 그랜트 사장 무엇보다 연구 인력과 경영 관리 파트의 직원들이 함께 모여 일을 하기 시작했어요. 많은 기술 중심 회사들은 연구 인력과 경영 인력이 따로 근무하고, 별로 교류하지 않습니다. 그리고 위계 서열이 뚜렷하죠(경영 관리 인력이 주도권을 잡는다는 의미)\n 269p\n SAS 좋은 복지 프로그램을 제공하면 직원들 스스로 회사를 다니는 일에 가치를 느끼고 만족해가기 때문이에요. 회사가 직원을 만족시키면 직원들은 좋은 제품을 개발해 외부 소비자를 만족시킨다. 고객을 행복하게 하려면 고객과 만나는 쌔스의 직원들이 행복해야 합니다.\n 271p\n 직원이 행복해야 고객이 행복할 수 있다는 점만은 어떤 조직에나 통용된다는 점이다. 직원이 행복하지 않은데, 어떻게 동기를 부여받을 거이며, 어떻게 스스로 열심히 일해 좋은 제품과 서비스를 창출할 것인가? 조직의 통은 조직원들의 만족과 행복을 끌어내고, 이것은 다시 고객의 만족과 행복으로 이어진다. 만족과 행복은 끊임없이 확대재생산되는 것이다.\n 273p\n 그렇다면 어떻게 해야 조직원이 위에서 내려오는 과업에 대해서도 마치 내발적 동기에 의해 하는 일처럼 스스로 신이 나서 열심히 하게 만들 수 있을가? 이와 관련해 에드워드 데시 교수를 비롯한 자기 결정성 이론 심리학자들이 개발한 개념이 내재화 Internalization이다. 즉 외부 요인에 의해 자극되거나 통제되는 행동의 경우에도 조직이 인간의 3가지 기본적 욕구를 충복만이 환경을 구축해 지원할 경우, 사람들은 일을 스스로의 것으로 내재화하고 통홥하게 된다는 것이다.\n 275p\n 데시 교수는 일견 재미없는 일일지라도 그것을 왜 해야 하는 지 근본적인 이유를 제시하고, 그 일에 대한 상대방의 관점과 느낌을 존중해주며, 스스로 선택하는 경험을 많이 할 수 있게 하고, 일에 대한 압력을 최소화하라고 조언한다.\n 277p\n 20세기 초반 이후로 관리자들의 임무란 \u0026lsquo;어떻게 하면 웬만한 실력의 기술자들을 데려와서 같은 일을 빠르고 정확히 반복하게 만들까\u0026quot;였죠. 기업의 경영 구조 자체가 혁신을 생상하도록 설계된 것이 아니라 같은 일을 반복하도록 설계돼 있기 때문입니다.\n 278p\n 리더의 역할은 직원 저마다가 가진 재능과 지식을 효율적으로 한데 모으는 것이지, 그들이 무작정 일을 더 열심히 하도록 만드는 게 아닙니다. 똑똑한 사람들이 일을 많이 하도록 하는 게 결코 중요한 문제가 아닌 거죠.\n 279p\n 피터 센게 교수 내가 보기에 아무도 도발하지 않는 조직은 가장 위험한 조직입니다. 깊은 곳에 문제점이 있는데도 자칫 계속 문제를 썩힐 수 도 있으니까요. 건강한 조직은 서로 속을 터놓고 애기하기 때문에 문제를 실시간으로 파악하고 해결할 수 있습니다. \u0026lsquo;내가 이런 말을 해서 일자리를 잃으면 어떻게 하지?', \u0026lsquo;이 얘기를 했는데 누군가 나를 비웃으면?\u0026rsquo; 이라는 걱정들로 가득 찬 조직은 희망이 없는 조직이죠. 겉으로는 통제가 잘 되는 것처럼 보이기 때문에 CEO를 흐뭇하게 만들 수도 있지만, 수면 아래엔 문제점들이 그득할 것입니다. 센게 교수에 따르면 두려움으로 경영되는 조직은 방어직 사고에 의해 억압된 조직이라고 표현할 수 있다. 이런 조직 속에선 모든 사람들이 항상 다른 사람에게 \u0026lsquo;내가 그 문제에 대한 답을 갖고 있다\u0026rsquo;는 확신을 주기 위해 노력한다. 그렇기 때문에 어떤 상황에서도 자심감 찬 모습만을 보이기 위해 분투한다. 뿐만 아니라 자기 자신이나 다른 사람을 \u0026lsquo;부끄럽게 만드는\u0026rsquo; 이슈들을 제기하는 것을 매우 꺼리게 된다. 중요한 이슈이긴 하지만 어렵거나 당황스러운 주제에 대해 얘기하는 것을 피하는 것이다. 이런 폐해를 없애기 위해서는 모든 구성원이 비전을 공유하고, 같이 머리를 맞대=고, 함께 살아남기 위해 노력한다는 정신을 심어야 한다는 것이 그의 주장이다.\n 282p\n Gore사 상사나 부하가 없는 완전한 수평 조직이어서 모두가 동료(Associate)로 불리운다. 빌 고어는 더글러스 맥그리거 Douglas McGregors의 Y이론에 대한 믿음을 바탕으로 독특한 조직을 만들었다. Y이론이란 성선설로 인간은 오락이나 휴식뿐 아니라 자존과 헌신에 대해서도 본성적으로 욕구가 있으므로, 자발적으로 일할 마음을 갖게 하면 능력의 극대화가 가능하다는 분석이다.\n 288p\n 리더의 책무는 매일 회사를 빠져나가는 그 90%의 중요 자산이 내일 다시 회사로 돌아와서 재미있게 일하도록 하는 것이다.\n ","id":52,"section":"posts","summary":"8p 혼 : 가슴 벅차게 하는 비전이 사람을 움직인다. 창 : 끊임없이 \u0026ldquo;왜\u0026quot;라고 물어라, 그러면 열린다. 통 : 만나라, 또 만나라. 들어라 잘 들","tags":["Book"],"title":"(책) 혼창통","uri":"https://cychong47.github.io/2018/07/hon-chang-tong/","year":"2018"},{"content":"p52 \u0026ldquo;당신의 삶입니다. 당신의 사람을 이야기하라는데 가족을 위해 사는 게 전부라. 생활비만 제대로 해결된다면 가족에게 당신은 없어도 되는 존재라는 말이군요. 그런 현금 지급기와 같은 삶을 원한다면 더 이야기하는 것도 \u0026lsquo;시간낭비\u0026rsquo;군요\u0026rdquo;\np89 파울로 코엘료의 \u0026lt;순례자\u0026gt;에서는 꿈들을 죽일 때 나타나는 첫 번째 징후가 \u0026lsquo;시간이 없다\u0026rsquo;라고 말하는 것이라고 했습니다.\np97 가장 먼저 해야 할 일은 진지하게 고민하며 한발 내딛는 일입니다. 어디로든 상관없습니다. 자신을 둘러싸고 있는 경계를 벗어나기만 하면 새로운 사람들과 새로운 경험이 당신을 기다리고 있을 겁니다. 그렇게 보내는 시간, 시간을 쪼개는 게 아니라, 스스로를 탐구하고 찾기 위해 가치있게 쓰는 시간.\np116 인간은 자신의 삶에 만족하지 못할수록 자꾸 \u0026lsquo;적\u0026rsquo;을 찾게 됩니다. 가령, 회사에서 같이 일을 할 \u0026lsquo;동료\u0026rsquo;를 찾아야 하는데 스트레스를 주는 \u0026lsquo;적\u0026rsquo;을 발견하게 되는 것과 같죠. 적을 발견한 후로부터는 그 적에 대해 생각하는 데 시간을 낭비하게 됩니다. 적에게 나의 시간을 낭비하는 것은 너무 아까운 일입니다.\np136 빅터 프랑클 \u0026lt;죽음의 수용소에서\u0026gt; 세상이 내 모든 것을 빼앗고 나에게 최악의 상황을 주었더라도 나에게는 절대 빼앗길 수 없는 한 가지가 있음을 기억해야 한다. 그것은 바로 그 상황을 어떻게 받아들일 것인지에 대한 내 선택권이다.\np143 회사와 가정을 위해서는 일했지만, 자신을 위해서는 아무것도 하지 않은 하루죠. 자신을 위해서 아무것도 하지 않았다면 그 하루는 쉬어도 되는 하루가 아닙니다. 아직 할 일이 남은 하루죠. 지금 당장 3시간이 주어졌을 때 무슨 일을 할 것인가. 이것에 대한 고밍는 그동안 나만의 시간에 대해 고민하지 않았기 때문에 생기는 것 입니다.\np173 시간을 돈으로 계산하는 일은 인생에 매우 중요합니다. 지나면 다시 돌아오지 않을 시간을 정작 중요한 일이 아닌, 불필요한 일에 쏟고 있지는 않은지 알아보기 위함입니다. 가령 필요하지도 않은 물건에 들어가는 돈을 줄인다면 그만큼 시간을 버는 것과 같죠. 시간을 만들라는 건 쓸데없는 데 들어가는 시간과 비용을 줄여서 시간을 확보하라는 말입니다. 필요 없는 물건을 사서 카드 값을 갚느라 괜히 야근하지 말고.\np176 첫째, 스스로 미칠 수 있꼬, 둘째, 다른 사람보다 월등히 말할 자신이 있으면 됩니다. 셋째, 그것을 하면서 돈을 벌지 못하더라도 다른 사람들과 비교하며 부끄럽지 않을 수 있으면 된 거죠.\np182 중요한 건 \u0026lsquo;종료 시점\u0026rsquo;을 정하는 일입니다. 당신의 꿈에는 기한이 있어야 합니다. 그렇지 않으면 막연하게 늘어질 뿐입니다.\n\u0026lsquo;언젠가\u0026rsquo;는 절대로 찾아오지 않습니다. 우리에게 주어지는 건 항상 또 다른 오늘이죠. 과거는 우리의 힘으로 바꿀 수 없습니다. 미래는 그 모습을 상상하는 것조차 어려운 일이고요. 우리가 우리를 평가하고 이해할 수 있는 시간은 바로 오늘뿐입니다.\n","id":53,"section":"posts","summary":"p52 \u0026ldquo;당신의 삶입니다. 당신의 사람을 이야기하라는데 가족을 위해 사는 게 전부라. 생활비만 제대로 해결된다면 가족에게 당신은 없어도 되는 존재라는 말","tags":["Book"],"title":"(책) 당신의 시간","uri":"https://cychong47.github.io/2018/07/your-time/","year":"2018"},{"content":"p32 너무 효율적인 사람은 너무나도 바쁘기 때문에, 무언가 새로운 일이 일어나는 경우 그 일에 즉시 대응할 수가 없게 된다.\np37 사실 효율성을 높이는 일은 매우 어렵다. 효율성 개선에는 엄청난 노력과 진정한 독창성이 필요하기 때문이다. 조직은 항상 스스로를 더욱 효율적으로 만들기 위해 끊임없이 노력해 왔기 때문에 조직을 더 효율적으로 만들기란 결코 쉬운 일이 아니다.\np38 짧은 시간안에 조직의 개선을 보여주어야 하는 효율성 전문가에게 유욯나 지름길은 무엇일까? 가장 자주 채택되는 지름길은 바로 각각의 직원을 모두 완전한 대체물이라고 가정하는 것이다.\np57 영리 조직에서 일하는 사람들은 급여를 받기 때문에 어느 정도의 자율성을 기꺼이 포기하고 어느 정도의 지시를 받아들인다는 점이다. 그렇다고 해서 자율성을 완전히 포기하는 것은 아니다. 사람들이 자율성을 완전히 포기할 만큼 충분한 급여를 제공할 수는 없다.\np59 조직도의 계층 구조는 권위의 경로이고, 의사 소통에 필요한 모든 정보를 유통하기에는 너무 좁다. 소통이 오직 조직도의 선을 통해서만 일어난다면 관리자들이 모든 통제권을 가지려 한다는 명백한 증거인 셈이다.\np60 여러분에게 주어진 지위만으로 여러분이 선택한 방법을 강요할 수 있을 것이라고 결코 기대하지 말아야 한다. 신뢰는 여러분이 자주 간섭할수록 금세 바닥나 버리고 만다.\np65 만약 변화가 변화 전문가의 지도에 의해서만 이루어질 수 있다면, 그 조직은 죽음이 코 앞에 와있다고 볼 수 있다. 변화할 수 있는 능력은 유기적으로 죽음이 코앞에 와있다고 볼 수 있다. 변화할 수 있는 능력은 유기적으로 조직의 일부가 되어야만 한다. 변화는 언제 어디서든 진행되어야 하는 것이다. 변화는 모든 사람의 일이 되어야 한다.\np66 직원들이 자신의 자율성을 포기하게 되면 결국 조직이 피해를 입게 된다는 사실이다.\n그 이유는 지식근로자의 업무에 투입되는 핵심 역량 중 하나가 도메인 지식이기 때문이다. (1) 일련의 기술들과 더불어 (2) 해당 업무 분야에 어떠한 기술들을 사용해야 하는지에 대한 명쾌한 지식을 갖고 있다. 기술만으로는 충분하지 못하다. 도메인 지식 역시 중요하다. 도메인 지식이 중요하면 할수록 그 사람은 더욱 대체하기 어려워진다. 그 직원이 기업을 떠나게 되면 그 자산 역시 사라진다.\np75 R\u0026amp;D 지출은 투자이기 때문이다. 그것을 줄이는 것은 미래의 이익을 올해로 옮겨오는 것과 같다. 그렇게 함으로써 비록 올해의 이익을 높일 수는 있겠지만 내년과 다음 여러 해의 이익이 감소하게 될 것이다.\np82 지식근로자들에 대한 인센티비는 그들을 어떻게 관리해야 할지 모른다는 슬픈 고백일 뿐이다.\n직원들에게 압박감을 주기 위해 행하는 대부분의 일들은 어떤 형태로든 그들의 행동을 의미 있는 방향으로 변화시키지 못한다.\np84 압력을 가하면 성과가 향상되며, 최고의 성과는 오직 최고의 압력을 가할 때에만 가능하다는 기업의 미신이 점점 확산되어 가고 있다.\np87 시간 압력을 받는다고 더 빠르게 생각할 수 있는 건 아니다. - 팀 리스터\np88 건강한 지식 조직에서 일하는 사람들은 실제로 많은 시간을 낭비하지 않는다. 왜냐하면 낭비되는 시간이 관리자에게 모욕적인 것이듯이, 지식근로자 스스로에게도 모욕이기 때문이다.\np91 압박감이 생산성과 완전히 무관한 것은 아니다. 하지만 그것은 분명히 우리 대부분이 이루려고 애쓰는 최종적인 목표는 아니다.\np92 공격적인 일정이라는 말을 마치 프로젝트의 실패를 부르는 일종의 주문이라고 생각한다.\np94 매우 공격적인(사실은 불가능한) 납기를 위해 노력하는 것이 비록 실제로 그 일자를 달성하지는 못하더라도 크게 손해 볼 것이 없다는 생각이 깔려있다. 예를 들어 프로젝트를 12개월 내에 완료하도록 결정해 놓고서 실제로는 18개월이 걸렸더라도 스스로에게 이렇게 말하면서 위안을 삼는다. \u0026ldquo;공격적인 일정 덕분에 다행히도 빨리 끝낸 거야. 그런 일정이 아니었으면 어리석게도 여전히 일을 하고 있을지도 몰라\u0026rdquo;\n많은 프로젝트 관리자들이 신참 관리자 시절에 최대한 불가능한 일정을 수립하고 분투하는 것이 결코 손해 볼 게 없는 행동이라고 교육받는다.\np96 관리자 대부분은 잘못된 일정 같은 건 존재하지 않는다고 믿기 때문에, 납기일을 못 맞추는 이유가 오직 직원들이 일을 제대로 못한 탓이라고 생각한다.\np97 잘못된 일정은 계획을 수립한 사람의 탓이지 일을 수행하는 사람의 탓이 아니다.\np100 스프린팅. 비정기적인 단기간의 초과근무. 모두가 함께 어떤 일을 하고 그 결과로 소중한 성공을 공유할 때 조직의 문화에 무언가 심오한 변화가 생긴다. 그렇게 만들어진 에너지는 격렬했던 주말이 지나간 후에도 오랫동안 지속된다.\n모든 사람을 하나로 묶을 수 있는 지도나로서의 타고난 재능을 갖추고 있다. 엄청난 신뢰가 축적되어 있어야 한다. 특별한 초과근무를 요구 받는 것이 정말 예외적인 상황이며 그러한 노력이 의미 없이 소진되거나 정기적으로 발생하지 않을 것이라는 믿음이 있어야 한다.\np103 장기간의 초과근무는 생산성을 감소시키는 탁월한 기술이다.\np107 과도한 일중독과 그에 따른 피로가 결합됨으로써 개인의 정신 역량이 감소된다는 점이다. 마약 사고이 질이 중요하다면 초과근무는 훌륭한 처방이 아니다.\n사람들은 동료가 밤늦게까지 계속 일할 것임을 알기 때문에 \u0026lsquo;정상 근무시간\u0026rsquo;에 난잡하게 맘 내키는 대로 동료들을 방해한다.\np122 우리는 지금까지 오버헤드의 성격을 가진 사람들을 줄이는 데에 너무 집중해왔기 때문에, 비싼 급여를 받는 많은 지식근로자와 관리자들이 업무 시간 중 4분의 1을 단순 작업에 낭비하는 조직을 만들고 말았다. 이것이 정말 경제적인 것일까?\np133 관리는 어렵다. 해야 할 일이 너무 많기 때문이 아니라 관리 기술이라는 게 본질적으로 숙련되기 어렵기 때문이다.\np139 분노한 관리자는 패배자다. 사람들을 어떻게 이끌어야 할 지 전혀 모르는 채 스스로 감당할 수 없는 일을 하고 있는 불행한 무능력자다.\np159 테일러 주의. 사람이 교환 가능한 부품이라는 관점을 일찍이 제시하였다. 테일러주의는 지식근로는 적합하지 않다.\np163 자동화가 새롭게 도입되면 전체 작업에서 사람이 할 일은 즐어들게 되지만, 남은 일은 더 힘든 일 뿐이다. 자동화는 업무를 더욱 어렵게 만들지 쉽게 만드는 게 아니라는 점이 바로 자동화의 역설이다.\np165 프로세스 소유권은 업무를 하는 사람의 손에 쥐어주어야 한다.\np166 실패에 대응하는 논리로써 표준 프로세스는 일종의 무기가 되는 것이다. 실패에 대해 더 많이 걱정할수록 더 강력한 무기를 지니려고 노력하게 된다. 그러나 그러한 무기들은 언제나 기동성을 감소시킨다.\np174 품질 프로그램은 품질의 손쉽고 실행 가능한 측면에만 집중하고 그 외의 나머지 내용들은 무시한다. 품질 프로그램은 실제 품질에서 대체로 부수적인 부분에만 집중하고 진짜 중요한 문제를 외면한다. 물론 아무것도 하지 않는 것보다야 무언가 하는 게 좋지 않냐고 생각할 수도 있다.\np179 품질 개선을 위해 가장 중요한 활동은 중요하지 않는 제품이나 부분을 과감히 버리는 것이다.\np182 스트레스가 과도한 조직은 효율을 강조하느라 바쁜 나머지, 효과적인 조직이 되는 법을 잊어버리게 된다. 어떤 일을 최소한의 낭비로 해내는 것을 효율적(efficient)이라고 하며, 그 일을 제대로 해내는 것을 효과적(effective)이라고 한다. 효과적이지만 효율적이지 못한 조직은 (비록 빠르지는 않을지라도) 목표를 향해 착실하게 나아간다. 목표에 대해 얼마만크의 진도를 보이는가는 효율의 문제이다. 효율적이지만 효과적이지 못한 조직은 엉뚱한 방향으로 나아간다.\np190 MBO는 상태가 계쏙 유지될 것이라는 기대에 의존한다. 기업의 부서처럼 크고 복잡한 대상의 순기여도를 하나의 지표로 합리적이고 정확하게 측정할 수 있다고 생각한다는 점이다. MBO는 어떻게든 단순한 숫자로 표현하라고 말한다.\np193 MBO(Management by Objectives)는 1950년에 일시적으로 유행했던 경영기법으로 지금은 평판이 매우 떨어지는 기법이다\u0026hellip;.. MBO형 기업들은 분기 결과가 나쁘면 더 많은 MBO를 시행하는 방법으로 대응한다.\n목표관리 또는 목표에 의한 관리라고 한다. 직원 스스로 혹은 상사와의 협의를 통해 양적으로 측정가능하고 구체적이고 단기적인 성과 목표를 설정하고, 스스로 그러한 성과 목표 달성의 정도를 평가해서 그 업적을 보고하게 하는 기법이다. 국내 기업에서도 폭넓게 활용되고 있다\np204 리더십은 여러분의 의제에 다른 사람을 동참시키는 능력이다.\np207 충분한 권한이 리더십의 필수 조건은 결코 아니다. 충분한 권한이라는 건 사실 존재하지 않는다. 리더십이란 충분한 권한이 주어지지 않은 상황에서 성공할 수 있는 역량이다.\np215 변화는 항상 포기를 수반한다. 여러분이 포기해야 하는 것은 일을 처리하는 오래된 기존 방식이다. 친숙한 방식, 숙달된 방식. 변화란 직원들에게 일에 대한 지배력을 포기하고 다시금 초보자로 돌아가 하위 계급이 되라는 것과 마찬가지인 것이다.\n사람들은 그런 종류의 변화를 이루어낼 수 있지만 그것은 오직 안전하다고 느낄 때만 가능하다. 불안전한 환경에 놓인 사람들은 경험하지 않은 분야로 자신을 떠미는 행동을 하려고 하지 않는다. 그런 상황에 그들은 변화를 거부할 것이며 여러분이 아무리 설득을 하더라도 변화에 불참하려는 그들의 생각을 바꿀 수 없을 것이다.\np224 신뢰를 받은 사람은 거의 자발적인 반응으로 충성심을 제공하낟. 무엇보다 나를 신뢰한 사람에게 절대 실망을 안겨주지 않을 것이라고 다짐했다.\n부하직원이 신뢰할 만한 지 알기 전에 먼저 얼마간의 신뢰를 주라는 것이다. 하지만 너무 많이 주어서도 안 된다. 리더에게는 부하직원이 얼마나 준비된 사람인가를 파악할 수 있는 확실한 감각이 있어야 한다. 신뢰할 만한 사람인지 알기 전에 신뢰를 주는 일은 위험을 수반한다.\np220 신뢰를 획득하지 않고서는 리더가 존재할 수 없고 진정한 변화도 불가능하다.\n일을 하기 전에 신뢰를 미리 얻어내기 위해서는 풍부한 인간적 매력이 필요하다는 사실을 알 수 있다. 신뢰를 잘 얻어내는 리더들은 생각이 분명하고, 발랄하며, 매력이 있꼬, 짓궃은 유머를 잘 하는 경향이 있다.\np226 변화의 타이밍에 대한 잘못된 상식. \u0026quot; 고장 나지 않았다면 고치지 말자\u0026quot;는 생각이다.\np232 중간관리자의 핵심 역할은 바로 재창조다.\n슬랙이 없다면 재창조에시간을 쓰기에 너무나 바쁜 상태라서 오로지 일상의 업무적 기능만 할 수 있을 뿐 재창조 수행이 불가능해진다.\np251\n지식근로자들이 일하는 조직에서 건전한 경쟁과 같은 것은 존재할 수 없다. 모든 내부 경쟁은 파괴적이다. 지식근로는 협업을 기반으로 한다.\n","id":54,"section":"posts","summary":"p32 너무 효율적인 사람은 너무나도 바쁘기 때문에, 무언가 새로운 일이 일어나는 경우 그 일에 즉시 대응할 수가 없게 된다. p37 사실 효율성을 높이는 일은 매우 어렵다. 효율","tags":["Book","slack"],"title":"(책) Slack","uri":"https://cychong47.github.io/2018/07/slack/","year":"2018"},{"content":"p65 효율적인 팀들은 한결같이 매우 구체적으로 논쟁을 벌였습니다. 팀원들간의 신뢰도가 매우 높은 팀에서도 흔히 논쟁이 벌어지더군요.\np114 전반전이 끝나고 라커룸으로 들어가는 농구코치를 상상해 봅시다. 그는 팀의 센터포워드를 자기 방으로 불러서 전반전에 대해 일대일로 대화합니다. 그러곤 포인트가드, 슈팅가드, 스몰포워드, 파워포워드를 차례로 불러서 똑같은 행동을 반복합니다. 선수들 중 누구도 코치가 다른 선수들에게 무슨 얘기를 했는 지 알 수 없는 상태에서 후반전이 시작됩니다. 후반전에서 그들은 더 이상 팀이 아닙니다. 그건 단지 개인들을 한데 모아놓은 것에 불과하죠.\np122 정치란 사람들이 말과 행동을 할 때 자신이 생각하는 대로 하지 않고 다른 사람들이 어떻게 반응할 것인가에 따라 하는 것을 말합니다.\np126 만약 우리가 서로를 신뢰하지 않는다면 우리는 충돌의 상황에 뛰어들지 않을 겁니다. 그 상황이 개방적이고 건설적일지라도 말입니다. 그리고 겉으로 보기에 융화된 것처럼 행동하면서 아무 문제없이 잘 지내게 되겠죠.\np127 긴장관계가 형성되어 있긴 하지만 건설적인 충돌은 거의 일어나지 않고 있습니다. 수동적이고 냉소적인 비난은 내가 말하는 충돌에 속하지 않습니다.\np148 모든 것이 다 중요하다면 아무것도 중요하지 않은 것과 같다.\np215 열심히 일하고 있는 사람을 비판하는 건 어려운 일이죠. 하지만 그건 좋은 변명이 아니예요. \u0026hellip;. 좀 더 분명하게 업무의 우선순위를 매겼어야 했어요. 그리고 자신의 요구에 따르지 않은 조직 내의 사람들에게 명확히 문제를 제기했어야 합니다.\np216 \u0026lsquo;신뢰\u0026rsquo;란 모두가 내 편이라는 생각과는 다른 겁니다. 서로 신뢰한다고 해서 상대에게 압박을 가할 필요가 없다고 생각해서는 안됩니다. 신뢰란 팀의 구성원이 언제 동료를 압박해야 할 지 그때를 정확히 아는 것입니다. 팀에 애정을 갖고 있기 때문에 그 일을 하는 것입니다.\n압박을 하되 존중하는 마음이 있어야 합니다. 그리고 내가 아니어도 누군가는 그렇게 했을 것이라는 생각을 염두에 두어야 하고요.\n팀을 위기에 빠뜨리는 5가지 함정\n첫번째 함정(신뢰의 결핍) 신뢰의 결핍은 팀원들이 동료의 비판을 기꺼이 받아들일 준비가 되어 있지 않을 때 생긴다. 진심으로 서로에게 마음을 열고, 상대방의 실수와 약점을 이야기할 수 없는 팀의 구성원들은 신뢰의 기반을 쌓기가 쉽지 않기 때문이다.\n두번째 함정(충돌의 두려움) 신뢰 구축의 실패는 충돌의 두려움을 불러온다. 신뢰가 없는 팀은 상대방의 생각에 대해 거리낌없이 비판을 하는 논쟁을 벌일 수 없기 때문이다. 그들은 솔직하지 못한 토론과 자기방어적인 수사법에만 의존하게 된다.\n세번째 함정(헌신의 결핍) 건전한 충돌의 결핍은 헌신의 결핍을 가져온다. 개방적이면서 치열한 충돌 속에서 서로의 의견을 조율하지 못한다면, 주어진 결정사항을 진심으로 받아들여 매진하기 어렵기 때문이다. 물론 회의 중에 동의한다는 의사는 얼마든지 꾸며 낼 수 있지만 말이다.\n네 번째 함정(책임의 회피) 헌신을 다해 팀의 목표에 매진하지 않는 사람은, 자기 자신이 결과에 책임지지 않는 것은 물론이고 팀의 목표에 어긋나는 결과를 불러일으킨 동료에게 책임을 추궁할 수 없게 된다.\n다섯 번째 함정(결과에 대한 무관심) 서로에 대한 책임을 묻지 못한다면 다섯 번째 함정에 빠지게 된다. 팀원들이 자신의 경력이나 대외 인지도 등 개인적 욕구를 공통 목표보다 우위에 놓을 때 결과에 대한 무관심이 발생한다.\n팀을 성공으로 이끄는 5가지 법칙 첫 번째 법칙. 팀원간에 서로를 신뢰한다. 두번째 법칙. 논쟁이 벌어졌을 때 거리낌 없이 의견 충돌을 일으킨다. 세번째 법칙. 한번 내려진 결정과 실행 계획에 헌신을 다해 노력한다. 네번째 법칙. 정해진 계획에 어긋나는 행동을 했을 경우 책임을 묻는다. 다섯째 법칙. 공동의 목표를 이루는 데 초점을 맞춘다.\n 신뢰가 결여된 팀워들의 행동방식 자신의 약점과 실수를 동료에게 감춘다.  ","id":55,"section":"posts","summary":"p65 효율적인 팀들은 한결같이 매우 구체적으로 논쟁을 벌였습니다. 팀원들간의 신뢰도가 매우 높은 팀에서도 흔히 논쟁이 벌어지더군요. p114 전반전이 끝나고 라커룸으로","tags":["Book","team"],"title":"(책) 팀이 빠지기 쉬운 5가지 함정","uri":"https://cychong47.github.io/2018/07/five-traps-team-can-fall-into/","year":"2018"},{"content":"p64 해결점까지 분명한 길이 있는 경우의 보상은 앞만 바라보며 더 빨리 나아가게 해주기 때문에 도움이 되지만, 양초 문제처럼 도전적인 상황에서 \u0026lsquo;만약-그러면\u0026rsquo;의 조건적 동기유인제는 효력을 발휘하지 못한다. 보상은 사람들의 시야를 좁히며, 기존 물건의 새로운 쓰임새를 볼 수 있는 포괄적인 시야를 흐리게 한다.\np65 다른 사람을 위해 작업할 때면 항상 그런 것은 아니지만 많은 경우에 작업이 즐거움보다는 일에 가까워진다. 반면 나 자신을 위해 작업할 때는 창조한다는 순전한 즐거움을 느끼면서 밤을 새는지도 모르고 일하기도 한다. 의뢰받은 작업의 경우는 스스로를 억제하고 고객의 요구를 따르기 위해 정신을 바짝 차려야 한다.\n헌열에 대한 보상 시험\np75 유치원 지각을 금전으로 보상하게 하자 부모와 교사간의 친밀한 유대관계가 순전한 계약으로 변질되었다.\np77 쓰레기를 버리면 용돈을 주겠다고 아들에게 제안했다고 가정해보자. 그 후 아들은 용돈을 받지 않으면 절대로 쓰레기를 버리지 않을 것이다. 더욱이 처음에 제시했던 돈의 흥분이 가라앉은 후에는 액수를 늘려야마 순응을 요구할 수 있다.\n보상은 제공되는 순간 중독성을 띤다. 대리인은 조건적인 보상을 제시받은 후에는 그와 비슷한 일이 생길 때마다 보상을 기대하게 된다. 그 후 주동자는 계속해서 보상을 이용하게 된다. 기존의 보상으로는 더 이상 만족할 수 없는 상황이 곧 발생하고, 보상은 보너스가 아니라 당연한 것으로 여겨진다. 그렇기 때문에 동일한 효과를 얻으려면 주동자가 그 이상의 보상을 제공해야만 한다.\np83 책을 3권 읽으면 상을 준다고 제시하면 많은 학생들이 네 번째 책을 읽기 않을 것이며, 평생 독서의 길에 들어서지도 않을 것이다.\n조건적인 보상이 연루되지 않거나 인센티브가 적절하게 이용되면 성과가 향상되고 이해력이 깊어진다. 위대함과 근시안은 양립하지 못한다. 자신의 시야를 들어 올려서 수평선까지 밀고 나갈 때 비로소 의미 있는 업적에 다다를 수 있는 법이다.\np88 그다지 흥미로지 않고 창의적인 사고도 별로 필요하지 않는 기계적인 일에서 보상은 해로운 부작용 없이 동기유발제 역할을 한다. 단, 이 일이 왜 필요한지 이론적 근거를 제시한다. 일이 따분하다는 사실을 인정한다. 사람들이 자기 방식대로 일을 완성하게 자율성을 허용한다.\np95 보상의 필수 조건 외부의 보상은 전혀 예상치 못한 것이어야 하며, 일이 완성된 후에 제시되어야 한다. \u0026lsquo;만약-그러면\u0026rsquo;에서 \u0026lsquo;이제-했으니까\u0026rsquo;로 전환\n그러나 \u0026lsquo;이제-했으니까\u0026rsquo; 보상도 반복되면 결국 \u0026lsquo;만약-그러면\u0026rsquo;으로 인식된다.\n칭찬과 피드백을 제시한다. 사람들을 통제하기보다는 유용한 정보를 제공한다.\np184 칙센트미하이는 아이들을 자기 마음대로 하게 놔두면 피할 수 없는 자연의 법칙에 따라 결국 몰입을 추구하게 된다고 말한다. 우리 모두 그렇게 해야 한다.\n","id":56,"section":"posts","summary":"p64 해결점까지 분명한 길이 있는 경우의 보상은 앞만 바라보며 더 빨리 나아가게 해주기 때문에 도움이 되지만, 양초 문제처럼 도전적인 상황에서 \u0026lsquo;만약-그","tags":["Book"],"title":"(책) 드라이브 - 다니엘 핑크","uri":"https://cychong47.github.io/2018/07/drive/","year":"2018"},{"content":"AVX2가 지원되지 않는 머신에서 쓸데없이 ACL library 빌드할 때 AVX2를 이용해서 빌드하려는 문제를 확인했다. 지금까지 아무도 고치지 않은 게 이상하긴 한데 그래도 내가 생각한 수정 방법이 제대로 동작하는 듯 해서 패치를 한번 보내보기로 했다.\n수정사항은 비교적 간단하다. ACL 라이브러리 빌드할 때 AVX2를 이용해서 빌드해야 하는 경우인지를 검사하는 코드가 lib/librte_acl/Makefile에 정의되어 있는데 여기서 항상 -march=core-avx2 옵션을 사용해서 AVX2가 지원되지 않는 머신에서도 AVX2를 사용해서 gcc가 빌드하도록 하는 걸로 보였다. 다른 코드 빌드할 때는 문제가 없는데 유독 ACL library에서만 이런 문제가 나서 보다 보니 아무래도 Makefile이 잘못된 듯 하다.\nhttps://www.dpdk.org/contribute/ 페이지 내용을 참고해서\ngit clone git://dpdk.org/dpdk  코드 수정\n$ git commit --signoff mk: Detect AVX2 capability based on the target CPU architecture AVX2 support check should be based on the target CPU architecure. For this, -march option should be $(RTE_MACHINE) instead of core-avx2.  commit comment 를 수정하려면\n$ git commit --amend  이제 patch를 생성해 보자. 최근 1개의 commit으로 패치 파일을 만드려면 - 옵션을 사용한다.\n$ git format-patch -1  패치 파일 내용 확인해 보고\n$ cat 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch From 7bed8881339afee9bbef31638d3f15dad27efb87 Mon Sep 17 00:00:00 2001 From: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; Date: Sat, 21 Jul 2018 22:51:19 +0900 Subject: [PATCH] mk: Detect AVX2 capability based on the target CPU architecture AVX2 support check should be based on the target CPU architecure. For this, -march option should be $(RTE_MACHINE) instead of core-avx2. Cc: stable@dpdk.org Signed-off-by: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; --- lib/librte_acl/Makefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) diff --git a/lib/librte_acl/Makefile b/lib/librte_acl/Makefile index ea5edf00a..c756eaeb2 100644 --- a/lib/librte_acl/Makefile +++ b/lib/librte_acl/Makefile @@ -44,7 +44,7 @@ ifeq ($(findstring RTE_MACHINE_CPUFLAG_AVX2,$(CFLAGS)),RTE_MACHINE_CPUFLAG_AVX2) CC_AVX2_SUPPORT=1 else CC_AVX2_SUPPORT=\\ -\t$(shell $(CC) -march=core-avx2 -dM -E - \u0026lt;/dev/null 2\u0026gt;\u0026amp;1 | \\ +\t$(shell $(CC) -march=$(RTE_MACHINE) -dM -E - \u0026lt;/dev/null 2\u0026gt;\u0026amp;1 | \\ grep -q AVX2 \u0026amp;\u0026amp; echo 1) ifeq ($(CC_AVX2_SUPPORT), 1) ifeq ($(CONFIG_RTE_TOOLCHAIN_ICC),y) -- 2.18.0  git에서 바로 패치 내용을 전송할 수 있는데 그러려면 SMTP 관련 설정을 해 봐야 한다. 관련 파일은 ~/.gitconfig 이거나 git repo에 있는 .git/config\n[sendemail] from = Chaeyong Chong \u0026lt;cychong@gmail.com\u0026gt; smtpserver = smtp.gmail.com smtpuser = cychong@gmail.com smtpencryption = tls smtppass = XXXXXXX chainreplyto = false smtpserverport = 587  이제 보내볼까?\nmbpr15:dpdk cychong$ git send-email --to konstantin.ananyev@intel.com --cc dev@dpdk.org 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch (mbox) Adding cc: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; from line 'From: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;' (body) Adding cc: stable@dpdk.org from line 'Cc: stable@dpdk.org' (body) Adding cc: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; from line 'Signed-off-by: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;' From: Chaeyong Chong \u0026lt;cychong@gmail.com\u0026gt; To: konstantin.ananyev@intel.com Cc: dev@dpdk.org, Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;, stable@dpdk.org Subject: [PATCH] mk: Detect AVX2 capability based on the target CPU architecture Date: Sat, 21 Jul 2018 23:06:23 +0900 Message-Id: \u0026lt;20180721140623.1293-1-cychong@gmail.com\u0026gt; X-Mailer: git-send-email 2.18.0 The Cc list above has been expanded by additional addresses found in the patch commit message. By default send-email prompts before sending whenever this occurs. This behavior is controlled by the sendemail.confirm configuration setting. For additional information, run 'git send-email --help'. To retain the current behavior, but squelch this message, run 'git config --global sendemail.confirm auto'. Send this email? ([y]es|[n]o|[e]dit|[q]uit|[a]ll): y Can't locate Net/SMTP/SSL.pm in @INC (you may need to install the Net::SMTP::SSL module) (@INC contains: /usr/local/Cellar/git/2.18.0/share/perl5 /Applications/Xcode.app/Contents/Developer/Library/Perl/5.18/darwin-thread-multi-2level /Library/Developer/CommandLineTools/Library/Perl/5.18/darwin-thread-multi-2level /Library/Perl/5.18/darwin-thread-multi-2level /Library/Perl/5.18 /Network/Library/Perl/5.18/darwin-thread-multi-2level /Network/Library/Perl/5.18 /Library/Perl/Updates/5.18.2 /System/Library/Perl/5.18/darwin-thread-multi-2level /System/Library/Perl/5.18 /System/Library/Perl/Extras/5.18/darwin-thread-multi-2level /System/Library/Perl/Extras/5.18 .) at /usr/local/Cellar/git/2.18.0/libexec/git-core/git-send-email line 1497.  무슨 에러가 난다. Perl 관련 에러로 보이는데 마땅한 해결책이 없나 보다. 인터넷을 뒤져 해결책을 찾아 적용해봤지만 백약이 무효\n원인을 찾아 보니 위 에러 메시지의 마지막에 있는 것처럼 git-send-email 파일 1497 라인에서 Net/SMTP/SSL.pm을 찾는 데 못찾고 있다는 거. 근데 그냥 perl로 확인해 보면 멀쩡히 @INC 경로에 포함되어 있다는 사실\n흥미로운 건 어디에 있는 perl을 쓰느냐에 따라 모듈 위치가 달라진 다는 거\n이건 OS X에 기본 내장된 perl을 사용한 경우\n$/usr/bin/perl -e 'print \u0026quot;@INC\u0026quot;;' /Library/Perl/5.18/darwin-thread-multi-2level /Library/Perl/5.18 /Network/Library/Perl/5.18/darwin-thread-multi-2level /Network/Library/Perl/5.18 /Library/Perl/Updates/5.18.2 /System/Library/Perl/5.18/darwin-thread-multi-2level /System/Library/Perl/5.18 /System/Library/Perl/Extras/5.18/darwin-thread-multi-2level /System/Library/Perl/Extras/5.18 .  이건 homebrew로 설치한 perl이 찾는 위치\nmbpr15:dpdk cychong$ perl -e 'print \u0026quot;@INC\u0026quot;;' /usr/local/Cellar/perl/5.28.0/lib/perl5/site_perl/5.28.0/darwin-thread-multi-2level /usr/local/Cellar/perl/5.28.0/lib/perl5/site_perl/5.28.0 /usr/local/Cellar/perl/5.28.0/lib/perl5/5.28.0/darwin-thread-multi-2level /usr/local/Cellar/perl/5.28.0/lib/perl5/5.28.0 /usr/local/lib/perl5/site_perl/5.28.0/darwin-thread-multi-2level /usr/local/lib/perl5/site_perl/5.28.0  그리고 git send-email 명령이 못찾고 있는 SSL.pm의 위치는 이미 /usr/bin/perl이 아닌 그냥 perl(실제는 /usr/local/bin/perl의 모듈 경로에 이미 포함되어 있다는\nmbpr15:dpdk cychong$ find / -name SSL.pm find: /usr/sbin/authserver: Permission denied /usr/local/Cellar/perl/5.28.0/lib/perl5/site_perl/5.28.0/Net/SMTP/SSL.pm  그래서 /usr/local/Cellar/git/2.18.0/libexec/git-core/git-send-email 이 brew 버전의 perl을 사용하도록 변경 후 다시 git send-email 시도\nSend this email? ([y]es|[n]o|[e]dit|[q]uit|[a]ll): a Need MIME::Base64 and Authen::SASL todo auth at /usr/local/Cellar/git/2.18.0/libexec/git-core/git-send-email line 1521.  이것 쯤이야 이젠 쉽게(?) 해결\nmbpr15:dpdk cychong$ sudo -H cpan MIME:Base64 ... mbpr15:dpdk cychong$ sudo -H cpan Authen::SASL ...  이젠 정말 되겠지?\nSend this email? ([y]es|[n]o|[e]dit|[q]uit|[a]ll): y 5.7.9 Application-specific password required. Learn more at 5.7.9 https://support.google.com/mail/?p=InvalidSecondFactor q81-v6sm10686681pfd.15 - gsmtp  음.. 깔끔하게 되었다는 말은 안 나오지만 그래도 이 메시지는 일단 메일 전송 요청을 받은 gmail server에서 보낸 걸로 보아 전송에 필요한 git 관련 이슈는 없나 보다. 이제 이 문제만 해결하면 이메일을 보낼 수 있겠다. 구글에서 gmail Application-specific password required 로 찾은 내용을 참고해서 gmail에 대해 mac에서 전송할 때 사용할 암호를 따로 지정. 왜 이렇게 해야 하는 지도 설명되어 있지만 일단 보내고 보자.\nmbpr15:dpdk cychong$ git send-email --to konstantin.ananyev@intel.com --cc dev@dpdk.org 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch (mbox) Adding cc: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; from line 'From: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;' (body) Adding cc: stable@dpdk.org from line 'Cc: stable@dpdk.org' (body) Adding cc: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; from line 'Signed-off-by: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;' From: Chaeyong Chong \u0026lt;cychong@gmail.com\u0026gt; To: konstantin.ananyev@intel.com Cc: dev@dpdk.org, Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;, stable@dpdk.org Subject: [PATCH] mk: Detect AVX2 capability based on the target CPU architecture Date: Sat, 21 Jul 2018 23:53:42 +0900 Message-Id: \u0026lt;20180721145342.6503-1-cychong@gmail.com\u0026gt; X-Mailer: git-send-email 2.18.0 The Cc list above has been expanded by additional addresses found in the patch commit message. By default send-email prompts before sending whenever this occurs. This behavior is controlled by the sendemail.confirm configuration setting. For additional information, run 'git send-email --help'. To retain the current behavior, but squelch this message, run 'git config --global sendemail.confirm auto'. Send this email? ([y]es|[n]o|[e]dit|[q]uit|[a]ll): a OK. Log says: Server: smtp.gmail.com MAIL FROM:\u0026lt;cychong@gmail.com\u0026gt; RCPT TO:\u0026lt;konstantin.ananyev@intel.com\u0026gt; RCPT TO:\u0026lt;dev@dpdk.org\u0026gt; RCPT TO:\u0026lt;cychong@samsung.com\u0026gt; RCPT TO:\u0026lt;stable@dpdk.org\u0026gt; From: Chaeyong Chong \u0026lt;cychong@gmail.com\u0026gt; To: konstantin.ananyev@intel.com Cc: dev@dpdk.org, Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;, stable@dpdk.org Subject: [PATCH] mk: Detect AVX2 capability based on the target CPU architecture Date: Sat, 21 Jul 2018 23:53:42 +0900 Message-Id: \u0026lt;20180721145342.6503-1-cychong@gmail.com\u0026gt; X-Mailer: git-send-email 2.18.0 Result: 250 mbpr15:dpdk cychong$  Result 250은 SMTP result code로 정상적으로 전송되었다는 의미란다.(https://www.greenend.org.uk/rjk/tech/smtpreplies.html)\n드디어 끝났다.\n","id":57,"section":"posts","summary":"AVX2가 지원되지 않는 머신에서 쓸데없이 ACL library 빌드할 때 AVX2를 이용해서 빌드하려는 문제를 확인했다. 지금까지 아무도 고치지 않은 게 이상하긴 한데 그래도 내","tags":["DPDK","homebrew","opensource","patch","git","perl"],"title":"2nd patch submit to DPDK","uri":"https://cychong47.github.io/2018/07/submit-patch-to-dpdk-with-git/","year":"2018"},{"content":"임백준. 2016.5\n96) dead code로 인한 사고  신규 기능을 위해 현재 지금은 disable로 설정된 변수를 재활용. 코드 변경을 깜빡하고 설정만 변경하여 잠자고 있던 예전 코드가 동작(예측 불가능한 동작) 사용하지 않는 코드는 소스 코드에서 삭제할 것. If 문으로 회피하는 것은 상당히 나쁘고 위험한 습관 소프트웨어의 전개 과정이 정확한 설명을 담고 있는 문서에 기반해야 함 효율성을 명목으로 코드의 간명함과 안정성을 해치는 행동은 피할 것  100) 오바마 케어 112) Detail  디테일이 살아 있고 빠르고 안정감 있게 동작하는 코드를 작성하는 것은 \u0026lsquo;능력\u0026rsquo;이 문제인 경우가 많지만 \u0026lsquo;태도\u0026rsquo;의 문제이기도 디테일과 사소함을 혼동하지 말 것 점 하나에 따라서 코드 전체의 의미가 달라질 수 있는 프로그래밍의 세계에서 디테일은 덤이 아니라 생명  121) 지식이 아니라 메타지식  전문성 보다는 부족한 정보를 토대로 최선의 판단을 내리는 적응력이 중요. 새로운 지식을 빨리 흡수해서 자기 것으로 만드는 능력이 더 중요.  131) 나이는 짐인가 훈장인가  노력하지 않는 사람에게 나이는 짐이고, 노력하는 사람에게 나이는 훈장이다.  167) Actor model 208) MS API, Bot  MS같은 회사가 인공지능을 개발하고 API를 통해 기능을 제공할 테니 여러분은 그런 플랫폼 위에서 앱을 개발하라. Bot  212) 팀 내 가장 실력이 낮은 사람이 되라  배울 것이 없는 팀에서 오래 머물지 말라  216) 내가 아는 언어의 한계  비드겐슈타인 내가 아는 언어의 한계가 곧 내가 사는 세상의 한계 http://code.org  263) LESS  Learn - 배우믄 즐겁고 재밌는 놀이. 그게 아니면 노동 Enjoy Solve - 문제를 해결하지 못하면 개발자가 아니다. Share - 즐김을 위한 수단  269) 무지의 인지가 공부의 시작  더 많이 알수록 자기가 모르는 것이 얼마나 많은지 알게 되는 것이 개발자의 숙명 그 많은 내용을 다 알고 있는 사람이 존재하지 않는다는 사실을 깨달을 것. 자기가 알아야 한다고 생각하는 것의 1%라도 제대로 알고 있는 사람도 별로 없다. 이런저런 것을 알아야 할 것 같은데 나는 언제 그걸 공부하지라고 생각한 사람은 이미 대부분의 사람보다 많은 것을 알고 있는 사람이라는 뜻(하지만 실제 행동하지 않으면 소용없음)  287) 비동기성  Erik Meijer 지금까지의 SW는 동시성과 블로킹을 기반으로 동작하는데 익숙 async, await agile은 관리자가 개발자를 통제하기 위한 수단에 불과하다  280) 10가지 철학  개발자가 회사에 기여하는 정도와 개발자가 실제로 받는 급여 사이에는 커다른 차이가 개발자와 개발자의 작업 숙 동일하지 않다. Egoless 운에 기대지 말라. 매일 노력하라. 계획보다는 행동이다 bias for action (Amazon), Move fast and break things (Facebook) 말하지 말고 행동하라. 사람들이 나의 말을 듣지 않는 이유는 말 그 자체는 행동이 아니기 때문이다 \u0026lsquo;최악\u0026rsquo;은 제한되어 있다. 도전하라. 한국의 현실은\u0026hellip; 10 Philosophies for Engineers http://traffic.libsyn.com/sedaily/10_philosophies.mp3  301) No Stackoverflow in Korean  자신감 결여. 수동적으로 닥치고 듣기만 하는 교육 방식에 길들여져 있어 질문하는 것이 불안하고 불편 여유 없음. 매일 야근인데 한가하게 질문에 답이나 달고 있을 시간이 있을리가 경쟁 하나의 특정한 기술로 평생을 살려는 사람은 시대착오적이다.  ","id":58,"section":"posts","summary":"임백준. 2016.5 96) dead code로 인한 사고 신규 기능을 위해 현재 지금은 disable로 설정된 변수를 재활용. 코드 변경을 깜빡하고 설정만 변경하여 잠자고 있던 예전 코","tags":["Book","culture","임백준"],"title":"(책) 대살개문","uri":"https://cychong47.github.io/2018/07/developer-culture/","year":"2018"},{"content":"Toward 5G RAN virtualization by Intel and Astri\nhttp://astri.oeg\nFlexible architecture Modular PHY processing architectures  PDCP Split MAC/PHY Split - HARQ processing in RRU(How???) Lower PHY Split - High FB overhead but smallest packet latency.  Good for JT and JR for COMP Good for Massive MIMO and Ultra low-latency communication(Why?)   FAPI based MAC/PHY communication  L1 adaptation layer for MAC/PHY split (and Lower PHY Split?)    MAC/PHY split in one CPU  MAC/PHY split in one machine but netrwork based MAC/PHY communication over OVS   Virtual Cell  A group of physical cells form a Virtual Cell which does not require HO between the physical cells.  Technical Specification   Commercial L1 reference design   Artesyn MacCore\n Xeon-D - 8 or 12 core/CPU * 2 CPU/slot * 15 slots https://www.artesyn.com/computing/products/product/max-core https://www.artesyn.com/computing/assets/maxcore_platform_ds_1484017329.pdf\u0000    ","id":59,"section":"posts","summary":"Toward 5G RAN virtualization by Intel and Astri\nhttp://astri.oeg\nFlexible architecture Modular PHY processing architectures  PDCP Split MAC/PHY Split - HARQ processing in RRU(How???) Lower PHY Split - High FB overhead but smallest packet latency.  Good for JT and JR for COMP Good for Massive MIMO and Ultra low-latency communication(Why?)   FAPI based MAC/PHY communication  L1 adaptation layer for MAC/PHY split (and Lower PHY Split?)    MAC/PHY split in one CPU  MAC/PHY split in one machine but netrwork based MAC/PHY communication over OVS   Virtual Cell  A group of physical cells form a Virtual Cell which does not require HO between the physical cells.","tags":["DPDK","virtualization","vran","lte","5g","cran","fapi"],"title":"Astri vRAN","uri":"https://cychong47.github.io/2018/07/astri-vran/","year":"2018"},{"content":" 다양한 분야에 대한 조언  p20 목표가 명확하겨 정답이 있는 일을 하는 경주마에서 길 잃은 양으로\np22  지식을 더 많이 아는 것이 아닌 아는 지식으로 뭘 할 지 Learn by doing.  결과가 아닌 과정. 직접 해 본 사람 vs. 배워서 아는 사람    p34  끈기와 뚝심  별게 아닌게 아니다 끝까지 해내는 힘 John Williams - 매일 작곡. 영감-\u0026gt;작곡이 아니라 작곡을 하다보면 영감을 얻게 됨    p41  영어 강의 준비 -\u0026gt; 영어 발음을 보완하기 보다 강의 준비를 철저하게 함. 강점을 강조함. 강의 핵심은 영어가 아니다. 가장 잘하는 일 -\u0026gt; 장점을 강화해야 함 -\u0026gt; 나의 강점은 무엇인가?  p47 기회는 공평하지 않다. 랑랑 pianist\np57  삼단 로켓  미련을 남기지 않을 만큼 하고, 다른 로켓을 찾자???    p67 인간의 생존은 적응력에서 옴\np70  불안을 다스리는 가장 완벽한 방법은 불안을 일으키는 일을 해 버리는 것  p79 차별화\n매일 한가지 새로운 일 하기 -\u0026gt; 사고가 예민해 짐\nBest one -\u0026gt; Only one\n독창성\n사고가 민감해짐\np86 메모\n메모 습관. 메모 행위 자체가 생각을 정리할 기회를 줌\n키워드, 개념 중심으로 정리하고, \u0026lsquo;자기 관점\u0026rsquo;을 담아 하나의 \u0026lsquo;문장\u0026rsquo;으로 만들라\np113 자율, 능동\n 자율성을 빼앗기지 않는 버릇이 필요 상황에 다른 통제력을 자신에게 두는 생각이 필요. 업무 스트레스 - 업무 부담 보다는 통제력이 없는 경우에 더 큼\n능동성*\nPlan B  p121 걷기\n매일 산책. 일에 쫓겨 마음이 조급해질 수록 산책\n\u0026lsquo;걷기 예찬\u0026rsquo; - 다비드 르 브르통\n\u0026lsquo;생각에 관한 생각\u0026rsquo; 행동 경제학, 다니엘 카너먼\np126  독서  손정의. 철학 - 역사, 지리, 인문.  인문은 기본을 질문하는 것. \u0026ldquo;옳다고 믿는 것들이 정말 옳은가?\u0026rdquo;   정보 \u0026laquo; 본질 하루에 한권 읽기  비록 실패했지만 속독, 독서 습관, 넓고 깊어진 시야를 갖게됨   속독  저자는 왜 이 이야기를 하려 하는가? 저자가 말하고자 하는 결론은 무엇인가? 나에게 어떤 의미를 주는 가?     습관  짬이 날 때마다 읽는 습관   넓고 깊어진 시야  p132 시어스로벅 \u0026laquo; 월마트 시어스로벅은 기존 고객을 충성 고객으로, 월마트는 새로운 고객을 목표로\np141  전문지식이 설득에세 결정적인 계기가 되는 것은 10% 미만.  \u0026ldquo;상대가 긍정적인 의도를 품었다고 믿어라\u0026rdquo;   Soft-skill 이 중요함  p155  Labor -\u0026gt; Work -\u0026gt; Play 평생 학습 필요 -\u0026gt; 주제별 3년간 독일회사 320만 중 200만이 1인 사업체  p205  지식 근로자  피터드러커 머리로 일하는 목표를 스스로 결정하고 달성하기 위해 노력. 시간을 효율적으로 사용해야 함. 더 바쁘게 -\u0026gt; 더 휴율적으로. 기록하고 체크    p215 정리의 원칙 -\u0026gt; 자료, 정리는 들어오는 즉시 바로바로 처리해서 머리 바깥으로\n목록 -\u0026gt; indexing\n 제일 바쁜 사람에게서 제일 먼저 답신이 온다. 미루지 않고 바로 처리하는 습관 자투리 시간을 잘 활용할 것  p223 주어진 시간에 맞는 일을 배치. 2분, 5분, 10분, 30분짜리\np224 나만의 몰입시간 -\u0026gt; 자신만의 시간 30분\np226 혼자 있는 시간 -\u0026gt; 방해 받지 않고 혼자 보내는 시간\np228  자신만의 시간 30분 \u0026lsquo;일하는 시간\u0026rsquo;, \u0026lsquo;쉬는 시간\u0026rsquo; 이 아닌 \u0026lsquo;생각/사색하는 시간\u0026rsquo;  ","id":60,"section":"posts","summary":"다양한 분야에 대한 조언 p20 목표가 명확하겨 정답이 있는 일을 하는 경주마에서 길 잃은 양으로 p22 지식을 더 많이 아는 것이 아닌 아는 지식으로 뭘 할 지 Learn by doing. 결과가 아닌 과정","tags":["Book"],"title":"(책) 도쿄대 교수가 제자들에게 주는 쓴소리","uri":"https://cychong47.github.io/2018/07/advice_from_tokyo_professor/","year":"2018"},{"content":"세바시 였던가, 공개 강의 동영상을 통해 처음 알게 된 김민식 PD. 예전에 인기있었던 시트콤, ‘논스톱’을 만든 PD인데 MBC 파업과 관련되어 힘든 시간을 보내다 “영어책 한 권 외워봤니?”라는 독특한 제목의 영어 책으로 대중에 알려졌다. 그와 동시에 대입부터 시작해서 방송국 파업 때문에 경영진에 찍혀 고생하는 기간에 블로그를 통해 재기(?)에 성공한 특이한 이력을 가지고 있는데 시트콤 PD 답게 재밌는 입담을 통해 자신의 힘들었던 과거를 통해 의미있는 이야기를 많이 해줬던 걸로기억한다. 매일 아침 써봤니? 는 제목 그대로 저자가 하고 있다는 매일 아침 글쓰기를 통해 변화된 인생에 대해 이야기해주고 있다.\n 저녁 약속을 잡지 않는다고 하면, 사회생활에 지장은 없느냐고 묻기도 합니다. 글쎄요, 저는 인생에서 무언가 더하고 싶은 게 있을 때 먼저 제 삶을 돌아봅니다. 지금 내 삶에서 뺄 수 있는 건 무엇일까? 아무것도 빼지 않고 그냥 더할 수는 없어요. 제 인생은 이미 ‘만땅’이거든요. 하나를 더하려면 하나를 빼야 합니다.\n  아이가 어릴 때는 아이에게 집중하는 것이 맞습니다. 자기계발도 마찬가지예요. 하고 싶은 일이 있을 때는 지금 당장 해야 합니다.\n  글자에는 주술적인 힘이 있어요. 머릿속 생각이나 말 한마디는 나를 붙들지 못하지만, 글로 남긴 약속은 인생을 바꾸는 마법의 주문이 됩니다.\n  열심히 사는 게 능사가 아닙니다. 시대의 흐름을 읽어야 해요. 세상이 변화하는데 혼자 옛날 방식을 고집하는 사람은 일의 세계에서 살아남지 못합니다.지금 이 순간이 미디어의 격변기라는 게 온몸으로 느껴집니다. 이제 자신의 컨텐츠를 만드는게 경쟁력이 되는 시대입니다.\n  공부를 잘하는 친구들은 의외로 단순하다네요. 그냥 지금 인 순간 자신이 하고 있는 공부 방식을 믿고 밀어붙인답니다. 공부는 방법보다 그냥 하는 게 가장 중요하거든요.영어 공부를 할 때도, 어떤 책을 어떤 방식으로 공부하느냐를 끊임없이 고민하는 것보다 그냥 밀어봍이는 편이 낫습니다. ‘무엇을 하느냐’ 또는 ‘어떻게 하느냐’ 보다 중요한 건 ‘왜 하느냐’ 입니다.\n 재밌게 읽었지만 이런 글이 있는 지는 기억이 없다 -_-. 타이탄의 도구들 중 글을 인용한. 그래도 난 낮에 하는 일이나 밤에 (어쩌다) 공부하는 하는 거나 비슷한 주제라 다행이네.\n 그들이 낮에 무슨 일을 하는지 상관없다. 중요한 것은 그들이 회사에서 퇴근해 무엇을 하느냐다. 우리는 그들의 낮 시간에는 관심 없다. 십중팔구 그들은 돈을 벌기 위해 회사에서 시키는 일들을 하고 있을 테니까. 우리가 집중하는 건 그들의 취미가 무엇이냐다.\n  재능을 타고나지 못했다고 포기할 필요는 없어요. 재능이 있는지 없는지도 끈기를 발휘하기 전에는 알 수 없고요. 결국 재능이 없는 걸 깨듣게 된다 해도 끈기를 기른다면, 재능보다 더 소중한 능력을 갖추게 되는 겁니다. 재능보다 더 중요한 건 끈기입니다. 인공지능의 시대, 가장 필요한 역량이 독창성인데요, 독창성의 첫 번째 재료가 바로 끈기입니다.\n 마침 오늘 프로야구에서 양준혁 선수가 가지고 있는 최다 안타 갯수 기록을 박용택 선수가 갱신했다.\n한 시즌에서의 최대 안타도 그렇긴 하지만 누적 최대 안타 개수는 정말 수년간(양준혁 선수는 18년, 박용택 선수는 17년 동안) 꾸준히 성적을 내야 가능한 기록이다. 그야말로 끈기가 필요한. 끈기를 가지고 암흑기를 버티고 이렇게 성적을 낸 박용택 선수는 특히 변화에 잘 적응하기 위해 노력한 선수로 알려져있다. 슬럼프가 오거나 나이를 먹음에 따라 체력 조건이 달라지는 것을 새로운 타격 폼 등으로 보상해 가면서 늘 공부하는 모습을 보여왔다. 그 덕분에 대한민국 야구 역사에 남을 기록을 만들 수 있고, 또 꾸준히 오랫동안 좋은 성적으로 정상급 실력을 보여주고 있는 거다.\n","id":61,"section":"posts","summary":"세바시 였던가, 공개 강의 동영상을 통해 처음 알게 된 김민식 PD. 예전에 인기있었던 시트콤, ‘논스톱’을 만든 PD인데 MBC 파업과 관련되어 힘든 시간을 보내다 “영어책","tags":["Book","writing"],"title":"(책) 매일 아침 써봤니?","uri":"https://cychong47.github.io/2018/07/did-you-write-in-every-morning/","year":"2018"},{"content":"오늘 회사에서 점심 시간에 배운 mindmap 활용법\niThoughtX를 OS X, iOS용으로 모두 구입할 만큼 마인드맵에 관심이 있긴 한데 생각을 풀어낼 때 다양한 framework을 활용할 수 있다는 건 몰랐다. 관련된 책을 한번 읽어보면 좋겠네.\n오늘 강의해준 신 분은 무려 자기 이름을 걸로 책을 낸 저자 동종성 님\n","id":62,"section":"posts","summary":"오늘 회사에서 점심 시간에 배운 mindmap 활용법 iThoughtX를 OS X, iOS용으로 모두 구입할 만큼 마인드맵에 관심이 있긴 한데 생각을 풀어낼 때 다양한 framew","tags":["til","mindmap"],"title":"생각 정리의 기술","uri":"https://cychong47.github.io/2018/06/mindmap/","year":"2018"},{"content":"이상하게 wordpress 버전이 올라가면 docker용 wordpress 버전도 함께 올라갈 텐데 아무리 최신 docker image를 받아 container를 만들어도 wordpress admin 계정에 들어가면 wordpress를 업데이트 해야 한다고 한다. docket store(http://store.docker.com)에 가면 분명히 wordpress 최신 버전으로 패키징되어 있는 데\u0026hellip;\n혹시나 하고 ansible-playbook을 보니 /var/www/html에 마운트되는 위치에 이전 버전의 wordpress 파일들이 존재하고 있었다.\n volumes: - \u0026quot;/Users/cychong/Documents/wordpress/html:/var/www/html\u0026quot; - \u0026quot;/Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads\u0026quot; - \u0026quot;/Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini\u0026quot;  바로 첫번째 줄이 문제를 유발하고 있는 곳\u0026hellip; 내가 왜 굳이 저렇게 했을까 생각해 보니 저 디렉토리에 바로 wp-content가 있고, 그 아래 themes와 plugins가 있다. 처음 docker로 wordpress를 띄울 때 이미 설치한 theme이나 plugin이 wordpress docker 버전이 올라가서 새로 container를 만들 때마다 다시 설치해야 하는 번거로움을 피하려고 저렇게 한 듯 하다. 지금 생각하면 참 바보같은\u0026hellip;\n이렇게 수정한 후에 정상적으로 최신 버전의 wordpress를 만날 수 있게 되었다.\n volumes: - \u0026quot;/Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads\u0026quot; - \u0026quot;/Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini\u0026quot; - \u0026quot;/Users/cychong/Dropbox/Apps/wordpress/plugins/easy-video-player:/var/www/html/wp-content/plugins/easy-video-player\u0026quot; - \u0026quot;/Users/cychong/Dropbox/Apps/wordpress/plugins/jetpack:/var/www/html/wp-content/plugins/jetpack\u0026quot; - \u0026quot;/Users/cychong/Dropbox/Apps/wordpress/plugins/wordpress-importer:/var/www/html/wp-content/plugins/wordpress-importer\u0026quot; - \u0026quot;/Users/cychong/Dropbox/Apps/wordpress/themes/independent-publisher:/var/www/html/wp-content/themes/independent-publisher\u0026quot;  ","id":63,"section":"posts","summary":"이상하게 wordpress 버전이 올라가면 docker용 wordpress 버전도 함께 올라갈 텐데 아무리 최신 docker image를 받아 container를 만들어도 wordpress admin 계정에 들어가면 wor","tags":["docker","wordpress","ansible","ansible-playbook","troubleshooting"],"title":"Update ansible-playbook for wordpress","uri":"https://cychong47.github.io/2018/06/update-ansible-playbook-for-wordpress/","year":"2018"},{"content":"문제 블로그 보는 거 자체는 문제가 없는데 admin 계정으로 로그인 시도하면 반복해서 로그인 페이지로 redirect됨\nhttp://sosa0sa.com/wp-login.php?redirect_to=http://sosa0sa.com/wp-admin/\u0026amp;reauth=1  구글링을 하니 대부분 쿠키를 초기화하고, theme, plugin등을 초기화하라는 의견이 대부분. 모두 따라해 봤으니 제대로 동작하지 않는다\u0026hellip; -_-;;;\n마지막으로 wp_usermeta table에서 session_token 값을 초기화하라는 말이 있어 이것도 해 보기로. phpmyadmin을 설치해서 table의 값을 변경하라고 해서 phpmyadmin을 역시 docker로 설치해 보기로\nhttps://wordpress.org/support/topic/possible-fix-for-sudden-redirect-loop-at-wp-login-with-reauth1/\nPhpmyadmin docker 설치 Wordpress ansible-playbook 에 다음과 같이 추가\nlinks를 통해 mysql container와 연결하고 PMA_HOST를 해당 mysql container의 name으로 지정하는 것이 중요한 내용임. 처음에는 PMA_HOST를 “localhost”나 “127.0.0.1”로 지정하니 정상적으로 mysql에 로그인이 되지 않음\n- name: Start phpmyadmin docker_container: name: phpmyadmin image: phpmyadmin/phpmyadmin links: - mysql:mysql # always pull the latest image pull: no state: started recreate: yes restart_policy: \u0026quot;always\u0026quot; ports: - \u0026quot;8181:80\u0026quot; env: PMA_HOST: \u0026quot;mysql\u0026quot; MYSQL_USERNAME: \u0026quot;root\u0026quot; MYSQL_ROOT_PASSWORD: \u0026quot;root_password\u0026quot;  그런데 mysql로 접속했는데 mysql의 DB 내용이 정상적으로 나오지 않음. 그런데 phpmyadmin 을 설치한 후 주소(http://192.168.1.200:8181)를 접근하니 예전에 본것과 다르게 뭔가 허전한 화면만 나온다.\n아는 것도 없지만 그래도 혹시나 하고 docker에 bash로 접근해서 얼마전에 influxDB에서 사용해 본 명령어가 같을 듯 해서 입력해 봤는데 이것도 제대로 동작하지 않는다.\nmini2:~ cychong$ docker exec -it a7681c4ec35e bash root@a7681c4ec35e:/# mysql ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES) root@a7681c4ec35e:/# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 39 Server version: 8.0.11 MySQL Community Server - GPL Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql\u0026gt; show databases; ERROR 1449 (HY000): The user specified as a definer ('mysql.infoschema'@'localhost') does not exist  web으로 다시 phpmyadmin 화면에 접근했을 때 나온 에러 메시지를 찾아보기로 바로 이거\nThe user specified as a definer ('mysql.infoschema'@'localhost') does not exist  구글링을 하니 역시나 흔한 문제인 듯. 다음과 같은 글을 찾을 수 있어 글에서 시킨대로 해봤다.\nhttps://stackoverflow.com/questions/49992868/mysql-errorthe-user-specified-as-a-definer-mysql-infoschemalocalhost-doe\n암호는 container 생성할 때 인자로 넣어주는 MYSQL_ROOT_PASSWORD값을 사용한다. wordpress.yaml 파일에서 확인 가능..\nroot@a7681c4ec35e:/var/log# mysql_upgrade -u root -p Enter password: Checking if update is needed. Checking server version. Running queries to upgrade MySQL server. Upgrading system table data. Checking system database. mysql.columns_priv OK mysql.component OK mysql.db OK mysql.default_roles OK mysql.engine_cost OK mysql.func OK mysql.general_log OK mysql.global_grants OK mysql.gtid_executed OK mysql.help_category OK mysql.help_keyword OK mysql.help_relation OK mysql.help_topic OK mysql.innodb_index_stats OK mysql.innodb_table_stats OK mysql.ndb_binlog_index OK mysql.password_history OK mysql.plugin OK mysql.procs_priv OK mysql.proxies_priv OK mysql.role_edges OK mysql.server_cost OK mysql.servers OK mysql.slave_master_info OK mysql.slave_relay_log_info OK mysql.slave_worker_info OK mysql.slow_log OK mysql.tables_priv OK mysql.time_zone OK mysql.time_zone_leap_second OK mysql.time_zone_name OK mysql.time_zone_transition OK mysql.time_zone_transition_type OK mysql.user OK Found outdated sys schema version 1.5.1. Upgrading the sys schema. Checking databases. sys.sys_config OK wordpress_db.wp_commentmeta OK wordpress_db.wp_comments OK wordpress_db.wp_links OK wordpress_db.wp_options OK wordpress_db.wp_postmeta OK wordpress_db.wp_posts OK wordpress_db.wp_term_relationships OK wordpress_db.wp_term_taxonomy OK wordpress_db.wp_termmeta OK wordpress_db.wp_terms OK wordpress_db.wp_usermeta OK wordpress_db.wp_users OK Upgrade process completed successfully. Checking if update is needed. root@a7681c4ec35e:/var/log#  이제 다시 phpmyadmin화면을 접근하니 이제 정상적인(?) 뭔가가 보인다.\n뭔가 제대로 되는 것 같다. 다시 wordpress admin 계정으로 로그인하니 이젠 된다!!! Finally\u0026hellip;\n그래도 안될때 (2019.02.28) wordpress가 5.1로 업데이트 되어 그걸 적용했더니 database 파일도 업그레이드를 해야 한다고. 그래서 해라 그랬더니 또 로그인이 안된다. 이번에는 위의 mysql_upgrade 명령을 써도 안되고\u0026hellip;.\n다행히 구글링에서 유용한 정보를 찾았다. 처음 본 순간 왠지 잘 될 것 같았는데 정말로 한번에 문제를 해결해줬다. https://www.fixrunner.com/cannot-login-wordpress-admin-area/\n한 줄 요약하면 mysql database에 저장되어 있는 로그인 암호를 직접 변경하는 것.\nwordpress database에서 wp_user라는 테이블의 user_pass라는 필드를 변경하는 거다. phpmyadmin으로 수정하는 창에서 보니 결국(?) 이런 sql 명령으로 변경할 수 있다고 한다. 아래 새 암호에 원하는 새로운 암호를 넣으면 그걸 md5 hash한 값을 user_pass 필드에 저장한다.\nUPDATE `wp_users` SET `user_pass` = MD5('새 암호') WHERE `wp_users`.`ID` = 1;  다행히 오랫동안 헤매지 않고 해결해서 다행이다.\n","id":64,"section":"posts","summary":"문제 블로그 보는 거 자체는 문제가 없는데 admin 계정으로 로그인 시도하면 반복해서 로그인 페이지로 redirect됨 http://sosa0sa.com/wp-login.php?redirect_to=http://sosa0sa.com/wp-admin/\u0026amp;reauth=1 구글링을 하니 대부분 쿠키를 초기화하고, theme, p","tags":["Getting Started","wordpress","mysql","troubleshooting"],"title":"wordpress admin 계정 복구","uri":"https://cychong47.github.io/2018/06/wordpress-admin-login-fail/","year":"2018"},{"content":"Time-series data를 python을 이용해서 influxDB에 저장하고, Grafana로 그래프를 보여주는 예제\nhttps://github.com/cychong47/influxdb_example.git\nInstall Grafana and influxDB Install Grafana 직접 호스트에 설치할 수도 있지만, 세상 편하게 만들어준 docker를 이용해서 grafana, influxdb등을 설치하자.\nmbpr15:~ cychong$ docker pull grafana/grafana Using default tag: latest latest: Pulling from grafana/grafana f2aa67a397c4: Pull complete 89573effc7c8: Pull complete b55c103da375: Pull complete Digest: sha256:364bec4a39ecbec744ea4270aae35f6554eb6f2047b3ee08f7b5f1134857c32c Status: Downloaded newer image for grafana/grafana:latest  Start grafana\nmbpr15:~ cychong$ docker run -d -p 3000:3000 —name grafana grafana/grafana 148894d7009259b02b04e1a98467f549400be91f9b055f8686557d69b9339e4b  Install influxDB influxdb도 docker 명령어 하나로 설치\ninfluxdb | Docker Documentation\nmbpr15:~ cychong$ docker pull influxdb Using default tag: latest latest: Pulling from library/influxdb cc1a78bfd46b: Pull complete 6861473222a6: Pull complete 7e0b9c3b5ae0: Pull complete ef1cd6af9147: Pull complete 07d71592a7b6: Pull complete 4df1ab172fbc: Pull complete 6f607c73c187: Pull complete 3fd297f39292: Pull complete Digest: sha256:e3efb51395d630a912c3c24edb7567ec1ac01d3dfdc39f27f53ca0e15c3da797 Status: Downloaded newer image for influxdb:latest  Install influxdb module for python python에서 직접 influxDB를 사용하려면 influxdb 모듈을 사용한다\nmbpr15:~ cychong$ pip3 install influxdb Collecting influxdb Downloading https://files.pythonhosted.org/packages/8d/79/7972c12e393080eda6920583c9c2ed2206771da7f6341c8971a2c02ff3d3/influxdb-5.0.0-py2.py3-none-any.whl (70kB) 100% |████████████████████████████████| 71kB 709kB/s Requirement already satisfied: requests\u0026gt;=2.17.0 in /usr/local/lib/python3.6/site-packages (from influxdb) (2.18.4) Collecting python-dateutil\u0026gt;=2.6.0 (from influxdb) Downloading https://files.pythonhosted.org/packages/cf/f5/af2b09c957ace60dcfac112b669c45c8c97e32f94aa8b56da4c6d1682825/python_dateutil-2.7.3-py2.py3-none-any.whl (211kB) 100% |████████████████████████████████| 215kB 2.9MB/s Collecting pytz (from influxdb) Downloading https://files.pythonhosted.org/packages/dc/83/15f7833b70d3e067ca91467ca245bae0f6fe56ddc7451aa0dc5606b120f2/pytz-2018.4-py2.py3-none-any.whl (510kB) 100% |████████████████████████████████| 512kB 5.0MB/s Requirement already satisfied: six\u0026gt;=1.10.0 in /usr/local/lib/python3.6/site-packages (from influxdb) (1.11.0) Requirement already satisfied: certifi\u0026gt;=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests\u0026gt;=2.17.0-\u0026gt;influxdb) (2017.11.5) Requirement already satisfied: idna\u0026lt;2.7,\u0026gt;=2.5 in /usr/local/lib/python3.6/site-packages (from requests\u0026gt;=2.17.0-\u0026gt;influxdb) (2.6) Requirement already satisfied: chardet\u0026lt;3.1.0,\u0026gt;=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests\u0026gt;=2.17.0-\u0026gt;influxdb) (3.0.4) Requirement already satisfied: urllib3\u0026lt;1.23,\u0026gt;=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests\u0026gt;=2.17.0-\u0026gt;influxdb) (1.22) hacking 1.0.0 has requirement flake8\u0026lt;2.6.0,\u0026gt;=2.5.4, but you’ll have flake8 3.5.0 which is incompatible. hacking 1.0.0 has requirement mccabe==0.2.1, but you’ll have mccabe 0.6.1 which is incompatible. hacking 1.0.0 has requirement pyflakes==0.8.1, but you’ll have pyflakes 1.6.0 which is incompatible. docker-compose 1.17.1 has requirement requests!=2.11.0,\u0026lt;2.12,\u0026gt;=2.6.1, but you’ll have requests 2.18.4 which is incompatible. Installing collected packages: python-dateutil, pytz, influxdb Successfully installed influxdb-5.0.0 python-dateutil-2.7.3 pytz-2018.4  Start influxdb Getting Started with Python and Influxdb | InfluxData\nmbpr15:working cychong$ mkdir influxdb mbpr15:working cychong$ cd influxdb/ mbpr15:influxdb cychong$ ls mbpr15:influxdb cychong$ docker run -d -p 8086:8086 -v $PWD:/var/lib/influxdb influxdb 5088889ce21c9c9e2249db701694aa0bd39429371b5dababcf6ebb8c2e7598d3  To have customized config file for influxdb. First generate the default configuration file and update it. Then restart influxdb with that config file.\nmbpr15:influxdb cychong$ docker run —rm influxdb influxd config \u0026gt; influxdb.conf Merging with configuration at: /etc/influxdb/influxdb.conf mbpr15:influxdb cychong$ docker run -d -p 8086:8086 -v $PWD:/var/lib/influxdb -v $PWD/influxdb.conf:/etc/influxdb/influxdb.conf influxdb -config /etc/influxdb/influxdb.conf 1d9ac4ffdca38b2c627da134273d7570c9c74182cb4bbedb8deebf09c3e5dc0a  Influx db write error influxdb-python/tutorial.py at master · influxdata/influxdb-python · GitHub 샘플코드를 그대로 실행시키면 다음과 같은 에러를 만난다.\nmbpr15:influxdb cychong$ python3 influxdb-ex.py Create database: example Create a retention policy Switch user: smly Write points: [{'measurement': 'cpu_load_short', 'tags': {'host': 'server01', 'region': 'us-west'}, 'time': '2009-11-10T23:00:00Z', 'fields': {'Float_value': 0.64, 'Int_value': 3, 'String_value': 'Text', 'Bool_value': True}}] Traceback (most recent call last): File \u0026quot;influxdb-ex.py\u0026quot;, line 73, in \u0026lt;module\u0026gt; main(host=args.host, port=args.port) File \u0026quot;influxdb-ex.py\u0026quot;, line 45, in main client.write_points(json_body) File \u0026quot;/usr/local/lib/python3.6/site-packages/influxdb/client.py\u0026quot;, line 468, in write_points tags=tags, protocol=protocol) File \u0026quot;/usr/local/lib/python3.6/site-packages/influxdb/client.py\u0026quot;, line 532, in _write_points protocol=protocol File \u0026quot;/usr/local/lib/python3.6/site-packages/influxdb/client.py\u0026quot;, line 312, in write headers=headers File \u0026quot;/usr/local/lib/python3.6/site-packages/influxdb/client.py\u0026quot;, line 271, in request raise InfluxDBClientError(response.content, response.status_code) influxdb.exceptions.InfluxDBClientError: 400: {\u0026quot;error\u0026quot;:\u0026quot;partial write: points beyond retention policy dropped=1\u0026quot;}  무슨 말인가 찾아보니 retention policy라는 건 db에 저장하는 데이터가 특정 기준이상으로 오래된 것이면 저장을 불허하기 때문에 이 policy에 걸려 write 동작이 실패했다는 것이다. points beyond retention policy !! what does this mean?? · Issue #9093 · influxdata/influxdb · GitHub\n참고로 예제에서는 retention policy를 3일로 지정하고 있는데 샘플용 json 데이터에 지정된 시각이 2009-11-10T23:00:00Z라 에러가 발생한 것.\nprint(\u0026quot;Create a retention policy\u0026quot;) client.create_retention_policy('awesome_policy', '3d', 3, default=True)  샘플에서 time 필드를 현재 시간으로 변경한다. 이때 influxdb가 원하는 시간 형태로 표시해야 한다. python - How to use time field in adding metrics data to the influx db? - Stack Overflow을 참고하여 수정.\nfrom datetime import datetime current_time = datetime.utcnow().strftime(‘%Y-%m-%dT%H:%M:%SZ’)   json_body[0]['time'] = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')  수정 후 정상적으로 동작\nmbpr15:influxdb cychong$ python3 influxdb-ex.py Create database: example Create a retention policy Switch user: smly Write points: [{‘measurement’: ‘cpu_load_short’, ‘tags’: {‘host’: ‘server01’, ‘region’: ‘us-west’}, ‘time’: ‘2018-06-06T03:08:17Z’, ‘fields’: {‘Float_value’: 0.64, ‘Int_value’: 3, ‘String_value’: ‘Text’, ‘Bool_value’: True}}] Querying data: select value from cpu_load_short; Result: ResultSet({}) Switch user: root Drop database: example  주기적으로 데이터를 influxdb에 저장 이제 주기적으로 데이터를 db에 저장해서 말그래도 time-series data가 되도록 한다.\nimport argparse import time import random from datetime import datetime from influxdb import InfluxDBClient def setup_db(host, port): user = 'root' password = 'root' dbname = 'example' dbuser = 'smly' dbuser_password = 'my_secret_password' client = InfluxDBClient(host, port, user, password, dbname) print(\u0026quot;Create database: \u0026quot; + dbname) client.create_database(dbname) print(\u0026quot;Create a retention policy\u0026quot;) client.create_retention_policy('awesome_policy', '3d', 3, default=True) print(\u0026quot;Switch user: \u0026quot; + dbuser) client.switch_user(dbuser, dbuser_password) return client def add_data(client, dl_tp, ul_tp): json_body = [ { \u0026quot;measurement\u0026quot;: \u0026quot;throughput\u0026quot;, \u0026quot;tags\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;server01\u0026quot;, \u0026quot;region\u0026quot;: \u0026quot;us-west\u0026quot; }, \u0026quot;time\u0026quot;: \u0026quot;2009-11-10T23:00:00Z\u0026quot;, \u0026quot;fields\u0026quot;: { \u0026quot;dl_tp\u0026quot; : 0, \u0026quot;ul_tp\u0026quot; : 0, } } ] json_body[0]['time'] = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ') json_body[0]['fields']['dl_tp'] = int(dl_tp) json_body[0]['fields']['ul_tp'] = int(ul_tp) #print(\u0026quot;Write points: {0}\u0026quot;.format(json_body)) client.write_points(json_body) def main(host='localhost', port=8086): \u0026quot;\u0026quot;\u0026quot;Instantiate a connection to the InfluxDB.\u0026quot;\u0026quot;\u0026quot; client = setup_db(host, port) while True: dl_tp = random.uniform(150,200) ul_tp = random.uniform(50,70) add_data(client, dl_tp, ul_tp) time.sleep(1) def parse_args(): \u0026quot;\u0026quot;\u0026quot;Parse the args.\u0026quot;\u0026quot;\u0026quot; parser = argparse.ArgumentParser( description='example code to play with InfluxDB') parser.add_argument('--host', type=str, required=False, default='localhost', help='hostname of InfluxDB http API') parser.add_argument('--port', type=int, required=False, default=8086, help='port of InfluxDB http API') return parser.parse_args() if __name__ == '__main__': args = parse_args() main(host=args.host, port=args.port)  Influxdb에서 데이터 확인 influxdb container에 접속해서 cli 명령을 통해 db 내용을 확인해 본다.\nmbpr15:influxdb cychong$ docker exec -it 1d9ac4ffdca3 influx Connected to http://localhost:8086 version 1.5.3 InfluxDB shell version: 1.5.3 \u0026gt; use example Using database example \u0026gt; show field keys; name: throughput fieldKey fieldType -------- --------- dl_tp integer ul_tp integer \u0026gt; select * from throughput; name: throughput time dl_tp host region ul_tp ---- ----- ---- ------ ----- 1528255918000000000 0 server01 us-west 0 1528255919000000000 0 server01 us-west 0 1528255920000000000 0 server01 us-west 0 1528255921000000000 0 server01 us-west 0 1528255922000000000 0 server01 us-west 0 ... 1528256939000000000 199 server01 us-west 50 1528256940000000000 189 server01 us-west 62 1528256941000000000 163 server01 us-west 50 1528256942000000000 152 server01 us-west 52 1528256943000000000 182 server01 us-west 69 1528256944000000000 191 server01 us-west 55 1528256945000000000 190 server01 us-west 61 1528256946000000000 178 server01 us-west 68 \u0026gt;  Grafana에서 influxdb에 저장된 정보 읽어오기 Grafana에서 data source로 influxdb 지정.(URL 필드에 http://localhost:8086 지정) 이상하게도 같은 머신에서 돌고 있는 influxdb의 주소를 localhost로 지정하면 연결이 안된다는 에러가 난다.\n머신에 할당된 다른 IP를 지정하면 정상적으로 설정(이때는 스타벅스에서 실행했는데 이때 할당된 IP가 172.20.10.3 이었다) Everything is working finally Tips for customizing grafana dashboard Metric 설정할 때는 FROM에서 influxDB의 measurement를 선택하면 아래 SELECT의 필드에 자동으로 선택할 수 있는 fields가 제시된다.\ninfluxDB에 정보를 저장할 때 사용한 json과 비교해 보면 fields 에 정의했던 키들이 제시된다. GROUP BY 는 데이터 중 특정 종류에 속하는 것만 보여주고 싶을 때 사용할 수 있다. 예를 들어 fields를 dl_tp와 ul_tp로 정의하지 않고, tags에 direction이라는 필드를 두고, fields는 그냥 tp로 정의할 수 있다. 즉 위 예제는 하나의 데이터 셋에 ul_tp와 dl_tp가 모두 있지만, UL tp만을 가진 데이터 셋과 DL tp만을 가진 데이터 셋으로 분리하여 influxdb에 저장할 수 있다. 이 경우 DL tp만을 가진 데이터 셋만으로 metric을 한정하려면 아래 있는 GROUP BY을 사용하여 tag(diretion)을 선택하면 되지 않을까? Axes 의 unit을 데이터에 맞는 적절한 것으로 선택하면 데이터의 특성을 강조할 수 있다. 아래는 data rate의 bits/sec를 선택한 경우이다.(데이터 값이 이미 Mbps로 전달된 경우에는 이를 고려하여 megabits/sec를 선택하면 된다)\n","id":65,"section":"posts","summary":"Time-series data를 python을 이용해서 influxDB에 저장하고, Grafana로 그래프를 보여주는 예제 https://github.com/cychong47/influxdb_example.git Install Grafana and influxDB Install Grafana 직접 호스트에 설치할 수도 있지만","tags":["Python","docker","elk","til","monitoring","grafana","influxdb"],"title":"Grafana, influxDB and python","uri":"https://cychong47.github.io/2018/06/grafana-influxdb-and-python/","year":"2018"},{"content":"Install Elastic Stack(ELK stack) with docker mbpr15:elk-wireshark cychong$ git clonehttps://github.com/deviantony/docker-elk.git git: 'clonehttps://github.com/deviantony/docker-elk.git' is not a git command. See 'git --help'. mbpr15:elk-wireshark cychong$ git clone https://github.com/deviantony/docker-elk.git Cloning into 'docker-elk'... remote: Counting objects: 1235, done. remote: Total 1235 (delta 0), reused 0 (delta 0), pack-reused 1235 Receiving objects: 100% (1235/1235), 259.29 KiB | 77.00 KiB/s, done. Resolving deltas: 100% (470/470), done. mbpr15:elk-wireshark cychong$ cd elk mbpr15:elk-wireshark cychong$ cd docker-elk/ mbpr15:docker-elk cychong$ ls LICENSE\telasticsearch\tlogstash README.md\textensions docker-compose.yml\tkibana  Install ELK with docker-compose mbpr15:docker-elk cychong$ docker-compose up -d Creating network \u0026quot;docker-elk_elk\u0026quot; with driver \u0026quot;bridge\u0026quot; Building elasticsearch Step 1/1 : FROM docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4 6.2.4: Pulling from elasticsearch/elasticsearch-oss 469cfcc7a4b3: Pull complete 8e27facfa9e0: Pull complete cdd15392adc7: Pull complete 19ff08a29664: Pull complete ddc4fd93fdcc: Pull complete b723bede0878: Pull complete Digest: sha256:2d9c774c536bd1f64abc4993ebc96a2344404d780cbeb81a8b3b4c3807550e57 Status: Downloaded newer image for docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4 ---\u0026gt; 3822ba554fe9 Successfully built 3822ba554fe9 Successfully tagged docker-elk_elasticsearch:latest WARNING: Image for service elasticsearch was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. Building logstash Step 1/1 : FROM docker.elastic.co/logstash/logstash-oss:6.2.4 6.2.4: Pulling from logstash/logstash-oss 469cfcc7a4b3: Already exists b4cfa2eb1616: Pull complete ec994fa6fa7f: Pull complete ccf455902ac6: Pull complete 6d54f3767ae5: Pull complete af0dd1a720da: Pull complete 457dbabd3f63: Pull complete f2c481bd6da1: Pull complete d04342e2b9a1: Pull complete e8bca7e9b0d9: Pull complete d0096563f301: Pull complete Digest: sha256:28668a65f6b6a4f1e2abef7aa3fd3b9c8476a16aa5bebc1a9acf0f7de5b80eef Status: Downloaded newer image for docker.elastic.co/logstash/logstash-oss:6.2.4 ---\u0026gt; 0bade66b6bee Successfully built 0bade66b6bee Successfully tagged docker-elk_logstash:latest WARNING: Image for service logstash was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. Building kibana Step 1/1 : FROM docker.elastic.co/kibana/kibana-oss:6.2.4 6.2.4: Pulling from kibana/kibana-oss 469cfcc7a4b3: Already exists 78e4c5fdc069: Pull complete d9ecdaefa1b8: Pull complete c8e48c8f74d7: Pull complete 1606c56cdbff: Pull complete 4e23ce1503d4: Pull complete d36b703b3f90: Pull complete da5da7625f92: Pull complete Digest: sha256:1d1f9bac326bf276010df82a2b4593619f48a5207619e8817c8b20d5a1bb3547 Status: Downloaded newer image for docker.elastic.co/kibana/kibana-oss:6.2.4 ---\u0026gt; 32510971af4e Successfully built 32510971af4e Successfully tagged docker-elk_kibana:latest WARNING: Image for service kibana was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. Creating docker-elk_elasticsearch_1 ... done Creating docker-elk_kibana_1 ... done Creating docker-elk_logstash_1 ... done  mbpr15:docker-elk cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4fc052e81fae docker-elk_logstash “/usr/local/bin/dock…” 9 minutes ago Up 9 minutes 5044/tcp, 0.0.0.0:5000-\u0026gt;5000/tcp, 9600/tcp docker-elk_logstash_1 46f049297c7b docker-elk_kibana “/bin/bash /usr/loca…” 9 minutes ago Up 9 minutes 0.0.0.0:5601-\u0026gt;5601/tcp docker-elk_kibana_1 8ff911ebab03 docker-elk_elasticsearch “/usr/local/bin/dock…” 9 minutes ago Up 9 minutes 0.0.0.0:9200-\u0026gt;9200/tcp, 0.0.0.0:9300-\u0026gt;9300/tcp docker-elk_elasticsearch_1  mbpr15:docker-elk cychong$ curl http://localhost:9200 { “name” : “npNAiWg”, “cluster_name” : “docker-cluster”, “cluster_uuid” : “7nY4KVvNS4epY4Z80NCUZw”, “version” : { “number” : “6.2.4”, “build_hash” : “ccec39f”, “build_date” : “2018-04-12T20:37:28.497551Z”, “build_snapshot” : false, “lucene_version” : “7.2.1”, “minimum_wire_compatibility_version” : “5.6.0”, “minimum_index_compatibility_version” : “5.0.0” }, “tagline” : “You Know, for Search” }  Open http://localhost:5601 with browser install metricbeats with docker - check the latest version from elastic.co docker pull docker.elastic.co/beats/metricbeat:6.2.4  metricbeat 는 시스템 통계 정보를 수집해서 elasticsearch로 보내는 역할을 함. 다양한 모듈들이 modules.d 디렉토리 아래 위치하고, metricbeats.yml은 수집한 정보를 보낼 위치를 변경하는 정도면 기본적인 동작을 확인할 수 있음.\nmbpr15:metricbeat-6.2.4-darwin-x86_64 cychong$ tree -f modules.d/ modules.d ├── modules.d/aerospike.yml.disabled ├── modules.d/apache.yml.disabled ├── modules.d/ceph.yml.disabled ├── modules.d/couchbase.yml.disabled ├── modules.d/docker.yml.disabled ├── modules.d/dropwizard.yml.disabled ├── modules.d/elasticsearch.yml.disabled ├── modules.d/etcd.yml.disabled ├── modules.d/golang.yml.disabled ├── modules.d/graphite.yml.disabled ├── modules.d/haproxy.yml.disabled ├── modules.d/http.yml.disabled ├── modules.d/jolokia.yml.disabled ├── modules.d/kafka.yml.disabled ├── modules.d/kibana.yml.disabled ├── modules.d/kubernetes.yml.disabled ├── modules.d/logstash.yml.disabled ├── modules.d/memcached.yml.disabled ├── modules.d/mongodb.yml.disabled ├── modules.d/mysql.yml.disabled ├── modules.d/nginx.yml.disabled ├── modules.d/php_fpm.yml.disabled ├── modules.d/postgresql.yml.disabled ├── modules.d/prometheus.yml.disabled ├── modules.d/rabbitmq.yml.disabled ├── modules.d/redis.yml.disabled ├── modules.d/system.yml ├── modules.d/uwsgi.yml.disabled ├── modules.d/vsphere.yml.disabled ├── modules.d/windows.yml.disabled └── modules.d/zookeeper.yml.disabled 0 directories, 31 files  아래에서 hosts의 기본값은 localhost이므로, 필요한 경우 elasticisearch가 동작하고 있는 특정 서버의 IP로 변경한다.\n#-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: # Array of hosts to connect to. hosts: [\u0026quot;192.168.1.70:9200\u0026quot;]  MBPr15와 mini2 에서 각각 metricbeat를 실행해서 metric 정보를 elasticsearch로 보내도록 함. 아래는 기본 yml인 metricbeat.yml에서 위 output부분만 수정하여 memphis.yml로 저장후 사용\nmbpr15:metricbeat-6.2.4-darwin-x86_64 cychong$ sudo ./metricbeat -e -c memphis.yml  mini2:metricbeat-6.2.4-darwin-x86_64 cychong$ ./metricbeat -e -c mini2.yaml  이렇게 하면 화면에 주기적으로 elasticsearch로 보내는 정보를 출력한다.(전체 정보는 아닐 듯\u0026hellip;.) 이렇게 옵션을 주면 화면에 별도의 로그 출력이 없다.\nsudo metricbeat -e \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;  이걸 하긴 했는데 굳이 따로 할 필요는 없는 듯. Kibana에 default dashboard를 생성하는 거라고 하는데(다시 확인해 보자)\nsudo ./metricbeat setup -c memphis.yml  mbpr15:~ cychong$ curl -XGET 'localhost:9200/_cat/indices?v\u0026amp;pretty' health status index uuid pri rep docs.count docs.deleted store.size pri.store.size yellow open metricbeat-6.2.4-2018.06.01 2WRn5ddLRAm5E7J56pwRXA 5 1 127340 0 35.8mb 35.8mb yellow open metricbeat-6.2.4-2018.05.31 8dsKJT4ASEadN9CD9-uQ-A 5 1 136 0 317.2kb 317.2kb green open .kibana tCI5Fu5BTda1gpDNm1cCeQ 1 0 126 14 316.8kb 316.8kb  system 정보를 얻어오는 거라 root 권한이 필요할 듯 한데 지금은 MBPr15에서는 루트 권한으로 그리고 mini2에서는 그냥 개인 계정으로 실행 중\nKibana dashboard System overview Host overview - MBPr15 Host overview - mini2 xcode command line update하느라 힘든 mini2. 위 그림보다 CPU utilization이 올라갔다. On ubuntu Linux의 경우 deb이나 rpm 패키지를 이용해서 설치할 수 있다. 이 경우 패키지가 설치되면 아래 위치에서 beat 관련 파일을 확인할 수 있다.\n$ ls -al /usr/share/metricbeat/ total 228 drwxr-xr-x 4 root root 4096 6월 1 08:48 ./ drwxr-xr-x 404 root root 16384 6월 1 09:32 ../ drwxr-xr-x 2 root root 4096 6월 1 08:48 bin/ -rw-r--r-- 1 root root 41 4월 13 05:25 .build_hash.txt drwxrwxr-x 4 root root 4096 6월 1 08:48 kibana/ -rw-r--r-- 1 root root 583 4월 13 05:25 LICENSE.txt -rw-r--r-- 1 root root 190678 4월 13 05:25 NOTICE.txt -rw-r--r-- 1 root root 806 4월 13 05:25 README.md  참고  메트릭비트(metricbeat)로 시스템 모니터링 하기 | KWANGSIK LEE’s log A Metricbeat Tutorial: Getting Started A Filebeat Tutorial: Getting Started Installing the ELK Stack on Docker  ","id":66,"section":"posts","summary":"Install Elastic Stack(ELK stack) with docker mbpr15:elk-wireshark cychong$ git clonehttps://github.com/deviantony/docker-elk.git git: 'clonehttps://github.com/deviantony/docker-elk.git' is not a git command. See 'git --help'. mbpr15:elk-wireshark cychong$ git clone https://github.com/deviantony/docker-elk.git Cloning into 'docker-elk'... remote: Counting objects: 1235, done. remote: Total 1235 (delta 0), reused 0 (delta 0), pack-reused 1235 Receiving objects: 100% (1235/1235), 259.29 KiB | 77.00 KiB/s, done. Resolving deltas: 100% (470/470), done. mbpr15:elk-wireshark cychong$ cd elk mbpr15:elk-wireshark cychong$ cd docker-elk/ mbpr15:docker-elk cychong$ ls","tags":["docker","container","elk","elasticsearch","metricbeat","monitoring"],"title":"Elastic stack and Metricbeat","uri":"https://cychong47.github.io/2018/05/install_elasticstack_and_metricbeat/","year":"2018"},{"content":"","id":67,"section":"posts","summary":"","tags":[],"title":"2018.01 home network","uri":"https://cychong47.github.io/2018/01/2018-01-home-network/","year":"2018"},{"content":"update homebrew mbpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes localhost | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew updated successfully.\u0026quot; } mini2 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew updated successfully.\u0026quot; }  upgrade all packages mbpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes -a upgrade_all=yes localhost | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew upgraded.\u0026quot; } mini2 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew upgraded.\u0026quot; }  install a package mbpr15:mp3 cychong$ ansible all -m homebrew -a name=neovim -a state=present  mbpr15:~ cychong$ cat install_brew_neovim.yaml --- - hosts: all tasks: - name : install neovim in homebrew homebrew: name: neovim state: present mbpr15:~ cychong$ ansible-playbook install_brew_neovim.yaml PLAY [all] ***************************************************************************************************************************************************************** TASK [Gathering Facts] ***************************************************************************************************************************************************** ok: [localhost] ok: [mini2] TASK [install neovim in homebrew] ****************************************************************************************************************************************** changed: [localhost] changed: [mini2] PLAY RECAP ***************************************************************************************************************************************************************** localhost : ok=2 changed=1 unreachable=0 failed=0 mini2 : ok=2 changed=1 unreachable=0 failed=0 mbpr15:~ cychong$ which nvim /usr/local/bin/nvim  삭제는 state만 absent로 변경하면 된다.\nmbpr15:~ cychong$ diff -u install_brew_neovim.yaml uninstall_brew_neovim.yaml --- install_brew_neovim.yaml\t2017-12-30 08:57:36.000000000 +0900 +++ uninstall_brew_neovim.yaml\t2017-12-30 08:58:19.000000000 +0900 @@ -1,8 +1,8 @@ --- - hosts: all tasks: - - name : install neovim in homebrew + - name : uninstall neovim in homebrew homebrew: name: neovim - state: present + state: absent  mbpr15:~ cychong$ ansible-playbook uninstall_brew_neovim.yaml PLAY [all] ***************************************************************************************************************************************************************** TASK [Gathering Facts] ***************************************************************************************************************************************************** ok: [localhost] ok: [mini2] TASK [uninstall neovim in homebrew] **************************************************************************************************************************************** changed: [localhost] changed: [mini2] PLAY RECAP ***************************************************************************************************************************************************************** localhost : ok=2 changed=1 unreachable=0 failed=0 mini2 : ok=2 changed=1 unreachable=0 failed=0 mbpr15:~ cychong$ which nvim mbpr15:~ cychong$  state  head latest present absent linked unlinked  ","id":68,"section":"posts","summary":"update homebrew mbpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes localhost | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew updated successfully.\u0026quot; } mini2 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew updated successfully.\u0026quot; } upgrade all packages mbpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes -a upgrade_all=yes localhost | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew upgraded.\u0026quot; } mini2 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew upgraded.\u0026quot; } install","tags":["ansible","homebrew","ansible-playbook"],"title":"Ansible - Install homebrew","uri":"https://cychong47.github.io/2017/12/ansible-homebrew/","year":"2017"},{"content":"YAML file state:absent 는 현재 존재하는 container를 중지시키고, 삭제한다. 단순히 stop만 시키려면 state:stopped로 지정하면 된다.\npull: yes 옵션을 사용하면 항상 최신 image를 pull한다고 한다.\n recreate Use with present and started states to force the re-creation of an existing container.\n mbpr15:ansible cychong$ cat recreate_container_ghost.yaml --- - hosts: mini2 tasks: - name: Stop and remove contianer docker_container: name: ghost state: absent - name: Create ghost Container docker_container: name: ghost image: ghost # always pull the latest image pull: yes state: started recreate: yes volumes: - \u0026quot;/Users/cychong/Dropbox/Apps/ghost/content/:/var/lib/ghost/content\u0026quot; - \u0026quot;/Users/cychong/Dropbox/Apps/ghost/config.production.json:/var/lib/ghost/config.production.json\u0026quot; ports: - \u0026quot;2368:2368\u0026quot; env: NODE_ENV: production  mbpr15:ansible cychong$ ansible-playbook recreate_container_ghost.yaml PLAY [mini2] *************************************************************************************************************************************************************** TASK [Gathering Facts] ***************************************************************************************************************************************************** ok: [mini2] TASK [Stop and remove contianer] ******************************************************************************************************************************************* changed: [mini2] TASK [Create ghost Container] ********************************************************************************************************************************************** changed: [mini2] PLAY RECAP ***************************************************************************************************************************************************************** mini2 : ok=3 changed=2 unreachable=0 failed=0  ","id":69,"section":"posts","summary":"YAML file state:absent 는 현재 존재하는 container를 중지시키고, 삭제한다. 단순히 stop만 시키려면 state:stopped로 지정하면 된다. pull: yes 옵션을 사","tags":["docker","ghost","ansible","ansible-playbook"],"title":"Ansible - recreate ghost container","uri":"https://cychong47.github.io/2017/12/recreate-ghost-container/","year":"2017"},{"content":"play  The goal of a play is to map a group of hosts to some well defined roles, represented by things ansible calls tasks. At a basic level, a task is nothing more than a call to an ansible module\n play는 명령을 수행할 대상과 수행할 명령을 모두 포함하고 있다.\nplaybook playbook은 하나 혹은 이상의 play들의 집합으로 정의한다.\nConventional template of playbook --- - hosts: XXX optoins.... tasks: -name: YYY MODULE_NAME : MODULE_ARGS -name : ZZZ MODULE_NAME: MODULE_ARGS ...  하나의 play는 “하나 혹은 이상의 목적지 그룹에 대해 수행되는 task들의 매핑”으로 정의된다. 즉 하나의 hosts 와 해당 hosts에서 수행할 tasks들 간의 매핑을 하나의 play로 정의한다. hosts 에는 접속 및 로그인에 관련된 옵션 들이 추가될 수 있다.\n remote_user : ssh 로그인 시 계정 become : sudo 사용 여부 vars: 변수들\u0026hellip; FIXME  tasks에는 { name, MODULE_NAME}의 조합으로 순차적으로 수행할 명령어들이 기술된다.\n(FIXME 자주 사용되는 명령어 추가)\nexamples playbook --- - hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running (and enable it at boot) service: name=httpd state=started enabled=yes handlers: - name: restart apache service: name=httpd state=restarted  key=value 형태의 명령은 다음과 같이 multi-line으로도 표현 가능\n - name: write the apache config file template: src: /srv/httpd.j2 dest: /etc/httpd.conf notify: - restart apache  examples playbook - multiple plays --- - hosts: webservers remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf - hosts: databases remote_user: root tasks: - name: ensure postgresql is at the latest version yum: name=postgresql state=latest - name: ensure that postgresql is started service: name=postgresql state=started  Execute task with root permission ssh 로그인 후 login 계정이 아닌 다른 계정으로 명령을 수행하는 경우 task에 become 옵션을 준다. (FIXME 모든 task에 대해 동일하게 옵션을 지정하려면???)\ntasks: -name: update APT package w/o upgrade become: yes apt: update_cache=yes -name: upgrade to the latest package become: yes apt: upgrade=dist Or apt: name=“*” state=latest  위와 같이 become만 지정한 경우 기본적으로 root 권한으로 실행한다는 의미이다. 만일 root가 아닌 다른 계정으로 실행하고 싶은 경우 become_user: XXX와 같이 해당 계정을 지정한다.\n그리고 ansible-playbook 실행 시 -K 혹은 --ask-become-pass 을 지정한다.\nansible-playbook test.yaml -K  Useful ansible play apt -name : install neovim apt: name: neovim force: yes state: present -name : uninstall neovim apt: name: neovim force: yes state: absent  reference  Intro to Playbooks — Ansible Documentation GitHub - ansible/ansible-examples: A few starter examples of ansible playbooks, to show features and how they work together. See http://galaxy.ansible.com for example roles from the Ansible community for deploying many popular applications.  ","id":70,"section":"posts","summary":"play The goal of a play is to map a group of hosts to some well defined roles, represented by things ansible calls tasks. At a basic level, a task is nothing more than a call to an ansible module play는 명령을 수행할 대상과 수행할 명령을 모두 포함하고 있다. playbook","tags":["ansible","ansible-playbook"],"title":"Ansible - basics of ansible-playbook","uri":"https://cychong47.github.io/2017/12/ansible-playbook/","year":"2017"},{"content":"Create inventory(Ansible hosts) file mbpr15:Homebrew cychong$ cat /etc/ansible/hosts mini1 ansible_host=x.y.z.a ansible_ssh_user=cychong ansible_ssh_port=22 mini2 ansible_host=x.y.z.b ansible_ssh_user=cychong ansible_ssh_port=22 localhost ansible_connection=local  ping ping 명령도 ansible이 제공하는 ping module을 이용하므로 -m 옵션을 사용한다.\nmbpr15:Homebrew cychong$ ansible all -m ping -k SSH password: localhost | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } mini2 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } mini1 | UNREACHABLE! =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;timed out\u0026quot;, \u0026quot;unreachable\u0026quot;: true }  ssh의 로그인 ID는 /etc/ansible/hosts에 기술하거나 명령어 옵션 —user=cychong으로 지정할 수 있다.\nshell module syntax -m MODULE_NAME -a MODULE_ARG [-u/--user] USER_ID [-sudo] 로그인 후 SUDO 권한으로 명령어 실행 [-sudo-user USER_ID] 로그인 후 특정 USER_ID 권한으로 명령어 실행 [-b] -sudo 옵션 대체 [--become-user USER_ID] -sudo-user 옵션 대체  example shell module의 명령어 df -k 실행 (df -h를 인자로 지정하면 -h가 ansible 명령의 —help 옵션으로 간주된다. 그러므로 이 경우에는 ”df -h”와 같이 따옴표로 module argument를 묶어준다)\nmbpr15:Homebrew cychong$ ansible all -m shell -a df -k SSH password: localhost | SUCCESS | rc=0 \u0026gt;\u0026gt; Filesystem 512-blocks Used Available Capacity iused ifree %iused Mounted on /dev/disk1s1 976490568 573048520 388412536 60% 1229764 9223372036853546043 0% / devfs 395 395 0 100% 684 0 100% /dev /dev/disk1s4 976490568 12582968 388412536 4% 6 9223372036854775801 0% /private/var/vm map -hosts 0 0 0 100% 0 0 100% /net map auto_home 0 0 0 100% 0 0 100% /home //cychong@DISKSTATION._afpovertcp._tcp.local/Shelter 7681886800 4548217416 3133669384 60% 568527175 391708673 59% /Volumes/Shelter //cychong@DISKSTATION._afpovertcp._tcp.local/media 1220947280 966911944 254035336 80% 120863991 31754417 79% /Volumes/media //cychong@DISKSTATION._afpovertcp._tcp.local/video 7681886800 4548217416 3133669384 60% 568527175 391708673 59% /Volumes/video //com.apple.idms.appleid.prd.4758655770614553526e3849724845577074615846773d3d@mini2._smb._tcp.local/cychong 249660000 199914656 49745344 81% 24989330 6218168 80% /Volumes/cychong mini2 | SUCCESS | rc=0 \u0026gt;\u0026gt; Filesystem 512-blocks Used Available Capacity iused ifree %iused Mounted on /dev/disk2s1 249660000 198640784 49745232 80% 1226230 9223372036853549577 0% / devfs 393 393 0 100% 682 0 100% /dev /dev/disk2s4 249660000 48 49745232 1% 0 9223372036854775807 0% /private/var/vm /dev/disk3s2 233769824 142965688 90804136 62% 757164 4294210115 0% /Volumes/120G /dev/disk1s2 1951845728 1515454904 436390824 78% 460710 4294506569 0% /Volumes/data map -hosts 0 0 0 100% 0 0 100% /net map auto_home 0 0 0 100% 0 0 100% /home map -fstab 0 0 0 100% 0 0 100% /Network/Servers /dev/disk4s2 976101344 523330000 452771344 54% 1596 4294965683 0% /Volumes/500G  copy module Target host 들에게 파일을 보내는 경우(put)\nmbpr15:Homebrew cychong$ ansible all -m copy -a \u0026quot;src=~/.vimrc dest=/tmp\u0026quot; localhost | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;checksum\u0026quot;: \u0026quot;052ddf17cff54f1fb8231c7a5930be30756456d3\u0026quot;, \u0026quot;dest\u0026quot;: \u0026quot;/tmp/.vimrc\u0026quot;, \u0026quot;gid\u0026quot;: 20, \u0026quot;group\u0026quot;: \u0026quot;staff\u0026quot;, \u0026quot;md5sum\u0026quot;: \u0026quot;f11f67ca155917ae34e4a459b2603562\u0026quot;, \u0026quot;mode\u0026quot;: \u0026quot;0644\u0026quot;, \u0026quot;owner\u0026quot;: \u0026quot;cychong\u0026quot;, \u0026quot;size\u0026quot;: 28, \u0026quot;src\u0026quot;: \u0026quot;/Users/cychong/.ansible/tmp/ansible-tmp-1514382698.5150971-237795226033898/source\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;file\u0026quot;, \u0026quot;uid\u0026quot;: 501 } mini2 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;checksum\u0026quot;: \u0026quot;052ddf17cff54f1fb8231c7a5930be30756456d3\u0026quot;, \u0026quot;dest\u0026quot;: \u0026quot;/tmp/.vimrc\u0026quot;, \u0026quot;gid\u0026quot;: 20, \u0026quot;group\u0026quot;: \u0026quot;staff\u0026quot;, \u0026quot;md5sum\u0026quot;: \u0026quot;f11f67ca155917ae34e4a459b2603562\u0026quot;, \u0026quot;mode\u0026quot;: \u0026quot;0644\u0026quot;, \u0026quot;owner\u0026quot;: \u0026quot;cychong\u0026quot;, \u0026quot;size\u0026quot;: 28, \u0026quot;src\u0026quot;: \u0026quot;/Users/cychong/.ansible/tmp/ansible-tmp-1514382698.5150971-84669710159236/source\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;file\u0026quot;, \u0026quot;uid\u0026quot;: 501 }  제대로 복사 되었는지 확인\nmbpr15:Homebrew cychong$ ansible all -m shell -a \u0026quot;ls -al /tmp/.vimrc\u0026quot; localhost | SUCCESS | rc=0 \u0026gt;\u0026gt; -rw-r--r-- 1 cychong staff 28 Dec 27 22:51 /tmp/.vimrc mini2 | SUCCESS | rc=0 \u0026gt;\u0026gt; -rw-r--r-- 1 cychong staff 28 Dec 27 22:51 /tmp/.vimrc  지원되는 모듈 Module Index — Ansible Documentation에서 참고\n  pip - Manages Python library dependencies. — Ansible Documentation\n  apt - Manages apt-packages — Ansible Documentation\n  homebrew - Package manager for Homebrew — Ansible Documentation\n  yum - Manages packages with the yum package manager — Ansible Documentation\n  at - Schedule the execution of a command or script file via the at command. — Ansible Documentation\n  ping - Try to connect to host, verify a usable python and return pong on success — Ansible Documentation\n  Files Modules — Ansible Documentation archive, copy, fetch, file, find, patch, replace, stat, temple, template, unarchive,\n  pause - Pause playbook execution — Ansible Documentation\n  wait_for - Waits for a condition before continuing — Ansible Documentation\n  wait_for_connection - Waits until remote system is reachable/usable — Ansible Documentation\n  Commands Modules — Ansible Documentation command, expect, raw, script, shell, telnet\n  Monitoring Modules — Ansible Documentation 몇가지 모니터링 툴(datadog, logstash, nagios, sensu, zabbix 등)\n  netconf_config - netconf device configuration — Ansible Documentation ncclient를 이용해서 Netconf 명령을 내리는 듯.\n  Database Modules — Ansible Documentation - influxes, elasticsearch, redis, kibana, mongodb, mysql, postgresql,\n  Network Modules — Ansible Documentation 이 정도로 원격으로 제어할 수 있도록 module이 제공되면 편할 듯. ONAP에서 원하는 게 이런 정도의 정리인 듯\n  Clustering Modules — Ansible Documentation consul, kubernetes\n  ","id":71,"section":"posts","summary":"Create inventory(Ansible hosts) file mbpr15:Homebrew cychong$ cat /etc/ansible/hosts mini1 ansible_host=x.y.z.a ansible_ssh_user=cychong ansible_ssh_port=22 mini2 ansible_host=x.y.z.b ansible_ssh_user=cychong ansible_ssh_port=22 localhost ansible_connection=local ping ping 명령도 ansible이 제공하는 ping module을 이용하므로 -m 옵션을 사용한다. mbpr15:Homebrew cychong$ ansible all -m ping -k SSH password: localhost | SUCCESS =\u0026gt;","tags":["ansible","tutorial"],"title":"Ansible - ad-hoc or basic","uri":"https://cychong47.github.io/2017/12/ansible-exercise-1/","year":"2017"},{"content":"Summary docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql docker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress  If required, import database to mysql (Once wordpress data is imported into mysql, upgrading mysql does not requires re-import ingof wordpress data)\nmysql install container cychong:~ cychong$ docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql Unable to find image 'mysql:latest' locally latest: Pulling from library/mysql aa18ad1a0d33: Pull complete a5745c3b8bcc: Pull complete 76375fcd129c: Pull complete 4f72cfb004cf: Pull complete 1d6a01e515fb: Pull complete a71e1163fa7e: Pull complete 8c1a568fa442: Pull complete e7a69cecc173: Pull complete 9759a0f979a1: Pull complete 3f71dac6110f: Pull complete 58f37de54392: Pull complete Digest: sha256:790b7b18b832822ef400e44ad9fac885a746db1a7028ec52325730cf9b831753 Status: Downloaded newer image for mysql:latest b1f54c680120898fc7ff16751048fe18ae461399d5d7f10308c156c68d40577b  check container is started cychong:~ cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b1f54c680120 mysql \u0026quot;docker-entrypoint...\u0026quot; 13 seconds ago Up 10 seconds 3306/tcp mysql dea965b550e6 ghost:latest \u0026quot;docker-entrypoint...\u0026quot; 8 days ago Up 8 days 0.0.0.0:2368-\u0026gt;2368/tcp ghost  check files are located where volume is mounted cychong:~/Dropbox/Apps/wordpress/database cychong$ ls auto.cnf\tib_buffer_pool\tmysql\tserver-key.pem ca-key.pem\tib_logfile0\tperformance_schema\tsys ca.pem\tib_logfile1\tprivate_key.pem\twordpress_db client-cert.pem\tibdata1\tpublic_key.pem client-key.pem\tibtmp1\tserver-cert.pem  wordpress install container cychong:~ cychong$ docker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress 525ba1e4fff2caccc020960908e4f538be9512c2541e62a94c5a36a341e7ff3c cychong:~ cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 525ba1e4fff2 wordpress \u0026quot;docker-entrypoint...\u0026quot; 44 seconds ago Up 42 seconds 0.0.0.0:80-\u0026gt;80/tcp wpcontainer b1f54c680120 mysql \u0026quot;docker-entrypoint...\u0026quot; 11 minutes ago Up 11 minutes 3306/tcp mysql dea965b550e6 ghost:latest \u0026quot;docker-entrypoint...\u0026quot; 8 days ago Up 8 days 0.0.0.0:2368-\u0026gt;2368/tcp ghost  check containers cychong:~ cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8ea2303518ad wordpress \u0026quot;docker-entrypoint...\u0026quot; About a minute ago Up About a minute 0.0.0.0:80-\u0026gt;80/tcp wpcontainer b1f54c680120 mysql \u0026quot;docker-entrypoint...\u0026quot; 3 minutes ago Up 3 minutes 3306/tcp mysql dea965b550e6 ghost:latest \u0026quot;docker-entrypoint...\u0026quot; 8 days ago Up 8 days 0.0.0.0:2368-\u0026gt;2368/tcp ghost  check files cychong:~ cychong$ ls Documents/wordpress/html/ index.php\twp-admin\twp-config.php\twp-links-opml.php\twp-settings.php license.txt\twp-blog-header.php\twp-content\twp-load.php\twp-signup.php readme.html\twp-comments-post.php\twp-cron.php\twp-login.php\twp-trackback.php wp-activate.php\twp-config-sample.php\twp-includes\twp-mail.php\txmlrpc.php  mysql dump data is not imported. copy mysql dump file to mounted volume directory\ncychong:~ cychong$ cp wordpress.dump.0910 ~/Dropbox/Apps/wordpress/database  Login to mysql container\ncychong:~ cychong$ docker exec -ti b1f54c680120 bash root@b1f54c680120:/# ls bin boot dev\tdocker-entrypoint-initdb.d entrypoint.sh etc\thome lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@b1f54c680120:/# cd /var/lib/mysql root@b1f54c680120:/var/lib/mysql# ls auto.cnf client-cert.pem ib_logfile0 ibtmp1\tprivate_key.pem server-key.pem\twordpress_db ca-key.pem client-key.pem ib_logfile1 mysql\tpublic_key.pem sys ca.pem\tib_buffer_pool ibdata1\tperformance_schema server-cert.pem wordpress.dump.0910  Import mysql dump file to mysql db\nroot@b1f54c680120:/var/lib/mysql# mysql -h localhost -u root -p wordpress_db \u0026lt; wordpress.dump.0910 Enter password: root@b1f54c680120:/var/lib/mysql#  This should be from the DB schema. Still don\u0026rsquo;t know if data is imported properly\nroot@b1f54c680120:/var/lib/mysql# mysqlshow -u root -p wordpress_db Enter password: Database: wordpress_db +-----------------------+ | Tables | +-----------------------+ | wp_commentmeta | | wp_comments | | wp_links | | wp_options | | wp_postmeta | | wp_posts | | wp_term_relationships | | wp_term_taxonomy | | wp_termmeta | | wp_terms | | wp_usermeta | | wp_users | +-----------------------+  Install jetpack And enable markdown from Jetpack Setting \u0026gt; Writing\nDone\n#wordpress #docker\n","id":72,"section":"posts","summary":"Summary docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql docker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress  If required, import database to mysql (Once wordpress data is imported into mysql, upgrading mysql does not requires re-import ingof wordpress data)\nmysql install container cychong:~ cychong$ docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql Unable to find image 'mysql:latest' locally latest: Pulling from library/mysql aa18ad1a0d33: Pull complete a5745c3b8bcc: Pull complete 76375fcd129c: Pull complete 4f72cfb004cf: Pull complete 1d6a01e515fb: Pull complete a71e1163fa7e: Pull complete 8c1a568fa442: Pull complete e7a69cecc173: Pull complete 9759a0f979a1: Pull complete 3f71dac6110f: Pull complete 58f37de54392: Pull complete Digest: sha256:790b7b18b832822ef400e44ad9fac885a746db1a7028ec52325730cf9b831753 Status: Downloaded newer image for mysql:latest b1f54c680120898fc7ff16751048fe18ae461399d5d7f10308c156c68d40577b  check container is started cychong:~ cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b1f54c680120 mysql \u0026quot;docker-entrypoint.","tags":["docker","container","wordpress","mysql"],"title":"Install Wordpress with docker","uri":"https://cychong47.github.io/2017/12/install-wordpress-with-docker/","year":"2017"},{"content":"pip3로는 설치가 안되네\nmbpr15:~ cychong$ pip3 install clientBBS Collecting clientBBS Could not find a version that satisfies the requirement clientBBS (from versions: ) No matching distribution found for clientBBS  그래서 그냥 github 링크에서 클론해서 실행\nmbpr15:working cychong$ git clone https://github.com/liza183/clienBBS.git Cloning into 'clienBBS'... remote: Counting objects: 219, done. remote: Compressing objects: 100% (25/25), done. remote: Total 219 (delta 20), reused 23 (delta 9), pack-reused 185 Receiving objects: 100% (219/219), 33.96 MiB | 3.84 MiB/s, done. Resolving deltas: 100% (122/122), done.  실행해 보자\nmbpr15:working cychong$ cd clienBBS/ mbpr15:clienBBS cychong$ python3 clien.py Traceback (most recent call last): File \u0026quot;clien.py\u0026quot;, line 2, in \u0026lt;module\u0026gt; import urllib3  의존성을 가진 모듈들을 설치해야 하는 구나. 대부분 많이 사용하는 기본 모듈이긴 한데 python2에서 사용하는 이름하고 조금 다르네\npip3 install urllib3 pip3 install requests pip3 install BeautifulSoup4 pip3 install pillow pip3 install lxml   클리앙 개편에 맞추어 PC통신 느낌으로 클리앙 사용하는 clienBBS 업뎃 v0.32 https://github.com/liza183/clienBBS  ","id":73,"section":"posts","summary":"pip3로는 설치가 안되네 mbpr15:~ cychong$ pip3 install clientBBS Collecting clientBBS Could not find a version that satisfies the requirement clientBBS (from versions: ) No matching distribution found for clientBBS 그래서 그냥 github 링크에서 클론해서 실행 mbpr15:working cychong$ git clone https://github.com/liza183/clienBBS.git Cloning into 'clienBBS'... remote: Counting objects: 219, done. remote: Compressing objects:","tags":[],"title":"clienBBS","uri":"https://cychong47.github.io/2017/12/clienbbs/","year":"2017"},{"content":"mac mini 2009에 windows 10을 무사히 설치.\n몇 가지 삽질을 적어보면\n  mac mini는 windows 7까지만 지원하고, optic drive를 이용한 설치만 지원하기 때문에 그냥(?) 해서는 windows 10을 설치할 수 없음. 이를 해결하려면 Applications/Utilities에 있는 Boot camp assistant 앱을 복사해서 Contents 디렉토리에 있는 Info.plist 파일 내용을 수정해야 함. 대충 보면 Win7OnlyModels 하는 부분이랑 USBBootSupportedModels 부분을 아예 삭제하면 된다.\n  Boot camp를 실행시켜 windows partition을 나누려고 했는데 이상하게 3조각으로 나뉘어지면서 윈도10용 설치 파티션을 만들 수 없다고 해서 결국 엘케피탄 설치 파일을 이용해서 다시 설치. 이 과정에서 이미 app store에서 숨겨진 El capitan 용 설치 SW 받기 위해 mas-cli라는 유틸리티를 알게 되서 활용(백투더맥 쵝오!)\n  OSX 새로 설치한 후 boot camp 수정해서 설치를 진행하는데 이번엔 윈도 설치 과정에서 boot camp가 만들어 넣은 파티션에 설치를 못하겠다고 반항. 한번 실패하면 그냥 맥 리붓 후 alt 키로 부팅 매체 선택해서는 윈도 설치 과정이 제대로 실행되지 않아 다시 맥으로 부팅한 후 boot camp를 통해 다시 disk partition을 하나로 뭉쳤다 다시 분할해서 리붓이 되어야 제대로 윈도 부팅 화면으로 넘어감. 그런데 역시 다시 시도해도 윈도 파티션에 윈도를 설치하지 못하겠다는.\n  클리앙에 질문을 올렸더니 USB에 연결된 거 다 빼보라고. 혹시나 하고 따라했는데 정말로 한방에 설치 진행. El capitan 다시 설치하느라 끼워둔 OS X 설치 USB때문이었다는.\n  다 설치하고 나니 2009년 mac mini - Core2Duo 2Ghz, 4GB RAM, 120GB SSD인데 회사 컴퓨터보다 빠른 것 같은 착각이 막 든다. 반응성도 전혀 문제 없고(하긴 설치한 게 없으니) 은행용으로만 딱 쓸거라.\n  이제 고민은 윈도 10용 라이센스를 살 것인가 아니면 HP mini PC에 SSD를 설치해서 사용할 것인가. 후자는 Windows 10 Pro 라이센스가 포함된 제품이라 SSD 7만원 투자하면 될 것 같은데 전자는?\n  일단 예전에 어디 대란일때 사 둔 윈도 라이센스를 한번 적용해 볼까 싶은데\n  ","id":74,"section":"posts","summary":"mac mini 2009에 windows 10을 무사히 설치. 몇 가지 삽질을 적어보면 mac mini는 windows 7까지만 지원하고, optic drive를 이용한 설치만 지원하기 때문에 그냥(?) 해서","tags":["Mac mini 2009","windows10"],"title":"mac mini 에 windows 10 설치","uri":"https://cychong47.github.io/2017/12/mac-mini-e-windows-10-seolci/","year":"2017"},{"content":"Vagrant What is a Vagrant? Backend에 virtualbox를 사용(변경 가능) 하고, virtualbox를 이용해 VM을 생성하여 그 VM 내 원하는 환경(특정 OS부터 특정 library까지) 을 구성함.\n예전에 fd.io에서 빌드하는 vpp 개발 환경이 vagrant로 되어 있었는데 왜 그런가 싶었는데 이제 생각해 보니 vpp 동작에 필요한 OS, kernel module, DPDK SDK 와 패치 들 그리고 vpp code 까지 모든 걸 제어할 수 있도록 VagrantFile을 만들어서 개발 환경을 표준화하려는 것 이었다는.\nContainer와 달리 독립된 OS환경을 가질 수 있으므로 OS버전이 다르거나 , 커널 모듈 수정 등을 필요로 한 경우에 유용할 듯\nVirtualbox가 생각보다 가벼워서 유용한 듯 하다.\nVagrantFile을 이용해서 vagrant up한 후 vagrant box list로 생성된 VM instance 들을 확인한 후 vagrant ssh VM_NAME하면 해당 VM으로 접속. 그러므로 미리 VagrantFile을 통해 지정한 환경이 모두 구성되어 있다는.\nDocker와 유사하게 host와 volume을 공유할 수 있음.(이건 그냥 virtualbox가 지원하는 shared folder 기능을 활용하는 듯)\n그 외 사용 측면에서는 docker나 virsh 명령어 사용하는 것과 유사.\nInstall Vagrant on OS X mbpr15:~ cychong$ brew cask install vagrant ==\u0026gt; Satisfying dependencies ==\u0026gt; Downloading https://releases.hashicorp.com/vagrant/2.0.1/vagrant_2.0.1_x86_64.dmg ######################################################################## 100.0% ==\u0026gt; Verifying checksum for Cask vagrant ==\u0026gt; Installing Cask vagrant ==\u0026gt; Running installer for vagrant; your password may be necessary. ==\u0026gt; Package installers may write to any location; options such as --appdir are ignored. Password: ==\u0026gt; installer: Package name is Vagrant ==\u0026gt; installer: Installing at base path / ==\u0026gt; installer: The install was successful. 🍺 vagrant was successfully installed!  Install vagrant-manager additionally\nmbpr15:~ cychong$ brew cask install vagrant-manager ==\u0026gt; Satisfying dependencies ==\u0026gt; Downloading https://github.com/lanayotech/vagrant-manager/releases/download/2.6.0/vagrant-manager-2.6.0.dmg ######################################################################## 100.0% ==\u0026gt; Verifying checksum for Cask vagrant-manager ==\u0026gt; Installing Cask vagrant-manager ==\u0026gt; Moving App 'Vagrant Manager.app' to '/Applications/Vagrant Manager.app'. 🍺 vagrant-manager was successfully installed!  Install Vagrant Box Virtualbox is already installed\nAdd Vagrant box which can be found from Vagrant Cloud\nmbpr15:~ cychong$ vagrant box add ubuntu/xenial64 https://app.vagrantup.com/ubuntu/boxes/xenial64 ==\u0026gt; box: Loading metadata for box 'https://app.vagrantup.com/ubuntu/boxes/xenial64' ==\u0026gt; box: Adding box 'ubuntu/xenial64' (v20171122.0.0) for provider: virtualbox box: Downloading: https://vagrantcloud.com/ubuntu/boxes/xenial64/versions/20171122.0.0/providers/virtualbox.box ==\u0026gt; box: Successfully added box 'ubuntu/xenial64' (v20171122.0.0) for 'virtualbox'!  Initialize Vagrant mbpr15:~ cychong$ cd /Users/cychong/Public/working mbpr15:working cychong$ vagrant init ubuntu/xenial64 A `Vagrantfile` has been placed in this directory. You are now ready to `vagrant up` your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on `vagrantup.com` for more information on using Vagrant.  Start Vagrant It takes some time\nmbpr15:working cychong$ vagrant up Bringing machine 'default' up with 'virtualbox' provider... ==\u0026gt; default: Importing base box 'ubuntu/xenial64'... ==\u0026gt; default: Matching MAC address for NAT networking... ==\u0026gt; default: Checking if box 'ubuntu/xenial64' is up to date... ==\u0026gt; default: Setting the name of the VM: working_default_1511385943610_77718 ==\u0026gt; default: Clearing any previously set network interfaces... ==\u0026gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==\u0026gt; default: Forwarding ports... default: 22 (guest) =\u0026gt; 2222 (host) (adapter 1) ==\u0026gt; default: Running 'pre-boot' VM customizations... ==\u0026gt; default: Booting VM... ==\u0026gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: ubuntu default: SSH auth method: password default: Warning: Connection reset. Retrying... default: Warning: Remote connection disconnect. Retrying... default: Warning: Connection reset. Retrying... default: Warning: Remote connection disconnect. Retrying... default: Warning: Connection reset. Retrying... default: Warning: Remote connection disconnect. Retrying... default: default: Inserting generated public key within guest... default: Removing insecure key from the guest if it's present... default: Key inserted! Disconnecting and reconnecting using new SSH key... ==\u0026gt; default: Machine booted and ready! ==\u0026gt; default: Checking for guest additions in VM... default: The guest additions on this VM do not match the installed version of default: VirtualBox! In most cases this is fine, but in rare cases it can default: prevent things such as shared folders from working properly. If you see default: shared folder errors, please make sure the guest additions within the default: virtual machine match the version of VirtualBox you have installed on default: your host and reload your VM. default: default: Guest Additions Version: 5.0.40 default: VirtualBox Version: 5.2 ==\u0026gt; default: Mounting shared folders... default: /vagrant =\u0026gt; /Users/cychong/Public/working  Login to Vagrant VM mbpr15:working cychong$ vagrant ssh Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-101-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage Get cloud support with Ubuntu Advantage Cloud Guest: http://www.ubuntu.com/business/services/cloud 0 packages can be updated. 0 updates are security updates. _____________________________________________________________________ WARNING! Your environment specifies an invalid locale. The unknown environment variables are: LC_CTYPE=UTF-8 LC_ALL= This can affect your user experience significantly, including the ability to manage packages. You may install the locales by running: sudo apt-get install language-pack-UTF-8 or sudo locale-gen UTF-8 To see all available language packs, run: apt-cache search \u0026quot;^language-pack-[a-z][a-z]$\u0026quot; To disable this message for all users, run: sudo touch /var/lib/cloud/instance/locale-check.skip _____________________________________________________________________ ubuntu@ubuntu-xenial:~$ df -h Filesystem Size Used Avail Use% Mounted on udev 490M 0 490M 0% /dev tmpfs 100M 3.1M 97M 4% /run /dev/sda1 9.7G 858M 8.8G 9% / tmpfs 497M 0 497M 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 497M 0 497M 0% /sys/fs/cgroup vagrant 466G 269G 197G 58% /vagrant tmpfs 100M 0 100M 0% /run/user/1000  /vagrant directory This directory is used to shared files between the host and VM and the size of this partition is same to the storage of host machine\nmbpr15:working cychong$ df -h . Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk1s1 466Gi 265Gi 197Gi 58% 1137732 9223372036853638075 0% /  install tools as usual linux box ubuntu@ubuntu-xenial:/vagrant$ sudo apt install gcc Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: binutils cpp cpp-5 gcc-5 libasan2 libatomic1 libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libgcc-5-dev libgomp1 libisl15 libitm1 liblsan0 libmpc3 libmpx0 libquadmath0 libtsan0 libubsan0 linux-libc-dev manpages-dev Suggested packages: binutils-doc cpp-doc gcc-5-locales gcc-multilib make autoconf automake libtool flex bison gdb gcc-doc gcc-5-multilib gcc-5-doc libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan2-dbg liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx0-dbg libquadmath0-dbg glibc-doc The following NEW packages will be installed: binutils cpp cpp-5 gcc gcc-5 libasan2 libatomic1 libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libgcc-5-dev libgomp1 libisl15 libitm1 liblsan0 libmpc3 libmpx0 libquadmath0 libtsan0 libubsan0 linux-libc-dev manpages-dev 0 upgraded, 23 newly installed, 0 to remove and 0 not upgraded. Need to get 27.6 MB of archives. After this operation, 99.7 MB of additional disk space will be used. Do you want to continue? [Y/n] y Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 libmpc3 amd64 1.0.3-1 [39.7 kB] Get:2 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 binutils amd64 2.26.1-1ubuntu1~16.04.5 [2311 kB] Get:3 http://archive.ubuntu.com/ubuntu xenial/main amd64 libisl15 amd64 0.16.1-1 [524 kB] Get:4 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 cpp-5 amd64 5.4.0-6ubuntu1~16.04.5 [7786 kB] ... Processing triggers for libc-bin (2.23-0ubuntu9) ... ubuntu@ubuntu-xenial:/vagrant$  No need to install Linux manually The Ubuntu is installed manually and the second working_default_xfasfa is installed with Vagrant.\nIn summary brew cask install vagrant brew cask install vagrant-manager vagrant box add ubuntu/xenial64 https://app.vagrantup.com/ubuntu/boxes/xenial64 cd /Users/cychong/Public/working vagrant init ubuntu/xenial64 vagrant up vagrant ssh  reference  Vagrant | Mac OS X Setup Guide VirtualBox와 Vagrant의 기본 사용법 - 나만모르는 이야기 RORLAB | rBlog : Vagrant를 이용한 손쉬운 개발환경 구축  #vagrant #TIL\n","id":75,"section":"posts","summary":"Vagrant What is a Vagrant? Backend에 virtualbox를 사용(변경 가능) 하고, virtualbox를 이용해 VM을 생성하여 그 VM 내 원하는 환경(특정 OS부","tags":["vagrant","til"],"title":"Vagrant","uri":"https://cychong47.github.io/2017/11/vagrant-2/","year":"2017"},{"content":"From Amdocs Preps \u0026lsquo;Carrier-Grade\u0026rsquo; Version of ONAP | Light Reading(http://www.lightreading.com/mobile/mec-(mobile-edge-computing)/amdocs-preps-carrier-grade-version-of-onap/d/d-id/738315)\n \u0026ldquo;We\u0026rsquo;re just about to make a big carrier [and] enterprise grade release of ONAP,\u0026rdquo; Angela Logothetis, VP and CTO of Amdocs Open Network, told Light Reading\n  Logothetis says that Amdocs is working with Intel Corp. (Nasdaq: INTC) on edge computing proofs-of-concept. This involves understanding what content and data needs to cached and where exactly that should happen on the network.\n Amdoc 이 MEC에 관심을 갖고 있다. 어떤 의미일까? MEC에 올라가는 SW에 대한 platform을 제공하려는 걸까?\n \u0026ldquo;That\u0026rsquo;s an easy place to start,\u0026rdquo; Logothetis suggested, while noting the irony that standards around the 5G core are probably the \u0026ldquo;least defined\u0026rdquo; of the next-gen specification, because the 3rd Generation Partnership Project (3GPP) typically focuses on the radio access network (RAN).\n ONAP Use case(in Amsterdam release) 는 Core 기반의 서비스가 많다고. 5G는 RAN에 대한 내용이 많은데. Core 기반으로 ONAP use case를 하기 쉬운 이유가 뭘까?\n​\n Logothetis says that amongst the next important task for the ONAP Project, which now numbers nearly 20 major global service providers and vendors among its members, is to understand AI. \u0026ldquo;The next interesting thing that comes around is artificial Intelligence and machine learning, which is new for all of us,\u0026rdquo; she said.\n 역시 관심은 AI 와 ML 겸손(?)하게 자신들을 포함한 많은 SP들에게 새로운 분야라고.\n The company is also looking at cloud RAN, which involves having virtualized basestation control functions running at the data center controlling distributed radioheads at the cellsite, and virtualized RAN. V-RAN involves \u0026ldquo;disaggregation\u0026rdquo; of the radio network, with some antenna functions eventually being run on white boxes at the cellsite.\n VRAN에 대해 Amdocs는 어떤 관심을 갖고 있는 걸까? Control function의 base를 ONAP으로 구현하려고? 아니면 Data center와 cell site등에 퍼져있는 다양한 장비를 관리하는 management system을 ONAP으로 만들려고?\n​ #amdocs #onap #edge #mec #vran\n","id":76,"section":"posts","summary":"From Amdocs Preps \u0026lsquo;Carrier-Grade\u0026rsquo; Version of ONAP | Light Reading(http://www.lightreading.com/mobile/mec-(mobile-edge-computing)/amdocs-preps-carrier-grade-version-of-onap/d/d-id/738315) \u0026ldquo;We\u0026rsquo;re just about to make a big carrier [and] enterprise grade release of ONAP,\u0026rdquo; Angela Logothetis, VP and CTO of Amdocs Open Network, told Light Reading Logothetis says that Amdocs is working with Intel Corp. (Nasdaq: INTC) on edge computing proofs-of-concept. This involves understanding what content and data needs to cached and where exactly that should happen on the network.","tags":["onap","amdocs","edge","mec","vran"],"title":"Amdocs Preps 'Carrier-Grade' Version of ONAP","uri":"https://cychong47.github.io/2017/11/amdocs-preps-carrier-grade-version-of-onap/","year":"2017"},{"content":"1st release Amsterdam release which is due to November 16\nCritics  It will not be stable enough to be used for product\n misunderstanding  That release will focus on providing support for three network functions or services \u0026ndash; a virtual firewall (vFW), virtual customer premises equipment (vCPE) and a voice-over-LTE service running on a virtual evolved packet core (vEPC)\n I think this is a misunderstanding. These are just an use case not the ONAP supports them only. Maybe that can be interpreted ONAP is verified for this cases. But still it does not mean ONAP supports only them\nBCE(Toronto)  As a member of ONAP, we look forward to working with our international partners to begin the implementation of Version 1 later this year. That Operations Manager should support the deployment, management and operation of the ONAP platform and its component parts. It could feature in Release 2, codenamed Beijing and set to appear on May 24 next year.\n ONAP Platform 자체를 쉽게 설치하고 관리할 수 있는 OOM에 대한 관심이 높음. OOM : ONAP Operations Manager\nEquinix - colocation service provider  While we have no immediate plans to use the upcoming first release in production,\n (original news](http://www.lightreading.com/open-source/industry-bodies-groups/onap-takes-flak-as-telcos-prep-for-release-1/d/d-id/737906)\n","id":77,"section":"posts","summary":"1st release Amsterdam release which is due to November 16 Critics It will not be stable enough to be used for product misunderstanding That release will focus on providing support for three network functions or services \u0026ndash; a virtual firewall (vFW), virtual customer premises equipment (vCPE) and a voice-over-LTE service running on a virtual evolved packet core (vEPC) I think this is a misunderstanding. These are just an use case","tags":["onap","Amsterdam release"],"title":"ONAP Takes Flak as Telcos Prep for Release 1 | Light Reading","uri":"https://cychong47.github.io/2017/11/onap-takes-flak-as-telcos-prep-for-release-1-light-reading/","year":"2017"},{"content":"book from Amazon\n","id":78,"section":"posts","summary":"book from Amazon","tags":[],"title":"Lead Follow or Get Out of the Way","uri":"https://cychong47.github.io/2017/10/lead-or-step-aside/","year":"2017"},{"content":"구글이 연구한 \u0026lsquo;좋은 관리자가 가져야 할 8가지 덕목\u0026rsquo;.\n 좋은 코치(coaches)다. 팀에게 권한을 양도하며 마이크로매니지를 하지 않는다. 팀원의 성공에 관심을 표명하며 개인적 삶에도 관심을 기울인다. 생산적이며 결과를 중심으로 사고한다. 훌륭한 커뮤니케이션 능력을 가지고 있다. 팀원들이 경력을 키워나가도록 도움을 준다. 팀을 위한 명확한 비전을 가지고 있다. 팀에게 조언을 해주기에 충분한 기술적인 능력을 갖추고 있다.  하나 하나 절대 쉬운 일이 없다.\n구글이 제시한 \u0026lsquo;관리자의 자격\u0026rsquo; .\n","id":79,"section":"posts","summary":"구글이 연구한 \u0026lsquo;좋은 관리자가 가져야 할 8가지 덕목\u0026rsquo;. 좋은 코치(coaches)다. 팀에게 권한을 양도하며 마이크로매니지를 하","tags":["manager"],"title":"관리자는 '관리'업무를 하는 동료이다.","uri":"https://cychong47.github.io/2017/10/what-is-good-manager/","year":"2017"},{"content":"Purpose 매일 낮 11시 부터 1시간 동안 CBS 뮤직 FM에서 진행되는 신영음을 듣고 싶다. 아주 오래 전 가장 좋아했던 라디어 프로가 정은임씨가 진행하던 영화음악 이었는데 한참 후에 알게된 신영음을 통해 내가 좋아하는 영화음악을 다시 들을 수 있게 되었다. 문제는 라디오 방송 시간. 어디서든 CBS FM 라디오를 들을 수 있는 공식 레인보우앱 이나 myTuner Pro 같은 앱을 쓰면 들을 수 있지만, 근무시간에 라디오를 듣기도 그렇고, 결정적으로 11시 30분에서 12시 사이에 점심 시간이 시작되어 제대로 듣기가 힘들었다.\n이를 해결(?)하기 위해 그냥 스트리밍을 녹음해서 듣는 걸로\nStep 1 - Find out the streaming URL 마이너 라디오 방송이라 그런지 의외로 streaming 주소가 쉽게 찾아지지 않았다. 그래도 myTuner Pro앱이나 Korea onAir 같은 OS X용 앱에서도 CBS를 들을 수 있는 걸 보면 분명히 어딘가에는 스트리밍 주소가 있을 거라는 생각에 찾다 드디어 제대로 동작하는 스트리밍 주소를 찾을 수 있었다.\nhttp://aac.cbs.co.kr/cbs939/_definst_/cbs939.stream/playlist.m3u8  Step 2 - register recording task to launchd crond를 사용해서 매일 오전 11시 부터 녹음되도록 할까 했는데 OS X에서는 crond를 대체하는 launchd를 사용하는 게 낫다는 글을 보고 한번 해보기로 했다.\n비교적 간단(?)하게 원하는 내용을 설정할 수 있는 crond와 달리 launchd는 plist 파일을 이용해서 원하는 작업을 정의해야 한다고 한다.\ncychong.record.plist file\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026quot;-//Apple Computer//DTD PLIST 1.0//EN\u0026quot; \u0026quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026quot;\u0026gt; \u0026lt;plist version=\u0026quot;1.0\u0026quot;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;cychong.record.cbs\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/Users/cychong/Dropbox/working/mp3/record.py\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;key\u0026gt;StartCalendarInterval\u0026lt;/key\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Hour\u0026lt;/key\u0026gt; \u0026lt;integer\u0026gt;10\u0026lt;/integer\u0026gt; \u0026lt;key\u0026gt;Minute\u0026lt;/key\u0026gt; \u0026lt;integer\u0026gt;57\u0026lt;/integer\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt;  이제 launchctl을 이용해 위 plist 파일을 등록한다.\n$ launchctl load cychong.record.cbs.plist  제대로 등록되었는 지 확인은 아래 명령어를 이용\nmbpr15:mp3 cychong$ launchctl list |grep cychong -\t0\tcychong.record.cbs  실제로 지정된 시간(11시 3분 전)에 실행되도록 한 script는 아래와 같다.\n#!/usr/bin/env python import os from time import localtime, strftime filename = strftime(\u0026quot;cbs_cinema_%Y%M%d.mp3\u0026quot;, localtime()) os.system(\u0026quot;/usr/local/bin/ffmpeg -y -t 3605 -i http://aac.cbs.co.kr/cbs939/_definst_/cbs939.stream/playlist.m3u8 /Users/cychong/Dropbox/working/mp3/%s\u0026quot; %filename)  생성된 파일 크기 size= 938kB time=00:01:00.00 bitrate= 128.1kbits/s speed=1.98x  ffmpeg이 출력하는 정보를 보면 128.1kbps이므로 1분당 960.75KB(128.1/8*60) 의 파일 생성. 1시간 짜리를 녹음하면 대략 58MB정도의 파일을 생성할 수 있다.\n처음에는 podcast에 등록해서 매일 저녁에 자동으로 그날 녹음한 파일을 폰에 다운로드 받게 할까 했는데 파일 크기가 크지 않아 그냥 dropbox에 저장되도록 하고 dropbox app을 이용해서 들어보려고 한다.\nHow about mms streaming? It is not clear whether ffmpeg support the recording mms streaming. I recommend to check mimms\nbrew install mimms  mimms -t 60 mms://STREAMING_ADDRESS  Something is wrong 실제 사용해 보니 이상하게 mp3 파일이 1시간 짜리 58MB가 아니라 1.2MB 정도만 만들어지고 만다. 혹시나 해서 예약 시간을 옮겨서 눈을 부릅뜨고 실험해 봐도 정상적으로 동작하는데. 녹음된 1분 가량의 분량은 정상적으로 재생되는데.\n뭘까 뭘까 하다 든 생각이 power-saving. launchd를 통해 녹음 작업을 등록한 머신은 정상적으로 power-saving 기능이 기본 설정되어 있어 혹시 이와 관련된 게 아닌가 싶다. 그래서 동일한 plist 파일을 power saving 기능을 꺼 놓은 맥미니에 설정했더니 정상적으로 동작한다. 다행이다.\nReference  launcha plist 파일을 만들어 주는 웹페이지 Mac OS X launchd examples (launchd plist example files) launchd.plist \u0026ndash; System wide and per-user daemon/agent configuration files. Schedule jobs using launchd launchd script to open webpage everyday at a certain time  ","id":80,"section":"posts","summary":"Purpose 매일 낮 11시 부터 1시간 동안 CBS 뮤직 FM에서 진행되는 신영음을 듣고 싶다. 아주 오래 전 가장 좋아했던 라디어 프로가 정은임씨가 진행하던 영화음악 이었는데 한참","tags":["launchd","plist","crond","ffmpeg"],"title":"Record CBS Music Radio in every day","uri":"https://cychong47.github.io/2017/10/record-cbs-fm-cinema-music/","year":"2017"},{"content":"최적화(?) 중.\nLightroom으로 사진 관리  Apple Photos 앱이 아닌 Adobe Lightroom으로 사진 관리. 사진 파일은 DB에 포함시키지 않고, meta data만 DB에 저장하도록 import 방식을 사용.  mbpr15:Lightroom cychong$ pwd /Users/cychong/Pictures/Lightroom mbpr15:Lightroom cychong$ ls -al total 55288 drwxr-xr-x 7 cychong staff 224 Oct 9 23:36 . drwx------+ 5 cychong staff 160 Oct 8 10:55 .. -rw-r--r--@ 1 cychong staff 6148 Oct 9 22:47 .DS_Store drwxr-xr-x 20 cychong staff 640 Oct 9 23:43 Lightroom Catalog Previews.lrdata -rw-r--r--@ 1 cychong staff 26193920 Oct 9 23:41 Lightroom Catalog.lrcat -rw-r--r-- 1 cychong staff 1687256 Oct 9 23:41 Lightroom Catalog.lrcat-journal -rw-r--r-- 1 cychong staff 55 Oct 9 18:58 Lightroom Catalog.lrcat.lock  1차 작업 공간은 500G SSD 백업 1차 백업 - Mac mini 2011 1TB 내장 하드에 백업 일단은 ditto app으로 일괄 복사.(incremental backup solution 찾아 적용 필요)\n주 작업 머신인 Mackbook Pro 15인치 2017에 mac mini 2011 1TB 하드 마운트(/Volumes/data) 후 작업\n$ ditto /Volumes/Samsung_T3/Pictures/2017/ /Volumes/data/Pictures/2017/ -v  2차 백업 - Mac mini 2011 2TB 외장 하드에 백업 (1차 백업과 동일한 이슈)\nMac mini 2011에 외장 하드 연결(/Volumes/ET) 후 작업\nmini2:/Volumes/ET/Pictures cychong$ mkdir 2017 mini2:/Volumes/ET/Pictures cychong$ ditto /Volumes/data/Pictures/2017/ ./2017/  3차 백업 - NAS 4TB에 백업 - FIXME 원래 백업 대상이던 primary HDD가 볼륨 에러(고장)으로 사용 불가 상태라 primray HDD에 대한 backup용으로 사용하던 secondary HDD에 직접 복사하도록 작업 필요\nNAS 디렉토리 마운트 후 동일 작업 수행\n  추가 고려사항) 2014/2015년에 구입한 하드라 secondary HDD도 고장이 날 수 있어 cloud backup 솔류션 확보 필요\nTODO  Cloud backup solution 검토 백업 자동화 다수의 공간에 산재한 파일 들 정리 필요  ","id":81,"section":"posts","summary":"최적화(?) 중. Lightroom으로 사진 관리 Apple Photos 앱이 아닌 Adobe Lightroom으로 사진 관리. 사진 파일은 DB에 포함시키지 않고, meta data만 DB","tags":["backup","nas","photo","storage"],"title":"사진 백업 2017 버전","uri":"https://cychong47.github.io/2017/10/sajin-baegeob-2017-beojeon/","year":"2017"},{"content":"When I call the homebrew modules for three hosts including the localhost, one host reports error.\nmbpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose No config file found; using defaults PLAY [all] ************************************************************************************************** TASK [Gathering Facts] ************************************************************************************** ok: [localhost] ok: [mini2] ok: [mini1] TASK [install ack in homebrew] ****************************************************************************** ok: [localhost] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} ok: [mini1] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} fatal: [mini2]: FAILED! =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Warning: git 2.14.2 is already installed\\nError: Git must be installed and in your PATH!\\nxcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\\nError: ack cannot be built with any available compilers.\\nInstall GNU's GCC\\n brew install gcc\u0026quot;} to retry, use: --limit @/Users/cychong/install_brew_ack.retry PLAY RECAP ************************************************************************************************** localhost : ok=2 changed=0 unreachable=0 failed=0 mini1 : ok=2 changed=0 unreachable=0 failed=0 mini2 : ok=1 changed=0 unreachable=0 failed=1  This requires xcrun is not installed. (The following command will have a pop-up window to install command line tool).\n$ xcode-select --install  After that, error is gone~\nReference  https://apple.stackexchange.com/questions/254380/macos-sierra-invalid-active-developer-path  ","id":82,"section":"posts","summary":"When I call the homebrew modules for three hosts including the localhost, one host reports error.\nmbpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose No config file found; using defaults PLAY [all] ************************************************************************************************** TASK [Gathering Facts] ************************************************************************************** ok: [localhost] ok: [mini2] ok: [mini1] TASK [install ack in homebrew] ****************************************************************************** ok: [localhost] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} ok: [mini1] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} fatal: [mini2]: FAILED!","tags":["brew","ansible","homebrew","xcrun"],"title":"Error in using homebrew module in ansible","uri":"https://cychong47.github.io/2017/10/untitled-2/","year":"2017"},{"content":"It is gone finally\u0026hellip; [macOS Server 5.4 changes in High Sierra you need to know about!])https://www.imore.com/changes-macos-server-54-high-sierra)\n File Transfer Protocol (FTP): A longtime a security risk, for example for sending password information in clear text, FTP support will be removed from macOS server if you upgrade.\n As my xeros printer/scanner suppors only ftp or samba(which is much much slower than the ftp) I have to run my own ftp server in my mac mini.\nGoogling sugggest me to use pyftpdlib\nmini2:~ cychong$ pip install pyftpdlib Collecting pyftpdlib Downloading pyftpdlib-1.5.2.tar.gz (179kB) 100% |████████████████████████████████| 184kB 2.6MB/s Building wheels for collected packages: pyftpdlib Running setup.py bdist_wheel for pyftpdlib ... done Stored in directory: /Users/cychong/Library/Caches/pip/wheels/74/7c/3f/011ccb0b834d0bb28d1cebed7bd8178713d5b879129dd0b828 Successfully built pyftpdlib Installing collected packages: pyftpdlib Successfully installed pyftpdlib-1.5.2  The simple way is just running pyftplib with argument.\nsudo python -m pyftpdlib -d /Users/scan/Public/incoming -p 21  However, this does not allow to specify user ID(seems that)\nI just copy the sample from the pyftpdlib (https://github.com/giampaolo/pyftpdlib)\nIt just works.\nmini2:~/Documents cychong$ cat pyftp.py #!/bin/env python from pyftpdlib.authorizers import DummyAuthorizer from pyftpdlib.handlers import FTPHandler from pyftpdlib.servers import FTPServer # change the username and password username = \u0026quot;FIXME\u0026quot; password = \u0026quot;FIXME\u0026quot; home_dir = \u0026quot;FIXME\u0026quot; authorizer = DummyAuthorizer() authorizer.add_user(username, password, home_dir, perm=\u0026quot;elradfmw\u0026quot;) #authorizer.add_anonymous(\u0026quot;/home/nobody\u0026quot;) handler = FTPHandler handler.authorizer = authorizer server = FTPServer((\u0026quot;\u0026quot;, 21), handler) server.serve_forever()  I changed the ftp port from 21 to something else not to use sudo to run this script.\n","id":83,"section":"posts","summary":"It is gone finally\u0026hellip; [macOS Server 5.4 changes in High Sierra you need to know about!])https://www.imore.com/changes-macos-server-54-high-sierra)\n File Transfer Protocol (FTP): A longtime a security risk, for example for sending password information in clear text, FTP support will be removed from macOS server if you upgrade.\n As my xeros printer/scanner suppors only ftp or samba(which is much much slower than the ftp) I have to run my own ftp server in my mac mini.","tags":["Python","osx","ftp","pyftplib"],"title":"FTP server is gone from High Siera OSX Server","uri":"https://cychong47.github.io/2017/10/ftp-server-is-gone-from-high-siera-osx-server/","year":"2017"},{"content":"Install Easy Video Player\nOthers 7 Free WordPress Video Player Plugins of 2017\n","id":84,"section":"posts","summary":"Install Easy Video Player\nOthers 7 Free WordPress Video Player Plugins of 2017","tags":["wordpress"],"title":"WP video plugin","uri":"https://cychong47.github.io/2017/10/wp-video-plugin/","year":"2017"},{"content":"Configuration  ansible client A ansible target B, C  In client Ansible targets(B,C) should be listed in the following file. If required additional parameters can be specified such as login account, ssh port and etc\n# /etc/ansible/hosts  192.168.1.100 ansible_ssh_user=cychong ansible_ssh_port=22 192.168.1.200 ansible_ssh_user=cychong ansible_ssh_port=22  In ansible targets A should be found on the following file\n# grep A .ssh/authorized_keys  Test run from A # ansible all -m ping 192.168.1.200 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } 192.168.1.100 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; }  Test run from A #2 mbpr15:~ cychong$ ansible all -a \u0026quot;/usr/bin/du -hs Downloads\u0026quot; 192.168.1.100 | SUCCESS | rc=0 \u0026gt;\u0026gt; 20G\tDownloads 192.168.1.200 | SUCCESS | rc=0 \u0026gt;\u0026gt; 11G\tDownloads  Test run from A #3 mbpr15:~ cychong$ ansible all -a \u0026quot;/bin/df -h .\u0026quot; 192.168.1.200 | SUCCESS | rc=0 \u0026gt;\u0026gt; Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk2s1 119Gi 103Gi 12Gi 90% 1178609 9223372036853597198 0% / 192.168.1.100 | SUCCESS | rc=0 \u0026gt;\u0026gt; Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk0s2 115Gi 58Gi 57Gi 51% 15210230 14862623 51% /  How ansible works  Playbooks contain plays Play contain taks Task call modules Taks run sequentially Handlers are triggered by task, and run once at the end of play  Playbooks  YAML files describes the desired state of something  Modules list up all modules $ ansible-doc -l  Show man-page of a specific module $ ansible-doc MODULE_NAME $ ansible-doc homebrew  Inventories  Statc lines of servers ranges dynamic list of servers : AWS, Azure, GCP  /etc/ansible/hosts\nmini1 ansible_host=192.168.1.100 ansible_ssh_user=cychong ansible_ssh_port=22 mini2 ansible_host=192.168.1.200 ansible_ssh_user=cychong ansible_ssh_port=22 localhost ansible_connection=local  Test run check git version of each targets mbpr15:tmp cychong$ ansible all -m command -a \u0026quot;/usr/local/bin/git --version\u0026quot; 192.168.1.200 | SUCCESS | rc=0 \u0026gt;\u0026gt; git version 2.14.2 192.168.1.100 | SUCCESS | rc=0 \u0026gt;\u0026gt; git version 2.14.2  update remote (home)brew packages FIXME Have to use homebrew module\nWhy two machines returns different result?\nmbpr15:tmp cychong$ ansible all -m homebrew -a \u0026quot;update_homebrew=yes\u0026quot; --verbose No config file found; using defaults 192.168.1.200 | FAILED! =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Warning: git 2.14.2 is already installed\\nError: Git must be installed and in your PATH!\u0026quot; } 192.168.1.100 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew already up-to-date.\u0026quot; }  update homebrew itself and upgrade all packages mbpr15:tmp cychong$ ansible all -m homebrew -a \u0026quot;update_homebrew=yes upgrade_all=yes\u0026quot; --verbose No config file found; using defaults mini2 | FAILED! =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: true, \u0026quot;msg\u0026quot;: \u0026quot;Warning: git 2.14.2 is already installed\\nError: Git must be installed and in your PATH!\u0026quot; } mini1 | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew packages already upgraded.\u0026quot; } localhost | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: true, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Homebrew upgraded.\u0026quot; }  install ack homebrew package mbpr15:~ cychong$ cat install_brew_ack.yaml --- - hosts: all tasks: - name : install ack in homebrew homebrew: name: ack state: present  run\nmbpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose No config file found; using defaults PLAY [all] ********************************************************************************** TASK [Gathering Facts] ********************************************************************** ok: [localhost] ok: [mini2] ok: [mini1] TASK [install ack in homebrew] ************************************************************** ok: [localhost] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} ok: [mini2] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} ok: [mini1] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} PLAY RECAP ********************************************************************************** localhost : ok=2 changed=0 unreachable=0 failed=0 mini1 : ok=2 changed=0 unreachable=0 failed=0 mini2 : ok=2 changed=0 unreachable=0 failed=0  After removing ack from mini2\nmini2\nmini2:~ cychong$ brew uninstall ack Uninstalling /usr/local/Cellar/ack/2.18... (4 files, 190.4KB) ack 2.14 1 is still installed. Remove all versions with `brew uninstall --force ack`. mini2:~ cychong$ brew uninstall --force ack Uninstalling ack... (3 files, 182.8KB) mini2:~ cychong$ ack -bash: ack: command not found  Try again - install ack in mini2\nmbpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose No config file found; using defaults PLAY [all] ************************************************************************************************** TASK [Gathering Facts] ************************************************************************************** ok: [localhost] ok: [mini1] ok: [mini2] TASK [install ack in homebrew] ****************************************************************************** ok: [localhost] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} ok: [mini1] =\u0026gt; {\u0026quot;changed\u0026quot;: false, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package already installed: ack\u0026quot;} changed: [mini2] =\u0026gt; {\u0026quot;changed\u0026quot;: true, \u0026quot;failed\u0026quot;: false, \u0026quot;msg\u0026quot;: \u0026quot;Package installed: ack\u0026quot;} PLAY RECAP ************************************************************************************************** localhost : ok=2 changed=0 unreachable=0 failed=0 mini1 : ok=2 changed=0 unreachable=0 failed=0 mini2 : ok=2 changed=1 unreachable=0 failed=0  Note that mini2 has changed as true(1) because ack is installed(state is changed).\nreference  Asible 소개 Ansible Quick Guide https://github.com/ideasonpurpose/ansible-playbooks/tree/master/roles https://moonstrike.github.io/ansible/2016/09/22/Ansible-Playbooks.html http://docs.ansible.com/ansible/2.4/playbooks_reuse_roles.html http://docs.ansible.com/ansible/latest/playbooks.html  ","id":85,"section":"posts","summary":"Configuration ansible client A ansible target B, C In client Ansible targets(B,C) should be listed in the following file. If required additional parameters can be specified such as login account, ssh port and etc # /etc/ansible/hosts 192.168.1.100 ansible_ssh_user=cychong ansible_ssh_port=22 192.168.1.200 ansible_ssh_user=cychong ansible_ssh_port=22 In ansible targets A should be found on the following file # grep A .ssh/authorized_keys Test run from A # ansible all -m ping 192.168.1.200 | SUCCESS =\u0026gt;","tags":["ansible","automation"],"title":"Play with Ansible","uri":"https://cychong47.github.io/2017/10/ansible/","year":"2017"},{"content":"https://www.youtube.com/watch?v=tIN8BjHwpNs\nOther similar videos Architecture for fine-grain, high-resolution Telemetry for network elements. Jun 4 2015, Juniper Networks, Presented in NANOG\nVisualizing Cisco Telemetry Data using Elasticsearch, Logstash and Kibana\n","id":86,"section":"posts","summary":"https://www.youtube.com/watch?v=tIN8BjHwpNs\nOther similar videos Architecture for fine-grain, high-resolution Telemetry for network elements. Jun 4 2015, Juniper Networks, Presented in NANOG\nVisualizing Cisco Telemetry Data using Elasticsearch, Logstash and Kibana","tags":["telemetry"],"title":"(Series","uri":"https://cychong47.github.io/2017/10/series-4-10-lessons-from-telemetry/","year":"2017"},{"content":"출처 : sdxcentral, Feb 5, 2016\ntools presented in the video reference  video ppt  ","id":87,"section":"posts","summary":"출처 : sdxcentral, Feb 5, 2016 tools presented in the video reference video ppt","tags":["cisco","telemetry","json","model-driven","grpc","netconf","snmp"],"title":"(Series","uri":"https://cychong47.github.io/2017/10/cisco-ios-xr-and-signalfx-demo/","year":"2017"},{"content":"출처 : https://blogs.cisco.com/sp/streaming-telemetry-with-google-protocol-buffers\nSummary JSON, \u0026ldquo;compact\u0026rdquo; GPB and \u0026ldquo;Key-Value\u0026rdquo; GPB\n \u0026ldquo;Compact\u0026rdquo; GPB data on wire can be decoded without the decoder ring while \u0026ldquo;Key-Value\u0026rdquo; GPB data is Self-Describing. Compact GPB can be used with UDP(default) and TCP(optionally) \u0026ldquo;Key-value\u0026rdquo; GPB is only for TCP 833 bytes of compact GPB while more than 4000 bytes for Key-value GPB Compressed JSON(?)  ","id":88,"section":"posts","summary":"출처 : https://blogs.cisco.com/sp/streaming-telemetry-with-google-protocol-buffers Summary JSON, \u0026ldquo;compact\u0026rdquo; GPB and \u0026ldquo;Key-Value\u0026rdquo; GPB \u0026ldquo;Compact\u0026rdquo; GPB data on wire can be decoded without the decoder ring while \u0026ldquo;Key-Value\u0026rdquo; GPB data is Self-Describing. Compact GPB can be used with UDP(default) and TCP(optionally) \u0026ldquo;Key-value\u0026rdquo; GPB is only for TCP 833 bytes of compact GPB while more than 4000 bytes for Key-value GPB Compressed JSON(?)","tags":["cisco","protocol buffer","gpb","protobufs"],"title":"(Series","uri":"https://cychong47.github.io/2017/10/streaming-telemetry-with-google-protocol-buffers/","year":"2017"},{"content":"Seems that configuration and operation data are defined in a different yang file though it is not clear they are module or submodule\n The models are in the .yang format. A model with: -oper in the model name indicates an operational model. For example, Cisco-IOS-XR-cdp-oper.yang is an operational model for Cisco Discovery Protocol (CDP). -cfg indicates a configuration model. For example, Cisco-IOS-XR-cdp-cfg.yang is a configuration model for CDP. -act indicates a NETCONF actions model. For example, Cisco-IOS-XR-ipv4-ospf-act.yang is an action model for OSPF.\n Programmability Configuration Guide for Cisco NCS 5500 Series Routers, IOS XR Release 6.2.x\nComponents to use Data models\nChapter: Use Cases with Data Models\n","id":89,"section":"posts","summary":"Seems that configuration and operation data are defined in a different yang file though it is not clear they are module or submodule\n The models are in the .yang format. A model with: -oper in the model name indicates an operational model. For example, Cisco-IOS-XR-cdp-oper.yang is an operational model for Cisco Discovery Protocol (CDP). -cfg indicates a configuration model. For example, Cisco-IOS-XR-cdp-cfg.yang is a configuration model for CDP. -act indicates a NETCONF actions model.","tags":["cisco","yang"],"title":"CISCO Yang data model","uri":"https://cychong47.github.io/2017/10/cisco-yang-data-model/","year":"2017"},{"content":"Why You Should Care About Model-Driven Telemetry from CISCO blog\nSummary  Periodic polling -\u0026gt; Pushing(Streaming) Model based data with YANG Use standard encoding such as JSON, Google Protocol Buffers Easy to manipulate, connect to analytic solutions  1-min poll is too slow  For the last 25 years, network operators have heavily relied on SNMP polling and CLI screen-scraping to extract operational data from the network. But the new and automated demands of today’s networks have pushed these mechanisms to the breaking point.\nNetwork operators often poll data from their network on the order of every five to thirty minutes. With careful tuning and testing, the bravest can push that interval down to one minute. But with today’s speeds and scales, even that’s not low enough to capture important network events. And as we move to higher density platforms, the amount of important operational data becomes truly staggering.\n streaming  Network operators poll periodically because they want the data at regular intervals.\nInstead of pulling data off the network, sit back and let the network push it to you\n Model-driven  Of course, it’s not enough to just push a lot of data off the device. Telemetry data must be structured in a sensible way to make it easy for monitoring tools to ingest. In other words, good telemetry data must be model-based. YANG,\n Analytic friendly  Telemetry data needs to be normalized for efficient consumption by Big Data tools. In the software world, encodings such as JSON and Google Protocol Buffers (GPB) are widely used to transfer data between software applications. These encodings have an abundance of open-source software APIs that make it easy to manipulate and analyze the data.\n  Model-driven telemetry is your first step in a journey that will transform how you monitor and operate networks. With the power of telemetry, you’ll discover things you never imagined and begin to ask more and better questions.\n References cited in the article\n bigmuddy-network-telemetry-collector JSON or GPB(Google Protocol Buffer) based. Have to see how GPB based can be used in program CISCO XR6.0.0 GPB Telemetry Streaming Telemetry Collector Stacks Streamlined to ELK, prometheus, kafka bus Yang data model of some network equipments Model-Driven Telemetry in CISCO  ","id":90,"section":"posts","summary":"Why You Should Care About Model-Driven Telemetry from CISCO blog\nSummary  Periodic polling -\u0026gt; Pushing(Streaming) Model based data with YANG Use standard encoding such as JSON, Google Protocol Buffers Easy to manipulate, connect to analytic solutions  1-min poll is too slow  For the last 25 years, network operators have heavily relied on SNMP polling and CLI screen-scraping to extract operational data from the network. But the new and automated demands of today’s networks have pushed these mechanisms to the breaking point.","tags":["cisco","telemetry","elk","protocol buffer","json"],"title":"(Series","uri":"https://cychong47.github.io/2017/10/model-driven-telemetry/","year":"2017"},{"content":"Just for the record as some environments are mentioned\nmbpr15:working cychong$ brew install python ==\u0026gt; Installing dependencies for python: readline, sqlite, gdbm, openssl ==\u0026gt; Installing python dependency: readline ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/readline-7.0.3_1.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring readline-7.0.3_1.high_sierra.bottle.tar.gz ==\u0026gt; Caveats This formula is keg-only, which means it was not symlinked into /usr/local, because macOS provides the BSD libedit library, which shadows libreadline. In order to prevent conflicts when programs look for libreadline we are defaulting this GNU Readline installation to keg-only.. For compilers to find this software you may need to set: LDFLAGS: -L/usr/local/opt/readline/lib CPPFLAGS: -I/usr/local/opt/readline/include ==\u0026gt; Summary 🍺 /usr/local/Cellar/readline/7.0.3_1: 46 files, 1.5MB ==\u0026gt; Installing python dependency: sqlite ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/sqlite-3.20.1.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring sqlite-3.20.1.high_sierra.bottle.tar.gz ==\u0026gt; Caveats This formula is keg-only, which means it was not symlinked into /usr/local, because macOS provides an older sqlite3. If you need to have this software first in your PATH run: echo 'export PATH=\u0026quot;/usr/local/opt/sqlite/bin:$PATH\u0026quot;' \u0026gt;\u0026gt; ~/.bash_profile For compilers to find this software you may need to set: LDFLAGS: -L/usr/local/opt/sqlite/lib CPPFLAGS: -I/usr/local/opt/sqlite/include ==\u0026gt; Summary 🍺 /usr/local/Cellar/sqlite/3.20.1: 11 files, 2.9MB ==\u0026gt; Installing python dependency: gdbm ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/gdbm-1.13.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring gdbm-1.13.high_sierra.bottle.tar.gz 🍺 /usr/local/Cellar/gdbm/1.13: 19 files, 553.9KB ==\u0026gt; Installing python dependency: openssl ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/openssl-1.0.2l.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring openssl-1.0.2l.high_sierra.bottle.tar.gz ==\u0026gt; Caveats A CA file has been bootstrapped using certificates from the SystemRoots keychain. To add additional certificates (e.g. the certificates added in the System keychain), place .pem files in /usr/local/etc/openssl/certs and run /usr/local/opt/openssl/bin/c_rehash This formula is keg-only, which means it was not symlinked into /usr/local, because Apple has deprecated use of OpenSSL in favor of its own TLS and crypto libraries. If you need to have this software first in your PATH run: echo 'export PATH=\u0026quot;/usr/local/opt/openssl/bin:$PATH\u0026quot;' \u0026gt;\u0026gt; ~/.bash_profile For compilers to find this software you may need to set: LDFLAGS: -L/usr/local/opt/openssl/lib CPPFLAGS: -I/usr/local/opt/openssl/include ==\u0026gt; Summary 🍺 /usr/local/Cellar/openssl/1.0.2l: 1,709 files, 12.3MB ==\u0026gt; Installing python ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/python-2.7.14.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring python-2.7.14.high_sierra.bottle.tar.gz ==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v ==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v ==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v ==\u0026gt; Caveats This formula installs a python2 executable to /usr/local/bin. If you wish to have this formula's python executable in your PATH then add the following to ~/.bash_profile: export PATH=\u0026quot;/usr/local/opt/python/libexec/bin:$PATH\u0026quot; Pip and setuptools have been installed. To update them pip2 install --upgrade pip setuptools You can install Python packages with pip2 install \u0026lt;package\u0026gt; They will install into the site-package directory /usr/local/lib/python2.7/site-packages See: https://docs.brew.sh/Homebrew-and-Python.html ==\u0026gt; Summary 🍺 /usr/local/Cellar/python/2.7.14: 3,517 files, 48.4MB  ","id":91,"section":"posts","summary":"Just for the record as some environments are mentioned\nmbpr15:working cychong$ brew install python ==\u0026gt; Installing dependencies for python: readline, sqlite, gdbm, openssl ==\u0026gt; Installing python dependency: readline ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/readline-7.0.3_1.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring readline-7.0.3_1.high_sierra.bottle.tar.gz ==\u0026gt; Caveats This formula is keg-only, which means it was not symlinked into /usr/local, because macOS provides the BSD libedit library, which shadows libreadline. In order to prevent conflicts when programs look for libreadline we are defaulting this GNU Readline installation to keg-only.","tags":["Python","osx","brew"],"title":"brew install python","uri":"https://cychong47.github.io/2017/10/brew-install-python/","year":"2017"},{"content":"정규식으로 http 분석 def processHTTP(data): str_method = \u0026quot;\u0026quot; str_uri = \u0026quot;\u0026quot;  정규표현식을 통해 넘어온 데이터에서 METHOD, URI, HTTP 버전 정보등으로 구분함 h = re.search(\u0026quot;(?P\u0026lt;method\u0026gt;(^GET|^POST|^PUT|^DELETE)) (?P\u0026lt;uri\u0026gt;.+) (?P\u0026lt;version\u0026gt;.+)\u0026quot;, data) if not h: return \u0026quot;Error\u0026quot; # 정규표현식에 해당하는 데이터가 없는 경우 Error 를 리턴해줌 # method 로 정의된 부준은 str_method 에 저장 if h.group(\u0026quot;method\u0026quot;): str_method = h.group(\u0026quot;method\u0026quot;) # URI 데이터는 str_uri 에 저장 if h.group(\u0026quot;uri\u0026quot;): str_uri = h.group(\u0026quot;uri\u0026quot;) return str_method,str_uri # method 와 uri 를 리턴해 줌  출처 : http://www.packetinside.com/2010/11/scapy-로-패킷-핸들링하는-프로그램-만들기-세번째.html?showComment=1423994884595\n","id":92,"section":"posts","summary":"정규식으로 http 분석 def processHTTP(data): str_method = \u0026quot;\u0026quot; str_uri = \u0026quot;\u0026quot; 정규표현식을 통해 넘어온 데이터에서 METHOD, URI, HTTP 버전 정보등으로 구분함 h = re.search(\u0026quot;(?P\u0026lt;method\u0026gt;(^GET|^POST|^PUT|^DELETE)) (?P\u0026lt;uri\u0026gt;.+) (?P\u0026lt;version\u0026gt;.+)\u0026quot;, data) if not h: return \u0026quot;Error\u0026quot; # 정규표현식에 해당하는 데이터","tags":["Python","scapy","http"],"title":"Parsing http header with scary","uri":"https://cychong47.github.io/2017/10/parsing-http-header-with-scary/","year":"2017"},{"content":"Maglev  Google( https://research.google.com/pubs/pub44824.html ) Used in Google Cloud since 2008 Scalable load balancer  Consistent hashing Connection Tracking Scale-out model backed by router\u0026rsquo;s ECMP   Bypass kernel space for performance. Support connection persistence  Network Architecture  DNS - Routers - Maglevs - Service EndPoints. One service is served by one or more VIPs  DNS returns VIP considering geolocation and load of location   One VIP is served by multiple Maglevs  Router use ECMP to select one Maglev   One VIP is mapped to multiple Service EndPoints  Maglev select Service EndPoint by seletion algorithm and connection tracking table   Maglev use GRE to send incoming packet to Service EndPoint or another Maglev  Send to IP fragment to another special Maglev servers Use only 3-tuple for IP fragment   Each Service EndPoint use Direct Server Return(DSR)  Maglev Controller  Responsible for VIP announcement with BGP Check health status of forwarder If forwarder is not headthy, withdraw all VIP announcements  Forwarder  Each VIP has one or multiple backend pools(BP) BP contain physical IP address of the Service EndPoint Each BP has specific health checking methods - depends on the service requirement(just reachability or more) Config Manager parse and update configuration of forwarder\u0026rsquo;s behavior based on the Config Objects Sharding  Sharding of Maglev enables service isolation - new service or QoS    Backend Selection  Consistent Hashing distribute loads Record selection in LOCAL connection tracking table  Connection tracking table is not shared with another Maglev Does not guarantee consistency on Maglev or Service EndPoint Changes(add/delete)   For different traffic type  TCP SYN : select Backend and record it in connection tracking table TCP non-SYN : lookup connection tracking table 5-tuple : (maybe) lookup connection tracking table and select backend if not found    Consistent Hashing  If Maglev is added or removed, router select different Maglev for the exsiting session - ECMP is changed If one Maglev\u0026rsquo;s local connection tracking table is overflowed, it will lose previous selection To resolve this issues,  Synchronize local connection tracking table between Maglevs -\u0026gt; overhead, overhead, overhead Consistent hashing for minimize disruption in member changes Maglev hashing - load balancing and minimal disruption on member changes    reference  Maglev: A Fast and Reliable Software Network Load Balancer Consistent Hashing The Simple Magic of Consistent Hashing  ","id":93,"section":"posts","summary":"Maglev  Google( https://research.google.com/pubs/pub44824.html ) Used in Google Cloud since 2008 Scalable load balancer  Consistent hashing Connection Tracking Scale-out model backed by router\u0026rsquo;s ECMP   Bypass kernel space for performance. Support connection persistence  Network Architecture  DNS - Routers - Maglevs - Service EndPoints. One service is served by one or more VIPs  DNS returns VIP considering geolocation and load of location   One VIP is served by multiple Maglevs  Router use ECMP to select one Maglev   One VIP is mapped to multiple Service EndPoints  Maglev select Service EndPoint by seletion algorithm and connection tracking table   Maglev use GRE to send incoming packet to Service EndPoint or another Maglev  Send to IP fragment to another special Maglev servers Use only 3-tuple for IP fragment   Each Service EndPoint use Direct Server Return(DSR)  Maglev Controller  Responsible for VIP announcement with BGP Check health status of forwarder If forwarder is not headthy, withdraw all VIP announcements  Forwarder  Each VIP has one or multiple backend pools(BP) BP contain physical IP address of the Service EndPoint Each BP has specific health checking methods - depends on the service requirement(just reachability or more) Config Manager parse and update configuration of forwarder\u0026rsquo;s behavior based on the Config Objects Sharding  Sharding of Maglev enables service isolation - new service or QoS    Backend Selection  Consistent Hashing distribute loads Record selection in LOCAL connection tracking table  Connection tracking table is not shared with another Maglev Does not guarantee consistency on Maglev or Service EndPoint Changes(add/delete)   For different traffic type  TCP SYN : select Backend and record it in connection tracking table TCP non-SYN : lookup connection tracking table 5-tuple : (maybe) lookup connection tracking table and select backend if not found    Consistent Hashing  If Maglev is added or removed, router select different Maglev for the exsiting session - ECMP is changed If one Maglev\u0026rsquo;s local connection tracking table is overflowed, it will lose previous selection To resolve this issues,  Synchronize local connection tracking table between Maglevs -\u0026gt; overhead, overhead, overhead Consistent hashing for minimize disruption in member changes Maglev hashing - load balancing and minimal disruption on member changes    reference  Maglev: A Fast and Reliable Software Network Load Balancer Consistent Hashing The Simple Magic of Consistent Hashing  ","tags":["google","maglev","load balancer","lb","http","tcp"],"title":"Google's Load Balancer","uri":"https://cychong47.github.io/2017/10/googles-load-balancer/","year":"2017"},{"content":"ZTE Pharos Lab Pharos : OPNFV를 시험하는 worldwide lab 외부에서 접속하는 것이 필요하므로 ssh를 열어줄 수는 없어서 openVPN을 제공하고, 망을 분리하는 등의 이슈 해결을 위해 노력한 듯\nhttps://www.opnfv.org/developers/pharos Pharos는 시험 환경을 구축해서 community에 공개해서 사용할 수 있는 환경을 제공하는 듯 Provide developers with substantial resources for early testing within realistic NFV environments via an open, consistent, repeatable test domain\nWhy donate Pharos environment NFV 환경에 사용할 HW를 직접 제조하는 업체들에게는 제품 호환성에 대한 시험을 유도할 수 있는 장점을 가짐.\nhttps://www.opnfv.org/news-faq/blog/2015/10/view-board-opnfv-one-year-part-1\n These are member- donated and operated labs that are available for testing of OPNFV software releases, the testing of OPNFV releases with third-party VNFs and other related systems. This has resulted in a global community that is engaged in the business of establishing interoperability, integration and standardization across the NFV solution space, in an open and transparent manner\n FuncTest https://wiki.opnfv.org/display/fds/FDS+Testing#FDSTesting-vPing https://wiki.opnfv.org/display/functest/Opnfv+Functional+Testing#OpnfvFunctionalTesting-VNF vPing SSH vPing userdata ODL suite - Robot framework, ODL functional testing\nhttps://git.opnfv.org/cgit/functest git clone git://git.opnfv.org/functest\n/Users/cychong/Work/functest/functest/opnfv_tests/OpenStack/vPing\nssh 접속에 paramiko module을 사용함.\nDoctor Project Project leader from NEC\nDemo : Openstack and OPNFV - Keeping your mobile phone calls connected\nhttps://www.youtube.com/watch?v=Dvh8q5m9Ahk\nDeveopment Tools On boarding - specially Jira for agile\nhttps://wiki.opnfv.org/display/DEV/Developer+On-boarding\nvPing example logger.info(\u0026quot;Trying to establish SSH connection to %s...\u0026quot; % floatip) username = 'cirros' password = 'cubswin:)' ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) timeout = 50 nolease = False got_ip = False discover_count = 0 cidr_first_octet = PRIVATE_SUBNET_CIDR.split('.')[0] while timeout \u0026gt; 0: try: ssh.connect(floatip, username=username, password=password, timeout=2) logger.debug(\u0026quot;SSH connection established to %s.\u0026quot; % floatip) break except: logger.debug(\u0026quot;Waiting for %s...\u0026quot; % floatip) time.sleep(6) timeout -= 1 console_log = vm.get_console_output()  paramiko example http://docs.paramiko.org/en/2.0/api/hostkeys.html\n\u0026gt;\u0026gt;\u0026gt; import paramiko \u0026gt;\u0026gt;\u0026gt; ssh = paramiko.SSHClient() \u0026gt;\u0026gt;\u0026gt; ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) \u0026gt;\u0026gt;\u0026gt; ssh.connect(\u0026quot;127.0.0.1\u0026quot;, username=\u0026quot;cychong\u0026quot;, password=\u0026quot;FIXME\u0026quot;, timeout=2)  Check what if key is not matched\nVisualization grafana http://testresults.opnfv.org/grafana/login\nhttp://grafana.org\nKibana based https://opnfv.biterg.io/\nNot a single vendor dominate contribution which was true for the OpenStack(Rockspace)\nEricsson, Huawei, RedHat are on tops.\n","id":94,"section":"posts","summary":"ZTE Pharos Lab Pharos : OPNFV를 시험하는 worldwide lab 외부에서 접속하는 것이 필요하므로 ssh를 열어줄 수는 없어서 openVPN을 제공하고, 망을 분리하는 등의 이슈 해결을","tags":["opnfv","meetup"],"title":"OPNFV Asia Meeting","uri":"https://cychong47.github.io/2017/10/opnfv-asia-meeting/","year":"2017"},{"content":"VES project VNF Event Stream Project\nDemo  vHello VES Demo in OpenStack Barcelona 2016 VES ONAP demo from OPNFV Summit 2017  From VF Event Streaming (VES) Project Proposal  Alok Gupta 13 Jun, 2016 OPNFV VES.pptx VNF Event Stream Prpoposal  OPNFV projects that potentially benefit from the VES project\n Fault Management ([Doctor] (https://wiki.opnfv.org/display/doctor)) *** Virtualized Infrastructure Deployment Policies (Copper) High Availability for OPNFV (Availability) Data Collection for Failure Prediction (Prediction) *** Audit (Inspector) Fault localization (RCA, Pinpoint ) *** Service Function Chaining (sfc) Moon Security Management   OpenStack projects that potentially benefit from the VES project\n Monasca: a monitoring-agent plugin for VES can provide a new/converged source for Monasca events Vitrage: similar to Monasca can provide new data for the Graph DB of Vitrage Congress: Congress data source drivers can integrate additional data from Monasca, Vitrage, or directly  VNF Event Streaming:Onboarding Telemetry Policies  Alok Gupta, Bryan Sullivan(AT\u0026amp;T) June 15, 2017 VES Project overview  ONAP and VES project ONAP is now the upstream home of VES and maintained in ONAP(where???)\nFiles used in demo https://wiki.opnfv.org/display/ves/VES+Home\n monitor.py : Collector and event processor on VDU4 evel_demo.c : VES agent sample code on VDU1 and VDU2 ves_data_model.json : VES data schema in JSON vHello_VES.sh : seems that deleted or rename to other ves_plugin.py : Python-based collectd client  ","id":95,"section":"posts","summary":"VES project VNF Event Stream Project\nDemo  vHello VES Demo in OpenStack Barcelona 2016 VES ONAP demo from OPNFV Summit 2017  From VF Event Streaming (VES) Project Proposal  Alok Gupta 13 Jun, 2016 OPNFV VES.pptx VNF Event Stream Prpoposal  OPNFV projects that potentially benefit from the VES project\n Fault Management ([Doctor] (https://wiki.opnfv.org/display/doctor)) *** Virtualized Infrastructure Deployment Policies (Copper) High Availability for OPNFV (Availability) Data Collection for Failure Prediction (Prediction) *** Audit (Inspector) Fault localization (RCA, Pinpoint ) *** Service Function Chaining (sfc) Moon Security Management   OpenStack projects that potentially benefit from the VES project","tags":["opnfv","ves","prediction","pinpoint"],"title":"Integrating VES to OPNFV","uri":"https://cychong47.github.io/2017/09/ves-to-opnfv/","year":"2017"},{"content":"Summary The VES can be supported with the help of Kafka broker with the collectd in OPNFV Barometer project which is aim to collect telemetrics from the NFVI.\nBarometer Project The purpose of this project is providing metrics can be used to decide quality of NFVI. For this, the followings are reported\n NIC statistics Resources such as CPU, Memory, load, cache, themals, fan speeds, voltages and machine check exceptions.  This means the output of this project will be used in the host itself as well as inside of VM.\nThe original project name was \u0026ldquo;Software Fastpath Service Quality Metrics\u0026rdquo;.\nCollectd Barometer project uses collectd open source project(https://wiki.opnfv.org/display/fastpath/Collectd+101) It was already provide a lot of statistics can be collected from the system(usually unix systme)\nInput and output plugins To support diverse of data and interface, collectd has input and output plugin. The input plugins fed the data to the collectd and output plugins export the data to other system.\nThe supported plugins are listed in here.\nReference  Collectd 101 Collectd advantages, disadvantages and a few asides  Barometer and Collectd Barometer develops several plugins for collectd.\n dpdkstat plugin: A read plugin that retrieves stats from the DPDK extended NIC stats API. dpdkevents plugin: A read plugin that retrieves DPDK link status and DPDK forwarding cores liveliness status (DPDK Keep Alive). gnocchi plugin: A write plugin that pushes the retrieved stats to Gnocchi. It’s capable of pushing any stats read through collectd to Gnocchi, not just the DPDK stats. aodh plugin: A notification plugin that pushes events to Aodh, and creates/updates alarms appropriately. hugepages plugin: A read plugin that retrieves the number of available and free hugepages on a platform as well as what is available in terms of hugepages per socket. Open vSwitch events Plugin: A read plugin that retrieves events from OVS. Open vSwitch stats Plugin: A read plugin that retrieves flow and interface stats from OVS. mcelog plugin: A read plugin that uses mcelog client protocol to check for memory Machine Check Exceptions and sends the stats for reported exceptions. PMU plugin: A read plugin that provides performance counters data on Intel CPUs using Linux perf interface. RDT plugin: A read plugin that provides the last level cache utilization and memory bandwidth utilization. virt: A read plugin that uses virtualization API libvirt to gather statistics about virtualized guests on a system directly from the hypervisor, without a need to install collectd instance on the guest. SNMP Agent: A write plugin that will act as a AgentX subagent that receives and handles queries from SNMP master agent and returns the data collected by read plugins. The SNMP Agent plugin handles requests only for OIDs specified in configuration file. To handle SNMP queries the plugin gets data from collectd and translates requested values from collectd’s internal format to SNMP format. Supports SNMP: get, getnext and walk requests.  VES Plugin for collectd https://wiki.opnfv.org/display/fastpath/VES+plugin+updates\n1st design - Implemented as Collectd Output plugin  The VES collectd plugin as output plugin of collectd VES plugin get the data from the collectd and export to VES collector in VES format VES schema change requires VES collectd plugin updated Collectd requries MIT license while OPNFV prefer Apache license  2nd design - Use Kafka broker VES Application(not collectd plugin anymore) get the data from the Kafka broker and convert the data based on the YAML configuration(collectd stats to VES events)\nReference [Apache Kafka] 1. 소개및 아키텍처 정리\n","id":96,"section":"posts","summary":"Summary The VES can be supported with the help of Kafka broker with the collectd in OPNFV Barometer project which is aim to collect telemetrics from the NFVI. Barometer Project The purpose of this project is providing metrics can be used to decide quality of NFVI. For this, the followings are reported NIC statistics Resources such as CPU, Memory, load, cache, themals, fan speeds, voltages and machine check exceptions. This","tags":["barometer","opnfv","collectd","kafka"],"title":"OPNFV Barometer and VES","uri":"https://cychong47.github.io/2017/09/opnfv-barometer/","year":"2017"},{"content":"From https://www.youtube.com/watch?v=rYRiH3HZFN4\u0026amp;t=3s\nPresented in OpenStack Summit 2017 Boston\nContainer will be used for workload processing after 2019 VNF is differ from Enterprise IT worklaod(4:19)\n VNF is not a simple VM Maintain a state Complex network configuration Sophisticated Storage Connectivity HA is important  2018-2019 vendor and open source project especially openstack should do something to meet the requirements.\nEven it takes some time for container to replace VM for workload perspective, running the Openstack service as a container is possible today.\nWhat AT\u0026amp;T expect from the container Better CI/CD means deploy Openstack more quickly with the help of container.\nCombining OpenStack and Container 2nd option is what AT\u0026amp;T is highly interested. Magnum integrates containers and VMs\nOpenstack is another apps which can be contolled with orchestrator such k8s(right figure)\nOpenstack Helm1\nContainer Sandwidth\nRuns Openstack services inside of the container and k8s governs them Several options Explains option 2, running VM inside of the container(container runs on bare-metal)\nBenefits of Openstack services inside of container Modular scaling of specific OpenStack service such as more authentication can be supported with more keystone containers deployment.\nHitless/In-place upgrade means enabling upgrade of Openstack version without removing or rebooting VMs.\nQ\u0026amp;A Not clear for me. Why running Openstack service inside of the container has more security with a little performance penalty?\nWhat makes NFV go slowly toward container?\nWhy K8s is chosen rather than the alternatives?\nPresentation   The goal of OpenStack-Helm is to enable deployment, maintenance, and upgrading of loosely coupled OpenStack services and their dependencies individually or as part of complex environments. Information specific to OpenStack-Helm can be found below. http://openstack-helm.readthedocs.io/en/latest/ \u0026#x21a9;\u0026#xfe0e;\n   ","id":97,"section":"posts","summary":"From https://www.youtube.com/watch?v=rYRiH3HZFN4\u0026amp;t=3s\nPresented in OpenStack Summit 2017 Boston\nContainer will be used for workload processing after 2019 VNF is differ from Enterprise IT worklaod(4:19)\n VNF is not a simple VM Maintain a state Complex network configuration Sophisticated Storage Connectivity HA is important  2018-2019 vendor and open source project especially openstack should do something to meet the requirements.\nEven it takes some time for container to replace VM for workload perspective, running the Openstack service as a container is possible today.","tags":["openstack","container","ATT","kubernetes","aic"],"title":"(Summary) AT\u0026T Container Strategy","uri":"https://cychong47.github.io/2017/09/summary-at-t-container-strategy/","year":"2017"},{"content":"September 12, 2017\nhttps://www.sdxcentral.com/articles/news/amdocs-brings-nfv-software-package-based-onap/2017/09/\nAmdocs announced its new NFV Powered by ONAP portfolio – a portfolio featuring modular capabilities that accelerate service design, virtualization and operating capabilities on demand.\n Service providers using technologies developed in ONAP and its ecosystem of capabilities can provide enterprises the ability to design their own networks as part of a richer set of service features.\n from : https://www.amdocs.com/media-room/amdocs-nfv-powered-onap-worlds-first-software-and-services-portfolio-carriers-based-open\nAmdoc? Amdocs was initially involved with AT\u0026amp;T’s home-grown ECOMP platform as an integrator.(2016/07)\nPowered by ONAP  Commercial versoins of ONAP modules which are contributed by Amdocs  Amdocs Service Design and Create module : automate service design Amdocs Active Inventory module : a unified live view of services Amdocs Orchestration module :   Cloud-based hosted development environment to simplify ONAP distribution  Deployed locally or in the public cloud.   Packaged NFV use cases to speed introduction of virtual services like SD-WAN  From Amdocs NFV powered by ONAP slidesahre\nAmdocs’ NFV Powered by ONAP software will be available later this year as well\nCommericialized ONAP? By offering a commercially hardened approach to the lifecycle management of virtual services, building on Open Network Automation Platform (ONAP) , Amdocs wants to capitalize on the years of software development work its done with AT\u0026amp;T\nfrom : Amdocs Claims ONAP First-Mover Status\n \u0026ldquo;a more hardened version of ONAP within the construct of a kind of a larger service lifecycle management portfolio,\u0026rdquo;\n Ann Hatchell - VP of Open Network Marketing at ONAP\nBesides AT\u0026amp;T, Amdocs is also working with other service providers within ONAP. Hatchell mentioned Bell Canada and Orange, but she wouldn’t confirm them as customers of its NFV Powered by ONAP software.\nAmdocs NFV Partner Ecosystem For the services, Amdocs has created a partner ecosystem of vendors that provide more than 80 VNFs.\nAvoid vendor lock-in\nhttp://www.amdocsnfvpartners.com/partners.html\n vCPE vEPC - Affirmed, Connectem vIMS - Metaswitch, Sonus, Tango networks, Tropo(CISCO). vRAN - Altiostar, Asocsa Probes and Assurance - Accedian, Exfo, \u0026hellip; NFV infrastructure - Cloudify, HP, Juniper, Mirantis, Openstack, Redhat, Ubuntu, Vmware, WindRver SDN - CISCO, ECI, HP, Juniper, nuage networks, vmware. Hardware - CISCO, Dell, ECI, EMC2, Hitachi, HP, IBM, Intel, Mellanox  Benefits of Amdocs Open Network Partner Program   Enable rapid VNF onboarding and fast TTM\n  Reduce hybrid (physical and virtual) complexity\n  Drive holistic NFV service lifecycle management\n  Foster innovation in NFV use cases\n​\n  Amdocs  https://www.amdocs.com https://www.amdocs.com/open-network/nfv-powered-by-onap AMDOCS NFV POWERED BY ONAP – THE WORLD’S FIRST SOFTWARE AND SERVICES PORTFOLIO FOR CARRIERS BASED ON OPEN SOURCE Amdocs looks to ease carriers\u0026rsquo; NFV migration with ONAP-based services portfolio ONAP insider(pdf)    ","id":98,"section":"posts","summary":"September 12, 2017\nhttps://www.sdxcentral.com/articles/news/amdocs-brings-nfv-software-package-based-onap/2017/09/\nAmdocs announced its new NFV Powered by ONAP portfolio – a portfolio featuring modular capabilities that accelerate service design, virtualization and operating capabilities on demand.\n Service providers using technologies developed in ONAP and its ecosystem of capabilities can provide enterprises the ability to design their own networks as part of a richer set of service features.\n from : https://www.amdocs.com/media-room/amdocs-nfv-powered-onap-worlds-first-software-and-services-portfolio-carriers-based-open\nAmdoc? Amdocs was initially involved with AT\u0026amp;T’s home-grown ECOMP platform as an integrator.","tags":["NFV","VNF","onap","amdocs"],"title":"(News) Amdocs Brings an NFV Software Package Based on ONAP","uri":"https://cychong47.github.io/2017/09/new-amdocs-brings-an-nfv-software-package-based-on-onap/","year":"2017"},{"content":"Cloud Native Computing Foundation(http://cncf.io)에 포함된 Container monitoring tool.\n집 맥미니에서 돌리고 있는 3개 container들을 관리하는데 사용할 수 있나 싶어(실은 관리할 것도 없지만 그냥 재미로 container monitor 기능을 보고 싶어서) 설치 해 봤다\nInstall cncf.io의 많은 툴이 그렇지만 golang으로 작성되어 있어 golang부터 설치했다\nbrew install go  OSX에서 brew는 사용할 때마다 감탄을 금치 못하게 한다. 물론 우분투에도 apt가 있지만 apt보다 brew가 훨씬 편한 것 같다.\n그 다음에는 그냥 docker hub에 있는 prometheus docker 가져다 설치\ncychong:~/Dropbox/Documents/my_docker_repo/prometheus cychong$ docker run -p 9090:9090 -v ~/Dropbox/Apps/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus Unable to find image 'prom/prometheus:latest' locally latest: Pulling from prom/prometheus 4b0bc1c4050b: Pull complete a3ed95caeb02: Pull complete d6ab6c75ce17: Pull complete 96eeb64debe6: Pull complete 1e7ee99aa461: Pull complete 8d3b35efed41: Pull complete be179630d433: Pull complete 63e70970c133: Pull complete 83449160ff0d: Pull complete Digest: sha256:4f6d3a525f030e598016be765283c6455c3c830997a5c916b27a5d727be718e1 Status: Downloaded newer image for prom/prometheus:latest time=\u0026quot;2017-09-18T12:46:39Z\u0026quot; level=info msg=\u0026quot;Starting prometheus (version=1.7.1, branch=master, revision=3afb3fffa3a29c3de865e1172fb740442e9d0133)\u0026quot; source=\u0026quot;main.go:88\u0026quot; time=\u0026quot;2017-09-18T12:46:39Z\u0026quot; level=info msg=\u0026quot;Build context (go=go1.8.3, user=root@0aa1b7fc430d, date=20170612-11:44:05)\u0026quot; source=\u0026quot;main.go:89\u0026quot; time=\u0026quot;2017-09-18T12:46:39Z\u0026quot; level=info msg=\u0026quot;Host details (Linux 4.9.41-moby #1 SMP Tue Aug 29 22:02:41 UTC 2017 x86_64 2bbd50a83799 (none))\u0026quot; source=\u0026quot;main.go:90\u0026quot; time=\u0026quot;2017-09-18T12:46:39Z\u0026quot; level=info msg=\u0026quot;Loading configuration file /etc/prometheus/prometheus.yml\u0026quot; source=\u0026quot;main.go:252\u0026quot; time=\u0026quot;2017-09-18T12:46:39Z\u0026quot; level=info msg=\u0026quot;Loading series map and head chunks...\u0026quot; source=\u0026quot;storage.go:428\u0026quot; time=\u0026quot;2017-09-18T12:46:39Z\u0026quot; level=info msg=\u0026quot;0 series loaded.\u0026quot; source=\u0026quot;storage.go:439\u0026quot; time=\u0026quot;2017-09-18T12:46:39Z\u0026quot; level=info msg=\u0026quot;Starting target manager...\u0026quot; source=\u0026quot;targetmanager.go:63\u0026quot; time=\u0026quot;2017-09-18T12:46:39Z\u0026quot; level=info msg=\u0026quot;Listening on :9090\u0026quot; source=\u0026quot;web.go:259\u0026quot;  실행시키는데 yaml 형태의 설정 파일이 필요하다고 해서 기본 값을 구해서 prometheus.yml파일에 저장했다. 이전에 ghost나 wordpress container 실행할 때 했던 것처럼 설정 파일은 ~/Dropbox/Apps/prometheus 디렉토리에 두고 docker 실행할 때 volume으로 연결했다\nhttps://prometheus.io/docs/introduction/install/ 에 설명된 대로 docker run!!!\ndocker run -p 9090:9090 -v ~/Dropbox/Apps/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus  특별한 문제 없이 실행된다. 웹 브라우저를 이용해 container들이 실행되고 있는 맥미니2011 서버에 접속하면 아주 심플한(이라고 쓰고 썰렁한 이라고 읽는다) 화면이 뜬다. http://192.168.1.200:9090\n그 다음부터는 그냥 맨붕.\nHow to monitor other containers Prometheus는 감시 당할 container에 prometheus를 위한 exporter를 실행해야 하는 듯 한다. 해당 Exporter가 export 하는 URL 주소를 prometheus.yml파일의 targets 항목에 넣어야 prometheus server가 해당 URL에 접근해서 정보를 가져오는 형식이다. 그래서 prometheus.yml파일에 적힌 targets 각각에 대해 상태를 확인할 수 있는 dashboard 화면을 제공한다.\nprometheus가 설치된 서버에 targets 주소(나의 경우 http://192.168.1.200:9090/targets)에 접근하면\n오늘은 여기까지. 나중에 container에서 해당 정보를 export하려면 어떻게 해야 하는지 알아봐야겠다.\n추가) 역시나 정보를 제공할 노드에는 exporter가 필요하다. 아래에 공식 및 비공식(비공식 exporter가 훨씬 많다)\nhttps://prometheus.io/docs/instrumenting/exporters/\n그래서 모니터링할 대상이 늘어날수록 prometheus server가 pull해야 할 대상이 많아지고, 반드시 모니터링 당할 노드에 exporter가 설치되어 한다는 것도 실제 deploy할 때 장애물이 될 수 있을 듯 하다(http://hyunki1019.tistory.com/127) 다만 이 중 두 번째는 문제는 다양한 서비스에 대한 exporter가 개발되고, 해당 서비스 패키지에 빌트인 될 수 있다면 완화될 수 있을 듯. Agent 를 사용하는 monitoring 방식의 숙명이지만, 그 만큼 monitoring tool이 원하는 정보를 획득하기 용이하고, monitoring tool에 최적화된 방법으로 정보를 수집할 수 있는 장점이 있어 반드시 agent-less 방식의 monitoring이 낫다고 보기는 힘들 듯\nPrometheus and Grafana http://hyunki1019.tistory.com/128 참고 Prometheus가 열심히 모든 데이터를 Grafana를 이용해서 좀 더 보기 쉽게 보일 수 있다는. Grafana가 prometheus data를 data source로 지원하고 있어 가능한\nGrafana vs. Kibana Kibana는 주로 ELK라고 불리는 삼총사(ElasticSearch - LogStash - Kibana) 에서 visual을 담당하고 있는 프로젝트. Grafana 와 유사해 보이는데 현재 대세는 Kibana로 보이고(다른 두 친구가 워낙 유명하고, 삼총사의 케미가 좋아)\n두 개를 아주 간단하게 비교한 글은 여기에서(http://opennaru.tistory.com/126)\n  graphite, Elasticsearch, InfluxDB, Zabbix 등 여러 데이터 소스를 지원하며, 데이터 소스에서 데이터를 조회하여 그래프로 표현 Kibana는 Elasticsearch와 사용되며, Grafana는 Graphite or InfluxDB을 주로 백엔드로 사용 다양한 표현방법은 Kibana가 압도적으로 우세함 Grafana는 시계열 그래프만 지원   Reference  오픈소스 모니터링 시스템 Prometheus #1 오픈소스 모니터링 시스템 Prometheus #2 https://prometheus.io/docs/introduction/install/ https://prometheus.io/docs/introduction/getting_started/  ","id":99,"section":"posts","summary":"Cloud Native Computing Foundation(http://cncf.io)에 포함된 Container monitoring tool. 집 맥미니에서 돌리고 있는 3개 container들을 관리하는데 사용할 수 있","tags":["docker","container","cncf","prometheus"],"title":"Prometheus","uri":"https://cychong47.github.io/2017/09/prometheus/","year":"2017"},{"content":"NGINX Releases Microservices Platform, OpenShift Ingress Controller, and Service Mesh Preview\nNGNIX also join for service mesh bandwagon?\nNGNIX Application Platform  NGINX Plus, the commercial variant of the popular open source NGINX web server. NGINX Web Application Firewall (WAF) NGINX Unit, a new open source application server that can run PHP, Python and Go NGINX Controller, a centralised control plane for monitoring and management of NGINX Plus  Additional release  a Kubernetes Ingress Controller solution for load balancing on the Red Hat OpenShift Container Platform an implementation of NGINX as a service proxy for the Istio service mesh control plane.   NGINX has also released nginmesh, an open source preview version of NGINX as a service proxy for Layer 7 load balancing and proxying within the Istio service mesh platform. It aims to provide key capabilities and integration with Istio when deployed as a sidecar container, and will facilitate communication between services in a \u0026ldquo;standard, reliable, and secure manner\u0026rdquo;. Additionally, NGINX will collaborate as part of the Istio community by joining the Istio networking special interest group.\nThe concept of a \u0026ldquo;service mesh\u0026rdquo; has risen in popularity recently, as it allows developers to implement loosely coupled microservices-based applications with an underlying mesh (or communication bus) to manage traffic flows between services, enforce access policies, and aggregate telemetry data. Istio is an open source service mesh project led by Google, IBM, Lyft and others, and aims to provide a control plane to the service proxies’ data plane. Currently Istio is tightly integrated into Kubernetes, but there are plans to also support platforms such as virtual machines, PaaS like Cloud Foundry, and potentially FaaS \u0026ldquo;serverless\u0026rdquo; offerings.\n  By default Istio uses the Envoy service proxy, which was created by Matt Klein and the team at Lyft, and has been in production use at Lyft for a number of years. NGINX appears to not be the only company to realise the potential benefits of providing (and owning) the service proxy component within a microservices mesh, as Buoyant are also in the process of modifying their JVM-based service proxy, Linkerd (which was spawned from the Twitter Finagle stack), for integration with Istio.\n istio는 기본적으로 envoy를 사용(c++로 구현) Linkerd는 JVM 기반 nginmesh(golang)으로 구현\n The NGINX nginmesh Istio service proxy module - written in Golang rather than C as used for the NGINX web server itself - integrates with an open source NGINX running as a sidecar (shown in Figure 2), and claims to offers \u0026ldquo;a small footprint, high-performance proxy with advanced load balancing algorithms, caching, SSL termination, scriptability with Lua and nginScript, and various security features with granular access control.\u0026rdquo;\n Reference  nginmesh architecture, repo nginx blog universal data plane Introduction to Service Meshes What is a service mesh and why do I need one  ","id":100,"section":"posts","summary":"NGINX Releases Microservices Platform, OpenShift Ingress Controller, and Service Mesh Preview NGNIX also join for service mesh bandwagon? NGNIX Application Platform NGINX Plus, the commercial variant of the popular open source NGINX web server. NGINX Web Application Firewall (WAF) NGINX Unit, a new open source application server that can run PHP, Python and Go NGINX Controller, a centralised control plane for monitoring and management of NGINX Plus Additional release a","tags":["golang","nginx","service mesh","istio","nginmesh"],"title":"NGNIX for service mesh","uri":"https://cychong47.github.io/2017/09/ngnix-for-service-mesh/","year":"2017"},{"content":"Under construction!!\nError https://docs.docker.com/compose/wordpress/#define-the-project 에 있는 에제대로 docker-compose.yaml 파일을 만든 후 도전~~\n근데 실패\ncychong:~/work/my_wordpress cychong$ docker-compose up -d Pulling db (mysql:5.7)... Traceback (most recent call last): File \u0026quot;docker-compose\u0026quot;, line 3, in \u0026lt;module\u0026gt; File \u0026quot;compose/cli/main.py\u0026quot;, line 68, in main File \u0026quot;compose/cli/main.py\u0026quot;, line 118, in perform_command File \u0026quot;compose/cli/main.py\u0026quot;, line 928, in up File \u0026quot;compose/project.py\u0026quot;, line 427, in up File \u0026quot;compose/service.py\u0026quot;, line 311, in ensure_image_exists File \u0026quot;compose/service.py\u0026quot;, line 1016, in pull File \u0026quot;site-packages/docker/api/image.py\u0026quot;, line 358, in pull File \u0026quot;site-packages/docker/auth.py\u0026quot;, line 50, in get_config_header File \u0026quot;site-packages/docker/auth.py\u0026quot;, line 97, in resolve_authconfig File \u0026quot;site-packages/docker/auth.py\u0026quot;, line 142, in _resolve_authconfig_credstore docker.errors.DockerException: Credentials store error: StoreError('Credentials store docker-credential-osxkeychain exited with \u0026quot;User interaction is not allowed.\u0026quot;.',) Failed to execute script docker-compose  저 에러가 뭘까 하고 Googling을 해 보니 \u0026quot;Credentials store docker-credential-osxkeychain exited with \u0026quot;User interaction is not allowed\u0026quot; 이런 해결책이 나왔다.\nhttps://github.com/docker/docker-credential-helpers/issues/82\n If I click on the docker icon in the menu bar -\u0026gt; preferences -\u0026gt; and I untick \u0026ldquo;Securely store docker logins in macOS keychain\u0026rdquo; this problem goes away.\n 시키는 대로 docker 옵션 수정 후 다시 실행했더니 이제 에러는 발생하지 않는다.\nError is gone cychong:~/work/my_wordpress cychong$ docker-compose up -d Pulling db (mysql:5.7)... 5.7: Pulling from library/mysql ad74af05f5a2: Already exists 0639788facc8: Pull complete de70fa77eb2b: Pull complete 724179e94999: Pull complete 50c77fb16ba6: Pull complete d51f459239fb: Pull complete 937bbdd4305a: Pull complete 35369f9634e1: Pull complete f6016aab25f1: Pull complete 5f1901e920da: Pull complete fdf808213c5b: Pull complete Digest: sha256:96edf37370df96d2a4ee1715cc5c7820a0ec6286551a927981ed50f0273d9b43 Status: Downloaded newer image for mysql:5.7 Creating mywordpress_db_1 ... Creating mywordpress_db_1 ... done Creating mywordpress_wordpress_1 ... Creating mywordpress_wordpress_1 ... done  마지막에 mywordpress_db_1 이란 말이 맘에 안들지만 그래도 일단 웹브라우저에서 접속을 해보는데 안되네\u0026hellip;.\nBut still in error ","id":101,"section":"posts","summary":"Under construction!! Error https://docs.docker.com/compose/wordpress/#define-the-project 에 있는 에제대로 docker-compose.yaml 파일을 만든 후 도전~~ 근데 실패 cychong:~/work/my_wordpress cychong$ docker-compose up -d Pulling db (mysql:5.7)... Traceback (most recent call last): File \u0026quot;docker-compose\u0026quot;, line 3, in \u0026lt;module\u0026gt; File \u0026quot;compose/cli/main.py\u0026quot;, line 68, in main File \u0026quot;compose/cli/main.py\u0026quot;, line 118, in perform_command File \u0026quot;compose/cli/main.py\u0026quot;, line 928, in up File \u0026quot;compose/project.py\u0026quot;, line 427, in up File","tags":["docker","container","wordpress","docker-compose","mysql"],"title":"Wordpress with docker-compose","uri":"https://cychong47.github.io/2017/09/wordpress-with-docker-compose-failing/","year":"2017"},{"content":"얼마전에 구성한 ghost container는 ghost가 1.x로 업데이트가 되면서 설정 정보의 위치가 변경되었는데 그걸 미처 몰라 블로그 주소가 기본값인 localhost로 설정되는 문제가 있었다. 기존 ghost container에 접근해서 확인해 보니 `/var/lib/ghost/config.production.json\u0026rsquo; 파일에 주소가 설정되어 있는 걸 보고 이 파일도 따로 지정해 주도록 변경했다. 그러면서 docker-compose를 한번 써 보기로\n일단 기존 ghost를 정리하고\ncychong:~ cychong$ docker stop ghost ghost cychong:~ cychong$ docker rm ghost ghost cychong:~ cychong$ docker rmi ghost Untagged: ghost:latest Untagged: ghost@sha256:a1f70641d35755395eb16827de4e67861e01bffe18bac8e54ab5c68cd170a2ea Deleted: sha256:e6ba3dd3c2491c6086d570fa9769a9f60d7c004129ff9ae7ff9fa0bad16a993b Deleted: sha256:c1ee9d43624bb4a1922c15d7a9175a80d1952cb71464d6d9d900fe21948227af Deleted: sha256:f8f95cdbafce4ecd226cdd690e6f909203a0f83d3507c53a71d4e59826ea881b Deleted: sha256:935d8847555992b702173b83b0d210f2728a24b5287467396dc8d5c68907691f Deleted: sha256:f4766b72a49d4cd2e897da0efcec94c33a0d24a95cb8426a790e1c45e6e39fae Deleted: sha256:0c0dbaebe17c6f585eb596e705ed5acba668097698a7780844c12597bb99b34a Deleted: sha256:c807796bea7a34c0b73eae853b728f2bbcd7a4fecc19d049455b322120f95ce7 Deleted: sha256:15f9f4e44e22d3287b6caf9555110383d3ff2e88ee9cc03823b1ba5a01b75eac Deleted: sha256:77809f11069f2abfb571cba07ee3d696ec32823df0f5d0587042ffdb27a80add Deleted: sha256:5d6bba18f7b25c9b93d3cc0d93a4cff54eb88b0ba22ed867633a21fc3ded5f57  하는 김에 최신 버전의 ghost받아오고\ncychong:~ cychong$ docker pull ghost Using default tag: latest latest: Pulling from library/ghost ad74af05f5a2: Already exists 2b032b8bbe8b: Pull complete ad85906adb69: Pull complete 3caae50f774b: Pull complete ef87a0ce8025: Pull complete fc62209fe861: Pull complete 8610d8088e2a: Pull complete c360787a43d4: Pull complete 5d4f585a7cb1: Pull complete e204e870e4fc: Pull complete Digest: sha256:6c1adf02635cf2a31479a436192068f60c3cc86242d21093f55783ab1d1dd107 Status: Downloaded newer image for ghost:latest  docker history 명령을 보니 ghost 버전이 1.8.1로 바뀐 걸 알 수 있네.(좀 쉽게 알 수는 없을까?)\ncychong:~ cychong$ docker history ghost IMAGE CREATED CREATED BY SIZE COMMENT 2d71383c27b9 2 days ago /bin/sh -c #(nop) CMD [\u0026quot;node\u0026quot; \u0026quot;current/in... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) EXPOSE 2368/tcp 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) ENTRYPOINT [\u0026quot;docker-ent... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) COPY file:ef6da72f41bc8f... 646B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) VOLUME [/var/lib/ghost/... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) WORKDIR /var/lib/ghost 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c set -ex; mkdir -p \u0026quot;$GHOST_INST... 289MB \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) ENV GHOST_CONTENT=/var/... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) ENV GHOST_INSTALL=/var/... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c npm install -g \u0026quot;ghost-cli@$GHOS... 143MB \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) ENV GHOST_VERSION=1.8.1 0B \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c #(nop) ENV GHOST_CLI_VERSION=1... 0B \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c #(nop) ENV NODE_ENV=production 0B \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c #(nop) ENV NPM_CONFIG_LOGLEVEL... 0B \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c set -x \u0026amp;\u0026amp; wget -O /usr/local/b... 1.29MB \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c #(nop) ENV GOSU_VERSION=1.10 0B \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c #(nop) CMD [\u0026quot;node\u0026quot;] 0B \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c set -ex \u0026amp;\u0026amp; for key in 6A0... 3.89MB \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c #(nop) ENV YARN_VERSION=0.27.5 0B \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c buildDeps='xz-utils' \u0026amp;\u0026amp; ARC... 42.5MB \u0026lt;missing\u0026gt; 4 weeks ago /bin/sh -c #(nop) ENV NODE_VERSION=6.11.2 0B \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c #(nop) ENV NPM_CONFIG_LOGLEVEL... 0B \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c set -ex \u0026amp;\u0026amp; for key in 955... 131kB \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c groupadd --gid 1000 node \u0026amp;\u0026amp; u... 335kB \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c set -ex; if ! command -v gpg \u0026gt;... 0B \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c apt-get update \u0026amp;\u0026amp; apt-get insta... 44.6MB \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c #(nop) CMD [\u0026quot;bash\u0026quot;] 0B \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c #(nop) ADD file:a023a99f7d01868... 123MB  my-ghost/docker-compose.yaml\nversion: '3' services: ghost: container_name: ghost image: ghost:latest volumes: - /Users/cychong/Dropbox/Apps/ghost/content/:/var/lib/ghost/content - /Users/cychong/Dropbox/Apps/ghost/config.production.json:/var/lib/ghost/config.production.json ports: - \u0026quot;2368:2368\u0026quot; restart: always environment: - NODE_ENV=production volumes: db_data:  go!\ncychong:~/work/my_ghost cychong$ docker-compose up -d Creating network \u0026quot;myghost_default\u0026quot; with the default driver Creating volume \u0026quot;myghost_db_data\u0026quot; with default driver Creating ghost ... Creating ghost ... done  어디 볼까?\ncychong:~/work/my_ghost cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dea965b550e6 ghost:latest \u0026quot;docker-entrypoint...\u0026quot; 17 seconds ago Up 16 seconds 0.0.0.0:2368-\u0026gt;2368/tcp ghost  잠시 후 웹브라우저로 확인해 보면 제대로 접속은 되는데 의도한 대로 주소가 localhost가 아니라 sosa0sa.com으로 되었는지는 이 글을 publish하면 알 수 있겠지.\n","id":102,"section":"posts","summary":"얼마전에 구성한 ghost container는 ghost가 1.x로 업데이트가 되면서 설정 정보의 위치가 변경되었는데 그걸 미처 몰라 블로그 주소가 기본값인 loca","tags":["docker","ghost","container","docker-compose"],"title":"ghost container with docker-compose","uri":"https://cychong47.github.io/2017/09/ghost-container-with-docker-compose/","year":"2017"},{"content":"docker 버전이 업데이트되고, 몇 가지 변경사항이 있은 후 ghost, wordpress/mysql 조합의 container들이 접속이 되질 않는다. 한참을 두고 보다 ghost는 새 버전(1.x)이 나온 걸 계기로 새로 설치를 했는데(당연히 이전 설치에서 데이터를 container 내부가 아니라 local machine에 두도록 해서 데이터는 그대로 보존) wordpress는 그러질 못했다.\n이것 역시 참다참다 못해 https://docs.docker.com/compose/wordpress/#define-the-project 에 나와있는 docker swarm을 이용해서 복구해 보려고 삽을 들었다.\n위 페이지에 있는 대로 설정 파일을 만들고\nversion: '3' services: db: image: mysql:5.7 volumes: - /Users/cychong/Dropbox/Apps/wordpress/:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: xxx MYSQL_DATABASE: xxx MYSQL_USER: xxx MYSQL_PASSWORD: xxx wordpress: depends_on: - db image: wordpress:latest volumes: - /Users/cychong/Documents/wordpress/:/var/www/html - /Users/cychong/Documents/wordpress/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini ports: - \u0026quot;8000:80\u0026quot; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: xxx WORDPRESS_DB_PASSWORD: xxx volumes: db_data:  문서에 있는 대로 docker compose 명령을 실행했는데\ncychong:~/work/my_wordpress cychong$ docker-compose up -d Creating network \u0026quot;mywordpress_default\u0026quot; with the default driver Creating volume \u0026quot;mywordpress_db_data\u0026quot; with default driver Pulling db (mysql:5.7)... Traceback (most recent call last): File \u0026quot;docker-compose\u0026quot;, line 3, in \u0026lt;module\u0026gt; File \u0026quot;compose/cli/main.py\u0026quot;, line 68, in main File \u0026quot;compose/cli/main.py\u0026quot;, line 118, in perform_command File \u0026quot;compose/cli/main.py\u0026quot;, line 928, in up File \u0026quot;compose/project.py\u0026quot;, line 427, in up File \u0026quot;compose/service.py\u0026quot;, line 311, in ensure_image_exists File \u0026quot;compose/service.py\u0026quot;, line 1016, in pull File \u0026quot;site-packages/docker/api/image.py\u0026quot;, line 358, in pull File \u0026quot;site-packages/docker/auth.py\u0026quot;, line 50, in get_config_header File \u0026quot;site-packages/docker/auth.py\u0026quot;, line 97, in resolve_authconfig File \u0026quot;site-packages/docker/auth.py\u0026quot;, line 142, in _resolve_authconfig_credstore docker.errors.DockerException: Credentials store error: StoreError('Credentials store docker-credential-osxkeychain exited with \u0026quot;User interaction is not allowed.\u0026quot;.',) Failed to execute script docker-compose  쩝.. 아직 갈길이 멀구나.\n","id":103,"section":"posts","summary":"docker 버전이 업데이트되고, 몇 가지 변경사항이 있은 후 ghost, wordpress/mysql 조합의 container들이 접속이 되질 않는다. 한참을 두고 보다 ghost는 새 버전(1.x)이 나","tags":["docker","container","wordpress","swarm"],"title":"Try to restore Wordpress container","uri":"https://cychong47.github.io/2017/09/try-to-restore-wordpress-docker/","year":"2017"},{"content":"난 반대로 기존 상용차업체들이 몇 년간 테슬라를 보면서도 고작(?) 전기차 라는 키워드에만 집중해서 분석한 듯한 모습이 더 실망스러운데. 여전히 테슬라를 전기동력을 이용한 차를 만드는 회사로 인지하는 건 아닌지.\n다른 분야와 마찬가지로 자동차부문에 SW라는 개념을 넣은 것도 전기차 못지 않은 혁신이라고 생각. 도대체 서비스센터 갈때마다 뭔 소프트웨어 업데이트를 했다고 하지만 사용자인 내가 느낄 수 있는 건 단 한번도 없었는데(이건 내 제한된 경험때문에 V사만 그런 것일지도 모르지만)\n한번 차를 팔면 땡(그나마 하드웨어에 대한 유지보수망)이라는 생각을 가지고 있는 회사와 끊임없이 SW를 통해 부가가치를 만들어 제공하려는 회사는 하늘과 땅 차이가 아닐까 싶다. 내가 테슬라를 산다면(일단 한숨부터 쉬고\u0026hellip; 가격이 ㅎㄷㄷ) 그건 전기차여서라기 보다는 SW를 통한 기능 혁신 때문일 듯\n별거없다면서못하는건뭔지 안하는거라고말하겠지\n페북에서 본 글\n 이런 뉴스 보면, 또한번 자뻑에 빠지지 않을 수가 없는 것이다!!\nhttp://biz.chosun.com/…/html_…/2017/08/11/2017081102367.html\n며칠전 내가 남긴 페북 포스팅 :\n\u0026ldquo;나보다 백만배 더 똑똑한 사람들이 테슬라에 열광하여 돈 태우는 걸 보면서\u0026hellip; 그래도 나는 이해가 안 되더라\u0026hellip;\n아니, 무슨 전기차가 어마어마한 기술이라고\u0026hellip;. 전기차랑 하이브리드랑 비교해 보면 뭐가 더 어려운 기술이겠나?\n게다가 나는 모델 3에 대해 수십가지 의문을 품고 있었다. 여러 면에서 합리적으로 설명되지 않아서\u0026hellip;\n테슬라만 독보적으로 싸고 좋은 차를 만들 수 있다고?? 내 의문의 핵심은 이 질문이다. 그럴 리가 없다는 게 내 의심이고\u0026hellip;\u0026rdquo;\n몇년전에 테슬라가 자사의 특허를 전부 무상공개하겠다는 뉴스를 발표했을 때.. 그때 정말 IT 힙스터들의 영웅이 되었었는데\u0026hellip;\n상식적으로 생각해서 진짜로 가치있는 특허라면 그건 \u0026ldquo;미친놈\u0026quot;이거나 \u0026ldquo;연쇄배임마\u0026quot;가 되는 것이었다. 그것도 나는 매우 의심스러운 눈으로 보았었다.\n예전부터 해오던 아주 간단한 의심이다. 전기차보다 하이브리드가 더 만들기 어렵다. 테슬라는 하이브리드를 만들 능력이 없고, 하이브리드 자동차 브랜드는 전기차를 만들 능력이 있다.\n그럼 누가 이기겠는가??\n이 간단한 질문에 답이 나와야 테슬라에 대해서도 답이 나온다고 생각한다.\n뭔 솔라시티니, 뭐니 하는 건 됐고. 그건 돈만 있으면 다 하는 거고\u0026hellip;\n ","id":104,"section":"posts","summary":"난 반대로 기존 상용차업체들이 몇 년간 테슬라를 보면서도 고작(?) 전기차 라는 키워드에만 집중해서 분석한 듯한 모습이 더 실망스러운데. 여전히 테슬라를 전기동력","tags":[],"title":"Tesla 폄하에 대한 나의 생각","uri":"https://cychong47.github.io/2017/08/tesla-pyeomhae-daehan-nayi-saenggag/","year":"2017"},{"content":"brew cask install qlmarkdown brew cask install quicklook-json brew cask install qlprettypatch brew cask install quicklook-csv  ","id":105,"section":"posts","summary":"brew cask install qlmarkdown brew cask install quicklook-json brew cask install qlprettypatch brew cask install quicklook-csv  ","tags":["quicklook","osx","finder"],"title":"Useful quicklooks","uri":"https://cychong47.github.io/2017/07/useful-quicklooks/","year":"2017"},{"content":"","id":106,"section":"posts","summary":"","tags":["team","collaboration"],"title":"Naver Labs 12 commandments","uri":"https://cychong47.github.io/2017/06/naver-labs-12-commandments/","year":"2017"},{"content":"출처 : O\u0026rsquo;reilly radar\n현장에서 발생하는 문제 몇 번 겪어본 사람이면 대부분 동의할 문제긴 한데 structured log 사용이나 application metric 측정 등은 오래\nWrap errors Error handler wrapper function을 이용해서 error code(annotation 포함) 등을 잘 출력해서 분석이 쉽게 하자\nReport panics Panic을 내야 하는 경우에는 해당 사실을 어딘가 기록(하거나 전송해서 남기고) 패닉 처리하자.\nUse structured logs 일반 text보다는 덜 human-readable하지만 SW를 이용해서 분석하기 쉬운 structured log를 남기자. ELK를 이용해 로그 분석하기도 용이하다.\nGo stdlib이 제공하는 lib은 unstructured log만 지원하므로 logrus(http://github.com/Sirupsen/logrus)와 같은 3rd party package를 활용한다.\nimport log \u0026quot;github.com/Sirupsen/logrus\u0026quot; log.SetFormatter(\u0026amp;log.JSONFormatter{}) log.WithFields(log.Fields{}).Info(\u0026quot;Redirecting User\u0026quot;)  Ship application metrics 프로그램의 성능이나 쓰임새를 알 수 있는 metric 측정 기능을 구현하자.\n 얼마나 많은 request에 대해 error response를 주는지? 99퍼센트의 request에 대한 응답 시간은?  Native go client library를 제공하는 metric system들\n Datadog Prometheus StatsD + Graphite  Write more tests than you think you should. API등은 더 자세히 테스트하자 필요하면 핵심 함수에 대해서는 code coverage를 측정하자.\ngo test -cover\n","id":107,"section":"posts","summary":"출처 : O\u0026rsquo;reilly radar 현장에서 발생하는 문제 몇 번 겪어본 사람이면 대부분 동의할 문제긴 한데 structured log 사용이나 application metric 측정 등은 오래 Wrap errors Error handler wrapper function을 이용해서 error code(annotation 포","tags":["golang","go"],"title":"(요약) How to ship production-grade Go","uri":"https://cychong47.github.io/2017/05/how-to-ship-production-grade-go/","year":"2017"},{"content":"Slack에서 제공하는 여러 가지 기능 중 하나로 \u0026ldquo;Do not disturb\u0026quot;가 있다. 아래는 그 기능을 설명한 블로그 글( Slack으로 막일을 줄여요 ~ 막일을 줄이기 위한 유용한 팁 2 )\nSlack 툴을 만든 회사 Slack에서의 문화를 따라 나온 기능이라고 하는데 직원들이 퇴근 후에도 회사 일에 연결되어 있다는 부담감을 없애주고 싶었단다.\n이 기능을 활용하면 사람들간에 저녁이나 주말에 나누고 싶은 정보가 있을 때, 각자의 설정에 따라 바로 알림을 받거나, 혹은 나중에 알 수도 있을 거다. 정보를 보내는 사람 관점에서는 보다 부담없이 나누고 싶은 이야기를 할 수 있지 않을까 싶은데.\n설정 화면을 보면 특정 채널에 대해서만 선별적으로 적용하는 것이 아니라 채널 전체에 대해서 적용되나 보다. 어떨까? Slack을 써보자고 하면 어떨까? 대부분 카톡을 쓰고 있어 귀찮아 할 것 같긴 한데. 거기에다 회사에서는 slack이 아닌 메신저나 M-chat을 써야 할텐니\n","id":108,"section":"posts","summary":"Slack에서 제공하는 여러 가지 기능 중 하나로 \u0026ldquo;Do not disturb\u0026quot;가 있다. 아래는 그 기능을 설명한 블로그 글( Slack으로 막일을 줄여요 ~ 막","tags":["slack"],"title":"Slack이 기능 중 하나 - 방해금지","uri":"https://cychong47.github.io/2017/04/slack-do-not-disturb/","year":"2017"},{"content":"요즘 재밌게 보고 있는 JTBC 윤식당. 이서진을 포함한 몇 명의 연기자가 해외에 식당을 내고 운영한다. 그나마 얼굴이 덜 알려진 해외에서 요리를 남에게 파는 행위를 해봤을 것 같지 않은 사람들이 모여 식당을 운영하는 걸 잔잔(?)한 톤으로 보여준다.\n그런데 우연히 읽은 글에서 \u0026lsquo;윤식당\u0026rsquo;과 스타트업을 연결한 걸 봤다.\nhttp://madedesignbyme.com/archives/1387\n 하지만 윤식당이란 타이틀처럼 식당장사를 하게되는데 그들은 이걸 처음 해보게 됩니다. 이들은 처음하는 식당을 어떻게하면 좋은 결과를 만들어 낼수 있는지 저녁을 먹으며 연구하고 그 다음날 아침, 전날의 피드백을 반영하기위해 식재료를 사러가는 것으로 그날의 하루를 시작합니다.\n 그러고 보니 매일 저녁 그날 장사를 회고하고, 다음 날 장사를 대비하여 새로운 메뉴를 개발하거나 영업 시간 등을 협의하여 개선해 나간다.\n1호점을 유지할 수 없어 새로운 장소로 옮겨야 하는 상황에서도 새로운 상황에 맞게 유연(?)하게 대응해 간다. 그것도 하루만에 빠르게. 할 수 있는 모든 사람이 힘을 합쳐\n주방팀에서는 종종 나와서 직접 고객의 feedback을 확인한다. 고객이 먹는 모습을 보기도 하고, 음식에 만족하는지 직접 물어보기도 하고, 다 먹은 식판에서 어떤 재료가 남았는지(좋아하지 않는지), 혹시 양은 많은 지 등을 확인해서 반영한다.\n스타트업 혹은 Agile에서 이야기하는 기민함을 보여주는 프로그램인 듯. 나피디는 실은 IT인?\n","id":109,"section":"posts","summary":"요즘 재밌게 보고 있는 JTBC 윤식당. 이서진을 포함한 몇 명의 연기자가 해외에 식당을 내고 운영한다. 그나마 얼굴이 덜 알려진 해외에서 요리를 남에게 파는 행위를 해봤을 것","tags":["agile","startup","feedback","윤식당","jtbc"],"title":"윤식당에서 배우는 agile","uri":"https://cychong47.github.io/2017/04/younkitchen-agile/","year":"2017"},{"content":"Slack에 개인 채널(?)을 만들었다. 이런 저런 내가 수집(?)하는 정보들을 한 군데서 모아서 히스토리를 만들면 어떨까 하는 생각에\n누구는 slack과 빌드 상황도 연동해서 사용한다고 하는데 그건 좀 공부가 필요해 보이고, 일단 제일 쉬워 보이는 ghost와 연동을 시도해 봤다.\nGhost의 admin 화면에서 Apps를 선택하면 이런 화면이 나온다.\n여기서 Slack항목의 Active를 선택하면 slack와 연동할 수 있는 URL을 입력하라고 나온다. 아래는 이미 연동이 된 상태로 처음 선택한 경우에는 URL 아래에 있는 \u0026ldquo;Set up a new incoming webhook here\u0026quot;의 here를 선택한다.\n\u0026lsquo;here\u0026rsquo;를 선택하면 나오는 화면에서 ghost와 연결할 slack channel을 선택하고 \u0026ldquo;Add incoming WebHooks integration\u0026quot;을 누르면 나오는 화면에서 URL을 복사해서 위의 ghost/apps/slack 화면에 입력하면 된다.\n그 다음부터 ghost에 새로운 글을 쓴 경우 다음과 같이 slack의 채널에 알림이 함께 올라온다. 위 화면을 보니 이상하게 글의 링크가 localhost로 나와 확인해보니 ghost의 config.js에 url: 'http://localhost:2368',와 같이 설정되어 있었다는\u0026hellip;\n이 부분을 고치고 다시 실행했으니 이제 이 글을 올리면 제대로 된 URL이 나올 듯\n추가) 예상대로 수정 후에 글이 제대로 나온다\n","id":110,"section":"posts","summary":"Slack에 개인 채널(?)을 만들었다. 이런 저런 내가 수집(?)하는 정보들을 한 군데서 모아서 히스토리를 만들면 어떨까 하는 생각에 누구는 slack과 빌드","tags":["ghost","slack"],"title":"Slack + Ghost","uri":"https://cychong47.github.io/2017/04/slack-ghost/","year":"2017"},{"content":"From Ericsson \u0026ldquo;Fueling 5G with DevOps\u0026rdquo;\n Maintaining one track in software development, using feature flag-driven development, and establishing version-controlled repositories for application code and application and system configuration data enables teams to create a complete environment that is ready for consistent “build and deploy”.\n What is feature flag-driven development? 특정 feature에 대해 일부 고객(예를 들면 전체 고객 중 1%)에 대해서만 먼저 적용한 후 feedback에 따라 확대 적용할 지 rollback할 지를 결정하는 방식\n문제가 발생하여 기능을 Rollback을 해야 하는 경우라도 일부 고객에만 영향을 주므로 부담이 적다는\nWaterfall, Agile과의 비교. Agile의 경우도 deploy 시점에는 all-or-nothing 방식으로 적용하는 것이 아니냐는 생각인 듯.\nRelated readings  FFDD에 대한 Reddit Feature branch와의 비교에 대한 의견 FFDD에 대한 Hacker News 사이트의 의견들 FFDD가 아닌 module flag-driven development(자체 용어)를 낫다는 의견(Management agrees which set of features is released in a group as a module) FFDD는 수 많은 if들로 코드가 복잡해 진다는 의견. 이를 위해 removal branch를 운영한다는 의견도 FFDD 관련 솔류션을 제공하는 LaunchDarkly에서 공유한 FFDD 관련 가이드 LaunchDarkly에서 운영하는 Hub for FFDD  ","id":111,"section":"posts","summary":"From Ericsson \u0026ldquo;Fueling 5G with DevOps\u0026rdquo; Maintaining one track in software development, using feature flag-driven development, and establishing version-controlled repositories for application code and application and system configuration data enables teams to create a complete environment that is ready for consistent “build and deploy”. What is feature flag-driven development? 특정 feature","tags":["continuous deployment","feature flag driven development"],"title":"Feature Flag Driven Development","uri":"https://cychong47.github.io/2017/04/feature-flag-driven-development/","year":"2017"},{"content":"Google Fellow Amin Vahdat,\n “Early on, we realized that the network we needed to support our services did not exist and could not be bought,”\n Espresso makes Google cloud faster, more available and cost effective by extending SDN to the public internet\n network should be treated as a large-scale distributed system leveraging the same control infrastructure we developed for Google’s compute and storage systems  Four pillars on Google\u0026rsquo;s SDN strategy  Jupiter: Google employed SDN principles to build Jupiter, a data center interconnect capable of supporting more than 100,000 servers. As of 2013 it supports more than 1 Pb/s of total bandwidth to host its services. B4 WAN interconnect: Google constructed B4 to connect its data centers to one another to replicate data in real-time between individual campuses. “It’s built on white boxes with our software controlling it,” said Vahdat at today’s session. “Our goal was to build a copy network. As it’s grown it’s become mission critical. B4 grows faster than our public network.” Andromeda: Google’s Andromeda is a network functions virtualization (NFV) stack that allows it to deliver the same capabilities available to its native applications all the way to containers and virtual machines running on the Google Cloud Platform. Espresso : Google\u0026rsquo;s peering edge architecture. Select the optimal internal server and route based on the real-time information  Background  For example, consider real-time voice search. Answering the question “What’s the latest news?” with Google Assistant requires a fast, low-latency connection from a user’s device to the edge of Google’s network, and from the edge of our network to one of our data centers. Once inside a data center, hundreds—or even thousands—of individual servers must consult vast amounts of data to score the mapping of an audio recording to possible phrases in one of many languages and dialects. The resulting phrase is then passed to another cluster to perform a web search, consulting a real-time index of internet content. The results are then gathered, scored and returned to the edge of Google’s network back to the end user.\n Innovation  dynamically choose from where to serve individual users based on measurements of how end-to-end network connections are performing in real time. separate the logic and control of traffic management from the confines of individual router “boxes. Rather than relying on thousands of individual routers to manage and learn from packet streams, we push the functionality to a distributed system that extracts the aggregate information.  Reference https://www.sdxcentral.com/articles/news/google-brings-sdn-public-internet/2017/04/\nhttps://blog.google/topics/google-cloud/making-google-cloud-faster-more-available-and-cost-effective-extending-sdn-public-internet-espresso/\n","id":112,"section":"posts","summary":"Google Fellow Amin Vahdat,\n “Early on, we realized that the network we needed to support our services did not exist and could not be bought,”\n Espresso makes Google cloud faster, more available and cost effective by extending SDN to the public internet\n network should be treated as a large-scale distributed system leveraging the same control infrastructure we developed for Google’s compute and storage systems  Four pillars on Google\u0026rsquo;s SDN strategy  Jupiter: Google employed SDN principles to build Jupiter, a data center interconnect capable of supporting more than 100,000 servers.","tags":["SDN","google","espresso","jupiter","b4","andromeda"],"title":"Espresso - Google's peering edge architecture","uri":"https://cychong47.github.io/2017/04/espresso-googles-peering-edge-architecture/","year":"2017"},{"content":"","id":113,"section":"posts","summary":"","tags":["message queue","microservice"],"title":"Why message queue used for microservice?","uri":"https://cychong47.github.io/2017/04/why-message-queue-used-for-microservice/","year":"2017"},{"content":"Open source language for \u0026ldquo;Programming Protocol-independent Packet Processor\u0026rdquo;\nhttp://p4.org\n Barefoot network - Tofino - PISA(Protocol Independent Switch Architecture) switch Netronome - smart NIC   5G: flexibility or high performance? Both - Ericsson Research Blog   POF/PIF and P4 initiatives all point in a direction where programmable packet processing will not depend on standardized OpenFlow action sets anymore\nPOF : Protocol Oblivious Forwarding PIF : Protocol Independent Forwarding\n  OF-PI P4 in wikipedia p4 in ONRC Revolutionising networking technology from newelectronics P4: driving innovation in server-based networking (Jan 4 2017) Extern objects in P4:an ROHC Compression Case study  ","id":114,"section":"posts","summary":"Open source language for \u0026ldquo;Programming Protocol-independent Packet Processor\u0026rdquo;\nhttp://p4.org\n Barefoot network - Tofino - PISA(Protocol Independent Switch Architecture) switch Netronome - smart NIC   5G: flexibility or high performance? Both - Ericsson Research Blog   POF/PIF and P4 initiatives all point in a direction where programmable packet processing will not depend on standardized OpenFlow action sets anymore\nPOF : Protocol Oblivious Forwarding PIF : Protocol Independent Forwarding","tags":["p4"],"title":"P4","uri":"https://cychong47.github.io/2017/04/p4/","year":"2017"},{"content":" They are going to have to make a choice here - do you want to be at the table or on the plate?\n 먹을래 먹힐래?\n","id":115,"section":"posts","summary":"They are going to have to make a choice here - do you want to be at the table or on the plate? 먹을래 먹힐래?","tags":["english"],"title":"Table or dish","uri":"https://cychong47.github.io/2017/04/table-or-dish/","year":"2017"},{"content":"지금 집에 있는 두 대의 mac mini를 이용해서 각각 wordpress와 ghost를 돌리고 있다.\nwordpress의 경우 2013년부터 시작한 블로그를 운영하는데 사용하고 있는데, 웹호스팅 회사 몇 군데를 전전하다 몇 년 전부터 집에 있는 mac mini 2009에 MAMP를 이용해서 자체 서버를 이용하고 있었다.\nGhost는 내가 좋아하는 markdown을 기본으로 사용하는 블로그 툴을 찾다 만났는데 지금은 사라졌지만 초기 홈페이지에 있던 멋진 dashboard에 낚여 설치했다. Open source 답지 않고 느린 개발 속도가 이해되지는 않지만, 여전히 markdwon을 제대로 지원하는 흔치 않은 설치형 블로그 툴이라 아직 희망을 버리지 않고 사용하고 있다. 현재는 0.11.2 버전이 공식 stable 버전이고 올해 나올 걸로 예상되는 1.0의 alpha 버전이 개발중이다.\nGhost역시 mac mini 2009에 node.js를 설치해서 그냥(?) 사용하다, docker for mac이 나온 걸 보고 mac mini 2011로 옮겼다. Docker for mac이 mac mini 2009를 지원하지 않는 바람에 -_-;;;\n초반에는 official docker image가 없어 다른 사람이 패키징해 놓은 걸 사용하고, 블로그 글 역시 docker container 안에 저장하다 이번에 정비를 하면서 official ghost image를 사용하고, 블로그 글도 container 밖에 저장하는 방식으로 변경하기로 했다.\nghost $ docker run -d -p 2368:2368 -v ~/Dropbox/Apps/ghost:/var/lib/ghost ghost  ghost의 데이터 파일이 저장되는 기본 위치인 /var/lib/ghost를 실제로는 ~/Dropbox/Apps/ghost위치로 지정하여 사용. 즉 docker를 실행할 때 ~/Dropbox/Apps/ghost 를 container에게 /var/lib/ghost로 인지하도록 하여 하여 container 내부에 ghost 블로그의 정보가 저장되지 않고 host 쪽에 저장되도록 했다. 이렇게 해야 행여 docker instance가 제대로 동작하지 않아도 데이터를 살릴 수 있다. 거기에 데이터 저장 위치를 아예 dropbox 위치로 지정해서 데이터가 자동으로 백업되도록 함.\n이제는 kitematic을 사용해서 동작 중. kitematic에서 제공하는 docker hub browsing 기능을 이용해서 ghost 최신 버전으로 업데이트해서 사용 중. Volume 외에 포트 값 등은 모두 기본값을 그대로 사용 중.\nwordpress wordpress는 좀 복잡하다. ghost도 실은 mysql을 사용하면 하나가 아닌 2개의 container를 연동해서 사용해야 하는데 실은 sqlite를 사용해서 간단한 것이라.\nwordpress는 ghost와 달리 다음과 같은 복잡성을 해결해야 한다.\n mysql과 wordpress의 2개 container를 연동해야 함 기존 MAMP(Mac/Apache/Mysql/PHP)를 통해 운영하던 기존 wordpress의 정보를 import해야 함 docker로 운영하는 mysql에 저장되는 블로그 정보를 mysql container내가 아닌 host 에 저장하도록 설정해야 함. wp-content에 저장하는 upload 파일 역시 wordpress container내가 아닌 외부에 저장하도록 해야 함  이 중 3번째는 mysql container의 volume 옵션을 사용하면 된다.\nwordpress의 파일들이 저장될 위치 /var/www/html위치도 host 머신의 `~/Documents/wordpress\u0026rsquo;를 사용하도록 지정했다.\n그리고 나서 RESTART를 선택하면 다음과 같이 wordpress가 실행된다. 왼쪽 console의 복잡한 내용은 모르겠지만, 오른쪽에 나오는 작은 화면을 보면 wordpress를 설치할 때 나오는 화면이 떴다는 것을 알 수 있다.\n그런데 이상하게 mysql에 연결이 안되어 결국 kitematic으로 wordpress를 실행하는 것은 포기하고 cli 명령을 이용해서 wordpress container를 새로 생성했다.\ncychong:~ cychong$ docker run --restart=always -e WORDPRESS_DB_PASSWORD=blog -d --name wordpress --link mysql:mysql -p 80:80 -v ~/Documents/wordpress:/var/www/html wordpress 3a0a8163171a54152a9281c2638b02046d0b99aaa018242d1b4c08a7511aa579  kitematic으로 설정한 경우 문제가 mysql에 연결이 안되는 것인데 서로 다른 container에서 동작하는 wordpress오 mysql을 연결시켜주는 것이 안되는 듯 한다. cli 명령에는 --link 옵션으로 mysql을 다른 container인 mysql에서 찾아오라고 명시적으로 지정하는 듯 한데 이와 관련된 설정을 kitematic에서 찾지 못했다. 일단 cli로 실행한 후에는 kitematic에서 실행한 것과 동일하게 container에 대한 정보를 볼 수 있는데 여기서도 특별히 mysql container와의 연결에 대한 내용을 찾지 못했다.\nwordpress 데이터 이전 이전 wordpress에서 tools / export 기능을 이용해서 post와 pages 등을 모두 export한 후 Wordpress docker에서 import를 하려는데 php에서 허용하는 upload file의 최대 크기가 2MB다. 이전 wordpress에서 export한 데이터 파일은 9.4MB인데\u0026hellip;\n이런 경우 이전에는 php.ini파일의 설정을 변경해서 파일 크기를 늘리는 방식으로 해결했는데 docker에서는 이 파일 정보가 없단다. 구글링을 해보니 docker 환경이라 해결방법이 다르다.\nhttps://github.com/docker-library/wordpress/issues/10\n위 글을 읽어보니 container image는 가능한 default와 동일하게 하고, 서로 다른 쓰임에 딸라 달라지는 부분은 가변부로 처리하게 한다는 것이 정책이라는 거다. base repository라면 당연하다는 생각이 들었다. 그래서 대부분의 사람들이 제안하는 방법 역시 dockerfile을 수정해서 docker를 생성할 때 아래 파일을 넣어주거나 하는 방법이거나 host에 필요한 파일을 만들어 놓고 그 파일을 container가 찾는 위치에 mount되도록 하는 방법이 주 였다.\n처음에는 이런 생각을 못하고 그냥 container 내 파일을 만들어 wordpress가 인식되기를 기대(?)했는데 일단 변경 사항이 반영되지도 않고(import 페이지를 화면에 보여줄 때 파일 크기 값을 읽어서 사용할 거라 기대했는데) 반영이 된다 하더라도 container를 종료했다 다시 실행하면 어차피 아래 파일이 사라지고 없을 거라는 생각이 들었다.\n# pwd /usr/local/etc/php/conf.d # cat \u0026gt; uploads.ini file_uploads = On memory_limit = 64M upload_max_filesize = 64M post_max_size = 64M max_execution_time = 600  문제는 이미 만들어진 docker container에 이런 파일 정보를 추가하는 것은 불가능하다는 점. 그러므로 다시 wordpress container를 새로 만들면서 위의 파일 정보도 함께 추가해야 한다.\n$ vi /Users/cychong/Documents/wordpress/php_uploads.ini file_uploads = On memory_limit = 64M upload_max_filesize = 64M post_max_size = 64M max_execution_time = 600  이제 추가한 파일을 포함해서 다시 docker instance를 생성(이전 wordpress instance를 제거하고)\ncychong:~ cychong$ docker run --restart=always -e WORDPRESS_DB_PASSWORD=blog -d --name wordpress --link mysql:mysql -p 80:80 -v ~/Documents/wordpress:/var/www/html -v ~/Documents/wordpress/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini wordpress  container를 실행한 후 mount된 volume을 보면 다음과 같다.\n이제 다시 wordpress의 import 기능을 선택하면 파일 최대 크기가 2MB가 아니라 64MB로 변경되었음을 확인할 수 있다.\n이렇게 해서 기존 wordpress에서 export한 파일들을 무사히 import해 왔는데\u0026hellip;\n남은 문제 일단 지금까지 확인된 건\n 기존 wordpress에서 wordpress의 첨부 파일 위치 정보가 모두 http://sosa0sa.com/wp/wp-content 이런 형식이었는데 이번에는 http://sosa0sa.com/wp-content로 되어 버렸네. 아마도 volume mapping하는 부분을 조정(?)하면 될지도 모르겠는데 아예 이번에 모두 정리하는 걸 고민해 봐야겠다. 어차피. URL이 저장된 정보가 xml파일이나 sql 파일 등에 있는 text라.  아니면 wordpress/settings에 있는 wordpress base url(?) 정보를 변경하면 될 지도 모르겠다.\n!!! 망했다. 혹시나 하고 위 마지막에 적은 내용을 적용했더니 wordpress자체가 접속이 안된다. wp-config.php파일 등에도 이 정보가 없던데. 그냥 아래 내용까지 고려해서 다시 해결할까? 아님 이참에 ghost로 확 이전?. 이건 ghost 1.0이 나오고 나서 생각해 보고 !!!\n이건 늘 wordpress를 설치할 때마다 겪는 문제인데\u0026hellip; markdown으로 작성한 글들을 보기 위해 jetpack을 설치하는데 jetpack을 설치하더라도 제대로 markdown 파일 형식이 렌더링 되지 않는다. 덕분에 문단 편집도 이상하게 보이고, 그림은 보이지도 않고. 일일이 글 하나 하나 마다 dashboard를 통해 한번 update를 해줘야 제대로 보이는데 이게 유일한 방법인지. 도저히 불가능한 방법이라\u0026hellip;. 해결책을 찾아봐야겠다.  벌써 새벽 1:40분이다. 이제 그만하고 자야겠다.\n2017/04/07 00:33 update). 간단(?)하게 wordpress container를 삭제하고 새로 설치했다. mysql은 그냥 mysql 정보가 저장되는 디렉토리의 파일을 삭제했다. (mysql container에게 /var/lib/mysql로 매핑한 디렉토리) DB내 저장된 블로그 글들에 지금과 다른 link를 가진 부분이 많이 있고, 위 1번 문제에서 언급한 망한 문제 관련된 내용이 mysql DB내 저장되어 있을 듯 해서 깔끔하게 초기화를 하려고 기존 파일들을 삭제했다.\nWordpress container를 만든 후 한 첫번째 작업은 Jetpack에서 markdown관련 내용을 켠 것이다. 이 작업은 Jetpack을 설치하면 생기는 admin의 Jetpack 메뉴가 아니라 plugins에 있는 Jetpack 의 setting 항목에서 지정했다. 그 다음 activate를 선택했다. 이 순서가 중요한 건지 모르겠다.\n그 다음 이전 wordpress에서 export한 xml 파일을 vi를 이용해서 http://sosa0sa.com/wp/를 http://sosa0sa.com/으로 일괄 변경한 후 다시 import했다. 일부 항목은 http://sosa0sa.com/wp/이 아니라 그냥 http://sosa0sa.com/wp로 되어 있는 경우도 있어 이 부분은 따로 찾아서 수정했다.\n그리고 나서 다시 웹페이지를 여니 짠. markdown으로 작성한 글도 제대로 보이고(그림도 제대로 보이고) 전반적으로 제대로 동작하는 듯 하다. 이제 이틀 밤에 걸쳐 진행한 wordpress 블로그의 docker로의 이전이 얼추 정리가 된 듯 하다.\n참고 mycontainer에 shell로 접속하려면\n$ docker exec -it \u0026lt;mycontainer\u0026gt; bash  ","id":116,"section":"posts","summary":"지금 집에 있는 두 대의 mac mini를 이용해서 각각 wordpress와 ghost를 돌리고 있다. wordpress의 경우 2013년부터 시작한 블로그를 운","tags":["docker","ghost","container","wordpress"],"title":"Move to docker","uri":"https://cychong47.github.io/2017/04/move-to-docker/","year":"2017"},{"content":"만독  책을 느리게(집중해서) 읽기 아이에게 책 읽어주기  부모가 읽어야 아이도 읽는다   1단계. 책 선정  초등학생이면 어휘가 풍부한 국내 소설 오래 살아남은 책. 고전 문학   2단계. 반복해서 읽기 3단계. 파생독서 하기  저자의 다른 책 저자가 참고한 책 비슷한 주제의 책   4단계. 챕터별 요약하기 5단계. 챕터별로 생각 적어보기  책을 읽으면 추가 자료와, 자신의 생각을 곁들여 정리   6단계. 장문 쓰기  다독  고정형/성장형 생각  특히 힘든 시기에 영향을 줌 갑자기 어려워지는 중학교 시절 두뇌도 근육과 같다. 능력을 키울 수 있다. 당신이 할 수 있다고 생각하든, 할 수 없다고 생각하든 생각하는 대로 될 것이다.   나도 책을 많이 읽을 수 있다!  남독  다양하게 읽기 수용적/비판적/창의적 사고  수렴적 vs. 발산성 지능 수렴적 - 성실 발산성 - 창의. 변칙 위기때는 발산성 지능이 필요    관독  ‘Seeing is believing”?  시각은 뇌를 속인다 ‘본 것’이 아니라 ‘봤다고 생각’한 것   저자의 관점을 이해하기 특정 관점을 가지고 책을 보기  재독  좋은 부모  안정적인 기지 마련 기지를 거점삼아 세상을 마음껏 탐구하도록 격려    필독  쓰면서 읽기  메모 남기기 다시 읽을 때 나의 관점을 기억   망각  10분 호 망각 시작, 한 시간 뒤 50%, 하루 뒤 70%, 한달 뒤 80% 망각   글은 제기하고자 하는 주제의 근거를 제시하고 타당성 입증  좋은 자료가 성패를 가른다   짧게 써야 읽힌다  ","id":117,"section":"posts","summary":"만독 책을 느리게(집중해서) 읽기 아이에게 책 읽어주기 부모가 읽어야 아이도 읽는다 1단계. 책 선정 초등학생이면 어휘가 풍부한 국내 소설 오래 살아남은 책. 고전 문","tags":["Book"],"title":"(책) 어떻게 읽을 것인가 - 2","uri":"https://cychong47.github.io/2016/06/how-to-read-2/","year":"2016"},{"content":" 고정형 - 지능은 변하지 않는다\n성장형 - 지능은 좋아질 수 있다\n 생각을 바꾼다는 것이 쉬운 일은 아니지만 인식의 변화가 주는 효과는 크다\n 중학교에서는 고정형 아이들의 성적이 급속히 떨어지고 지속적으로 하양곡선을 그림. 중학생이 되면 초등학교 과정과 질적으로 더 어려운 학과 공부에 직면하므로 실패와 좌절을 할 가능성이 더 많은데 고정형 학생들은 실패와 좌절에 더 큰 영향을 받기 때문\n 힘든 상황에서 더 큰 영향을 준다.\n 두뇌는 근육과 같이 운동을 통해 근육을 키우듯 두뇌 능력을 키울 수 있다. 필요한 건 시간과 노력이다.\n 일단 믿어 보자.\n 당신이 할 수 있다고 생각하든, 할 수 없다고 생각하든 생각하는 대로 될 것이다.\n 명언\n 다독을 하려면 성장형 사고방식을 갖다. 처음에는 힘들지만 뇌는 책 읽는 뇌로 변할 수 있다.\n \u0026ldquo;난 책하고 안 맞아\u0026quot;라는 생각이 들때 성장형 사고방식으로 한번 시도해 보자.\n 내 편견을 자극하고 그럴듯 해 보이면 명저로 생각하기 쉽다.\n 내가 미처 생각하지 못했던 걸 알려준다고 다 명저는 아니다.\n 수용적 사고, 비판적 사고, 창의적 사고\n수렴성 지능과 발산성 지능.\n수렴적 사고는 위기가 없으며 일상적이고 반복적인 세계에서는 유용할지 모르지만, 예기치 못한 위기가 닥쳐오고 변칙적인 상황이 되면 오히려 역효과를 낼 수 있다. 새로운 상황에서는 새로운 생각, 곧 창의적인 생각이 필요하며, 실제로 급변하는 세상에서 최고의 부가가치를 내고 있는 것들은 모두 창의적 사고의 부산물을 통해서다.\n 위기의 시절에는 좀 나내는 사람이 필요하다.\n 책을 선정했으면 챕터별로 정리를 하되, 그냥 요약하지 말고 관련 주제를 담은 책이나 인터넷에서 자료를 토대로 자신의 견해를 덧붙여 완성된 글로 만들어라.\n 내 생각을 곁들이고, 책에 없는 내용을 \u0026ldquo;찾아서\u0026rdquo; 함께 정리하면 더 오래 기억에 남는다.\n Seeing is believing. But sometimes not\n‘본다’는 것은 철저히 주관적 행위이다. 객관적 시선이란 허상이며, 우리에게는 오직 주관적 관점만이 있을 뿐이다.\n 분명히 \u0026lsquo;본 것\u0026rsquo;이라고 다 사실은 아니다. \u0026lsquo;본 것\u0026rsquo;이라고 착각할 수도 있고, 맥락을 모른 체 본 것은 \u0026lsquo;주관적 판단\u0026rsquo;에 의해 \u0026lsquo;사실\u0026rsquo;과 다른 기억을 갖게 할 수 있다.\n ‘생각의 탄생’에서는 ‘명백히 달라 보이는 두 개의 사물이 중요한 특질과 기능을 공유하고 있음을 깨닫는 일이야말로, 세계에서 가장 위대한 학문과 예술작품, 불후의 과학이론, 공학적 발명을 이루어내는 일의 중심에 놓여 있는 것이다’\n  ‘좋은 부모는 아이에게 안정적인 기지를 마련해 주고, 아이가 그 기지를 거점 삼아 마음껏 세상을 탐구할 수 있도록 격려한다\u0026rsquo;라고 말했다.\n 부모의 의무\n 고통의 경중보다 고통에 대한 대응이 행복과 불행을 갈라 놓는 가장 중요한 키워드임을 밝혀냈다. ‘성숙한 방어기제’를 갖고 있는 사람일수록 행복을 빼앗기지 않는다.\n 상황보다 상황에 대한 대응이 그 \u0026lsquo;상황\u0026rsquo;으로 인한 결과를 만들어낸다.\n 헤르만 에빙하우스.\n 학습 후 10분 후부터 망각 시작 한 시간 뒤에는 50% 하루 뒤에는 70% 한달 뒤에는 80%를 망각  단순히 읽는 것이 아니라 열심히 학습을 하더라도 하루가 지나면 열에 일곱은 사라진다.\n 잊는 게 자연스러운 거다. 자신의 기억력을 탓하지 말고 반복해서 읽거나 적어서 보완하자\n 글은 자신이 제기하고자 하는 주제의 근거를 제시하고 그 타당성을 입증해 보이는 싸움이다. 이 싸움은 좋은 자료를 얼마나 많이 모으느냐에 성패가 좌우된다. 자료가 충분하면 그 안에 반드시 길이 있다. 자료를 찾다보면 새로운 생각이 떠오른다.\n 논리 싸움. 근거는 곧 총알\n 퓰리처. “무엇이든 짧게 써라. 그러면 읽힐 것이다”\n 일단 짧아야 눈이 간다\n","id":118,"section":"posts","summary":"고정형 - 지능은 변하지 않는다 성장형 - 지능은 좋아질 수 있다 생각을 바꾼다는 것이 쉬운 일은 아니지만 인식의 변화가 주는 효과는 크다 중학교에서는 고정형 아이들의 성","tags":["Book"],"title":"(책) 어떻게 읽을 것인가","uri":"https://cychong47.github.io/2016/06/how-to-read/","year":"2016"},{"content":" fossilize also -lise\n(usually passive) if people, ideas, systems etc fossilize or are fossilized, they never change or develop, even when there are good reasons why they should change\n Most couples, however fossilized their relationship, have some interests in common.\n 간혹 팟캐스트에 공룡에 대한 이야기가 나온다. 공룡에 대한 연구가 상대적으로 오래되지 않고, 현존하지 않은 생명체에 대한 거라 발굴된 화석에 의존해서 복원해야 해서 그 복원 결과가 시간에 따라 달라진다고 한다. 새로운 증거나 보다 논리적인 설명이 나오면 그걸로 기존의 가설의 결과가 달라진다고. 예를 들면 티라노사우르스가 빠르게 달리는 것처럼 알려졌지만, 요즈음은 티라노사우르스는 뛰지 못했다는 게 정설이다. 몸무게 덕에 뛰었다간 무릎이 다 망가진다고.\n아무튼 오늘 들은 재밌는(실은 황당하고 어이없는) 이야기는 코드에 주석이 적다고 구박하고, 코드 제일 위에 있는 file comment에 수정 이력을 안 적었다고 구박한단다. 이미 화석화된 지식이다. 주석이 필요없게 코드를 작성하는게 가장 좋은 거고, 주석은 정말 필요한 부분에만 \u0026lsquo;왜\u0026rsquo;에 대해서 적으라는 것이 요즘 트렌드다(적어도 내가 이해하기엔. 내가 그렇게 못하더라도) 그리고 파일 수정 이력은 예전부터 쓰고 있는 소스 관리 시스템에 다 있는 정보라 쓸데없이 파일에 쓰는 건 권장하지 않는다. 코드 열었을 때 몇 장에 걸쳐서 구구절절 이력이 있다면.\n혹여 소스 관리 시스템에서 변경 이력을 찾기 어려워서 저런 말을 했을 거라고는 생각하지 않는다.\n개발자 뿐만 아니라 개발자랑 같이 일하는 관리자도 계속해서 공부해야 한다. 저런 엉뚱한 이야기를 안하려면\n","id":119,"section":"posts","summary":"fossilize also -lise (usually passive) if people, ideas, systems etc fossilize or are fossilized, they never change or develop, even when there are good reasons why they should change Most couples, however fossilized their relationship, have some interests in common. 간혹 팟캐스트에 공룡에 대한 이야기가 나온다. 공룡에 대한 연구가 상대","tags":["anti-work pattern"],"title":"fossilization","uri":"https://cychong47.github.io/2016/05/fossilization/","year":"2016"},{"content":"먼저 주변을 의심해 보자.\n상식적인 혹은 알려진 것과 다른 결과가 나왔다면 내가 한 시험 방법을 다시 한번 의심해 보자. 제발\n","id":120,"section":"posts","summary":"먼저 주변을 의심해 보자. 상식적인 혹은 알려진 것과 다른 결과가 나왔다면 내가 한 시험 방법을 다시 한번 의심해 보자. 제발","tags":["anti-work pattern"],"title":"상식과 다른 결과를 보면","uri":"https://cychong47.github.io/2016/05/too-early-confident/","year":"2016"},{"content":"개발자의 품을 가벼이 여기는 조직에서 일 할때는 일정보다 일을 빨리하면 안된다. 기껏 한 일이 아무 소용없을 때가 많다.\n","id":121,"section":"posts","summary":"개발자의 품을 가벼이 여기는 조직에서 일 할때는 일정보다 일을 빨리하면 안된다. 기껏 한 일이 아무 소용없을 때가 많다.","tags":["anti-work pattern"],"title":"빨리 해봐야 소용없다","uri":"https://cychong47.github.io/2016/05/no-need-to-rush/","year":"2016"},{"content":"theme을 수정해서 ghost blog 화면에서 글 본문이 다 나오도록 할 수 있다.\n대신 theme마다 조금씩 적용 방법이 다른데 기본적으로 변경해야 할 내용은 동일\ncasper theme casper는 index.hbs 파일에서 loop.hbs라는 별도 파일을 통해 본문을 보이게 하고 있다.\nindex.hbs\n 21 {{! The main content area on the homepage }} 22 \u0026lt;main id=\u0026quot;content\u0026quot; class=\u0026quot;content\u0026quot; role=\u0026quot;main\u0026quot;\u0026gt; 23 24 {{! The tag below includes the post loop - partials/loop.hbs }} 25 {{\u0026gt; \u0026quot;loop\u0026quot;}} 26 27 \u0026lt;/main\u0026gt;  위 코드에서 가리키는 partials/loop.hbs 코드에서 exceprt인 부분을 찾아서 다음과 같이 변경한다. 아래에서 13라인부터 15라인이 원본으로 각 post의 일부만 보이게 하고, 더 읽으려면 \u0026gt;\u0026gt;등을 클릭하게 한다. 이 부분을 막고 post 전체를 표시하는 17라인에서 19라인까지의 내용을 추가한다.\npartials/loop.hbs\n 12 \u0026lt;!-- 13 \u0026lt;section class=\u0026quot;post-excerpt\u0026quot;\u0026gt; 14 \u0026lt;p\u0026gt;{{excerpt words=\u0026quot;26\u0026quot;}} \u0026lt;a class=\u0026quot;read-more\u0026quot; href=\u0026quot;{{url}}\u0026quot;\u0026gt;\u0026amp;raquo;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; 15 \u0026lt;/section\u0026gt; 16 --\u0026gt; 17 \u0026lt;section class=\u0026quot;post-content\u0026quot;\u0026gt; 18 {{content}} 19 \u0026lt;/section\u0026gt;  landyon theme 이건 별도의 loop.hbs없이 직접 index.hbs에서 처리하고 있어 보다 구조가 간단하다. 위 방법 역시 이 theme 파일을 분석(?)해서 알아냈다. Caspser theme에서와 동일하게 post-exceprt인 부분을 post-content class로 변경하면 동일하게 기본 화면에서 post 내용을 모두 볼 수 있다.\n참고로 post를 모두 보는 방법은 특정 post를 화면에 출력할 때 사용하는(것으로 추정되는) page.hbs파일의 내용을 통해 알아냈다.\n깔끔한 page.hbs\n{{!\u0026lt; default}} \u0026lt;article class=\u0026quot;{{post_class}}\u0026quot;\u0026gt; {{#post}} \u0026lt;h1 class=\u0026quot;post-title\u0026quot;\u0026gt;{{title}}\u0026lt;/h1\u0026gt; \u0026lt;section class=\u0026quot;post-content\u0026quot;\u0026gt; {{content}} \u0026lt;/section\u0026gt; {{/post}} \u0026lt;/article\u0026gt;  ","id":122,"section":"posts","summary":"theme을 수정해서 ghost blog 화면에서 글 본문이 다 나오도록 할 수 있다. 대신 theme마다 조금씩 적용 방법이 다른데 기본적으로 변경해야 할 내용은 동일 casper theme cas","tags":["ghost","theme"],"title":"Ghost 본문 다 보이기","uri":"https://cychong47.github.io/2016/05/display-post-by-default-ghost/","year":"2016"},{"content":"set environment export RTE_ARCH=x86_64 export RTE_SDK=/home/cychong/Work/dpdk-2.1.0 export RTE_TARGET=x86_64-native-linuxapp-gcc export RTE_OUTPUT=$RTE_SDK/$RTE_TARGET  run sudo ./build/ip_reassembly -c 0x1 -n 4 -m 1000M --no-huge --no-pci --no-hpet -- --display_pps 1 --tx_pps 10  ","id":123,"section":"posts","summary":"set environment export RTE_ARCH=x86_64 export RTE_SDK=/home/cychong/Work/dpdk-2.1.0 export RTE_TARGET=x86_64-native-linuxapp-gcc export RTE_OUTPUT=$RTE_SDK/$RTE_TARGET  run sudo ./build/ip_reassembly -c 0x1 -n 4 -m 1000M --no-huge --no-pci --no-hpet -- --display_pps 1 --tx_pps 10  ","tags":[],"title":"Frag \u0026 Reassembly Test","uri":"https://cychong47.github.io/2016/05/frag-reassembly-test/","year":"2016"},{"content":"2 다른 이들과 달리 멋지게 시작하라\n 자신의 경력을 사업으로 봐야 한다. 자신의 정체성이나 경력은 조직에서 주어진 역할과 별개로 존재한다고 생각 팔수 있는 제품이나 서비스가 필요 그 가치가 정확히 뭔지, 그 가치가 다른 개발자가 제공하는 가치와 어떻게 다른지 설명할 수 있어야 한다  3 목표를 설정하고 미래에 대비하라\n 목표를 설정. 목표를 정확히 이해  명확한 목표가 없으면 아무리 열심히 살아도 의미가 없다. 목표 없이 인생을 낭비하지 말라   큰 목표를 정하고 밟아갈 작은 목표를 설정  큰 목표는 방향을 제시할 정도만 되도 된다. 최종적으로이루고 싶은 꿈은? 큰 목표에 이르는 길목에 작은 목표들. 큰 목표에서 현재 상태까지 거꾸로 생각   매월, 혹은 매일 일정 분량을 읽고 학습하겠다는 더 작은 목표를 세운다 자신이 세운 목표를 주기적으로 살펴보고 필요할 때마다 조금씩 업데이트  4 소프트 스킬은 생각보다 중요하다\n 하고 싶은 말을 전부 내뱉지 말고 응원의 말만 하는 법을 배워야 당신이 원하는 바를 상대에게 와 닿는 방식으로 표현 어떤 기능을 왜 특정 방식으로 구현했는지 설명하기 보다 어떤 이득이 있는 지 알려주라 다른 이들도 논리적으로 사고할 거라는 착각. 확고한 논리를 제시하면 상대방도 자신의 사고방식을 받아들일 거라는 착각 어떤 수를 쓰든 논쟁을 피하라. 논쟁에서 이기는 유일한 방법은 논쟁을 피하는 것  7 전문성을 갖춰라\n 전문성이 높아질수록 잠재적 기회가 줄어드는 반면 기회를 잡을 확률은 올라간다 전문 분야 - 웹 개발 기술, 임베디드 시스템, 특정 OS, 모바일 개발, framework, SW system  9 승진하기\n 기회 만들기.  아무도 원하지 않는 legacy application이나 코드 중 문제가 많은 모듈 자신의 문제 외에 다른 이들의 문제까지 함께 부딪쳐 해결하다보면 많은 것을 배우고, 팀의 해결사라는 평판을 얻을 수 있다. 업무 절차를 기록하고, 이러한 문서를 항상 최신 정보로 채워두는 역할 누구나 피하려 하지만 당신이 맡아서 더 수월하게 하거나 자동화할 수 있는 일   존재감 있게 일하기  주간 보고서로 자신의 업무를 홍보 팀이 다뤄야 하는 주제나 문제에 대해 발표 의견을 분명히 밝힐 것. 언제 어디서든 기회가 있을 때마다 눈에 띄도록 노력. 정기적으로 상사와 만날 것. 꼭 자주 만날 것   학습하기 - 리더십, 관리, 비즈니스 등의 분야도 공부.  배운 내용을 다른 이들과 공유   해결사 되기  어떤 문제든 해결책을 제시하는 사람, 또 해결책을 실행할 수 있는 사람이 돼라    10 전문가 되기\n 전문가는 맡은 일과 경력을 진지하게 생각하는 사람 옳다고 생각하는 바를 실천하기 위해 손해를 감수하고 어려운 결정을 내릴 용기가 있는 사람 일을 맡겼을 때 제대로 완수할 것이라고 믿을 수 있는 사람 자신의 기술수준을 철저히 파악해두고 발전하고자 꾸준히 노력 답을 모를 때 스스럼없이 인정. 결국 해결책을 찾아내리라 믿을 수 있다 스스로 설정한 높은 작업 품질 수준을 한결같이 지킨다 약속을 어기지 않는다. 전문가가 되려면 좋은 습관부터  전문가다운 습관 사전 준비(회의 등) 매일 계획을 세워 시간을 효과적으로 관리하는 습관 그날 꼭 마쳐야 하는 일이 뭔지, 마칠 때까지 시간이 얼마나 될지 대략 예상 일관성이 있어야 다른 이들이 당신을 신뢰할 수 있다. 해야할 일을 가늠하고 우선 순위를 정한 뒤 업무에 착수 디테일까지 정해둔 품질 기준에 미치도록 노력. 적당히 만족하는 나쁜 습관은 버리도록    11 이렇게 독립하라\n So Good they Can\u0026rsquo;t ignore you. Cal Newport. Act Big, Think Small. 실력이 열정을 이긴다.  24 강연, 강의 그리고 발표\n 전문가인 척할 필요는 없다. 배운 내용을 공유한다는 마음으로 성의껏 임하라  27 학습 방법 익히기\n 배우려면 바로 실행에 올기자.(뒤에 나오는 10단계 참고)  28 10단계 학습법\n http://simpleprogrammer.com/ss-10steps 1단계. 큰 그림을 보라  학습이 아니라, 배울 주제에 어떤 내용이 있는 지, 범위가 어느정도 인지 등 큰 그림을 보는 일에 주력   2단계. 범위를 정하라  1단계에서 모은 정보를 활용하여 배우고자 하는 영역을 적절한 크기로 선택 학습 목적을 생각하여 적정 학습 범위 설정 범위 설정이 어려우면 시간부터 제한. 시간내 할 수 있는 범위를 대상으로 설정 예) 사진 배우기 -\u0026gt; 인물 사진 촬영용 디지털 사진 기술 배우기   3단계. 성공을 정의하라  성공 기준을 명확히 정의 성공 기준은 달성할 목표에 따라 정해야 목표가 명확하면 목표에서 거슬러 오면서 목표에 이르는 길을 생각할 수 있다 간결하게 한 문장으로 정의 예) C# 기초를 배우겠다 -\u0026gt; C#의 주요 기능을 활용해서 간단한 응용 프로그램을 만들겠다   4단계. 자료를 찾아라  선택한 주제에 대해 최대한 다양한 자료를 찾는다   5단계. 학습 계획을 세워라  자료를 바탕으로 무엇을 어떤 순서로 배울 지 정리 책의 목차처럼 학습 순서를 정리   6단계. 자료를 선별하라  수집한 자료 중 목표 달성에 도움이 될 가치가 있는 자료만 선별 중복을 피해 목표 달성에 가장 도움이 되는 자료를 고른다. 자료의 품질도 검증    31 멘토 찾기\n 누군가에게 도움을 구할 때는 자기가 아는 것이 정답이라는 생각을 버려야  32 멘토 되기\n 해당 주제에 대한 자신의 생각을 정리하고 새로운 관점에서 바라볼 기회가 됨 멘토 역할을 하려면 \u0026lsquo;왜?\u0026lsquo;라는 질문과 씨름해야 한다. \u0026ldquo;왜?\u0026ldquo;라는 질문을 마주해야 지금까지 자신이 그 답ㅇ르 모르고 있었다는 사실을 깨닫는다. 다른 사람을 돕기 위해 답을 찾는 동안 해당 주제를 깊이 있게 이해할 수 있으며, 때로는 생각이 완전히 달라지기도 한다.  33 가르치기\n 가르쳐본 경험이 있어야 전문가로 인정받음 다른 사람에게 무언가 가르치려면 해당 주제에 관한 어려운 문제를 정면으로 돌피해야 한다 단순히 아는 수준을 넘어 제대로 정확히 이해하는 수준까지 파헤쳐야 한다. 배운 내용은 금세 까먹어도 이해한 내용은 오래 간다. 가르칠 때는 겸손한 자세를 유지하되, 권위를 잃지 않고. 말에 확신과 자신감을 실어서 전달 당신이 즐겁게 배울 수 있게 도와준, 당신에게 가장 큰 영향을 끼친 선생님은 어떤 자질을 지니고 있었고, 어떤 방식으로 가르쳤는가?  35 지식의 빈틈 찾기\n 평소 유난히 시간이 많이 드는 부분이나 반복적으로 자주 하는 작업을 살펴볼 것 더 찾아볼 필요가 있거나 명확히 이해가 되지 않는 사항을 한데 모아서 적어두고, 그 문제를 얼마나 자주 마주치는 지 기록 정확히 무엇을 배워야 할 지 알아내라. 집중할 영역을 최대한 구체적이고 명확하게 설정  36 집중이 중요하다\n 생산적 != 효율적 생산적 : 많은 일을 하는 것 효율적 : 필요한 일을 하는 것 생산성에 가장 중요한 것은 집중  37 생산성 계획\n Kanbanflow  38 Pomodoro\n 뽀모도로/하루 목표 수립 및 수행 기록 대개 업무 예측에 대해 과장하는 착각 일을 더 해야 할 것 같은 죄책감. 하루에 해낼 수 있는 작업량을 모르고, 완료할 작업목표를 명확히 설정하지 않아서  39 할당 체계를 도입해 생산성을 높여라\n 매주 일정한 수준만큼 꾸준히 진행 진행 정도도 명확하게 측정 비가 오나 눈이 오나 변함없이 할당량 완수 일관성이 있어 시간에 따른 진척도를 측정/기록할 수 있다. 실천이 가장 중요 달성 가능하고 유지 가능한 할당량 선택 할당량은 무조건 완료. 할당량을 실천하는 도중에는 결코 규칙을 중단하거나 바꾸지 않아야 함 느리지만 꾸준한 속도로 일하는 게 빠르지만 지속성이 없는 것보다 낫다  40 책임감을 가져라\n 자기 자신에 대한 책임감 자제력은 스스로 동기를 부여할 수 있는 방법 자기 동기 부여의 핵심은 자기 책임감  41 멀티태스킹 규칙\n 일괄 처리가 훨씬 더 생산적 생산성을 떨어뜨리지 않는 조합의 작업 선택  42 탈진 극복하기\n 휴가에서 돌아와도 더 심한 탈진감. 내적 동기나 흥미에 대한 회복도 없고, 관성도 사라졌기 때문 시간이 지나면 처음 느꼈던 일에 대한 흥미는 떨어지는 것이 당연 해결책은 벽 너머의 일을 생각할 것 탈진이 오더라도 신경 쓰지 말고 고통을 견뎌야 한다. 벽을 넘어야 탈진을 \u0026lsquo;치유\u0026rsquo;할 수 있다. 고통을 견디는 것 이야말로 탈진을 극복하는 비결 벽을 넘기 위해서는 꾸준히 앞으로 나아가는 자신만의 규칙을 만들어야 함  43 낭비되는 시간 줄이기\n 당장 TV를 꺼라 TV 프로그램은 뇌에서 문제 해결을 담당하는 부위를 축소하고 머릿 속에 온갖 것을 주입한다 TV를 많이 볼수록 자신의 생각과 행동에 대한 자기 지배력을 잃어가는 꼴 하루 중 SNS 활동에 사용할 시간을 정해두고 몰아서 할 것 회의로 시간을 낭비하지 않는 가장 좋은 방법은 회의에 참석하지 않는 것 회의는 시간을 덜 소비하는 메일이나 전화 같은 다른 수단으로는 도저히 다룰 수 없는 사안일 때만 사용 시간을 어디에 썼는지 정확하게 알 수 있다면 시간을 가장 많이 낭비하는 요인을 찾아서 없앨 수 있다.  44 반복 행위의 중요성\n 자신의 삶과 목표 꿈을 위해 나아가기 위해 실제로 매일 노력하고 있는가? 매일 한 걸음씩 목표에 다가갈 반복 행위를 만든다면 결국 목표를 달성할 수 있지 않을까? 지금이 바로 행동에 옮길 때. 내일이나 다음 주는 없다. 지금이어야 한다. 좋은 반복 행위는 큰 목표를 정하는 것에서부터 시작 큰 목표를 정한 후 목표를 달성할 수 있는 단계를 생각 목표를 이룰 일정을 결정 반복 행위 일정. 예) TV보는 시간 30분 대신 글 읽기/쓰기 등 반복 행위가 내가 이룬 성공의 기반 매일 30분씩 규칙적으로 내 업무와 관련 있는 기술을 공부. \u0026lsquo;연구 시간\u0026rsquo;  45 코드 손질하듯 습관 개발하기\n \u0026lsquo;당신이 반복하는 일이 당신을 규정한다. 위대함은 하나의 행위가 아니라 습관에서 온다\u0026rsquo; 아리스토텔레스 습관 = (신호, 반복 행위 , 보상) 나쁜 습관을 인식하는 가장 좋은 방법은 늘 하는 일 중 죄책감이 느껴지는 것을 찾아보기. 그만두고 싶지만 지끔껏 미뤄왔던 습관 가장 어려운 것은 새 습관이 예전 습관을 밀어내고 자리잡을 때까지 충분히 오랜 기간 동안 노력 새로운 습관을 잘 만들려면 충분한 시간을 들여 반복 행위를 해야 함 Http://ejohn.org/blog/write-code-every-day  46 작업 분할하기\n 일을 미루는 이유는 문제에 압도되기 때문 문제의 크기가 크다고 놀라느라 실제로 문제를 해결할 생각을 하지 못함 인간은 먼 미래를 보지 못하는 존재 -\u0026gt; 큰 작업을 받으면 심리적으로 압박을 받는 동시에 생산성도 떨어짐. 문제를 해결하려 하기보다 문제 자체를 생각하는데 시간을 더 많이 씀. 인간에게는 가장 편한 길을 택하려는 습성 큰 작업을 작은 작업으로 나눠야 하는 이유  작업은 클수록 정의하기 어려움 큰 작업은 측정하기도 어려움 작업이 작을 수록 쉬워짐 작업이 작을 수록 작업 완료 시간를 더 정확하게 예측할 수 있으며 작업을 정확하게 수행할 가능성도 큼. 작은 작업으로 나누다보면 자신이 해야 할 일에 대한 정보가 충분하지 않다는 사실을 깨닫게 됨. 큰 작업을 작게 나눌 때 중요한 과정 중 하나는 누락된 정보를 확인하는 것 작은 작업 하나하나에는 명확한 목표가 있어야 함 작게 나누면 고객이 원하는 것을 더 잘 설명할 수 있게 도와줄 수 있음   독립적으로 해결할 수 있는 작은 조각으로 나누어 작업  47 힘든 일을 피하지 마라\n 가치 있는 것들은 모두 힘들게 일해서 얻은 결과물. 자신의 인생을 위해, 특히 소프트퉤어 개발자로서 경력을 다지기 위해 제대로 된 성과를 얻고 싶다면 자리를 지키고 앉아서 원하는 일이든 그렇지 않은 일이든 모두 해내는 법을 배워야 당신이 힘들다고 말하는 일은 거의 당신에게 득이 되는 일이며, 경력을 개척하거나 새로운 기회를 열 수 있는 일. 하지만 별 소득이 없는 일은 항상 굉장히 쉽게 느껴짐 정말 효율적으로 일하고 싶다면 똑똑하게 일하는 법과 열심히 일하는 법을 둘 다 배워라. 똑똑한 것만으로는 부족하다. 일정 수준의 영리함과 일정 수준의 끈기가 모두 필요 힘든 일을 피하는 이유는 지루하기 때문. 그러나 장기적으로 노력하고 인고의 시간을 보내며 꼭 필요한 지루한 일을 해낸 사람이 앞서간다. 큰 격차로 세상에 쉽게 얻을 수 있는 건 하나도 없다. 성공은 성공을 낳는다. 더 많이 성공할수록 다른 성공도 쉽게 얻을 수 있다. 올라야 하는 첫 번째 산이 길고 가파를 뿐이다 의지는 반드시 필요하다. 배운 것을 실천하여 효과를 보려면 기꺼이 힘든 일을 해낼 의지가 있어야 한다. 누구나 같은 문제로 싸우고 있다. 이제는 해야 할 일을 해야겠다고 결심하라. 목표를 이룰 방법은 하나밖에 없다고 깨달아야 한다. 자신의 모든 잠재력을 발휘할 수 있는 방법은 칼을 갈고, 이를 악물고, 일하러 가는 것이다.  48 뭐라도 하는 게 아무것도 하지 않는 것보다 낫다\n \u0026lsquo;배우는 게 있다면 실수는 더 이상 실수가 아니다. 아무것도 하지 않는다면 아무것도 배울 수 없다\u0026rsquo; 가장 악질적인 생산성 훼방꾼은 바로 아무런 행동도 하지 않는 것이다. 행동하지 않으면 엄청나게 많은 기회와 가능성을 놓친다. 내가 행동하지 않는 이유는 두렵기 때문이다. 가장 좋은 답을 찾지 못했거나 잘못된 선택을 할까 두려워서 아무것도 하지 않은 채 무조건 실패하는 선택을 한 적은 몇 번이나 되는가? 지금이야말로 행동에 옮길 때다 움직이는 차의 방향을 트는 것이 더 쉽다.  55 보너스. 나는 33세에 은퇴했다.\n 투자할 줄 모른다면 은퇴라는 목표는 이룰 수 없다. 기회를 잡는 것만으로는 부족하다. 아무리 일생일대의 기회라 해도 자신이 잡은 기회에서 최선의 결과를 내지 못한다면 큰 의미가 없다.  69 추천 도서 목록\n How to win friends and influence people 부정적인 지적은 전혀 도움이 되지 않으며 타인을 내가 원하는 대로 움직이려면 그들 스스로 원하게 해야 한다는 것을 깨달았다.  그외\n 투자/금융 49 ~ 54 운동 56 ~ 64 영혼  ","id":124,"section":"posts","summary":"2 다른 이들과 달리 멋지게 시작하라 자신의 경력을 사업으로 봐야 한다. 자신의 정체성이나 경력은 조직에서 주어진 역할과 별개로 존재한다고 생각 팔수 있는 제품이나 서","tags":["Book","soft-skill"],"title":"(책) 소프트 스킬","uri":"https://cychong47.github.io/2016/04/soft-skill/","year":"2016"},{"content":"rte_ipv4_frag_reassemble_packet()\n ip_frag_find()  기존에 존재하는 flow면 해당 flow를 저장한 entry 정보를(ip_frag_pkt *pkg) 신규 flow인 경우 해당 신규 flow를 저장할 신규 혹은 재사용된 entry를 return함 추가할 수 있는 통계  신규 flow? 기존 flow에 정상 추가 기존 flow에 비정상 추가(기존 flow가 timeouted) 이도 저도 아닌 상황(할당 실패) LRU entry free tbl-\u0026gt;max_entries tbl-\u0026gt;use_entries   return  기존 존재하는 flow, 신규 할당한 flow entry 혹은 NULL 만일 NULL을 return하면 현재 수신한 mbuf를 death row에 추가한다. 불쌍한\u0026hellip;   ip_frag_lookup()  if matched entry is exist  return flow entry return \u0026amp;stale if time-outed entry is exist   if new entry  return NULL return free for new empty entry return \u0026amp;stale if time-outed entry is exist   ip_frag_key_cmp() return 0 if key matched   if ip_frag_lookup() returns NULL  if stale entry is not NULL, remove it with ip_frag_tbl_del() and save to free for reuse even if free is not NULL, check if tbl-\u0026gt;use_entries does not exceed tbl-\u0026gt;max_entries. If so, check if the LRU entry is timeouted, then free the LRU entry. Otherwise, fail to add new entry to the tbl tbl에서 할당하는 것고 max_entries, use_entries간의 차이점은?? If free is not NULL, add new flow to this free entry   if ip_frag_lookup() returns non-NULL  if timeouted, reuse it for the received flow   tbl-\u0026gt;use_entries—; del_num++   ip_frag_process() rte_ip_frag_free_death_row() 주기적으로 호출해줘야 함  ","id":125,"section":"posts","summary":"rte_ipv4_frag_reassemble_packet() ip_frag_find() 기존에 존재하는 flow면 해당 flow를 저장한 entry 정보를(ip_frag_pkt *pkg) 신규 flow인 경우 해당 신규 flow를 저장할 신규 혹은 재사용된","tags":["DPDK","reassembly","ipv4"],"title":"DPDK IPv4 reassembly","uri":"https://cychong47.github.io/2016/03/dpdk-ipv4-reassembly/","year":"2016"},{"content":" 코드에 신경쓰기  어떤 코드든 간에 수정한 후에는 이전 보다 나아져야 한다 기능이 추가된 것은 \u0026lsquo;나아진\u0026rsquo; 것이 아니다. 기능이 추가되고, 코드 수가 늘어나도 여전히 좋은 구조를 유지하는 것이 \u0026lsquo;나아진\u0026rsquo; 것이다.   정돈된 코드 유지하기  좋은 코드는 명백하며 일관성이 있다. 보기 좋은 코드는 의도를 드러낸다(예술) 코드를 읽을 사람은 지금 당장의 나 외에 몇 달 후의 나, 다른 동료 그리고 미래의 유지 보수 프로그래머다. 그들이 혼란을 덜 겪도록 코드를 작성해야 한다. 실은 다른 사람을 위해 코딩한다는 것을 인정해야 하고, 잊으면 안된다. 코딩 스타일 가이드를 정리한다. 코딩 스타일의 목적은 일관성이다. 불필요하게 반복되는 단어를 피한다. DataObject(?) 간결함보다 중요한 것은 명확함이다. 코드를 \u0026lsquo;정리정돈\u0026rsquo;해야 할 경우에는 기능 변경과 모양 변경을 동시에 진행하지 말라 프로젝트의 공통 관습이 존재한다면 따른다.   코드 작게 쓰기  소프트웨어를 개선하는 최고의 방법 가운데 하나는 바로 코드를 제거하는 것이다. 매일 같이 코드를 더 좋게 만들라. 중복 코드는 발견 즉시 제거한다. 더 많은 양의 코드가 더 좋은 SW를 의미하지는 않는다. 필요하지 않다면 코딩하지 말라. 적게 쓰고 그 대신 더 재미난 것을 찾으라.   코드 줄여 개선하기  C의 전처리기는 사용되지 않는 코드를 만들어 내는 역효과를 낼 수 있다. 함수의 return 값이 사용되지 않으면 void로 변경한다. 가능하면 죽은 코드를 제거한다. 죽은 코드를 발견했음에도 아무런 조치를 취하지 않는 것이야말로 실패의 징조다.   코드베이스의 망령  프로그래머로서 자질은 작성한 코드가 아닐 그것을 대하는 태도와 작성하는 방식에 의해 결정된다. 예전에 작성한 코드가 최신 라이브러리에 의해 대체할 수 있을 경우도 있다. 기존의 코드를 돌아보는 것은 자신을 위한 코드 리뷰이자, 가치있는 행동이다.   경로 탐색하기  코드를 작성하는 것이 읽는 것보다 쉽다.(하지만 숨겨진 의도를 파악하지 못하고 새로 작성하면 새로운 문제를 일으킨다. 실은 예전에 발생했던 문제를 부활시키는…) 코드 분석을 통해 알아낸 것이 있으면 프로젝트의 최상위 위치에 README파일을 만든다. 의도, 주의사항, 의존성, 빌드 방법 등   똥통에서 뒹굴기  goto 문이 남발되면 알고리즘 구조를 읽기 어렵다. 외부에 노출하는 API는 깔끔하고 합리적인가? 자료형을 잘 고르고, 변수 명이 적절한가? 코드의 레이아웃을 정돈하여 일관성 있게 작성했는가?  코드의 외관이 코드의 근본적인 품질을 보장하지는 않지만, 일관성 없고 지저분한 코드가 대개 구조도 부적절하고, 다루기 어려웠다(저자의 경험상)   특정 기능을 구현하는 코드 부분이 어디에 있는 지 쉽게 찾을 수 있는가? 보이스카웃 규칙을 따른다. 어떤 코드를 건드리건 이전보다 나아지도록 한다. 거대한 함수는 더 작으면서도 적절히 명명된 작은 함수들로 나눈다.  성능 최적화 측면에서 함수 호출이 갖는 penalty는 어떻게 할 것인지?   주기적으로 코드 일부라도 확인하고 그때마다 조금씩 나아지게 만든다. 수정으로 인해 기존 기능에 문제가 생기지 않음을 보장할 수 있는 모든 수단을 사용한다. 똥떵어리 수정을 별 의미없는 작업이라 치부하기보다는 더 나은 품질을 실현할 기회로 삼으라 수정하면서 자신의 태도도 확인하라. 어쩌면 당신은 원 저자보다 자신이 더 잘 알고 있다고 생각할 수도 있다. 과연 언제나 그럴까?   오류 무시하지 않기  반환 코드는 주로 정수 값으로 0은 성공, 그 외의 수는 오류를 의미   예상하지 못한 것을 예상하기  에러 코드는 절대로 무시하지 말라   버그 사냥하기  버그를 피할 수 있는 가장 좋은 충고는 믿기 힘들 정도로 \u0026lsquo;영리한(종종 복잡한 것과 동일시 되는)\u0026rsquo; 코드를 만들리 말라는 것이다. Martin Fowler, 미련한 프로그래머는 컴퓨터가 이해할 수 있는 코드를 만들고, 좋은 프로그래머는 사람이 이해할 수 있는 코드를 만든다. 단위 테스트에 시간을 투자 특정 코드가 test coverage에 포함되지 않으면 제대로 작동한다고 신뢰할 수 없다. 문제를 다른 사람에게 설명해 보라. Rubber Duck strategy 버그를 찾고 해결하려 할 때 마구잡이로 달려들어서는 안된다. 코드의 어느 부분에 더 많은 문제가 있는 지 메모해둔다. 핫스팟을 찾으면 집중적인 개선 노력을 기울일 수 잇다. 아이젠버그. \u0026lsquo;관찰자\u0026rsquo;가 있으면 양상이 달라질 수 있다는 \u0026lsquo;관리자 효과\u0026rsquo;라는 용어를 만든 Werner Heisenberg   테스트하기  위대한 소프트웨어를 제대로 만들려면 피드백을 받아야 한다. 가능하면 자주, 그리고 빨리 좋은 테스트 전략은 피드백 절차를 간소화하는 것 피드백 과정이 짧을 수록 설계 변경을 더 빠르게 반복할 수 있고, 코드에 대해 더 강하게 확신할 수 있다. 더 열심히 일하려 하기보다 더 영리하게 일하라 코드에 대한 확신은 곧 테스트 코드의 품질이 결정한다. 실패 경우를 유닛 테스트로 만들어 재발을 방지한다. 성능이 주요 요구사항이면, 코드의 성능을 모니터링하는 테스트도 수행한다. 나쁜 테스트는 짐이 된다. 자산이라기보다 채무다 나쁜 테스트는 코드에 약간만 수정을 가해도 처리하기 어렵고, 조밀하며 이해하기 힘들다 좋은 테스트의 조건 나쁜 테스트란 테스트 코드도 유지 보수한다. 프로그램 테스트를 통해 버그의 존재를 확인할 수는 있지만, 버그가 없음을 확신할 수는 없다.   복잡도 다루기  Blob(Binary Large Object)은 정확한 역할과 책임을 확실히 가져야 한다. 우리의 뇌는 문제를 계층으로 나누고 추상화하여 추론하는데 최적화되어 있다. 사용하지 않은 helper method는 제거한다. 순환 의존 관계는 가장 복잡한 관계다. 프로그래머들에게 리팩토링할 시간도 허락하지 않은 채, 시스템을 확장하고 확장하며 또 확장한다. 버려야할 prototype을 출시 시스템으로 둔갑시킨다.   두 개의 시스템에 대한 이야기  대도시 이야기 vs. 디자인 타운 소프트웨어는 건강하지 못한 회사 구조와 개발 절차로 인해 잘못 설계될 수 있다. 이해 불가. 소프트웨어 설계의 품질을 유지 보수하라. 나쁜 설계는 더 나쁜 설계를 불러온다. 응집도의 부족. 각각의 컴포넌트는 필요하지 않은 다양한 기능을 포함하고 있다.  개발팀의 작업자들 간의 관계가 얼마나 건강한지는 소프트웨어 설계의 품질에 직접적 영향을 끼친다. 부적절한 관계와 자만심은 잘못된 소프트웨어를 만든다. 훌륭한 소프트웨어 디자인은 모듈 간의 상호 작동에서 필요한 것들만 허용한다.   불필요한 결합. 좋은 설계는 상호 연결 구조나 컴포넌트 간 연결의 분량을 검토한다. 시스템의 개별 부분은 단독으로 작동할 수 있어야 한다. 밀착 결합은 테스트하기 어렵게 만든다.  코드 문제. 공통된 규칙이나 공통 라이브러리 사용, 공통된 관례에 대한 무신경   새로운 기능을 붙이기가 너무 어렵다 보니 사람들은 점점 더 자주 실수했고, 디자인 타운은 초기 설계를 작동하기에 알맞은 수준으로 결정. 최상위 수준의 디렉토리 구조, 명명 규칙, 일반적 코딩 관례에 덧붙인 코드 작성 방법, 유닛 테스트 프레임워크 선택과 기반 구조가 되는 내부 구조들. 시스템 구조에 대한 명확한 비전. 일관성. 모든 수준에서의 모든 결정을 전체 설계의 관점에서 수행 구조 확장. 그 어떤 것도 변하지 않은 것은 없다. 소프트웨어의 구조는 불변이 아니다. 필요하다면 변경하라. 변경 가능하게 만들려면 구조를 간결하게 유지해야 한다. 기술 부채에 대한 인정과 후속 개선 작업 훌륭한 자동화 테스트는 최소한의 위험만으로 근본적인 구조 변경을 수행할 수 있게 한다. 팀이 분열되어 있다면, 코드도 어색하게 엮인다. 코드 작성에 앞서 계획적으로 설계한다. 더도 말고 덜도 말고 알맞게 설계.   소프트웨어 개발이란  훌륭한 프로그래머의 주요 특징 중 하나는 작성한 소프트웨어와 그 작성법에 대해 진심으로 주의를 기울이는 것이다. 좋은 소프트웨어는 정확하고, 입증되고, 측정되고, 실험되며, 검증되어야 한다 -\u0026gt; 좋은 테스트 자신이 작성한 소프트웨어는 언제나 완전히 정확하고 완벽하게 정밀한가? 이를 증명하는 방법은 무엇인가? 어떻게 하면 현재와 미래에 명시화 할 수 있는가? 일련의 규칙과 특정 팀 문화를 기반으로 개발을 진행 효율적인 프로그래머가 되려면 집안일을 두려워해서는 안 된다. 제품의 최신 버전에 대해 멋진 설계를 하는 것은 대단한 일이지만, 제품을 출시하고 지저분한 코드에서 오류를 찾아 수정하는 지루한 작업을 해야 할 때도 종종 있다. 문제의 수정 방법을 찾으면 적절한 시점에 파괴적이지 않은 방식으로 수정해야 하낟. 청소부로서 다른 사람에게 즐겁지 않은 작업을 넘겨버리지 말고 책임을 져야 한다. 죽은 코드를 제거하고, 망가진 코드를 수정한다. 적절하지 않은 코드를 리팩토링하고 재구성하며, 코드를 줄이고 깔끔하게 만든다. 코드가 황폐한 상태에 빠지지 않도록 하기 위함이다.   규칙 가지고 놀기  때때로 못난 프로그래머들에게는 더 많은 규칙이 필요하다. 규칙은 새로운 팀원에게 줄 수 있을 만큼의 단순해야 한다. 단순히 방법론과 절차에 대한 것이 아닌 팀에서 좋은 플레이어가 되는 방법과 같은 코딩 문화를 설명하는 규칙이어야 한다. 좋은 코드를 작성하기 위한 세개의 규칙이란  간결하게 하라 머리를 쓰라 변하지 않는 것은 없다.     간결하게 하기  간결한 코드는 설계하는 데 많은 노력이 필요하다. 다만 간결한 코드가 곧 과도하게 단순한 코드를 의미하지는 않는다. 잘못되고 단세포적인 \u0026lsquo;단순함\u0026rsquo;이 아니라 가장 간결한 코드를 작성하기 위해 노력해야 간결한 설계는 빠르고 명확하게 묘사할 수 있고, 쉽게 이해할 수 있다 \u0026lsquo;간결한\u0026rsquo; 인터페이스 설계에서는 동적으로 할당한 객체를 받아 사용 후 사용자가 그 객체를 직접 삭제할 필요가 없다. 간결한 코드는 읽기 쉽고 이해하기 쉽다. 따라서 작업하기에도 쉽다. 명백한 방식으로 납득할 만한 코드를 작성하면, 코딩 스타일도 그렇게 된다. 그러면 유지 보수하는 프로그래머들이 고마워할 것이다. 오류를 수정하면서 간결함을 유지해야 한다. 증상 부위가 아닌 근본 원인에 대해 버그 수정을 적용하라 설계/구현을 위해 세운 가설이 있다면 코드에 명시한다. 유용할 것이라고 생각되는 대량의 코드를 작성하지 말라. 사용되지 않는 코드는 그저 잠일 뿐이다. 요구사항을 충족시키는 데 필요한 만큼의 코드만 작성하라. 코드를 적게 작성할 수로고 더 적은 버그가 만들어질 것이다.   머리 쓰기  일을 멈추고 생각하라. 바보 같은 코드를 작성하지 말라. 일단 작업을 멈추고 정신을 차린 뒤 대안이 있는 지 확인해보라. 가차없는 수정이 필요한 누더기 코드를 발견했을 때는 거기에 또 다른 누더기 코드를 덧씌우지 말라.   변하지 않는 것은 없다.  항상 시간이 해결해 준다고들 하지만, 실제로는 당신 스스로 변하게 만들어야 한다. 프로그래머는 두려움을 느끼고 코드를 깨뜨리지 않도록 하려다 보니, 코드를 단단히 얼어붙게 만든다. 이것이 바로 소프트웨어 사후 경직이다. 본래의 개발자가 프로젝트를 떠나고 오래된 중요한 코드를 완벽하게 이해하는 사람이 남지 않았을 때, 해당 코드가 사후 경직되는 경우가 종종 있다. 코드가 구속력을 가지면, 더 이상 소프트웨어를 개발한다고 볼 수 없으며 코드에 맞서 싸우는 형태가 된다. 코딩 시 두려움을 가지고 피하기만 한다면, 코더의 인생은 쉽게 만들어줄 지 몰라도, 설계는 썩어간다. 코드 성장에 도움이 되는 태도  수정하기 두려운 코드를 발견한다면 반드시 수정해야 한다. 리팩토링 또한 권장한다. 누구도 코드의 어떤 영역을 소유하고 있지 않다. 좋은 프로그래머는 변화를 기대한다. 변화야말로 소프트웨어 개발의 전부다.   모양과 의도를 드러내고, 간결함과 명확함, 일관성을 표방하는 코드.   코드 재사용 사례  코드가 하나의 프로젝트가 아닌 더 많은 용도로 사용될 지 의심스러운 상황에서 처음부터 다양하게 사용할 수 있도록 처리하는 것은 가치가 없는 일이다. 당장의 요구사항을 만족할 수 있는 가장 간단한 코드를 만드는 데에만 집중한다. 가능한 가장 적은 양의 소프트웨어를 만듦으로써, 버그를 양산하거나 향후 수년간 지원해야 하는 불필요한 API를 만들 위험을 줄일 수 있다. 한 곳이 아닌 여러 곳에서 사용되어야 한다면 공통 라이브러리 혹은 공통 코드 파일을 만든다. 가능하다면 기존에 존재하는 코드를 재사용한다.   효과적인 버전 관리  최상위 디렉토리에 도움이 되는 README 문서를 포함한다. 자주 조금씩 변경 사항을 체크인한다. 한 번에 두 가지 이상의 변경 사항을 다루는 체크인을 해서는 안 된다. 커밋 메시지는 코드와 같은 성격을 갖는다. 명확/간결/DRY. 변경한 파일을 나열할 필요는 없다. 개선하려면 변화해야 한다. 완벽하려면 자주 변화해야 한다.   골기퍼 있다고 골 안 들어가랴  QA와 개발을 별도의 단계이자 행위로 보고 다른 팀으로 나누어버리면, 경쟁심은 커지고 단절감은 심해진다. 신뢰감이 없어진다. 그러나 비개발 출신의 관리자는 부서간의 관계를 신뢰하지 못하고 별개의 부서로 만든다 품질 보장 업무는 개발자들과 테스터들이 긴밀히 연계될 때 비로소 효과적으로 수행될 수 있다. 팀 간의 의사소통이 건전하지 않으면 코드도 건전해지지 않는다. 개발자는 반드시 QA와 좋은 관계를 유지해야 하며, 우정과 동지애를 가져야 한다. 정확하고 신뢰할 만한 오류 보고서를 만든 뒤 구조화되고 규칙을 따르는 방식, 예를 들면 좋은 오류 추적 체계를 사용해 전달하는 것은 테스터의 의무이다. 오류 보고서를 개인적으로 받아들이지 말라. 개인적 모욕이 아니다!! 다툼이 있는 곳에는 언제나 관계를 해치는 결과와 더 긴밀히 만드는 결과로 구분 짓는 하나의 요소가 존재한다. 바로 \u0026lsquo;태도\u0026rsquo;이다. 폭포수 모델에 따라 테스트에 도달하기 전에 90%수준에 도달했다면, 프로젝트를 마감하기 위해 또 다른 90%수준의 노력이 필요함을 깨닫게 될 것이다. QA는 같은 팀의 일부임을 기억하라. 그들은 경쟁 집단이 아니다.   동결된 코드의 신기한 사례  코드 동결은 코드가 완전해졌다고 판단되는 시점으로 모든 기능이 구현되었을 뿐 아니라, 어처구니 없는 버그가 없는 때를 의미한다. \u0026lsquo;코드 동결\u0026rsquo;은 변경을 완전히 막는다기보다는 개발 작업에 대해 새로운 규칙을 적용한다는 의미 가깝다. 변경 사항이 아무리 가치 있다 해도 신중한 합의 후에 이루어져야 한다. 코드 동결 기간에는 기술적 부채가 발생할 수도 있다. 부채의 발생을 감시하고, 배포 이후에 곧바로 빚을 갚을 준비를 하라.   제발 저를 배포해주세요 배움을 사랑하며 살기  프로그래머에게는 배움, 즉 기량과 능력의 향상이 지속적으로 요구된다. 배움을 즐기는 것을 배우라 배울 때 재미있을 만한 것을 조사하는데 우선 시간을 들이라. 새로운 기술/기법/문제 영역에 대해 배우라. 사람들과 함께 일하는 것을 배우라. 사회학이나 경영학 책을 공부해보라. 소프트웨어 팀의 리더가 되는 것에 대해 읽어보라. 어떻게 배워야 할 지 배우라. 완전히 다른 것을 배우라. 새로운 외국어나 악기, 다른 과학 분야 미술 혹은 철학을 배우라. 나중에 버릴지언정 지금 배우고 있는 것을 기록하라 Knowledge Portfolio. 현재 업무 지식을 투자 포트폴리오로 간주해보라. 수집한 정보를 어떻게 관리해야 하고, 현재의 포트폴리오를 유지하기 위해 어떤 방식으로 신중하게 투자해야 하며, 포트폴리오를 강화하기 위해 새로운 투자를 어떻게 이끌어낼지를 밝혀낼 수 있다. 아인슈타인. 간단하게 설명할 수 없다면, 충분히 잘 이해하지 못했다는 증거이다. 배움에 있어 핵심적인 기술은 행동하는 것이다. 추상적으로만 알고 있던 것들을 구체적이고 실천적으로 알 수 있도록 하라. 뛰어들어 실행해보라.   테스트 기반 개발자  아무런 생각 없이 \u0026lsquo;성급하게 반응하는\u0026rsquo; 식의 접근 방법은 카우보이 코더에게나 찾아볼 수 있는 증상이다. 오랜 경력을 가진 코드라고 해도 누구나 전문적인 기술자가 되지 않는다. 관련 업계에서 보낸 시간만으로는 판단할 수 없다. 승진했다고 해서 당신이 처음 개발을 시작했을 때보다 더 좋은 프로그래머라는 의미는 아니다.   도전 즐기기  코딩 연습, 코딩 문제, 개인적인 프로젝트, 새로운 직업을 찾아본다. 작업 중인 진행 상황을 볼 수 있도록 하라. 무엇을 성취했는 지 확인할 수 있도록 소스 로그를 리뷰하라.   부진 피하기  자신의 능력 이상을 해낸 마지막 시점은 언제였는가? 안전지대는 유해한 영역이다. 편한 삶이란 곧 학습하지 않고, 진행하지 않으며, 더 이상의 발전이 없는 것을 의미한다. 안전지대에 있는 것은 정체되었다는 뜻이다. 안전지대는 퇴보로 가는 지름길이다. 타성에 젖어버리기란 쉬운 일이다. 스스로를 불편한 상황에 두어야 하고 많은 노력을 쏟아 부어야 한다. 위험하고 어려운 일이며 자신을 난처하게 만들 수도 있다. 의식적으로 자신의 기술에 투자하려 해야 한다. 그런 결정을 지속해야 한다. 힘든 일이라 생각하지 말라. 도전 안에서 즐거움을 느끼라. 다른 도구/프로그래밍 언어/OS/편집기를 사용해 본다. 키보드 단축키를 알아본다. 개인적인 프로젝트를 시작한다. 프로젝트의 새로운 부분을 담당하라. 한 가지 직업/역할에 너무 오래 머물거나 아무런 도전거리도 없는 같은 일만 반복하는 것은 위험하다. 자신만의 작은 코딩 제국의 왕이 되는 것이다. 참으로 안락한 상황이다. 좋은 프로그래머는 코드에 대한 접근 방식에서든 자신의 경력에 대한 접근 방식에서든 과감하다.   윤리적인 프로그래머  기술 부채를 추후 탐금하기 위해 작업 목록에 새로운 업무에 추가한다.   언어에 대한 사랑  좋은 프로그래머들은 다양한 언어와 방법론을 알고 있는 만큼 문제 해결의 범위가 넓다. 언어 고유의 방식과 관습에 돌입해야 한다. 의사소통은 말하는 것만큼이나 듣는 것도 중요하다.   프로그래머의 자세 \u0026lsquo;더 열심히\u0026rsquo;보다는 \u0026lsquo;더 현명하게\u0026rsquo;  기술적 통찰력만이 아닌 문제를 풀고 전투를 선택하는 방법에서 찾아볼 수 있다. 좋은 프로그래머는 일을 빠르게 끝낸다. 어떻게 하면 문제를 잘 해결할 수 있는 지 아는 것이다. 현명하게 재사용한다. 직접 만들기보다는 이미 있는 코드를 사용하고, 더 중요한 일에 시간을 투자하라. 다른 사람이 거들어줄 수 있거나 훨씬 빨리 완료할 수 있다면, 그의 작업 목록에 올려주는편이 훨신 나을 것이다. 모든 것을 테스트하지 않고 취약할 것으로 예상되는 지점들에 집중하라. 테스트의 전장을 잘 선택하라. 최선책을 골라내기 위해 심사숙고하느라 많은 시간을 소모하지 말라. 우선 순위 설정에 엄격하라. 중요하지 않은 사소한 것에 몰두하지 말라. 새로운 업무가 할당될 때는 지금 당장 필요한 일인지부터 확인한다. 초기부터 지나치게 많은 코드를 작성하는 행동은 위험하다. 하나를 끝내고 다른 것을 하라. 코드와 설계를 가능한 한 작고 간결하게 유지하라. 미래의 요구사항이 무엇일지 지금 정확히 예견할 수는 없다. 지금 당장은 나중에 코드를 고치기 쉽도록 하는 정도에서 만족하는 것이 더 쉽고 똑똑한 일이다. 언젠가 발생할 가능성이 있는 기능을 미리 만들어주는 것은 더 어렵고 어리석다. 어려운 일을 미뤄두지 말라. 코드 통합 등이 그 예이다. 많은 사람들이 고통을 줄이기 위해 일을 미뤄두고 있다. 반복 작업은 손수하는 것보다는 도구를 작성하고 해당 도구를 한 번만 실행하는 편이 더 빠를 수 있다. 건전한 프로젝트는 연속한 야근을 요구하지 않는다. 항상 업무 흐름을 가속화해줄 새로운 도구를 찾으라. 다만 새로운 도구를 찾는 일에 노예가 되지는 말자.   끝나야 끝나는 것  \u0026lsquo;완료 상태란 어떤 것인지, 그리고 \u0026lsquo;완료\u0026rsquo; 상태에 얼마나 가까운 지를 현실적으로 파악하는 것이다. 엄청난 업무를 할당받았다면, 일을 시작하기 전에 더 작고 이해할 만한 부분으로 일을 나누도록 하라. \u0026lsquo;완료\u0026rsquo; 상태를 정의해야 한다. \u0026lsquo;완료 상태\u0026rsquo;는 명확하고 구체적어야 한다. 구현해야 할 기능, 추가 혹은 확장해야 할 모든 API, 수정해야 할 특저 오류를 목록화한다. 모든 주요 관련자들이 성공 기준을 확인하도록 하라. 작동함을 증명하기 위해 코드로 작성된 테스트를 사용하라. 필요 이상으로 많은 작업을 수행하지 말라. \u0026lsquo;완료\u0026rsquo; 상태까지만 작업하라. 그런 뒤에는 중지하라.    교훈 얻기  다른 프로그래머에게 의무감을 가지라. 그들과 주기적으로 작업 경과를 확인하라.   사람의 힘 생각이 중요하다.  작업의 품질을 보증하기 위해 다른 프로그래머들에 대한 의무감을 가지면, 코드 품질을 환상적으로 높일 수 있다. 다른 사람이 코드를 읽고 품평하리라는 것을 알고 나면 좋은 코드를 짜고 싶은 마음이 더 커진다.   말하기  코드는 다른 사람과의 의사소통이다. 명백하고 애매호호함이 없어야만 다른 사람들이 코드를 유지 보수할 수 있다.   선언문  코드에 신경 쓰라 팀의 힘을 키우라 간결함을 유지하라 머리를 쓰라 그 무엇도 고정된 것은 없다. 꾸준히 배우라 (주체가 자신이든 팀이든 코드든 간에) 나아질 방향을 꾸준히 모색하라 언제나 가치를 전달하려 애쓰라. 길게 볼 수 있도록 해보라.   코드 찬가  Rober C. Martin 보이스카웃 규칙 리더 자신이 문제의 일부라면? 보통 소프트웨어 개발과 관련해 까다로운 부분은 기술적인 측면에 있지 않다. 결국 사람의 문제다. 나쁜 습관에 빠져들지 않도록 하라. 보통 소프트웨어 개발과 관련핸 까다로운 부분은 기술적인 측면에 있지 않다. 결국 사람의 문제다. 나쁜 습관에 빠져들지 않도록 하라. 코드에 신경 쓰지 않는 코더에게 둘러싸여 있다면, 자신만이라도 건전한 태도를 유지하라.   태도가 핵심이다.  좋은 프로그래머와 나쁜 프로그래머를 구분하는 요소는 바로 태도다. 태도는 기술적인 부분을 넘어선다.    ","id":126,"section":"posts","summary":"코드에 신경쓰기 어떤 코드든 간에 수정한 후에는 이전 보다 나아져야 한다 기능이 추가된 것은 \u0026lsquo;나아진\u0026rsquo; 것이 아니다. 기능이 추가되고, 코","tags":["Book","programming"],"title":"(책) Becoming a better Programmer","uri":"https://cychong47.github.io/2016/03/becoming-a-better-programmer/","year":"2016"},{"content":"l2_len, l3_len, l4_len 등을 사용하는 라이브러리가 존재함\n reassembly Tx checksum offload  Reassembly rte_ipv6_frag_reassemble_packet(), rte_ipv4_frag_reassemble_packet() Incoming mbuf should have its l2_len and l3_len fields setup correctly.\nL4 checksum HW offloading To use hardware L4 checksum offload, the user needs to\n fill l2_len and l3_len in mbuf set the flags PKT_TX_TCP_CKSUM, PKT_TX_SCTP_CKSUM or PKT_TX_UDP_CKSUM set the flag PKT_TX_IPV4 or PKT_TX_IPV6 calculate the pseudo header checksum and set it in the L4 header (only for TCP or UDP). See rte_ipv4_phdr_cksum() and rte_ipv6_phdr_cksum(). For SCTP, set the crc field to 0.  L3 checksum HW offloading  set the flag PKT_TX_IPV4 (IP checksum은 IPv4에만 존재) set the IP checksum field in the packet to 0 fill the mbuf offload information: l2_len, l3_len PKT_TX_IP_CKSUM  IP checksum offloading example from prog_guide/mbuf_lib.rst\nThis is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM.\nmb-\u0026gt;l2_len = len(out_eth) mb-\u0026gt;l3_len = len(out_ip) mb-\u0026gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CSUM set out_ip checksum to 0 in the packet  IP, UDP checksum offloading\nThis is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM and DEV_TX_OFFLOAD_UDP_CKSUM.\nmb-\u0026gt;l2_len = len(out_eth) mb-\u0026gt;l3_len = len(out_ip) mb-\u0026gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CSUM | PKT_TX_UDP_CKSUM set out_ip checksum to 0 in the packet set out_udp checksum to pseudo header using rte_ipv4_phdr_cksum()  Outer IP, inner IP and inner TCP checksum offloading\nThis is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM, DEV_TX_OFFLOAD_UDP_CKSUM and DEV_TX_OFFLOAD_OUTER_IPV4_CKSUM.\nmb-\u0026gt;outer_l2_len = len(out_eth) mb-\u0026gt;outer_l3_len = len(out_ip) mb-\u0026gt;l2_len = len(out_udp + vxlan + in_eth) mb-\u0026gt;l3_len = len(in_ip) mb-\u0026gt;ol_flags |= PKT_TX_OUTER_IPV4 | PKT_TX_OUTER_IP_CKSUM | \\ PKT_TX_IP_CKSUM | PKT_TX_TCP_CKSUM; set out_ip checksum to 0 in the packet set in_ip checksum to 0 in the packet set in_tcp checksum to pseudo header using rte_ipv4_phdr_cksum() ","id":127,"section":"posts","summary":"l2_len, l3_len, l4_len 등을 사용하는 라이브러리가 존재함 reassembly Tx checksum offload Reassembly rte_ipv6_frag_reassemble_packet(), rte_ipv4_frag_reassemble_packet() Incoming mbuf should have its l2_len and l3_len fields setup correctly. L4 checksum HW offloading To use hardware L4 checksum offload, the user needs to fill l2_len and l3_len in mbuf set the flags PKT_TX_TCP_CKSUM, PKT_TX_SCTP_CKSUM or PKT_TX_UDP_CKSUM set the flag PKT_TX_IPV4 or PKT_TX_IPV6 calculate","tags":["DPDK","mbuf"],"title":"DPDK new mbuf 사용 주의사항","uri":"https://cychong47.github.io/2016/03/header-length-in-mbuf/","year":"2016"},{"content":"DPDK to KNI RX KNI는 rx_q로부터 mbuf를 수신한 후 data_len 크기의 skb를 할당하여 데이터를 복사한 후 netif_rx를 호출한다. 그러므로 mbuf는 KNI kernel module까지만 사용되고, 커널 networking stack에서는 사용되지는 않는다.\nkni_net.c의 kni_net_rx_normal() 함수가 DPDK application으로부터 mbuf를 받아 커널에 전달하는 함수인데 실제 함수는 batch processing을 위해 한번에 여러 개의 패킷을 rx_q로부터 읽어 처리하도록 구현되어 있다.\n아래는 하나의 패킷에 대해 수행되는 코드를 간략화 한 것이다(예외 처리 부분도 제외)\nnum_rx = kni_fifo_get(kni-\u0026gt;rx_q, (void **)va, num_rx); kva = (void *)va[i] - kni-\u0026gt;mbuf_va + kni-\u0026gt;mbuf_kva; len = kva-\u0026gt;data_len; data_kva = kva-\u0026gt;buf_addr + kva-\u0026gt;data_off - kni-\u0026gt;mbuf_va + kni-\u0026gt;mbuf_kva; skb = dev_alloc_skb(len + 2); /* Align IP on 16B boundary */ skb_reserve(skb, 2); memcpy(skb_put(skb, len), data_kva, len); skb-\u0026gt;dev = dev; skb-\u0026gt;protocol = eth_type_trans(skb, dev); skb-\u0026gt;ip_summed = CHECKSUM_UNNECESSARY; /* Call netif interface */ netif_rx(skb); /* Update statistics */ kni-\u0026gt;stats.rx_bytes += len; kni-\u0026gt;stats.rx_packets++; /* Burst enqueue mbufs into free_q */ ret = kni_fifo_put(kni-\u0026gt;free_q, (void **)va, num_rx);  In case DPDK application restarted\n만일 DPPK application이 비정상적으로 종료되어 다시 실행하는 경우 버퍼를 초기화 과정에서 문제가 발생할 수 있다.\n1. DPDK -\u0026gt; KNI rx_q나 free_q에는 이전 DPDK application에서 KNI에 전달했던 mbuf정보이다. 해당 버퍼 영역은 더 이상 유효하지 않고, rx_q, free_q 조차도 유효하지 않다. 그러므로 새로 실행된 DPDK application이 rx_q, free_q에 접근하여 queue에 존재하는 버퍼를 처리하는 것 조차 문제될 수 있다(확실한가???)\n2. KNI -\u0026gt; DPDK tx_q나 alloc_q 역시 rx_q, free_q 와 동일한 이슈를 갖는다. Tx를 위해 사용할 mbuf를 미리 할당해 놓은 alloc_q에 존재하는 mbuf는 이전 DPDK application이 할당한 것이고, tx_q 에 존재하는 mbuf 역시 동일하다.\nstruct rte_kni_mbuf는 DPDK와 KNI kernel module간 통신할 때 사용되는 구조체로 rte_mbuf 중 KNI에게 필요한 정보만 모은 것이다.\n/* * The kernel image of the rte_mbuf struct, with only the relevant fields. * Padding is necessary to assure the offsets of these fields */ struct rte_kni_mbuf { void *buf_addr __attribute__((__aligned__(RTE_CACHE_LINE_SIZE))); char pad0[10]; uint16_t data_off; /**\u0026lt; Start address of data in segment buffer. */ char pad1[4]; uint64_t ol_flags; /**\u0026lt; Offload features. */ char pad2[4]; uint32_t pkt_len; /**\u0026lt; Total pkt len: sum of all segment data_len. */ uint16_t data_len; /**\u0026lt; Amount of data in segment buffer. */ /* fields on second cache line */ char pad3[8] __attribute__((__aligned__(RTE_CACHE_LINE_SIZE))); void *pool; void *next; };  ","id":128,"section":"posts","summary":"DPDK to KNI RX KNI는 rx_q로부터 mbuf를 수신한 후 data_len 크기의 skb를 할당하여 데이터를 복사한 후 netif_rx를 호출한다. 그러므로 mbuf는 KNI kernel m","tags":["DPDK","kni","study"],"title":"KNI가 buffer를 free 하는 방법","uri":"https://cychong47.github.io/2016/03/how_kni_free_mbuf/","year":"2016"},{"content":"Without Suppressing Scapy IPv6 warning cychong@ubuntu:~$ python Python 2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2] on linux2 Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; from scapy.all import * WARNING: No route found for IPv6 destination :: (no default route?) \u0026gt;\u0026gt;\u0026gt;  Suppress scapy IPv6 warning cychong@ubuntu:~$ python Python 2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2] on linux2 Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; import logging \u0026gt;\u0026gt;\u0026gt; logging.getLogger(\u0026quot;scapy.runtime\u0026quot;).setLevel(logging.ERROR) \u0026gt;\u0026gt;\u0026gt; from scapy.all import * \u0026gt;\u0026gt;\u0026gt;  ","id":129,"section":"posts","summary":"Without Suppressing Scapy IPv6 warning cychong@ubuntu:~$ python Python 2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2] on linux2 Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; from scapy.all import * WARNING: No route found for IPv6 destination :: (no default route?) \u0026gt;\u0026gt;\u0026gt;  Suppress scapy IPv6 warning cychong@ubuntu:~$ python Python 2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2] on linux2 Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information.","tags":["scapy"],"title":"(Scapy) Suppress Scapy warning message","uri":"https://cychong47.github.io/2016/03/scapy-suppress-scapy-warning-message/","year":"2016"},{"content":"import modules $ python \u0026gt;\u0026gt;\u0026gt; from scapy.all import * \u0026gt;\u0026gt;\u0026gt; from scapy.layers.ipsec import *  build plaintext packet \u0026gt;\u0026gt;\u0026gt; p = IP(src='1.1.1.1', dst='2.2.2.2') / TCP(sport=45012, dport=80) / Raw('testdata') \u0026gt;\u0026gt;\u0026gt; p = IP(str(p))  setup SA \u0026gt;\u0026gt;\u0026gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo='AES-CBC',crypt_key='sixteenbytes key')  Encrypt w/o IV \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |\u0026lt;ESP spi=0xdeadbeef seq=5 data='uD\\x7fdj19\\xe7\\xc4\\xff8\\x10\\xcdQ\\xf0\\xa6\\x1e!\\x84\\xc3\u0026gt;!\\x18\\xa6\\xf6\\xb8\\x93\\xc6it\\x9a\\xfc\\x1c\\xee\\xe5C\\xcd\\xf0\\x7fD\\xca\\x8d\\xadKh\\xa8\\xe5x' |\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show() ###[ IP ]### version = 4L ihl = 5L tos = 0x0 len = 76 id = 1 flags = frag = 0L ttl = 64 proto = esp chksum = 0x747a src = 1.1.1.1 dst = 2.2.2.2 \\options \\ ###[ ESP ]### spi = 0xdeadbeef seq = 5 data = 'uD\\x7fdj19\\xe7\\xc4\\xff8\\x10\\xcdQ\\xf0\\xa6\\x1e!\\x84\\xc3\u0026gt;!\\x18\\xa6\\xf6\\xb8\\x93\\xc6it\\x9a\\xfc\\x1c\\xee\\xe5C\\xcd\\xf0\\x7fD\\xca\\x8d\\xadKh\\xa8\\xe5x'  Encrypt w/ IV \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026quot;1234567890123456\u0026quot;) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |\u0026lt;ESP spi=0xdeadbeef seq=5 data='1234567890123456\\xa4\\x0b\\xebZ\\xa7\\xc8\\xb6\\x95\\xfb\\x13\\x07\\xc5TD\\xa2\\xe7DP\\xfcP\\xa5y\\xc4\\x06W\\xe8\\xf5\\xf0\\x86\\xe1\\x0c\\xfd' |\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show() ###[ IP ]### version = 4L ihl = 5L tos = 0x0 len = 76 id = 1 flags = frag = 0L ttl = 64 proto = esp chksum = 0x747a src = 1.1.1.1 dst = 2.2.2.2 \\options \\ ###[ ESP ]### spi = 0xdeadbeef seq = 5 data = '1234567890123456\\xa4\\x0b\\xebZ\\xa7\\xc8\\xb6\\x95\\xfb\\x13\\x07\\xc5TD\\xa2\\xe7DP\\xfcP\\xa5y\\xc4\\x06W\\xe8\\xf5\\xf0\\x86\\xe1\\x0c\\xfd'  data 의 시작 부분에 IV값 \u0026lsquo;1234567890123456\u0026rsquo;이 있음을 알 수 있다. ESP는 SPI(4B), SEQ(4B), IV(16B) , Encrypted Data 형태로 구성된다.\n만일 IV값의 길이가 틀리면 다음와 같이 에러 출력\n\u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026quot;1234567890\u0026quot;) Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;ipsec.py\u0026quot;, line 903, in encrypt return self._encrypt_esp(pkt, seq_num=seq_num, iv=iv) File \u0026quot;ipsec.py\u0026quot;, line 787, in _encrypt_esp raise TypeError('iv length must be %s' % self.crypt_algo.iv_size) TypeError: iv length must be 16  SecurityAssocaition 옵션 1. tunnel_header Tunnel mode를 사용하려면 tunnel_header 인자로 outer IP header instance를 넘긴다.\n\u0026gt;\u0026gt;\u0026gt; outer_ip = IP(src='10.10.10.10', dst='20.20.20.20') \u0026gt;\u0026gt;\u0026gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo='AES-CBC',crypt_key='sixteenbytes key', tunnel_header=outer_ip) \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026quot;1234567890123456\u0026quot;) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=108 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x3e24 src=10.10.10.10 dst=20.20.20.20 |\u0026lt;ESP spi=0xdeadbeef seq=5 data='1234567890123456`\\xc6\\xa9\\xe9Q\\x97-\\xd6\\xe5\\x07\\xb3\\x85\\xfb\\xc9\\xeaz\\x07~\\xfe\\x14\\xd1\\x19\\xd8F\\x8cS\\x10[\\x8f\\xfe\\x93_ut\\xef1\\xc0\\xc4|\\xdb\\xccH\\xea\\xf8\\xd2\\xd0jj\\xeeD\\x88\\x80\\xc5}U\\xb5_x)\\xaal/,\\x96' |\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show() ###[ IP ]### version = 4L ihl = 5L tos = 0x0 len = 108 id = 1 flags = frag = 0L ttl = 64 proto = esp chksum = 0x3e24 src = 10.10.10.10 dst = 20.20.20.20 \\options \\ ###[ ESP ]### spi = 0xdeadbeef seq = 5 data = '1234567890123456`\\xc6\\xa9\\xe9Q\\x97-\\xd6\\xe5\\x07\\xb3\\x85\\xfb\\xc9\\xeaz\\x07~\\xfe\\x14\\xd1\\x19\\xd8F\\x8cS\\x10[\\x8f\\xfe\\x93_ut\\xef1\\xc0\\xc4|\\xdb\\xccH\\xea\\xf8\\xd2\\xd0jj\\xeeD\\x88\\x80\\xc5}U\\xb5_x)\\xaal/,\\x96'  Tunnel mode를 사용하지 않은 경우와 별반 차이가 없어 보이지만, IP의 total length값이 기존 76바이에서 108바이트로 변경되었고, ESP data값도 달라졌다. Tunnel mode의 경우 ESP data에 원본 패킷 전체가 포함되는 반면 Transport mode이 경우 L4 layer이상만 포함되므로 값이 달라진다. IP total length의 경우 32바이트가 차이나는데 20 + 12 ???? FIMXE\n2. nat_t_header NAT traversal을 위해는 UDP encapsulation을 이용하는데 이 역시 SA 를 생성할 때 지정할 수 있다. IP total length의 경우 추가된 8byte의 UDP header가 고려되어 108byte에서 116byte로 커졌다.\n\u0026gt;\u0026gt;\u0026gt; nat_t_udp = UDP(dport=4500) \u0026gt;\u0026gt;\u0026gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo='AES-CBC',crypt_key='sixteenbytes key', tunnel_header=outer_ip, nat_t_header=nat_t_udp) \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026quot;1234567890123456\u0026quot;) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=116 id=1 flags= frag=0L ttl=64 proto=udp chksum=0x3e3d src=10.10.10.10 dst=20.20.20.20 options=[] |\u0026lt;UDP sport=domain dport=ipsec_nat_t len=8 chksum=0x0 |\u0026lt;ESP spi=0xdeadbeef seq=5 data='1234567890123456`\\xc6\\xa9\\xe9Q\\x97-\\xd6\\xe5\\x07\\xb3\\x85\\xfb\\xc9\\xeaz\\x07~\\xfe\\x14\\xd1\\x19\\xd8F\\x8cS\\x10[\\x8f\\xfe\\x93_ut\\xef1\\xc0\\xc4|\\xdb\\xccH\\xea\\xf8\\xd2\\xd0jj\\xeeD\\x88\\x80\\xc5}U\\xb5_x)\\xaal/,\\x96' |\u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show() ###[ IP ]### version = 4L ihl = 5L tos = 0x0 len = 116 id = 1 flags = frag = 0L ttl = 64 proto = udp chksum = 0x3e3d src = 10.10.10.10 dst = 20.20.20.20 \\options \\ ###[ UDP ]### sport = domain dport = ipsec_nat_t len = 8 chksum = 0x0 ###[ ESP ]### spi = 0xdeadbeef seq = 5 data = '1234567890123456`\\xc6\\xa9\\xe9Q\\x97-\\xd6\\xe5\\x07\\xb3\\x85\\xfb\\xc9\\xeaz\\x07~\\xfe\\x14\\xd1\\x19\\xd8F\\x8cS\\x10[\\x8f\\xfe\\x93_ut\\xef1\\xc0\\xc4|\\xdb\\xccH\\xea\\xf8\\xd2\\xd0jj\\xeeD\\x88\\x80\\xc5}U\\xb5_x)\\xaal/,\\x96'  ","id":130,"section":"posts","summary":"import modules $ python \u0026gt;\u0026gt;\u0026gt; from scapy.all import * \u0026gt;\u0026gt;\u0026gt; from scapy.layers.ipsec import * build plaintext packet \u0026gt;\u0026gt;\u0026gt; p = IP(src='1.1.1.1', dst='2.2.2.2') / TCP(sport=45012, dport=80) / Raw('testdata') \u0026gt;\u0026gt;\u0026gt; p = IP(str(p)) setup SA \u0026gt;\u0026gt;\u0026gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo='AES-CBC',crypt_key='sixteenbytes key') Encrypt w/o IV \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |\u0026lt;ESP spi=0xdeadbeef seq=5 data='uD\\x7fdj19\\xe7\\xc4\\xff8\\x10\\xcdQ\\xf0\\xa6\\x1e!\\x84\\xc3\u0026gt;!\\x18\\xa6\\xf6\\xb8\\x93\\xc6it\\x9a\\xfc\\x1c\\xee\\xe5C\\xcd\\xf0\\x7fD\\xca\\x8d\\xadKh\\xa8\\xe5x' |\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show()","tags":["Python","scapy","IPsec","공부"],"title":"how to build IPsec packet with scapy","uri":"https://cychong47.github.io/2016/02/how-to-use-snapy-for-ipsec/","year":"2016"},{"content":"다음과 같이 scapy를 이용해서 fragment를 쉽게 만들 수 있다.\nfrom scapy.all import * dip=\u0026quot;10.0.0.1\u0026quot; payload=\u0026quot; \u0026quot;*1000 packet=IP(dst=dip)/UDP(dport=0x1234)/payload frag_list=fragment(packet,fragsize=500) counter=1 for fragment in frag_list: print \u0026quot;Packet no%d\u0026quot; %counter print fragment.show() counter+=1 send(fragment)  frag_list에서 counter 변수를 확인해서 전송하지 않으면 간단하게 fragment가 수신되지 않은 경우에 시험할 수 있음.\n필요하면 frag_list의 순서를 뒤집는 것도 가능하고, 각 fragment의 offset값을 조정하거나 패킷 크기를 변경하면 다른 비정상 경우도 쉽게 시험할 수 있다.\nscapy interactive tutorial\n","id":131,"section":"posts","summary":"다음과 같이 scapy를 이용해서 fragment를 쉽게 만들 수 있다. from scapy.all import * dip=\u0026quot;10.0.0.1\u0026quot; payload=\u0026quot; \u0026quot;*1000 packet=IP(dst=dip)/UDP(dport=0x1234)/payload frag_list=fragment(packet,fragsize=500) counter=1 for fragment in frag_list: print \u0026quot;Packet no%d\u0026quot; %counter print fragment.show() counter+=1 send(fragment) frag_list에서 counter 변수를 확","tags":["Python","scapy","fragment"],"title":"fragment missing test with scapy","uri":"https://cychong47.github.io/2016/02/fragment-missing-test-with-scapy/","year":"2016"},{"content":"Vagrant\nfd.io의 개발 환경 구성하는 문서를 보니 vagrant를 사용한다. 그런데 또 virtualbox니 vmware 이야기를 한다. 이전에도 vagrant라는 단어를 들어본적이 있었는데 이번 기회에 좀 알아보기로\nWhy Vagrant를 보면 다음과 같이 설명하고 있다.\n Vagrant provides easy to configure, reproducible, and portable work environments built on top of industry-standard technology and controlled by a single consistent workflow to help maximize the productivity and flexibility of you and your team.\nTo achieve its magic, Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox, VMware, AWS, or any other provider. Then, industry-standard provisioning tools such as shell scripts, Chef, or Puppet, can be used to automatically install and configure software on the machine.\n Chef, Puppet 역시 다른 글에서 본 적은 있지만 구체적으로 뭔지는 모른다. 하지만 대충(?) 이해하기에는 VirtualBox, vmware, AWS용 이미지 등을 만드는데 필요한 설정 내용을 기술하는 방법으로 보인다. 그래서 지원하는 몇 가지 양식에 맞게 필요한 요구사항을 기술하면 vagrant가 VM용 이미지를 만들어 준다는 것으로 보인다.\nVPP 빌드를 생각해 보면 다음과 같다.\n VirtualBox 혹은 vmware 설치 vagrant up 명령 실행. 아마도 지정한 VAGRANT PROVIDER(VirtualBox 혹은 wmware)에 맞는 VM 이미지를 생성 VM 실행  흠. 그런데 vagrant up 명령을 내\n","id":132,"section":"posts","summary":"Vagrant fd.io의 개발 환경 구성하는 문서를 보니 vagrant를 사용한다. 그런데 또 virtualbox니 vmware 이야기를 한다. 이전에도 vagrant라는 단","tags":["vagrant"],"title":"Vagrant","uri":"https://cychong47.github.io/2016/02/vagrant/","year":"2016"},{"content":"├── build-data │ ├── packages │ └── platforms ├── build-root │ ├── deb │ │ └── debian │ │ └── source │ ├── emacs-lisp │ ├── packages │ ├── rpm │ ├── scripts │ └── vagrant ├── dpdk │ ├── dkms │ ├── dpdk-2.1.0_patches │ └── dpdk-2.2.0_patches ├── g2 ├── gmod │ └── gmod ├── perftool ├── sample-plugin │ └── sample ├── svm ├── test │ ├── resources │ │ ├── libraries │ │ │ ├── bash │ │ │ ├── python │ │ │ └── robot │ │ │ └── vat │ │ └── templates │ │ └── vat │ └── tests │ └── suites │ ├── bridge_domain │ └── vhost_user_dummy ├── vlib │ ├── example │ └── vlib │ └── unix ├── vlib-api │ ├── vlibapi │ ├── vlibmemory │ └── vlibsocket ├── vnet │ ├── etc │ │ └── scripts │ │ ├── dhcp │ │ ├── ludd-cluster-1 │ │ ├── ludd-cluster-3 │ │ ├── mpls-o-ethernet │ │ ├── mpls-o-gre │ │ ├── sr │ │ └── virl │ └── vnet │ ├── cdp │ ├── classify │ ├── devices │ │ ├── dpdk │ │ ├── ssvm │ │ └── virtio │ ├── dhcp │ ├── dhcpv6 │ ├── ethernet │ ├── flow │ ├── gre │ ├── hdlc │ ├── ip │ ├── ipsec │ ├── l2 │ ├── l2tp │ ├── lawful-intercept │ ├── lisp-gpe │ ├── llc │ ├── map │ │ └── examples │ ├── mcast │ ├── mpls-gre │ ├── nsh-gre │ ├── nsh-vxlan-gpe │ ├── osi │ ├── pg │ ├── plugin │ ├── policer │ ├── ppp │ ├── snap │ ├── sr │ ├── srp │ ├── unix │ ├── vcgn │ └── vxlan ├── vpp │ ├── api │ ├── app │ ├── conf │ ├── oam │ ├── stats │ └── vnet ├── vpp-api-test │ ├── scripts │ └── vat ├── vpp-japi │ ├── japi │ │ ├── org │ │ │ └── openvpp │ │ │ └── vppjapi │ │ └── test │ └── m4 ├── vppapigen └── vppinfra ├── config ├── tools └── vppinfra  ","id":133,"section":"posts","summary":"├── build-data │ ├── packages │ └── platforms ├── build-root │ ├── deb │ │ └── debian │ │ └── source │ ├── emacs-lisp │ ├── packages │ ├── rpm │ ├── scripts │ └── vagrant ├── dpdk │ ├── dkms │ ├── dpdk-2.1.0_patches │ └── dpdk-2.2.0_patches ├── g2 ├── gmod │ └── gmod ├── perftool ├── sample-plugin │ └── sample ├── svm ├── test │ ├── resources │ │ ├── libraries │ │ │ ├── bash │ │ │ ├── python │ │ │ └── robot │ │ │ └── vat │ │ └── templates │ │ └── vat │ └── tests │ └── suites │ ├── bridge_domain │ └── vhost_user_dummy ├── vlib │ ├── example │ └── vlib │ └── unix ├── vlib-api │ ├── vlibapi │ ├── vlibmemory │ └── vlibsocket ├── vnet │ ├── etc │ │ └── scripts │ │ ├── dhcp │ │ ├── ludd-cluster-1 │ │ ├── ludd-cluster-3 │ │ ├── mpls-o-ethernet │ │ ├── mpls-o-gre │ │ ├── sr │ │ └── virl │ └── vnet │ ├── cdp │ ├── classify │ ├── devices │ │ ├── dpdk │ │ ├── ssvm │ │ └── virtio │ ├── dhcp │ ├── dhcpv6 │ ├── ethernet │ ├── flow │ ├── gre │ ├── hdlc │ ├── ip │ ├── ipsec │ ├── l2 │ ├── l2tp │ ├── lawful-intercept │ ├── lisp-gpe │ ├── llc │ ├── map │ │ └── examples │ ├── mcast │ ├── mpls-gre │ ├── nsh-gre │ ├── nsh-vxlan-gpe │ ├── osi │ ├── pg │ ├── plugin │ ├── policer │ ├── ppp │ ├── snap │ ├── sr │ ├── srp │ ├── unix │ ├── vcgn │ └── vxlan ├── vpp │ ├── api │ ├── app │ ├── conf │ ├── oam │ ├── stats │ └── vnet ├── vpp-api-test │ ├── scripts │ └── vat ├── vpp-japi │ ├── japi │ │ ├── org │ │ │ └── openvpp │ │ │ └── vppjapi │ │ └── test │ └── m4 ├── vppapigen └── vppinfra ├── config ├── tools └── vppinfra  ","tags":[],"title":"fd.io","uri":"https://cychong47.github.io/2016/02/fd-io-tree/","year":"2016"},{"content":"2016년 2월 11일 공개된 CISCO 주도의 프로젝트. 무려 2002년부터 개발한 것으로 현재 버전은 3번째 revision이라고 한다.\n간만에 dpdk.org mailing list에 들어갔다 가장 최근에 올라온 글 제목이 눈에 띄었다.\n [dpdk-dev] [dpdk-announce] new project using DPDK - FD.io Vincent JARDIN\n \u0026ldquo;new project\u0026rdquo;?\n그래서 내용을 봤더니 이게 다 였다는\nA new project using DPDK is available, http://FD.io said FiDo You can clone it from: http://gerrit.fd.io/ Best regards, Vincent  그래도 첫 번째 링크를 따라가 보니 화려하다. CISCO, Ericsson, Intel이 platinum member네. 어딜가나 있는 여러 회사 이름도 보이고. Cavium도 있네. ODP를 밀고 있는데 잘 안되나? 물론 내용을 보면 조금 다르긴 하지만.\n거기에 6wind도 있다. 역시 직접적인 경쟁회사라고 볼 수도 있을 텐데. E, H사가 보이는데 N사는 아직 없다. OFP에 집중하려는 걸까\n코드는 github에 올려있어 확인해 봐야겠지만, https://fd.io/technology 에 설명된 내용을 잠깐 보면 이런 특징을 갖는다고 한다.\nVector Packet Processing Rather than processing the first packet through the whole graph, and then the second packet through the whole graph, VPP instead processes the entire vector of packets through a graph node before moving on to the next graph node. ... Picking up each tool in order for each piece of lumber is going to be much slower.  예전 Network Processor와 달리 Instruction Cache의 영향을 많이 받는 General Purpose Processor를 목적으로 한 SW라 instruction cache miss에 대한 고민을 많이 한 듯 하다.\n기능 들은 graph node라고 표현했는데 일반적인 모듈 형태와 동일한 것으로 이해되고\nConfiguration 설정관련해서는 다양한 방법을 제공한다. 이를 윟 HoneyComb Agent라는 것을 두는데 NetConf/Yang, REST 등의 인터페이스를 제공한다.\nExternal App과의 연동도 가능한데 C혹은 Java library를 지원한다고 한다. 이 부분도 좀 구체적으로 봐야 할 듯 한데.\n재밌는 프로젝트로 보인다. 기존에 하고 있는 일과 많이 겹치는 게 사실이라는 것이 이슈지만\u0026hellip;\n성능 관련 내용은 lightreading 기사(2015년 10월) Validating Cisco\u0026rsquo;s NFV Infrastructure Pt. 1 를 참고. Part 2도 참고\nbuild 빌드하려면 VM과 valgrid환경이 필요하다고 하는데.\nSetting Up Your Dev Environment\nmailing list  vpp-dev, mail archive irc  2/11일 당일 기사 The Linux Foundation Forms Open Source Effort to Advance IO Services\n founding members 6WIND, Brocade, Cavium, Cisco, Comcast, Ericsson, Huawei, Inocybe Technologies, Intel Corporation, Mesosphere, Metaswitch Networks (Project Calico), PLUMgrid and Red Hat The design of FD.io is hardware, kernel, and deployment (bare metal, VM, container) agnostic. providing an out-of-the-box vSwitch/vRouter VPP is production code currently running in products available on the market today. VPP runs in user space on multiple architectures, including x86, ARM, and Power, and is deployed on various platforms including servers and embedded devices. Continuous Performance Lab (CPL). The CPL provides an open source, fully automated testing infrastructure framework for continuous verification of code functionality and performance. Code breakage and performance degradation is flagged before patch review, conserving project resources and increasing code quality.  ","id":134,"section":"posts","summary":"2016년 2월 11일 공개된 CISCO 주도의 프로젝트. 무려 2002년부터 개발한 것으로 현재 버전은 3번째 revision이라고 한다. 간만에 dpdk.org mailing list에 들","tags":["DPDK","Intel","cisco"],"title":"fd.io","uri":"https://cychong47.github.io/2016/02/fd-io/","year":"2016"},{"content":" 왜 공부해야 하는가\n사회의 변화속도는 우리의 변화속도를 압도하기 때문입니다.\n\u0026lt;누가 내 치즈를 옮겼을까\u0026gt;에 잘 묘사되어 있지요.\n따라잡지 않으면 뒤쳐지기 때문에 우리는 늘 공부해야 합니다.\n https://brunch.co.kr/@choihs0228/4\n","id":135,"section":"posts","summary":"왜 공부해야 하는가 사회의 변화속도는 우리의 변화속도를 압도하기 때문입니다. \u0026lt;누가 내 치즈를 옮겼을까\u0026gt;에 잘 묘사되어 있지요. 따라잡지 않으면 뒤","tags":["공부","생각"],"title":"왜 공부해야 하는가에 대한 간단하지만 명확한 답","uri":"https://cychong47.github.io/2016/02/why_have_to_keep_studying/","year":"2016"},{"content":"constructor attribute http://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/\nconstructor attribute을 가진 함수는 main 함수를 실행하기 전에 호출한다.\n예제 (출처)\n#include \u0026lt;stdio.h\u0026gt; void begin (void) __attribute__((constructor)); void end (void) __attribute__((destructor)); int main (void) { printf (\u0026quot;\\nInside main ()\u0026quot;); } void begin (void) { printf (\u0026quot;\\nIn begin ()\u0026quot;); } void end (void) { printf (\u0026quot;\\nIn end ()\\n\u0026quot;); }  실행하면\nIn begin () Inside main () In end ()  DPDK DPDK의 경우 device driver들을 모두 constructor attirbute을 사용해서 main 함수 전에 호출되록 한다.\nPMD_REGISTER_DRIVER(pmd_igb_drv); PMD_REGISTER_DRIVER(pmd_igbvf_drv); PMD_REGISTER_DRIVER(em_pmd_drv);  Physical device 외에 virtual device들도 동일하게 등록한다.\nPMD_REGISTER_DRIVER(cryptodev_aesni_mb_pmd_drv); PMD_REGISTER_DRIVER(pmd_qat_drv);  PMD_REGISTER_DRIVER()는 lib/librte_eal/common/include/rte_dev.h에 다음과 같이 정의되어 있다.\n#define PMD_REGISTER_DRIVER(d)\\ void devinitfn_ ##d(void);\\ void __attribute__((constructor, used)) devinitfn_ ##d(void)\\ {\\ rte_eal_driver_register(\u0026amp;d);\\ }  rte_eal_deriver_register()는 lib/librte_eal/common/eal_common_dev.c에서 static 변수로 정의된 rte_driver_list[]에 함수 인자로 넘겨진 driver를 등록한다.\n인자는 다음 struct 형태로 정의된다.\n/** * A structure describing a device driver. */ struct rte_driver { TAILQ_ENTRY(rte_driver) next; /**\u0026lt; Next in list. */ enum pmd_type type; /**\u0026lt; PMD Driver type */ const char *name; /**\u0026lt; Driver name. */ rte_dev_init_t *init; /**\u0026lt; Device init. function. */ rte_dev_uninit_t *uninit; /**\u0026lt; Device uninit. function. */ };  등록된 디바이스들은 rte_eal_init() 초기화 과정에서 호출되는 함수 rte_eal_dev_init()에서 각 디바이스의 초기화 함수가 호출된다.\nint rte_eal_dev_init(void) { /* call the init function for each virtual device */ TAILQ_FOREACH(devargs, \u0026amp;devargs_list, next) { if (devargs-\u0026gt;type != RTE_DEVTYPE_VIRTUAL) continue; if (rte_eal_vdev_init(devargs-\u0026gt;virt.drv_name, devargs-\u0026gt;args)) { ... } /* Once the vdevs are initalized, start calling all the pdev drivers */ TAILQ_FOREACH(driver, \u0026amp;dev_driver_list, next) { if (driver-\u0026gt;type != PMD_PDEV) continue; /* PDEV drivers don't get passed any parameters */ driver-\u0026gt;init(NULL, NULL); }  QAT device static struct rte_driver pmd_qat_drv = { .type = PMD_PDEV, .init = rte_qat_pmd_init, };  QAT PMD 초기화  rte_qat_pmd_init() rte_cryptodev_pmd_driver_register() rte_cryptodev_init() \u0026amp; rte_eal_pci_register()  AESNI_MB device static struct rte_driver cryptodev_aesni_mb_pmd_drv = { .name = CRYPTODEV_NAME_AESNI_MB_PMD, .type = PMD_VDEV, .init = cryptodev_aesni_mb_init, .uninit = cryptodev_aesni_mb_uninit };  AESNI_MB 초기화  cryptodev_aesni_mb_init() cryptodev_aesni_mb_create()   CPU가 AES 연산을 지원하는 지 확인 CPU가 AVX2/AVX/SSE4_1 중 최소 한 가지를 지원하는 지 확인 rte_cryptodev_pmd_virtual_dev_init()를 이용해 PMD device로 등록  e1000 static int rte_em_pmd_init(const char *name __rte_unused, const char *params __rte_unused) { rte_eth_driver_register(\u0026amp;rte_em_pmd); return 0; } struct rte_driver em_pmd_drv = { .type = PMD_PDEV, .init = rte_em_pmd_init, };  Physical NIC은 rte_eth_driver_register()함수를 이용하여 rte_eth_dev에 등록된다. 이때 등록되는 디바이스 구조체는 다음과 같다.\nstatic struct eth_driver rte_em_pmd = { .pci_drv = { .name = \u0026quot;rte_em_pmd\u0026quot;, .id_table = pci_id_em_map, .drv_flags = RTE_PCI_DRV_NEED_MAPPING | RTE_PCI_DRV_INTR_LSC | RTE_PCI_DRV_DETACHABLE, }, .eth_dev_init = eth_em_dev_init, .eth_dev_uninit = eth_em_dev_uninit, .dev_private_size = sizeof(struct e1000_adapter), };  rte_eth 구조체에 등록하는 함수 rte_eth_driver_register()는 다음과 같이 구현되어 있어, PCI device list에 NIC을 등록한다. 등록된 PCI device들은 rte_eal_init() 과정에서 호출되는 PCI scan 과정을 통해 실제 NIC을 찾는 과정을 거친다.\n/** * Register an Ethernet [Poll Mode] driver. * * Function invoked by the initialization function of an Ethernet driver * to simultaneously register itself as a PCI driver and as an Ethernet * Poll Mode Driver. * Invokes the rte_eal_pci_register() function to register the *pci_drv* * structure embedded in the *eth_drv* structure, after having stored the * address of the rte_eth_dev_init() function in the *devinit* field of * the *pci_drv* structure. * During the PCI probing phase, the rte_eth_dev_init() function is * invoked for each PCI [Ethernet device] matching the embedded PCI * identifiers provided by the driver. */ void rte_eth_driver_register(struct eth_driver *eth_drv) { eth_drv-\u0026gt;pci_drv.devinit = rte_eth_dev_init; eth_drv-\u0026gt;pci_drv.devuninit = rte_eth_dev_uninit; rte_eal_pci_register(\u0026amp;eth_drv-\u0026gt;pci_drv); }  ","id":136,"section":"posts","summary":"constructor attribute http://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/ constructor attribute을 가진 함수는 main 함수를 실행하기 전에 호출한다. 예제 (출처) #include \u0026lt;stdio.h\u0026gt; void begin (void) __attribute__((constructor)); void end (void) __attribute__((destructor)); int main (void) { printf (\u0026quot;\\nInside main ()\u0026quot;); } void begin (void) { printf (\u0026quot;\\nIn begin ()\u0026quot;); } void end","tags":["DPDK"],"title":"DPDK NIC 초기화","uri":"https://cychong47.github.io/2016/02/dpdk_nic_init/","year":"2016"},{"content":"Introducing Python 을 판교어린이도서관에서 짧게 보고 적은 아이템들\npython3 based\nDecorator는 공부가 필요한 내용\nsys.path : module 검색 경로 __init__.py 파일이 있으면 그 디렉토리를 PKG로 간주함\ndefaultdic()\nCounters()\ndicionary는 key의 순서를 보장하지 않음. OrderedDict()로 사전을 정의하면 가능 deque = stack + queue pprint()는 print보다 깔끔하게 출력한다고.\n'\\uXXX' 유니코드\n%10.4s : 10칸의 공간. 문자열 중 4개만 출력\nstruct '\u0026gt;LL' : '\u0026gt;' Big endian, L : uint32_t\nlist comprehension : for loop보다 빠름. 어떻게 사용하는 지 구체적으로 좀 더 알아봐야 함.\nConfiguration pyyaml : load() 대신 safe_load() 사용 1단계 정보면 내장 configuration을 사용하는 것이 가장 편리함. ConfigParser()\n[A] B=C  접근할 때는 config = ConfigParser(filename)\nconfig[\u0026lsquo;A\u0026rsquo;][\u0026lsquo;B\u0026rsquo;]\nRedis Redis 서버. pip install redis redit.Redis() Request - Agent - Redis server - Checker\npip install requests\ngevent\nfab을 이용해 명령을 내린 후 PKG 정보를 알아낼 수 있음. cat XXX /pkg/.RegInfo endtime 파일 확인\nmodule dependency pip -r requirements.txt\ndebugging pylint\npyflakes\npep8\n","id":137,"section":"posts","summary":"Introducing Python 을 판교어린이도서관에서 짧게 보고 적은 아이템들 python3 based Decorator는 공부가 필요한 내용 sys.path : module 검색 경로 __init__.py 파일이 있으면 그 디렉토리를 PKG로 간주함","tags":["Python"],"title":"Introducing Python","uri":"https://cychong47.github.io/2016/02/introducing-python/","year":"2016"},{"content":"SR-IOV and DPDK\nAccelerating the NFV Data Plane : SR-IOV and DPDK… in my own words 를 읽고 요약\nBefore HW assisted Virtualisation SR-IOV 전까지는 VMM이 패킷 송수신에 매번 개입해야 했음.\n 1st interrupt from NIC to VMM 2nd interrupt from VMM to VM  Intel VMDq Only one interrupt from NIC to VM as each VM has its own Rx queue.\nSR-IOV  SR-IOV : Standard IO memory Memory Management Unit from Intel(VT-d) and AMD(IOV) Virtual Function - Limited, lightweight, PCIe resource and a dedicated Tx/Rx packet queue Interrupt 부담이 없다고 하는데 왜??? 마지막 결론에서는 SR-IOV를 사용하면 interrupt를 두 개 다 없앨 수 있다고 하는데 이 부분은 잘 이해가 안된다. HW 기반  SR-IOV and vSwitch SR-IOV는 VMM의 부담을 덜어주는 장점을 가지고 있지만, 반대로 vSwitch가 제공할 수 있는 네트웍 기능들 - portability, flexibility, QoS, complex traffic steering 등을 이용할 수 없게 되었다는. 문제는 이런 기능들이 NFV환경에서 필요하고(할 거고). vSwitch의 기능을 사용할 수 없으면 service chaining 같은 건 고민할 것도 없고, 위 기능들을 모두 각 VNF에서 구현해야 하는데. 물론 기존 PNF가 그랬던 것 처럼 못할 것도 없지만, 한 곳에 모아놓은 VNF사이에 구현해야 하는 공통 기능이면 가능하면 NFVI에서 구현할 수 있으면 좋겠지\nSR-IOV is good for stand-alone virtualised appliance or architecture where high-traffic VNFs, routers and L3 centric devices vSwitch is good for strict intra-host east-west demands\nHybrid architecture requires additional management complexities and rule out the possibility of a common, efficient and flexible SDN shot deployment infrastructure\nSR-IOV it isn’t currently possible to take advantage of overlay-based network virtualization, which is commonly used in large-scale virtualization environments.\nAccelerated vSwitch solutions do support overlay-based network virtualization, they are less efficient overall and they may also expose additional security risks through the use of shared memory that may be accessible from untrusted VMs on the same compute node.\nOVS/DPDK Megaflow : wildcard\nMicro flow : exact match based cache\nExcept 64B, SR-IOV and OVS/DPDK shows almost same performance against Bare-Metal (HP) http://www.slideshare.net/jstleger/dpdk-summit-2015-hp-al-sanders\nHowever, IMAX shows 50-60% is 64Byte\nhttp://www.metaswitch.com/the-switch/tackling-the-nfv-packet-performance-challenge\nTackling the NFV Packet Performance Challenge\nSR-IOV vs. virtue SRIOV is good for some cases in a VM but does not scale to many VMs or containers as NIC’s support for VF is limited in number and performance\nSRIOV is very god in the host user space to gain direct access to the devices.\nRight-now, virtue is the only solution we have today as a standard\n","id":138,"section":"posts","summary":"SR-IOV and DPDK Accelerating the NFV Data Plane : SR-IOV and DPDK… in my own words 를 읽고 요약 Before HW assisted Virtualisation SR-IOV 전까지는 VMM이 패킷 송수신에 매번 개입해야 했음. 1st interrupt from NIC to VMM 2nd interrupt from VMM to VM Intel VMDq Only one interrupt","tags":["DPDK","SRIOV","VNF","nfv"],"title":"SR-IOV and DPDK","uri":"https://cychong47.github.io/2016/02/sriov-and-dpdk/","year":"2016"},{"content":"pktmbuf_offload  pool은 rte_pktmbuf_offload_pool_create()를 사용하여 생성  l2fwd_mbuf_ol_pool = rte_pktmbuf_offload_pool_create( \u0026quot;mbuf_offload_pool\u0026quot;, NB_MBUF, 128, 0, rte_socket_id());   할당은 rte_pktmbuf_offload_alloc()를 이용.  rte_pktmbuf_offload_alloc(l2fwd_mbuf_ol_pool, RTE_PKTMBUF_OL_CRYPTO);   mbuf 마다 하나씩 할당해서 crypto 연산에 사용 crypto 연산에 필요한 추가 옵션 등을 설정함.  /* Append space for digest to end of packet */ ol-\u0026gt;op.crypto.digest.data = (uint8_t *)rte_pktmbuf_append(m, cparams-\u0026gt;digest_length); ol-\u0026gt;op.crypto.digest.phys_addr = rte_pktmbuf_mtophys_offset(m, rte_pktmbuf_pkt_len(m) - cparams-\u0026gt;digest_length); ol-\u0026gt;op.crypto.digest.length = cparams-\u0026gt;digest_length; ol-\u0026gt;op.crypto.iv.data = cparams-\u0026gt;iv_key.data; ol-\u0026gt;op.crypto.iv.phys_addr = cparams-\u0026gt;iv_key.phys_addr; ol-\u0026gt;op.crypto.iv.length = cparams-\u0026gt;iv_key.length; ol-\u0026gt;op.crypto.data.to_cipher.offset = ipdata_offset; ol-\u0026gt;op.crypto.data.to_cipher.length = data_len; ol-\u0026gt;op.crypto.data.to_hash.offset = ipdata_offset; ol-\u0026gt;op.crypto.data.to_hash.length = data_len;  l2fwd_simple_crypto_enqueue()  crypto operation에 맞게 data align에 맞게 padding rte_crypto_op_attach_session() ol-\u0026gt;op에 crypto 연산에 필요한 정보를 설정  crypto 대상 위치, 길이 등 session 개념이 있는데 정확히 뭔지는 모르겠음…   rte_crypto_op_attach_session()  op-\u0026gt;session = sess; op-\u0026gt;type = RTE_CRYPTO_OP_WITH_SESSION;   rte_pktmbuf_offload_attach()  l2fwd_crypto_enqueue()  l2fwd_crypto_send_burst()  rte_cryptodev_enqueue_burst()    struct rte_mbuf_offload /** * Generic packet mbuf offload * This is used to specify a offload operation to be performed on a rte_mbuf. * Multiple offload operations can be chained to the same mbuf, but only a * single offload operation of a particular type can be in the chain */ struct rte_mbuf_offload { struct rte_mbuf_offload *next; /**\u0026lt; next offload in chain */ struct rte_mbuf *m; /**\u0026lt; mbuf offload is attached to */ struct rte_mempool *mp; /**\u0026lt; mempool offload allocated from */ enum rte_mbuf_ol_op_type type; /**\u0026lt; offload type */ union { struct rte_crypto_op crypto; /**\u0026lt; Crypto operation */ } op; };  ","id":139,"section":"posts","summary":"pktmbuf_offload pool은 rte_pktmbuf_offload_pool_create()를 사용하여 생성 l2fwd_mbuf_ol_pool = rte_pktmbuf_offload_pool_create( \u0026quot;mbuf_offload_pool\u0026quot;, NB_MBUF, 128, 0, rte_socket_id()); 할당은 rte_pktmbuf_o","tags":[],"title":"DPDK 2.2 crypto dev API","uri":"https://cychong47.github.io/2016/01/dpdk-2-2-crypto-dev-api/","year":"2016"},{"content":"2016.02.10 기준\n DPDK-dump TRex - Realistic traffic generator\ngit-hub - trex-core, trex-doc, trex-profiles, trex-qt-gui Packet-journey git-hub FD.io Fast Data Path DPDK-nginx DPDK-pktgen DPDK-ODP TCP/IP stack for DPDK  ","id":140,"section":"posts","summary":"2016.02.10 기준 DPDK-dump TRex - Realistic traffic generator git-hub - trex-core, trex-doc, trex-profiles, trex-qt-gui Packet-journey git-hub FD.io Fast Data Path DPDK-nginx DPDK-pktgen DPDK-ODP TCP/IP stack for DPDK","tags":["DPDK"],"title":"DPDK based applications","uri":"https://cychong47.github.io/2016/01/dpdk_based_apps/","year":"2016"},{"content":"우연히 tumblr를 보니 2013년에 적었던 답답한 현실이 지금도 똑같다는 사실에 놀랐다. 들으려고 하는 사람은 없고, 쓸데없는 일에 시간을 보내는 건 지금도 전혀 바뀐게 없어 보인다.\n여전히 사용하라는 툴에서 제공하는 정보와 취합해 달라고 하는 정보가 다르다. 그럼 어떻게 하라는 건지? 툴을 고치던가, 툴의 정보를 원하는 정보로 바꾸는 기준을 제시해줘야 하는 거 아닌가? 내용은 관심없고, 그냥 결과만 달라고 하는. 자기가 그런 변환 작업을 한 적이 없으니 얼마나 귀찮은지 모르는 거다. 그리고 사람마다 다른 기준으로 정보를 취합해도 별 문제가 없다는 건 결국 별로 중요하지 않는 내용이라는 거다. 그런 걸 사람들이 못 느낄까? 다 안다. 결국 정보를 제공해야 하는 사람도 대충 대충 하게 된다. 악순환.\n정말 이젠 지겹다.\n","id":141,"section":"posts","summary":"우연히 tumblr를 보니 2013년에 적었던 답답한 현실이 지금도 똑같다는 사실에 놀랐다. 들으려고 하는 사람은 없고, 쓸데없는 일에 시간을 보내는 건 지금도 전","tags":[],"title":"2년전에 느꼈던 답답함이 여전하네","uri":"https://cychong47.github.io/2016/01/two-years-back/","year":"2016"},{"content":"일단 읽다가 중단. 다른 걸 먼저 봐야 할 것 같다. 공감하는 내용이 많지만 이 책을 본다고 내가 어쩔 수 있는 내용이 별로 없어서\u0026hellip;.\np78\n 이렇게 투명하게 공개함으로써 얻을 수 있는 이득은 회사의 모든 직원이 현재 무슨 일이 어떻게 진행되고 있는 지 알게 된다는 것이다. 어쩌면 별것 아닌 것처럼 들릴 수도 있지만 전혀 그렇지 않다. 덩치가 큰 조직에서는 흔히 여러 하부 조직들이 쓸데없는 일을 하면서 자원을 낭비한다. 그러나 정보가 공유될 때 전 직원은 다른 부서나 팀의 목표가 제각기 다르다는 사실을 충분히 이해하고 내부의 소모적인 경쟁을 피한다.\n p81\n 투명성이 가져다주는 뜻하지 않은 이득 가운데 하나는 단지 자료를 공유하는 것만으로도 생산성이 향상된다는 점이다. 존스홉킨스 병원. 관상동맥 우회 수술의 사망률\n p85\n 직원의 목소리에 귀를 기울일 때 나타나는 긍정적인 효과는 이미 입증됐는데\u0026hellip;\n 직원의 목소리를 이끌어내는 것은 정확한 판단과 조직에 효율성을 더하는 핵심 요인이라는 사실을 사람들은 오래전부터 알고 있었다. 직원의 목소리를 주제로 한 여러 연구조사는 직원의 목소리가 의사 결정의 질, 팀의 성과 그리고 회사의 성과에 긍정적인 효과를 발휘한다는 사실을 꾸준히 확산시켜준다.\n   직원들이 가장 크게 좌절감을 느?낀 문제들은 사소하면서도 쉽게 고칠 수 있는 것들이었다.\n ","id":142,"section":"posts","summary":"일단 읽다가 중단. 다른 걸 먼저 봐야 할 것 같다. 공감하는 내용이 많지만 이 책을 본다고 내가 어쩔 수 있는 내용이 별로 없어서\u0026hellip;. p78 이렇게 투명하게 공개","tags":["Book"],"title":"(책) 구글의 아침은 자유가 시작된다.","uri":"https://cychong47.github.io/2016/01/google-work-rules/","year":"2016"},{"content":"SCI 결과를 개선하기 위해 실질적으로 이뤄지는 노력이 안 보인다는 것. 노력한다해도 그건 관리자와 비관리자가 함께 노력해야 하는 일일텐데(관리자나 회사에 대한 불만이므로 그 불만 개선이 노력이 맞는 방향인지는 당연히 비관리지에게도 한께 논의되어야 한다) 그런 건 보기 어렵다.\n문제 제기는 니들이 하지만 문제 해결은 나만 할 수 있다고 착각은 버려야 한다. 직원들이 불만에 대해 공감도 못하는데 어떻게 그 불만을 해결하기 위해 노력할 수 있겠나. 아니 공감을 하지 못하면 이해하기 위해 혹은 설득하기 위해 함께 이야기해야 하는데 그런 노력은 대부분 알아서 하란다. 잘 될 턱이 있나.\n일년에 한 번 있는 피드백을 기다리겠다는 것 역시 불만을 제기하는 직원들이 지쳐서 포기하게 만들겠다는 게 아닌가 싶다. 직원들은 결과전에 진행상황만 봐도 자신의 이야기가 공감을 받았다고 생각하고 기뻐할 텐데 그런 점에 대한 고민은 없는 듯.\n구글의 아침은 자유가 시작된다 p218\n","id":143,"section":"posts","summary":"SCI 결과를 개선하기 위해 실질적으로 이뤄지는 노력이 안 보인다는 것. 노력한다해도 그건 관리자와 비관리자가 함께 노력해야 하는 일일텐데(관리자나 회사에 대한 불만","tags":["google","sci"],"title":"Googlegeist vs. SCI","uri":"https://cychong47.github.io/2016/01/googlegeist_vs_sci/","year":"2016"},{"content":"출처 : 왜 “애자일”, 특히 스크럼이 끔찍한가\n 스크럼 팀에 실제 시니어 엔지니어의 역할은 없는데, 문제는 스크럼을 도입한 많은 회사에서 보통 전사적으로 시행한다는 것이다. 관리직으로 넘어가는 것 말고는, “스크럼 마스터”가 되어 이것을 말단에 도입하는 책임을 지는 선택지가 있다. 권한이 없는, 헛소리에 불과한 가짜 관리직 말이다. 스크럼 팀을 떠나서 해로운 마이크로매니지먼트를 받으면서 살지 않으려면 괴물 안으로 깊숙히 파고들어서 다른 사람에게 유해한 마이크로매니지먼트를 강요하는 수 밖에 없다. “애자일”과 스크럼이 나에게 말하는 것은 시니어 프로그래머는 반드시 필요하지 않다고 여겨지므로, 무시해도 좋으며, 마치 프로그래밍이란 35세 이전에 접어야 하는 유치한 것이라고 하는 것 같았다\n 그렇게 볼 수도 있구나….\n 출세지향적인 선동가 (“스크럼 마스터”) 에게는 우선 마을에 드래곤이 꼬이지 않게 하는 것보다 “드래곤 슬레이어”가 되는 것이 더 멋져 보일 것이다. 스크럼의 사업부 주도 엔지니어링에 대한 공격적인 주장의 문제점은, (“요구사항”이라 하는) 용을 꾀어내어 처치하는 것을 (“고객의 협력”이라는) 미덕으로 삼는 것이다. 처음부터 동굴에서 용을 꾀어내지 않는 편이 더 사려깊었을 것이지만.\n 이건 애자일이 아니어도 흔히 적용되는 문제가 아닌가 싶다. 늘 문제가 생겨 요란스럽게(?) 문제를 해결하는 사람이 인정받지 문제가 발생하지 않도록 대비한 사람은 인정받기 어렵다. 전자는 문제를 해결했다는 눈에 보이는 성과가 있지만, 발생하지 않은 문제는 무형의 성과라 구분하기 어렵다.\n","id":144,"section":"posts","summary":"출처 : 왜 “애자일”, 특히 스크럼이 끔찍한가 스크럼 팀에 실제 시니어 엔지니어의 역할은 없는데, 문제는 스크럼을 도입한 많은 회사에서 보통 전사적으로 시행한다는","tags":["agile"],"title":"(글) 왜 “애자일”, 특히 스크럼이 끔찍한가.","uri":"https://cychong47.github.io/2016/01/anti-agile/","year":"2016"},{"content":"http://click.pocoo.org/5/\nC로 프로그램을 짤 때 사용할 표준 포맷도 이렇게 해야겠다.\n$ python hello.py --help Usage: hello.py [OPTIONS] Simple program that greets NAME for a total of COUNT times. Options: --count INTEGER Number of greetings. --name TEXT The person to greet. --help Show this message and exit. ","id":145,"section":"posts","summary":"http://click.pocoo.org/5/ C로 프로그램을 짤 때 사용할 표준 포맷도 이렇게 해야겠다. $ python hello.py --help Usage: hello.py [OPTIONS] Simple program that greets NAME for a total of COUNT times. Options: --count INTEGER Number of greetings. --name TEXT The person to greet. --help Show this message and exit.","tags":["Python","click"],"title":"click - python option 처리 모듈","uri":"https://cychong47.github.io/2016/01/click-python-module/","year":"2016"},{"content":"Download dpdk-2.2.0.tar.gz Refer http://dpdk.org/download\nwget http://dpdk.org/browse/dpdk/snapshot/dpdk-2.2.0.tar.gz  Download qat_mux Refer https://01.org/packet-processing/intel®-quickassist-technology-drivers-and-patches\nwget https://01.org/sites/default/files/page/qatmux.l.2.5.0-80.tgz  Getting Started Guide 문서도 받아 둔다.\nwget https://01.org/sites/default/files/page/330750-004_qat_gsg.pdf  Configure DPDK export RTE_SDK=/home/cychong/work/dpdk-2.2.0 export RTE_TARGET=x86_64-native-linuxapp-gcc make config T=$RTE_TARGET O=$RTE_TARGET make  Configure QAT Ubuntu (14.04) 기준으로 몇 개 패키지를 설치해야 QAT를 빌드할 수 있는데 나름 기본적인 패키지들이라 그냥 설치해 놓으면 좋을 듯.\nsudo apt-get install zlib1g-dev sudo apt-get install libssl-dev  적당한 위치에 풀면 되는데 ~/work/qat에 압축을 푼 경우를 기준으로 정리\ncychong@ubuntu:~/work/qat$ ls LICENSE.GPL QAT1.5 QAT1.6 filelist installer.sh qatmux.l.2.5.0-80.tgz versionfile  QAT HW에 따라사 1.5 혹은 1.6 버전을 사용해야 하는데 만일 이 두 개 버전을 모두 사용해야 하는 경우 qatmux.l.2.5.0-80.tgz도 빌드해야 한다고 한다.\nQAT1.5, QAT1.6아래에는 각각 다음과 같은 압축 파일이 있으므로 필요한 QAT 버전 밑에 있는 압축 파일을 풀어준다.\ncychong@ubuntu:~/tmp$ tree . |-- filelist |-- installer.sh |-- LICENSE.GPL |-- QAT1.5 | `-- QAT1.5.L.1.10.0-80.tar.gz |-- QAT1.6 | `-- QAT1.6.L.2.5.0-80.tar.gz |-- qatmux.l.2.5.0-80.tgz `-- versionfile 2 directories, 7 files  Build QAT QAT Getting Started Guide를 보면 installer.sh을 이용해서 빌드할 수 있는데 이 스크립트는 빌드하는 머신에 QAT HW가 있는 경우에만 사용할 수 있다.\ncychong@ubuntu:~/work/qat$ sudo ./installer.sh [sudo] password for cychong: ========================================================= Welcome to Intel(R) QuickAssist Interactive Installer -v2 ========================================================= Please Select Option : ---------------------- 1 Build 2 Clean Build 3 Install 4 Uninstall 5 Show Accel Info 6 Change Configuration 7 Dependency List 0 Exit QAT Devices found: 0 QAT1.6 devices 0 QAT1.5 devices Configuration: Build Acceleration and Sample Code No Device detected And SR-IOV Disabled Exit and re-enter to set defaults 1 Driver mode auto selected. But no devices detected. Cannot build  QAT HW가 없는 경우 cross compile 방식을 사용해야 하는데 QAT Getting Started Guide 3.6절을 참고해서 수동(?)으로 빌드하면 된다.\nexport ICP_ROOT=/home/cychong/work/qat/QAT1.6 cd quickassist\u2028export ICP_ENV_DIR=$ICP_ROOT/quickassist/build_system/build_files/env_files export ICP_BUILDSYSTEM_PATH=$ICP_ROOT/quickassist/build_system export ICP_BUILD_OUTPUT=$ICP_ROOT/build export ICP_TOOLS_TARGET=accelcomp export LD_LIBRARY_PATH=$ICP_ROOT/build  이제 빌드\n$ make ICP_ARCH_USER=x86_64 … Copying QAT-FW Binary Copying MMP Binary Copying Install Scripts Build Done  빌드 결과물은 ../build에\ncychong@ubuntu:~/work/qat/QAT1.6/build$ file * adf_ctl: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.24, BuildID[sha1]=e1b508cd4404dbeaf268d92271ef2ea894a143e7, not stripped dh895xcc_qa_dev0.conf: ASCII text icp_qa_al.ko: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), BuildID[sha1]=5dffbaaac6514d161835bf7c9a4b086ff6a42b6b, not stripped libadf_proxy.a: current ar archive libicp_qa_al.a: current ar archive libicp_qa_al_s.so: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, not stripped libosal.a: current ar archive mmp_firmware.bin: data mof_firmware.bin: data qat_service: Bourne-Again shell script, ASCII text executable  Build DPDK_QAT example 이제 QAT 라이브러리가 준비되었으니 DPDK_QAT example 빌드\ncychong@ubuntu:~/work/dpdk-2.2.0/examples/dpdk_qat$ make LD dpdk_qat INSTALL-APP dpdk_qat INSTALL-MAP dpdk_qat.map  QAT 라이브러리를 빌드하기 전에 example을 빌드하면 다음과 같이 에러 발생\ncychong@ubuntu:~/work/dpdk-2.2.0/examples/dpdk_qat$ make LD dpdk_qat /usr/bin/ld: cannot find /home/cychong/work/qat/QAT1.6/build/libicp_qa_al.a: No such file or directory /usr/bin/ld: cannot find -losal /usr/bin/ld: cannot find -ladf_proxy collect2: error: ld returned 1 exit status make[1]: *** [dpdk_qat] Error 1 make: *** [all] Error 2  ","id":146,"section":"posts","summary":"Download dpdk-2.2.0.tar.gz Refer http://dpdk.org/download wget http://dpdk.org/browse/dpdk/snapshot/dpdk-2.2.0.tar.gz Download qat_mux Refer https://01.org/packet-processing/intel®-quickassist-technolog","tags":["DPDK","QAT"],"title":"DPDK QAT example  빌드하기","uri":"https://cychong47.github.io/2016/01/build_dpdk_qat/","year":"2016"},{"content":"Designing a RESTful API with Python and Flask\nRESTful API는 URI에 필요한 인자를 다 넘기는 형태라 사용자가 직접 주소를 입력하는 것이 아니라 다른 SW에서 해당 URI를 입력하는 형태로 사용하는 게 자연스러운 거네.\n","id":147,"section":"posts","summary":"Designing a RESTful API with Python and Flask RESTful API는 URI에 필요한 인자를 다 넘기는 형태라 사용자가 직접 주소를 입력하는 것이 아니라 다른 SW에서 해당 URI를 입력하는 형태로 사용하","tags":["Python","Flask","RESTful"],"title":"Designing a RESTful API with Python and Flask","uri":"https://cychong47.github.io/2015/12/designing-a-restful-api-with-python-and-flask/","year":"2015"},{"content":"virtualenv 설치\nmini-2:~ cychong$ sudo easy_install pip mini-2:~ cychong$ sudo pip install virtualenv  virtualenv로 project directory 생성\nmini-2:work cychong$ mkdir click mini-2:work cychong$ cd click/ mini-2:click cychong$ ls mini-2:click cychong$ virtualenv venv New python executable in venv/bin/python Installing setuptools, pip, wheel...done. mini-2:click cychong$ ls venv  virtualenv 환경으로 들어가기\nmini-2:click cychong$ . venv/bin/activate  원하는 패키지 설치\n(venv)mini-2:click cychong$ pip install Click Collecting Click Downloading click-6.2-py2.py3-none-any.whl (70kB) 100% |████████████████████████████████| 73kB 270kB/s Installing collected packages: Click Successfully installed Click-6.2  ","id":148,"section":"posts","summary":"virtualenv 설치 mini-2:~ cychong$ sudo easy_install pip mini-2:~ cychong$ sudo pip install virtualenv virtualenv로 project directory 생성 mini-2:work cychong$ mkdir click mini-2:work cychong$ cd click/ mini-2:click cychong$ ls mini-2:click cychong$ virtualenv venv New python executable in venv/bin/python Installing setuptools, pip, wheel...done. mini-2:click cychong$ ls venv virtualenv 환경으로 들어가기 mini-2:click cychong$ . venv/bin/activate","tags":["Python","virtualenv"],"title":"virtualenv 사용","uri":"https://cychong47.github.io/2015/12/virtualenv/","year":"2015"},{"content":"from Google Work Rules\n2006년에 구글에 입사. 72년 생\n구글 임직원 나이 평균에 비하면 많지만, 그래도 비슷한 덩치의 국내 기업의 인사 담당자와 비교하면. 하긴 구글을 국내 (대)기업과 비교하는 것 자체가 의미없는 일이지만\n과연 현실은 그렇다해도 저런 생각을 가진 사람을 주변에서 볼 수 있을까?\n그러기에 현실은 너무 지난하다.\n","id":149,"section":"posts","summary":"from Google Work Rules 2006년에 구글에 입사. 72년 생 구글 임직원 나이 평균에 비하면 많지만, 그래도 비슷한 덩치의 국내 기업의 인사 담당자와 비교하면. 하긴 구글을 국내 (","tags":["google","work_rules"],"title":"Culture should be setup first","uri":"https://cychong47.github.io/2015/12/culture/","year":"2015"},{"content":"Another Open source project.\nUser-land protocol stack. Incorporate with ODP\nTo use with DPDK, ODP and ODP-DPDK should be used.\nFrom the FAQ\nQ: Does the OFP IP stack mimic Linux stack config inside the fastpath, meaning does it intercept Linux ipconfig/ip commands and automatically create similar entities inside the fastpath stack? A: Yes. Uses Netlink to sync with ifconfig commands and also with routes. Q: Does the OFP IP stack have full IPv4/IPv6 fragmentation/re-assembly support? A: IPv4 only. Fragmentation and reassembly on IPv4. Q: Does the OFP IP stack have a replacement/equivalent of DPDK KNI (Kernel Network Interface) to allow forwarding packets between Linux/Fastpath? A: OFP uses a generic solution called TAP, not intended for performance. Fastpath can relay packets to Linux(slowpath). The use case to relay packets from Linux to Fastpath is not implemented. Linux will send packets straight to NIC/wire. ","id":150,"section":"posts","summary":"Another Open source project.\nUser-land protocol stack. Incorporate with ODP\nTo use with DPDK, ODP and ODP-DPDK should be used.\nFrom the FAQ\nQ: Does the OFP IP stack mimic Linux stack config inside the fastpath, meaning does it intercept Linux ipconfig/ip commands and automatically create similar entities inside the fastpath stack? A: Yes. Uses Netlink to sync with ifconfig commands and also with routes. Q: Does the OFP IP stack have full IPv4/IPv6 fragmentation/re-assembly support?","tags":["OFP","OpenFastPath","odp"],"title":"OpenFastPath","uri":"https://cychong47.github.io/2015/12/openfastpath/","year":"2015"},{"content":"Linux에서 사용하는 기본 page size는 4KB. 이 대신 2MB 혹은 1GB의 큰 크기를 hugepage라고 한다. Hugepage는 연속된 physical memory에 할당되어야 한다는 제약 조건이 있지만, 대신 swap out되지 않아 성능 개선 효과가 있다.\n아래 링크에서는 Oracle DB를 사용하는데 page swapping때문에 CPU 부하가 간헐적으로 크게 증가하는 현상을 hugepage를 사용해서 해결한 경우.\n Performance tuning : hugepages in Linux Enabling huge pages for shared memory  기왕 hugepage를 사용한다면 shared memory도 hugepage에 할당하는 것이 유리할 듯.\n","id":151,"section":"posts","summary":"Linux에서 사용하는 기본 page size는 4KB. 이 대신 2MB 혹은 1GB의 큰 크기를 hugepage라고 한다. Hugepage는 연속된 physical memory에 할당되","tags":[],"title":"Hugepage","uri":"https://cychong47.github.io/2015/12/hugepage/","year":"2015"},{"content":"난 특히 멀티태스킹이 안된다.\n하나에도 제대로 집중하기 힘들다. 11월은 아무 쓸데없는 TF 2개에 참여하느라 제대로 일을 못했다. 정말\u0026hellip;\n","id":152,"section":"posts","summary":"난 특히 멀티태스킹이 안된다. 하나에도 제대로 집중하기 힘들다. 11월은 아무 쓸데없는 TF 2개에 참여하느라 제대로 일을 못했다. 정말\u0026hellip;","tags":[],"title":"Single tasking","uri":"https://cychong47.github.io/2015/12/single-tasking/","year":"2015"},{"content":"Last login: Thu Dec 10 00:38:48 on ttys000 Chae-yongs-MacBook-Pro:~ cychong$ Chae-yongs-MacBook-Pro:~ cychong$ vi hard.txt Chae-yongs-MacBook-Pro:~ cychong$ ack \u0026ldquo;You have to\u0026rdquo; hard.txt | sort | uniq \u0026gt; a Chae-yongs-MacBook-Pro:~ cychong$ vi a Chae-yongs-MacBook-Pro:~ cychong$ ack \u0026ldquo;You have to\u0026rdquo; hard.txt | uniq \u0026gt; a Chae-yongs-MacBook-Pro:~ cychong$ vi a\n You have to do the hard things. You have to make the call you’re afraid to make. You have to get up earlier than you want to get up. You have to give more than you get in return right away. You have to care more about others than they care about you. You have to fight when you are already injured, bloody, and sore. You have to feel unsure and insecure when playing it safe seems smarter. You have to lead when no one else is following you yet. You have to invest in yourself even though no one else is. You have to look like a fool while you’re looking for answers you don’t have. You have to grind out the details when it’s easier to shrug them off. You have to deliver results when making excuses is an option. You have to search for your own explanations even when you’re told to accept the “facts.” You have to make mistakes and look like an idiot. You have to try and fail and try again. You have to run faster even though you’re out of breath. You have to be kind to people who have been cruel to you. You have to meet deadlines that are unreasonable and deliver results that are unparalleled. You have to be accountable for your actions even when things go wrong. You have to keep moving towards where you want to be no matter what’s in front of you.  출처 : http://www.businessinsider.com/hard-things-you-need-to-do-to-be-successful-2015-12?amp 20 substitutions on 20 lines\n","id":153,"section":"posts","summary":"Last login: Thu Dec 10 00:38:48 on ttys000 Chae-yongs-MacBook-Pro:~ cychong$ Chae-yongs-MacBook-Pro:~ cychong$ vi hard.txt Chae-yongs-MacBook-Pro:~ cychong$ ack \u0026ldquo;You have to\u0026rdquo; hard.txt | sort | uniq \u0026gt; a Chae-yongs-MacBook-Pro:~ cychong$ vi a Chae-yongs-MacBook-Pro:~ cychong$ ack \u0026ldquo;You have to\u0026rdquo; hard.txt | uniq \u0026gt; a Chae-yongs-MacBook-Pro:~ cychong$ vi a You have to do the hard things. You have to make the call you’re afraid to make. You have","tags":["inspiration"],"title":"19 hard things you need to do to be successful","uri":"https://cychong47.github.io/2015/12/19-hard-things-you-need-to-do-to-be-successful/","year":"2015"},{"content":"부정하기 어렵다. 하지만 코드가 늘어나는 것은 피할 수 없으니 불필요한 기능/코드는 삭제하는 노력을 끊임없이 해야 한다. 그렇지 않으면 technical debt만 늘어날 뿐이다. 개발할 때는 제대로 이해하고 만들어서 technical debt가 아니었더라도 시간이 지나 동작하지 않는 코드가 되면 불필요한 짐만 된다.\n","id":154,"section":"posts","summary":"부정하기 어렵다. 하지만 코드가 늘어나는 것은 피할 수 없으니 불필요한 기능/코드는 삭제하는 노력을 끊임없이 해야 한다. 그렇지 않으면 technical debt만 늘어날 뿐이다","tags":["SW 개발 문화"],"title":"Code 량이 늘면 버그도 함께 들어나기 마련","uri":"https://cychong47.github.io/2015/12/errors_from_more_code/","year":"2015"},{"content":"누군가의 말을 빌리자면 품질 관리의 바이블(?)이라고 하는.\n내용면에서는 특별한 건 없지만, 그래도 국내에서는 SW를 잘한다고 하는 사람들이 많이 가는 회사이고, 누구못지 않게 SW 문화가 좋을 거라고 생각하는 회사라 어떤 고민을 하고 어떻게 SW 품질을 위해 노력하는 지 알 수 있게 해주는 유일한 책이다.\n외국의 많은 회사처럼 사내에 노하우 등을 많이 공유하는 좋은 모습을 보이고 있고, 실제 제공되는 서비스의 독점성이나 중립적이지 못한 언론 관련 내용은 맘에 들지 않지만 그래도 개발자 입장에서는 이렇게 현실적인 내용을 공유해주는게 감사할 따름\n2009년, 2010년에 있던 일이라 벌써 옛날 이야기이고, 지금도 그러는 지는 알 수 없다는 게 아쉬울 따름.\nSW의 생산성에 대해서도 참고할 만한 정의를 내리고 있다. 특별히 SW 생산성 보다는 품질 지표로 생산성을 보겠다는 생각에는 나도 동감. 관리하는 사람이 그렇게 보질 않아 문제지만.\nCoding Convention Code Review Code coverage Static Analysis Complexity analysis 5가지 면에서 어떤 도구를 사용해서 어떤 점을 측정하고, 개선하려고 노력하는 지, 그리고 목표 수준은 어떤 지 등을 설명하고 있다. 실제 각 항목 별로 100점 만점을 목표로 하는 것이 아니라 현실적인 수준과 NHN의 현재 수준을 실제로(2009년 정보지만) 보여주고 있어 참고할 만 하다.\n각 항목별 개발자들의 피드백을 보면 비슷하다(아니 5년 전 내용이니 5년 정도 뒤떨어졌다고 봐야 하나? 그렇지는 않을 듯)\n뭔가 변화를 주는 것이나, 의미없는(?) 수치화, 기존 코드의 수정에 대한 부담감. Test coverage 를 높이기 위해 들이는 노력에 대한 부담감, Online code review만으로 부족해 결국 offline code review를 하고 다시 online code review를 해야 하는 불합리성에 대한 고민 등은 내가(스스로 그리고 주변 사람들로부터) 보고 느낀 것과 크게 다르지 않다.\n적용 효과 순 적용 비용 순 책을 쓴 사람들은 품질관리하는 부서에 있는 사람들이다 보니 실제 저런 활동의 주체가 되어야 하는 개발자들의 의견은 피드백으로 기술된 내용으로 한정된다. 그래도 저 책에 기술된 내용과 크게 다르지 않을 것 같다. 그렇지 않으면 저 책을 쓴 사람들이 회사내에서 욕 먹을 각오를 했어야 하는데 그렇게까지 없는 내용을 쓰지는 않았을 테니.\n결국 개발 문화를 변화시키는 대는 개개인의 노력이 가장 중요하지만, 합리적인 접근을 통해 점진적인 변화를 유도해 가는 것이 가장 중요하다고 생각된다. 그렇지 않으면 실제 품질이 높아져 품질 지표가 올라가는 것이 아니라 품질 지표만 올라가는 현실과 동떨어진 숫자만 남게 될 수 있기 때문이다. 아울러 이런 활동을 할 때는 개발자들에게 의도부터 방법까지 충분한 설명을 통해 공감을 얻어야 하고, 개발자들이 필요한 정보를 충분히 받을 수 있도록 지원 체계를 만들어야 한다.\n지금처럼 주먹구구식으로 감시 항목만 늘어나는 한 숫자 뿐인 품질 수치만 좋아질 거다. 적어도 개발자들이 고통받는 혹은 들이는 노력에 비해 품질 향상은 아주 미비할 것이다. 누굴 위한 노력인지 정말 궁금할 뿐.\n","id":155,"section":"posts","summary":"누군가의 말을 빌리자면 품질 관리의 바이블(?)이라고 하는. 내용면에서는 특별한 건 없지만, 그래도 국내에서는 SW를 잘한다고 하는 사람들이 많이 가는 회사이고","tags":["SW 개발 문화","Book","NHN","SW Quality"],"title":"(책)  NHN은 이렇게 한다. 소프트웨어 품질 관리","uri":"https://cychong47.github.io/2015/12/nhn_sw_quality_control/","year":"2015"},{"content":"출처 : Harvard Businee Review\n최소 52개 대형 회사가 기존 년 단위의 고과 평과 제도를 없앰. 이 중 33개 업체를 집중 분석하여 해당 업체에서 일어난 변화를 정리\n  manager-employee간 대화가 극적으로 증가. 33개 미국 기반의 업체 중 76%는 기존에 1년 단위의 역량 대화를 나눴으나, 이젠 68%가 최소 분기별 대화를 권장하고 있다고 함.\n  관리 부담이 크게 줄어듬 33개 업체의 2/3에서 역량 평가를 위한 관리자의 문서 작성 요구가 공식적으로 줄어듬. 다른 30% 업체는 문서 작성을 아예 없앰.\nHBR에서 확인한 바로는 65,000이상의 고용인을 리뷰하기 위해 매년 2백만 시간이 필요했음. 실제 통상적인 고과 면담이 업무 역량을 높이는 데 도움이 되지 않는 것을 생각하면 이 시간은 낭비임.\n  대화는 Goal, Growth 그리고 성장에 초점이 맞춰짐\n기존 고과 면담은 이미 지난 성과에 대한 평가가 주였으나, 새로운 체계에서는 목적을 세우고, 성장을 계획하고, 행동에 집중함.\n새로운 고과 관리 체계는 empower individuals, driver performance, support development, and crate a sense of purpose.\n성과와 관리는 비평가자들이 관리자들의 지원과 코치를 받고, 그들이 절차에 대해 더 많은 주도권을 가질 때 가장 효과적이라는 인식을 갖게 됨. 새로운 quality conversation은 관리자와 비평가자 모두 만족함\n  No single best practice\n회사마다 다른 상황이라 접근하는 방식 등은 다르다.\n  pay-for-performance 혹은 차등화된 연봉이 없어지지는 않는다. 기존과 유사하게 관리자들이 업적에 대한 기존보다 좋은 대화(better-quality conversations about performance)를 통해 우수 인력을 찾아내고, 그들의 판단에 따라 보상하라고 독려하고 있다.\n  Well-designed change management is essential\n단번에 새로운 제대를 적용하면 안되고, 시간을 가지고 계획을 충분히 세운 후 적용해야 한다.\n  ","id":156,"section":"posts","summary":"출처 : Harvard Businee Review 최소 52개 대형 회사가 기존 년 단위의 고과 평과 제도를 없앰. 이 중 33개 업체를 집중 분석하여 해당 업체에서 일어난 변화를 정리 manager-em","tags":["HBR"],"title":"역량 평가를 없앤 회사에서 일어난 일","uri":"https://cychong47.github.io/2015/12/what_happens_if_performance_rating_is_omitted/","year":"2015"},{"content":"Neuron\nPython project 체계를 잡는데 도움이 될 듯 하다. 아래는 pylink를 이용해서 syntax 검사하는 script\nhttps://github.com/openstack/neutron/blob/master/tools/coding-checks.sh\n","id":157,"section":"posts","summary":"Neuron Python project 체계를 잡는데 도움이 될 듯 하다. 아래는 pylink를 이용해서 syntax 검사하는 script https://github.com/openstack/neutron/blob/master/tools/coding-checks.sh","tags":["neuron","openstack"],"title":"OpenStack이  Python으로 만들어졌다니","uri":"https://cychong47.github.io/2015/11/openstacki-pythoneuro-mandeuleojyeossdani/","year":"2015"},{"content":"http://www.cisco.com/c/en/us/products/collateral/routers/cloud-services-router-1000v-series/datasheet-c78-733443.html\nHow many vCPUs are required for processing.\n","id":158,"section":"posts","summary":"http://www.cisco.com/c/en/us/products/collateral/routers/cloud-services-router-1000v-series/datasheet-c78-733443.html\nHow many vCPUs are required for processing.","tags":["IPsec","cisco"],"title":"Cisco Cloud Services Router 1000V","uri":"https://cychong47.github.io/2015/11/cisco-cloud-services-router-1000v/","year":"2015"},{"content":"Data sheet (PDF)\n Some Cisco virtual network services that use the DPDK include Cisco Cloud Services Router (CSR) 1000V, Cisco Virtual Mobile Packet Core software, and Cisco IOS® XR 9000v virtual router. Supporte CISCO appliances  Cisco Cloud Services Router (CSR) 1000V virtual router Cisco Virtual Adaptive Security Appliance (ASAv) Cisco Prime™ Data Center Network Manager (DCNM) Cisco Virtual Network Analysis Module (vNAM) Cisco Virtual Security Gateway (VSG) for Cisco Nexus® 1000V Switch deployments Cisco Virtual Supervisor Module (VSM) for Cisco Nexus 1000V Switch deployments   1U 2 CPU, each has 8 core Ivy Bridge(E5-2630 v3) REST API It uses REST API and NETCONF protocol for north-bound management and orchestration (MANO) tools. Network services could be abstracted to a pool of high-availability resources among several hosts.  Cisco Systems and Intel Corporation NFV Partnership\nTechnical Reference  Cisco Cloud Services Platform 2100 REST API Guide Cisco Cloud Services Platform 2100 Command Reference Guide Quick Start Guide - Must check Cisco Cloud Services Platform 2100 Hardware Installation Guide  ","id":159,"section":"posts","summary":"Data sheet (PDF)\n Some Cisco virtual network services that use the DPDK include Cisco Cloud Services Router (CSR) 1000V, Cisco Virtual Mobile Packet Core software, and Cisco IOS® XR 9000v virtual router. Supporte CISCO appliances  Cisco Cloud Services Router (CSR) 1000V virtual router Cisco Virtual Adaptive Security Appliance (ASAv) Cisco Prime™ Data Center Network Manager (DCNM) Cisco Virtual Network Analysis Module (vNAM) Cisco Virtual Security Gateway (VSG) for Cisco Nexus® 1000V Switch deployments Cisco Virtual Supervisor Module (VSM) for Cisco Nexus 1000V Switch deployments   1U 2 CPU, each has 8 core Ivy Bridge(E5-2630 v3) REST API It uses REST API and NETCONF protocol for north-bound management and orchestration (MANO) tools.","tags":["DPDK","virtualization","cisco"],"title":"CISCO Cloud Service Platform 2100","uri":"https://cychong47.github.io/2015/11/cisco-cloud-service-platform-2100/","year":"2015"},{"content":"철학의 부재. 중심의 부재. 대화의 부재\n제품을 만드는데 철학이 없다는 건 정말 큰 문제다. 누군가 대충 스케치만 그린 그림을 가지고 차를 만든다고 생각하면 끔찍하다. 각 부분 부분별로 , 기능 별로 어떻게 만들 것인지 고민없이 그냥 각 부서별로 자기가 맡은 걸 만든다면 그 차가 굴러가기만 해도 기적이지만, 제대로 굴러가는 커녕 일정 내 만들어질 리가 없다.\n처음부터 끝까지 혹은 적어도 그걸 만드는 사람들이 충분히 제품의 철학(성격 등)을 공감할 때까지 끊임없이 대화해서 그나마 비슷한 생각을 가진 후에야 각 기능별 부분별 설계가 이뤄져야 한다.\n하지만 대부분 기능에 대한, 제품의 성격에 대한 이야기는 하지않고 필요한 표준만 나열한다. 그리곤 알아서 하라고 한다. 거기까지가 스케치 하는 사람의 영역이라고.\n늘 하던 대로 기존 제품을 조금씩 개선하는 일이라면 이렇게 해도 큰 무리가 없을 것이다. 이미 경험적으로 제품의 성격을 알고 있으므로. 하지만 새로운 제품을 만드는 경우에는 달라야 한다. 그렇지 않으면 새로운 성격의 제품이 기존 제품과 똑같아진다.\n업무 영역간 일정부분의 겹치는 것으로는 부족하다. 제품 기획부터 개발 그리고 검증까지 제품의 성격을 확인하는 노력이 필요하다. 하지만 ‘과제’ 관리하는 사람들은 과제 진행이 목적이지 어떤 제품을 만들어야 하는 지에 대해서는 관심이 부족한 듯 하다. 관리되고 평가되는 건 오직 숫자로 표현되는 과제 진척도외 산출물 뿐이니.\n정말 제대로 \u0026lsquo;개발\u0026rsquo;을 하고 있는 걸까\n","id":160,"section":"posts","summary":"철학의 부재. 중심의 부재. 대화의 부재 제품을 만드는데 철학이 없다는 건 정말 큰 문제다. 누군가 대충 스케치만 그린 그림을 가지고 차를 만든다고 생각하면 끔찍하다.","tags":["개발이야기"],"title":"제대로 만들려면 제품의 성격부터 정의해야","uri":"https://cychong47.github.io/2015/11/what_is_the_target_product/","year":"2015"},{"content":"잘못된(?) 진단은 잘못된 처방을 낳는다.\n모든 걸 개인의 잘못으로 돌리려는 의도는 의외로 단순. 잘못을 저지른 개인은 개선시키면 된다는 단순한 해법을 제시할 수 있으므로. 개인을 구박하거나 심지어는 그 조직에서 제외시키면 문제가 해결(?)되는 것처럼 보이니까.\n하지만 그 뒤에 숨어있는 실은 개인의 잘못으로 돌려진 관리의 문제, 시스템의 문제는 아무도 건드리지 않는다. 문제의 원인이 너무 커서, 문제의 원인이 너무 근본적이라, 문제의 원인이 권력자에게 있는 터라. 그렇게 문제는 반복된다. 비난의 대상이 되는 \u0026lsquo;개인\u0026rsquo;만 바뀔 뿐. 병든 조직은 서서히 그렇게 스러진다\u0026hellip;\n","id":161,"section":"posts","summary":"잘못된(?) 진단은 잘못된 처방을 낳는다. 모든 걸 개인의 잘못으로 돌리려는 의도는 의외로 단순. 잘못을 저지른 개인은 개선시키면 된다는 단순한 해법을 제시할 수 있","tags":["SW 개발 문화","조직관리","조직문화"],"title":"개인의 잘못으로만 돌리는 이유","uri":"https://cychong47.github.io/2015/11/why_blame_personals/","year":"2015"},{"content":"관리자들이 개발자들을 위해 한 일이 뭐가 있나?\n아무리 생각해도 잘 모르겠다.\n그럼 개발자를 위한 사람이나 제도는 없다는 건데\n그러면서 개발자가 잘 하기 기대하는 건 도둑놈 심보가 아닌가?\n자꾸만 벗어나길 원하는 \u0026lsquo;개발\u0026rsquo;업무를 만든 게 누구인지? 왜 그렇게 된 건지?\n이런 근본적인 질문에 대한 고민과 해결 없이 SW품질을 논한다는 건 어불성설이다.\n","id":162,"section":"posts","summary":"관리자들이 개발자들을 위해 한 일이 뭐가 있나? 아무리 생각해도 잘 모르겠다. 그럼 개발자를 위한 사람이나 제도는 없다는 건데 그러면서 개발자가 잘 하기 기대하는 건 도","tags":["SW 개발 문화"],"title":"개발자를 위해 한 일이 뭐가 있지?","uri":"https://cychong47.github.io/2015/11/what_for_the_developer/","year":"2015"},{"content":"규제를 풀기 어려운 이유는 그 규제를 풀어도 문제가 없는 지 자신이 없기 때문이다. 증명하기 어려운 경우가 대부분. 하지만 머리를 맞대고 함께 이야기해봐야 한다. 정말 필요한 절차인지 고민해야 한다. 가능하면 절차는 줄이고 또 줄여야 한다고 생각.\n이런 고민조차 어려운 이유는 대부분 한 쪽이 들으려 하지 않기 때문. 기존에 하던 (불필요해보이는) 절차를 없애는 경우 발생할 수 있는 위험요소를 감수할 의지가 없으므로. 혹시 이렇게 생각하고 있는 건 아닌지\n 그런 번거로운 절차는 내가 하는 게 아니라 니들이 하는 거니까\n 곧 이 문제는 조직 문화가 변하기 힘든 것도 같은 이유라고 생각된다.\n","id":163,"section":"posts","summary":"규제를 풀기 어려운 이유는 그 규제를 풀어도 문제가 없는 지 자신이 없기 때문이다. 증명하기 어려운 경우가 대부분. 하지만 머리를 맞대고 함께 이야기해봐야 한다. 정말","tags":["SW 개발 문화","조직관리","문화"],"title":"규제를 풀기 어려운 이유는","uri":"https://cychong47.github.io/2015/11/gyujereul-pulgi-eoryeoun-iyuneun/","year":"2015"},{"content":"TAILQ_HEAD(ip_pkt_list, ip_frag_pkt); /**\u0026lt; @internal fragments tailq */  자료 구조체 Fragment 관리용 table struct rte_ip_frag_tbl *frag_tbl;  locking 없이 IP reassembly를 수행할 단위(통상 core)로 한 개씩 만든다. 즉 하나의 core가 여러 rx queue를 처리하더라도 하나의 frag_tbl만 가지면 된다.\n아래 rte_ip_frag_table_create()함수를 이용해서 생성한다.\nstruct rte_ip_frag_death_row death_row core별로 갖는 death_row. IP reassembly를 호출한 후 해당 함수내에서 free할 mbuf를 이 리스트에 담아줌.\nmain loop에서 reassembly작업 후 rte_ip_frag_free_death_row()함수를 호출해 reassembly에 실패한 mbuf를 free함\nIP_MAX_FRAG_NUM defines the maximum fragments of one reassembly. Defined same as RTE_LIBRTE_IP_FRAG_MAX_FRAG aka 4.\n주요 함수 rte_ipv4_frag_reassemble_packet 실제 reassembly를 수행하는 함수.\n 첫번째 인자는 ip fragment들이 저장된 ip_frag_tbl의 pointer 두번째 인자는 death_row를 저장할 pointer. 세번째 인자는 현재 수신한 mbuf의 pointer 네번째 인자는 패킷이 수신한 timestamp. rdtsc_tsc()의 결과 다섯번째 인자는 pointer to ip header(struct ipv4_hdr *)  rte_ipv6_frag_reassemble_packet() IPv6용 reassembly 함수. 함수의 인자는 rte_ipv4_frag_reassemble_packet()와 유사하지만, 마지막에 struct ipv6_extension_fragment *가 추가된다.\nrte_ipv4_frag_pkt_is_fragmented() Return 1 if packet is fragmented.\nrte_ipv6_frag_get_ipv6_fragment_header() IPv6 경우 위 함수를 통해 frag_hdr 위치를 돌려받는다. struct ipv6_extension_fragment * 단순히 IPv6 base header 바로 뒷 헤더만 확인함.(표준 확인 필요)\nrte_ip_frag_table_create() struct rte_ip_frag_tbl * rte_ip_frag_table_create( uint32_t bucket_num, uint32_t bucket_entries, uint32_t max_entries, uint64_t max_cycles, int socket_id);   bucket_num : # of bucket(Flow 개수). Should be power of 2 bucket_entries : bucket당 개수(hash associativity) max_entries : # of flows to be stored in table. less or equal to max_flow_num * bucket_entries max_cycles : Maximum TTL in cycles for each fragmented packet. frag_cycles = (rte_get_tsc_hz() + MS_PER_S - 1) / MS_PER_S * max_flow_ttl; 예. 1ms에 해당하는 TSC value socket : 메모리를 할당할 socket ID. core와 함께 있는 socket 정보를 넣으면 됨.  defined in lib/librte_ip_frag/rte_ip_frag.h\n/** fragmentation table */ struct rte_ip_frag_tbl { uint64_t max_cycles; /**\u0026lt; ttl for table entries. */ uint32_t entry_mask; /**\u0026lt; hash value mask. */ uint32_t max_entries; /**\u0026lt; max entries allowed. */ uint32_t use_entries; /**\u0026lt; entries in use. */ uint32_t bucket_entries; /**\u0026lt; hash assocaitivity. */ uint32_t nb_entries; /**\u0026lt; total size of the table. */ uint32_t nb_buckets; /**\u0026lt; num of associativity lines. */ struct ip_frag_pkt *last; /**\u0026lt; last used entry. */ struct ip_pkt_list lru; /**\u0026lt; LRU list for table entries. */ struct ip_frag_tbl_stat stat; /**\u0026lt; statistics counters. */ struct ip_frag_pkt pkt[0]; /**\u0026lt; hash table. */ };  rte_ip_frag_free_death_row() prefetch가 왜 필요한 지??(FIXME)\n/* * Free mbufs on a given death row. * * @param dr * Death row to free mbufs in. * @param prefetch * How many buffers to prefetch before freeing. */ void rte_ip_frag_free_death_row(struct rte_ip_frag_death_row *dr, uint32_t prefetch);  예) if death_row has 10 entries and prefetch is 5\n\u0026lt;\u0026lt; Step 1 \u0026gt;\u0026gt; prefetch 0 prefetch 1 prefetch 2 prefetch 3 prefetch 4 \u0026lt;\u0026lt; Step 2 \u0026gt;\u0026gt; prefetch 5 free 0 prefetch 6 free 1 prefetch 7 free 2 prefetch 8 free 3 prefetch 9 free 4 \u0026lt;\u0026lt; Step 3 \u0026gt;\u0026gt; free 5 free 6 free 7 free 8 free 9  동작 rte_ipv4_frag_reassemble_packet() 혹은 rte_ipv6_frag_reassemble_packet()는 reassembly에 성공한 경우 해당 struct mbuf *를 리터한다. 그러므로 해당 mbuf를 다음 작업에 처리하면 됨.\nstruct rte_ip_frag_death_row *dr = \u0026amp;qconf-\u0026gt;death_row; if (rte_ipv4_frag_pkt_is_fragmented(ip_hdr)) { struct rte_mbuf *mo; tbl = rxq-\u0026gt;frag_tbl; dr = \u0026amp;qconf-\u0026gt;death_row; /* prepare mbuf: setup l2_len/l3_len. */ m-\u0026gt;l2_len = sizeof(*eth_hdr); m-\u0026gt;l3_len = sizeof(*ip_hdr); /* process this fragment. */ mo = rte_ipv4_frag_reassemble_packet(tbl, dr, m, tms, ip_hdr); if (mo == NULL) /* no packet to send out. */ return; else /* mo를 이용해서 post processing */ } rte_ip_frag_free_death_row(dr, PREFETCH_OFFSET);  IPv6 경우\nfrag_hdr = rte_ipv6_frag_get_ipv6_fragment_header(ip_hdr); if (frag_hdr != NULL) { struct rte_mbuf *mo; tbl = rxq-\u0026gt;frag_tbl; dr = \u0026amp;qconf-\u0026gt;death_row; /* prepare mbuf: setup l2_len/l3_len. */ m-\u0026gt;l2_len = sizeof(*eth_hdr); m-\u0026gt;l3_len = sizeof(*ip_hdr) + sizeof(*frag_hdr); mo = rte_ipv6_frag_reassemble_packet(tbl, dr, m, tms, ip_hdr, frag_hdr); if (mo == NULL) return; if (mo != m) { m = mo; eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *); ip_hdr = (struct ipv6_hdr *)(eth_hdr + 1); } } rte_ip_frag_free_death_row(dr, PREFETCH_OFFSET);  ","id":164,"section":"posts","summary":"TAILQ_HEAD(ip_pkt_list, ip_frag_pkt); /**\u0026lt; @internal fragments tailq */ 자료 구조체 Fragment 관리용 table struct rte_ip_frag_tbl *frag_tbl; locking 없이 IP reassembly를 수행할 단위(통상 core)로 한 개씩 만든다. 즉 하나의 core가 여러 rx qu","tags":["DPDK","R210"],"title":"DPDK IP reassembly example","uri":"https://cychong47.github.io/2015/11/dpdk-ip-reassembly-example/","year":"2015"},{"content":" 자네는 Agile이 뭔지, Scrum Master가 어떤 일을 해야 하는 지 모르겠지만, 앞으로 자네를 \u0026lsquo;Scrum Master\u0026rsquo;라고 부르겠네.\n이제 우리는 Scrum Master를 가졌으니, Agile을 하는 걸쎄\n 글쎄요\u0026hellip;\n저도 Agile을 잘 모르지만, 동의할 수가 없네요.\n국정교과서의 필요성에 대해 이야기하는 이상한 나라의 사람들 만큼이나 이해하기 어렵네요.\n","id":165,"section":"posts","summary":"자네는 Agile이 뭔지, Scrum Master가 어떤 일을 해야 하는 지 모르겠지만, 앞으로 자네를 \u0026lsquo;Scrum Master\u0026rsquo;라고 부르겠네. 이제 우리는 Scrum Ma","tags":["agile"],"title":"또 하나의 코미디","uri":"https://cychong47.github.io/2015/11/do_you_know_agile/","year":"2015"},{"content":"We can’t measure Programmer Productivity… or can we?\nLOC The more fundamental problem is that measuring productivity by lines (or Function Points or other derivatives) typed doesn’t make any sense. A lot of important work in software development, the most important work, involves thinking and learning – not typing.\nThe best programmers spend a lot of time understanding and solving hard problems, or helping other people understand and solve hard problems, instead of typing. They find ways to simplify code and eliminate duplication. And a lot of the code that they do write won’t count anyways, as they iterate through experiments and build prototypes and throw all of it away in order to get to an optimal solution.\nMoney Velocity But velocity (how much work, measured in story points or feature points or ideal days, that the team delivers in a period of time) is really a measure of predictability, not productivity. Velocity is intended to be used by a team to measure how much work they can take on, to calibrate their estimates and plan their work forward.\nOnce a team’s velocity has stabilized, you can measure changes in velocity within the team as a relative measure of productivity. If the team’s velocity is decelerating, it could be an indicator of problems in the team or the project or the system. Or you can use velocity to measure the impact of process improvements, to see if training or new tools or new practices actually make the team’s work measurably faster.\n Organizations and managers who equate internal velocity with external productivity start to set targets for velocity, forgetting that what actually matters is working software in production. Treating velocity as productivity leads to unproductive team behaviors that optimize this metric at the expense of actual working software.\n The down side of equating delivery speed with productivity? Optimizing for cycle time/speed of delivery by itself could lead to problems over the long term, because this incents people to think short term, and to cut corners and take on technical debt.\nBetter Software It’s easy to measure that you are writing good – or bad – software. Defect density. Defect escape rates (especially defects – including security vulnerabilities – that escape to production). Static analysis metrics on the code base, using tools like SonarQube.\nDevops  As I pointed out in an earlier post this makes operational metrics more important than developer metrics. According to recent studies, success in achieving these goals lead to improvements in business success: not just productivity, but market share and profitability.\n 그래서 결론은? Stop trying to measure individual developer productivity.\nIt’s a waste of time.\nEveryone knows who the top performers are. Point them in the right direction, and keep them happy.\nEveryone knows the people who are struggling. Get them the help that they need to succeed.\nEveryone knows who doesn\u0026rsquo;t fit in. Move them out.\nMeasuring and improving productivity at the team or (better) organization level will give you much more meaningful returns.\nWhen it comes to productivity:\n Measure things that matter – things that will make a difference to the team or to the organization. Measures that are clear, important, and that aren\u0026rsquo;t easy to game. Use metrics for good, not for evil – to drive learning and improvement, not to compare output between teams or to rank people.  ","id":166,"section":"posts","summary":"We can’t measure Programmer Productivity… or can we? LOC The more fundamental problem is that measuring productivity by lines (or Function Points or other derivatives) typed doesn’t make any sense. A lot of important work in software development, the most important work, involves thinking and learning – not","tags":[],"title":"Software developer의 생산성을 측정할 수 있을까?","uri":"https://cychong47.github.io/2015/11/software-developeryi-saengsanseongeul-ceugjeonghal-su-isseulgga/","year":"2015"},{"content":"예 ipsec on asf/se/\u0026hellip;\n불럭별 특징이 아니라 프로토콜별 호환성이나 주의사항에 대한 취합 필요\n보통 postmortem하면 그 블럭의 특징이라고 보는 경향이 강한데 그것과 무관하게 프로토콜 특성에 대한 내용은 블럭 설계와 별개로 모아놔야 하지 않을까?\nStackOverflow 처럼 분야별로\u0026hellip;\n","id":167,"section":"posts","summary":"예 ipsec on asf/se/\u0026hellip; 불럭별 특징이 아니라 프로토콜별 호환성이나 주의사항에 대한 취합 필요 보통 postmortem하면 그 블럭의 특징이라고 보는 경향이 강한데 그것과 무관","tags":[],"title":"분야별 노하우 공유가 필요한데","uri":"https://cychong47.github.io/2015/11/bunyabyeol-nohau-gongyuga-pilyohande/","year":"2015"},{"content":"VirtualBox supports emulated e1000 NIC for VM while VMware fusion does not. VMware Fusion\u0026rsquo;s VM setting does not support configuring of NIC HW type. The NIC HW is PCnet32 which is not supported by DPDK.\nHowever, we can change NIC HW type by editing VM configuration file directly.\nRefer : How to emulate 10 Gbps NIC in a VMware Fusion VM\nEdit vmx file to VMX file is in where vmware image located\nFor my case, this is where I can find\n~/Documents/Virtual Machines.localized/Ubuntu.vmwarevm/Ubuntu.vmx  Note. VMX file is updated when VM is closed. Therefore, changes on this file while VM is running is overwritten by the VM\u0026rsquo;s current configuration. Be sure to quit VMware Fusion before changing this file.\nethernet3.present = \u0026quot;TRUE\u0026quot; ethernet3.connectionType = \u0026quot;custom\u0026quot; ethernet3.wakeOnPcktRcv = \u0026quot;FALSE\u0026quot; ethernet3.addressType = \u0026quot;static\u0026quot; ethernet3.vnet = \u0026quot;vmnet2\u0026quot; ethernet3.address = \u0026quot;00:50:56:2B:EC:A4\u0026quot;  The reference guides to change the virtualDev string from e1000 to something else(10G for vmxnet3). However, I can not find ethernet3.virtualDev. So I just add it.\nethernet3.present = \u0026quot;TRUE\u0026quot; ethernet3.connectionType = \u0026quot;custom\u0026quot; ethernet3.wakeOnPcktRcv = \u0026quot;FALSE\u0026quot; ethernet3.addressType = \u0026quot;static\u0026quot; ethernet3.vnet = \u0026quot;vmnet2\u0026quot; ethernet3.address = \u0026quot;00:50:56:2B:EC:A4\u0026quot; ethernet3.virtualDev = \u0026quot;e1000\u0026quot;  After starting VM, I can find VM has e1000 NIC for ethernet3.\nNow, eth3 is e1000 NIC.\n$ ethtool -i eth3 driver: e1000 version: 7.3.21-k8-NAPI firmware-version: bus-info: 0000:02:07.0 supports-statistics: yes supports-test: yes supports-eeprom-access: yes supports-register-dump: yes supports-priv-flags: no  vmxnet3 for eth2 Once more, convert eth2 to vmxnet3\nethernet2.present = \u0026quot;TRUE\u0026quot; ethernet2.connectionType = \u0026quot;bridged\u0026quot; ethernet2.wakeOnPcktRcv = \u0026quot;FALSE\u0026quot; ethernet2.addressType = \u0026quot;generated\u0026quot; ethernet2.linkStatePropagation.enable = \u0026quot;TRUE\u0026quot; ethernet2.pciSlotNumber = \u0026quot;160\u0026quot; ethernet2.generatedAddress = \u0026quot;00:0c:29:52:14:e3\u0026quot; ethernet2.generatedAddressOffset = \u0026quot;20\u0026quot; ethernet2.virtualDev = \u0026quot;vmxnet3\u0026quot;  And, it works too.\n$ ethtool -i eth2 driver: vmxnet3 version: 1.2.0.0-k-NAPI firmware-version: bus-info: 0000:03:00.0 supports-statistics: yes supports-test: no supports-eeprom-access: no supports-register-dump: yes supports-priv-flags: no  Note. \u0026lsquo;e1000e\u0026rsquo; is also supported.\nethernet3.virtualDev = \u0026quot;e1000e\u0026quot;  e1000 and e1000e are emulated device each for 1 Gbit Intel 82545EM card and 1 Gbit Intel 82574. e1000e is a newer one. Reference\n$ ethtool -i eth3 driver: e1000e  Build DPDK The most easy way to build DPDK is using setup.sh\n$ source tools/setup.sh Option: 10 ================== Installing x86_64-native-linuxapp-gcc Configuration done == Build lib ... Build complete [x86_64-native-linuxapp-gcc] ------------------------------------------------------------------------------ RTE_TARGET exported as x86_64-native-linuxapp-gcc  Three important environments.\nRTE_ARCH=x86_64 RTE_SDK=/home/cychong/dpdk-2.1.0 RTE_TARGET=x86_64-native-linuxapp-gcc  ","id":168,"section":"posts","summary":"VirtualBox supports emulated e1000 NIC for VM while VMware fusion does not. VMware Fusion\u0026rsquo;s VM setting does not support configuring of NIC HW type. The NIC HW is PCnet32 which is not supported by DPDK.\nHowever, we can change NIC HW type by editing VM configuration file directly.\nRefer : How to emulate 10 Gbps NIC in a VMware Fusion VM\nEdit vmx file to VMX file is in where vmware image located","tags":["DPDK","Vmware","NIC"],"title":"Running DPDK on VMware Fusion","uri":"https://cychong47.github.io/2015/10/running-dpdk-on-vmware-fusion/","year":"2015"},{"content":"DPDK Userspace in Dublin 2015에서 발표\nStageful traffic generator\n특징  Generate traffic based on templates of real, captured flows No TCP/IP stack Up to 200Gbps with standard server hardware Low cost 1RU (C220M UCS-1RU) Cisco internal DPDK, ZMQ, Python libs Virtualization(vmxnet3/e1000) ~20Gbps per core Generate flow templates Support 1K templates Yaml based traffic profile  GUI GUI which monitors real-time properties of TRex - min/max/average latency, jitter\nPython 연동 Code https://github.com/cisco-system-traffic-generator/trex-core\nManual http://trex-tgn.cisco.com/trex/doc/trex_manual.html\nWeb-site http://trex-tgn.cisco.com\nPresentation http://trex-tgn.cisco.com/trex/doc/trex_preso.html\n","id":169,"section":"posts","summary":"DPDK Userspace in Dublin 2015에서 발표 Stageful traffic generator 특징 Generate traffic based on templates of real, captured flows No TCP/IP stack Up to 200Gbps with standard server hardware Low cost 1RU (C220M UCS-1RU) Cisco internal DPDK, ZMQ, Python libs Virtualization(vmxnet3/e1000) ~20Gbps per core Generate flow templates Support 1K templates Yaml based traffic profile GUI GUI which monitors real-time properties of TRex -","tags":["DPDK"],"title":"TRex - DPDK based traffic generator","uri":"https://cychong47.github.io/2015/10/trex-dpdk-based-traffic-generator/","year":"2015"},{"content":"From http://www.theeffectiveengineer.com/blog/what-makes-a-good-engineering-culture\n1. Optimize for iteration speed  Continous deployment to support rapid validation High test coverage to reduce build and site breakages Fast unit tests to encourage people to run them Fast and incremental compiles and reloads to reduce development time  Bill Walsh, 49ers to 3 Super bowls,\n Commit, Explode, Recover\n A team crippled with indecisiveness will just cause individual efforts to flounders\n2. Push relentlessly toward automation Consider operational burden per engineer\n ratio of users to engineer radio of features to engineers  Automating solutions and scripting repetitive tasks are important because they free up the engineers team to work on the actual product\nEasy\u0026rsquo;s motto of \u0026ldquo;Measure anything, measure everything\u0026rdquo; Automation must be driven by data and monitoring\n3. Build the right software abstractions MIT professor, Daniel Jackson\n Pick the right one, and programming will flow naturally from design modules will have small and simple interface\nnew functionality will more likely fit in without extensive reorganization\n Google, Jeff Dean and Sanjay Ghemawat\nKeeping core abstractions simple and general\n reduces the need for custom solutions increases the team\u0026rsquo;s familiarity and expertise with the common abstraction common libraries get more robust monitoring gets more intelligent performance characteristics get better understood tests get more comprehensive  4. Develop a focus on high code quality with code reviews Technical debt easily accumulate from poorly written code\n5. Maintain a respectful work environment 6. Build shared ownership of code Free engineers from the sense that they\u0026rsquo;re stuck on certain projects and encourages them to work on a diversity of projects\nSwarm : The idea is that everyone on your team works on the same story at the same time\n7. Invest in automated testing Unit test coverage and some degrees of integrating test coverage is the only scalable way of managing a large codebase with a large group of people without constantly breaking the build or the product.\n8. Allot 20% time 9. Build a culture of learning and continuous improvement 10. Hire the best ","id":170,"section":"posts","summary":"From http://www.theeffectiveengineer.com/blog/what-makes-a-good-engineering-culture 1. Optimize for iteration speed Continous deployment to support rapid validation High test coverage to reduce build and site breakages Fast unit tests to encourage people to run them Fast and incremental compiles and reloads to reduce development time Bill Walsh, 49ers to 3 Super bowls, Commit, Explode, Recover A team crippled with indecisiveness will just cause individual efforts to flounders 2. Push relentlessly toward automation Consider operational","tags":["SW 개발 문화","programming","culture"],"title":"What makes a good engineering culture?","uri":"https://cychong47.github.io/2015/09/what-makes-a-good-engineering-culture/","year":"2015"},{"content":"부서간 협력이 잘 안되는 듯 하니 대책으로 \u0026lsquo;부서간 협력지수\u0026rsquo;를 수치화해서 평가하겠다. 그럼 협력이 잘 될까 궁금하네\n","id":171,"section":"posts","summary":"부서간 협력이 잘 안되는 듯 하니 대책으로 \u0026lsquo;부서간 협력지수\u0026rsquo;를 수치화해서 평가하겠다. 그럼 협력이 잘 될까 궁금하네","tags":[],"title":"부서간 협력이 안 되니 대책으로","uri":"https://cychong47.github.io/2015/09/buseogan-hyeobryeogi-an-doeni-daecaegeuro/","year":"2015"},{"content":"HP, Intel, Cisco/Juniper, WindRiver 외에 Orchestrator 관련 회사도 다수 존재.\n개인적으로는 역시 Nokia가 가장 관심이 가는데\n Telco Cloud portfolio - virtualizing radio functions - LTE eNB L2/L3 processing, MME and GW functionality, Wi-Fi controllers and virtual RNCs and vBSCs Multi-layer architecture - pioneers the use of Ethernet fronthaul and any combination of distributed and centralized deployments Processing capacity is allocated from almost anywhere in the network, such as an adjacent cell or a centralized data center, to where it is needed most for coordination and capacity. The multi-layer approach supports distributed and centralized deployments, or a combination of both, using multiple fronthaul types, including Ethernet. Ready for the upcoming demands of 5G core and radio demands  출처 : Leading Lights 2015 Finalists: Most Innovative NFV Product Strategy (Vendor)\n","id":172,"section":"posts","summary":"HP, Intel, Cisco/Juniper, WindRiver 외에 Orchestrator 관련 회사도 다수 존재. 개인적으로는 역시 Nokia가 가장 관심이 가는데 Telco Cloud portfolio - virtualizing radio functions - LTE eNB L2/L3 processing, MME and GW functionality, Wi-Fi controllers and virtual RNCs and vBSCs Multi-layer architecture - pioneers the use of Ethernet","tags":["Nokia","2015","nfv"],"title":"Leading Lights 2015 Finalists - Most Innovative NFV Product Strategy (Vendor)","uri":"https://cychong47.github.io/2015/09/leading-lights-2015-finalists-most-innovative-nfv-product-strategy-vendor/","year":"2015"},{"content":"어딘가 보고 정리한 글인데 출처를 기억하지 못하겠다\u0026hellip;.\nSW 품질 개선 노력의 대상   SW 품질을 높이는데 Tool, System, People 그리고 Management중에 어떤 면을 개선하는 경우 효과가 높을까?\n Tool : 2 배 System : 10배 People : 30배 Management : 60배 이상    그렇지만 대개의 관리자는 개선효과를 반대로 알고 있다.\n  사람은 변화해야 할 때 변화한다(더 이상 저항하지 못할 때) 그러나 위기는 갑자기 오지 않는다. 다만 위기에 대한 인지를 갑자기 할 뿐이다.\n  변화는 성능 저하를 유발한다. 그 성능 저하를 감수하고, 계속 변화해가야 변화가 주는 효과를 얻을 수 있다.\n  고객 가치 중심  Agile은 가치가 높은 것을 가장 먼저 개발하여 SW의 가치를 초기부터 높이려고 노력한다. Action과 Result사이에 시간차가 크면 학습효과가 낮다. SW에서는 설계 내용이 Coding을 거쳐 Test하는 시점이 설계 시점과 멀면 멀 수록 학습효과가 낮아진다(잘못된 설계를 다른 기능 설계시에도 반영할 가능성이 높아진다) Agile에서는 설계/구현/Test의 간극을 줄여 학습효과를 높인다. 이를 위해 기능을 User story로 나누고, 1개 혹은 몇 개의 user story를 기준으로 빌드하여 User story를 추가해 나간다. 이때 user story는 사용자 입장에서의 사용 패턴이다. 하나의 Story는 여러개의 task로 나뉘어진다. Story가 사용자 측면의 기능이라면 task는 개발자 입장에서의 업무이다. 예) \u0026ldquo;xx 카드 승인 기능\u0026quot;이 story라면 해당 story를 구현하기 위해 필요한 기능들 \u0026ldquo;DB 설계\u0026rdquo;, \u0026ldquo;UI 구현\u0026quot;등등이 task다.  Collaboration  한 사람이 1시간 동안 핵심적인 버그를 발견할 확률이 0.1이라고 하면, 총 7명이 있을 때  모든 사람이 버그를 발견할 확률은? 0.1^7 = 0.0000001 한 사람이라도 버그를 발견할 확률은? 1 - 0.9^7 = 0.53    예측  Task는 세분화할 수록 소요시간 예측력이 높아진다. 상벌은 개개인별이 아니라 팀단위로 이루어져야 효과가 높다. 동시에 팀웍 강화 노력도 필요. 개발자들은 절대시간으로 표현해야 하는 절대 시간 추정 능력은 떨어지지만, Story끼리의 상대적인 시간 소요를 비교할 때 필요한 상대 시간 추정 능력은 뛰어나다.  ","id":173,"section":"posts","summary":"어딘가 보고 정리한 글인데 출처를 기억하지 못하겠다\u0026hellip;. SW 품질 개선 노력의 대상 SW 품질을 높이는데 Tool, System, People 그리고 Management중에 어떤 면","tags":["SW 개발 문화","Quality"],"title":"SW 품질 강화 노력","uri":"https://cychong47.github.io/2015/09/sw_quality/","year":"2015"},{"content":"경쟁을 부추켜서 조직의 성과를 얻으려는 관리자는 아무런 노력도 하지 않고 결과만 날로 먹으려는 것과 같다. 아무 고민없이 할 수 있는 제일 쉬운 방법이니까.\n조직원들에게 동기부여를 줄지, 조직의 협동심을 아떻게하면 높일 수 있을 지 고민할 필요가 없이 결과만 취하면 되니까. 그런 관리자는 조직에 해를 끼치는 존재다.\n할 수 있는 게 없는 건지,해도 안되는 건지. 여러가지 방법을 써도 안된다면 조직원과 함께 고민하면 안될까. 함께 속해 있는 \u0026lsquo;조직\u0026rsquo;의 성과를 위한 거니까\n@유정식의 \u0026lsquo;착각하는 CEO\u0026rsquo;를 읽는 중 프랑스/베트남/쥐 박멸/쥐 사육 부분을 읽고\n","id":174,"section":"posts","summary":"경쟁을 부추켜서 조직의 성과를 얻으려는 관리자는 아무런 노력도 하지 않고 결과만 날로 먹으려는 것과 같다. 아무 고민없이 할 수 있는 제일 쉬운 방법이니까. 조직원들에","tags":["잡생각","SW 개발 문화","경쟁","공유","착각하는 CEO"],"title":"경쟁을 통한 성과 추구는 마약과 같다","uri":"https://cychong47.github.io/2015/09/competetion_is_like_drug/","year":"2015"},{"content":"일단 책 제목부터 구박.\n\u0026ldquo;People Analytics: How social technology will transform business and what it tells us about the future of work\u0026quot;인데 이게 왜 저런 한글 제목이 된건지. 책 내용을 보면 짐작은 가지만, 책 제목만 봐서는 구글이 빅데이터를 이용해서 어떤 서비스를 만들어냈는지 라고 해석할 수 있지 않을까? 실제로는 구글등의 회사에서 빅데이터를 이용해 직원들 관리에 어떻게 활용했는지에 대한 내용이다. 그리고 실제 구글 이야기는 많이 나오지도 않는다.\n하지만 책 내용에는 저자가 강조하는 몇 가지 핵심 내용이 있다. 그리고 그 내용에 나도 동의한다. 그것도 쌍수를 듣고. 그리고 지금 우리 회사에서 가장 문제가 되는 취약점이 이게 아닌가 싶다. 더불어 지금의 위기를 해결해 나가는데 이런 점을 해결하면 위기 극복에 분명 큰 도움이 될 거라고 생각한다.\n 직원의 생산성에 영향을 끼치는 가장 강력한 예측 변수가 바로 직원들 간의 대화라는 자료를 내놓았다.\n 책에서 강조하는 핵심 내용은 조직을 구성하는 구성원들이 서로 정보를 공유하는 가장 효과적인 방법은 회의와 같은 공식적인 채널보다는 식수대 앞에서와 같이 편하게 만나 나누는 대화라는 점이다. 공식적인 대화 채널로는 진정으로 유의미한 정보를 자발적으로 공유하게 만들 수 없고, 위에서 시키는 내용만 형식적으로 전달하기 마련이다. 그럼 그 정보를 좀 더 의미있는 것으로 만들기 위해 윗 사람은 그 정보를 평가하고, 또 다른 지시를 내린다. 다시 그 지시를 받은 사람은 또 다른 숙제를 할 뿐 진정으로 다른 이에게 도움이 되는 정보는 좀처럼 공유되지 않는다.\n 직원들간의 네트워크 방식은 회사 내에서 정보의 흐름과 업무 방식에 중대한 영향을 미친다.\n 그리고 보니 회사에서 정보가 공유되는 방식은 거의 일방적이다. 늘 위에서 그 위로부터 받은 내용을 해석해서(혹은 해석도 하지 않고) 아래로 내려 보낸다. 이때 네트워크는 정보를 받는 사람과 주는 사람간에만 활발해진다. 정보를 받은 사람들 간의 네트워크는 별로 없다. 실은 그 사람들이 서로 받은 그리고 서로 알고 있는 정보를 공유해서 새로운 정보를 만들어 내야 함에도 불구하고\n 기업들은 반드시 개발자들끼리 얼굴을 맞대고 의사소통을 많이 할 수 있는 분위기를 만들어야 한다. 우리 연구 결과가 분명히 보여주듯이, 의사소통의 불일치를 좁히는 데 디지털 의사소통 수단에만 의존할 수 없기 때문이다.\n 여기서 말하는 디지털 의사 소통은 이메일을 말하는 듯 하다. 이메일은 일방적인 경우가 많다. 말로하면 서로의 오해를 쉽게 그리고 빠르게 풀 수 있는 경우도 여러 번의 이메일 교환이 필요한 경우도 있다.\n 직원들의 소셜 네트워크가 얼마나 응집력이 높은지에 따라 생산성이 크게 달려졌기 때문이다. 직원들이 서로 대화를 많이 하면 할수록 직원들의 생산성이 더욱 높아졌다.\n 과연 우리는 자발적으로 정보를 공유하고 있는지 의문이다. 그러다면 왜 정보를 공유하지 않는 걸까?\n 직원들의 지식 공유가 바로 궁극적인 회사 생산력 향상의 원동력이다.\n 왜 관리자들은 이런 지식 공유에 대해 강조하지 않을까? 단 한번도 지식/정보 공유에 대해 강조하거나, 분위기 조성을 위해 노력한 관리자를 본 적이 없다.\n그렇다면 어떻게 해야 할까? 정보를 공유할 수 있는 공간을 만들고, 내가 알게 된, 내가 정리한 정보를 계속해서 공유하고, 공유하는 모습을 보여줘야 한다. 솔선수범해야 다른 사람에게도 시킬 수 있다.\n 기업에서 장기적으로 창의성이 계속해서 일어나려면, 다양한 분야의 직원들이 서로 교류를 해야 한다. 자신이 아는 사람만 사귀다 보면, 항상 같은 의견을 가진 직원들하고만 대화하기 마련이다. 그렇게 해서 노키아는 자신이 속한 휴대전화 시장에서 주요한 파괴적인 혁신이 일어났는지 몰랐다. 노키아는 그 폐쇄적인 조직 문화때문에 시장 장악력을 활용해서 스마트폰을 기업 전략의 핵심으로 올려놓는 혁신을 이루어내지 못했다.\n대형 프로젝트를 추진할 때 직원들은 흔히 큰 문제에만 집중하고 작은 문제는 방치하다가 나중에 문제가 커지는 사태를 맞는 경우가 많다. 형식에 얽매이지 않는 의사소통이 중요한 이유가 바로 여기에 있다. 이런 작은 문제는 공식적인 회의에서는 잘 드러나지 않는다. 그것은 모든 사람이 시간을 들여 귀 기울일 만큼 중요하지 않기 때문이다. 하지만 그런 사소한 문제는 직원들이 정수기 앞에서 잡담하기에 안성맞춤인 주제다. 직원들이 이렇게 사소한 문제를 두고 의사소통할 때, 앞으로 일어날 문제를 미연에 방지할 수 있다.\n메사추세츠 교통국의 문제 해결 방식은 작은 문제점들을 몇 년동안 방치하면서 그것이 갑자기 눈덩이처럼 불어나 큰 문제로 닥쳐왔다는 것이 문제였다. 이렇게 문제가 커졌을 때 이를 바로잡으려면 더 많은 비용이 들어간다.\n의존성 추척 도구는 거의 모든 주료 소프트웨어 개발 환경으로 통합되었고, 의존성 문제를 자동으로 검출하기 위한 수십가지 방법은 지난 수십 년 동안 컴퓨터 공학계의 화제가 되었다 최근에는 의사소통의 중요성이 이런 단계까지 이르렀다. 연구자와 산업계 종사자들은 공식적인 보고 도구만으로는 의존성 문제를 해결할 수 없다는 사실을 깨달았다. 개발자들 사이의 상호작용(의사소통)이 있어야 의존성 문제를 적절히 해소할 수 있다고 판단한 것이다. 연구자와 개발자들은 심지어 상호작용의 문제점을 지칭하는 전문용어까지 만들어냈다.\n소프트웨어 개발 과정에서 의존성 문제는 의사소통으로 제대로 해결되거나 그렇지 않으면 도중에 실패한다.\n프로젝트와 관련된 팀들이 자신의 의존성 문제를 언급할 수 있는 문제를 조성하는 것이 프로젝트의 성공의 관건이다.\n개발자들끼리 대화하는 데 추가로 시간을 5퍼센트 더 쓸 것인지 아니면 오류를 수정하는 데 시간을 30퍼센트 더 쓸 것인지, 둘 중에 어떤 선택을 해야 할 지는 분명해 보인다.\n기업들은 반드시 개발자들끼리 얼굴을 맞대고 의사소통을 많이 할 수 있는 분위기를 만들어야 한다. 우리 연구 결과가 분명히 보여주듯이, 의사소통의 불일치를 좁히는 데 디지털 의사소통 수단에만 의존할 수 없기 때문이다.\n ","id":175,"section":"posts","summary":"일단 책 제목부터 구박. \u0026ldquo;People Analytics: How social technology will transform business and what it tells us about the future of work\u0026quot;인데 이게 왜 저런 한글 제목이 된건지. 책 내용을 보면 짐작은 가지만, 책 제목만","tags":["잡생각","관리능력","조직관리","리더","생산성","Book","회의","기록"],"title":"(책) 구글은 빅데이터를 어떻게 활용했는가","uri":"https://cychong47.github.io/2015/09/caeg-gugeuleun-bigdeiteoreul-eoddeohge-hwalyonghaessneunga/","year":"2015"},{"content":"Link : http://www.bloter.net/archives/233978\n 스포카는 측정 가능한 업무 시스템을 위해 깃허브, 슬랙, 지라 같은 협업 도구를 이용했다. 직원들은 협업 도구들로 기록을 철저히 하면서 업무상황을 공유하고 있다. 기록 내용은 아주 자세한 내용을 담는다. 예를 들어 ‘○○에게 e메일을 보냈다’, ‘A에게 답변을 받았다’, ‘개발을 위한 자료 조사 중’ 같은 식이다. 이 내용은 직원별로 볼 수 있다. e메일 내용이 어떤 것이었는지, 자료 조사는 어떤 것을 했는지도 상세히 기록되고 있다.\n  김재석 CTO는 “처음에는 기록을 습관화하는 데 시간이 조금 더 걸렸다”라며 “기록을 편하게 할 수 있도록 기존 협업도구를 스포카 환경에 맞게 재개발하기도 했다”라고 설명했다. 예를 들어 스포카는 채팅도구에 일본어 번역기를 붙여 일본어와 한국어를 모르는 직원들이 서로 정보를 공유할 수 있게 돕고 있다.\n 기록의 습관화. 중요하다. 어떤 일을 한 후에 기록하지 않으면 시간이 지나면 그 일을 한 사람조차 \u0026ldquo;어떤 일\u0026quot;이 있었는지, 그 일의 \u0026ldquo;이유\u0026quot;가 뭐 였는지, 그 \u0026ldquo;결과\u0026quot;가 어땠는 지 기억조차 남지 않는다. 하물며 그 담당자가 다른 업무를 하거나, 연락이 안되는 상황이라면 어떻게 할 건지.\n 리모트를 도입하며 스포카엔 보고 문화가 없어졌다. 정보가 모든 팀원을 상대로 투명하게 공유되기 때문이다. 김재석 CTO는 “의도하지 않았지만 해외 진출하는 과정에서 좋은 효과를 보고 있다”라며 “해외 지사 혹은 본사에서 나눴던 이야기가 차별 없이 많은 사람에게 공유되고 있다”라고 설명했다.\n 정말 좋은 결과. 단순히 어떤 일이 있었는지를 보고하는 시간만큼 시간 낭비가 없다. 여러 사람이 함께 하는 만큼 그 시간은 보도 생산적인 일에 투자해야 한다. 함께 논의할 필요가 있거나, 함께 고민해야 할 일에 대해 시간을 투자해야지, 각자 필요한 정보를 보고 혼자서 할 수 있는 것을 굳이 여러 사람이 모인 자리에서 말로 설명할 필요는 없다.\n","id":176,"section":"posts","summary":"Link : http://www.bloter.net/archives/233978 스포카는 측정 가능한 업무 시스템을 위해 깃허브, 슬랙, 지라 같은 협업 도구를 이용했다. 직원들은 협업 도구들로 기록을 철저히 하면서 업무상황을 공유하고 있","tags":["생산성","회의","문화","기록"],"title":"(펌) 스포카, \"성장 배경? '리모트'와 '블로그 문화' 덕분이죠\"","uri":"https://cychong47.github.io/2015/07/peom-seupoka-seongjang-baegyeong-rimoteuwa-beulrogeu-munhwa-deogbunijyo/","year":"2015"},{"content":"from NASA/JPL(Jet Propulsion Laboratory)\nThe result is that most existing guidelines contain well over a hundred rules, sometimes with questionable justification. Some rules especially those that try to stipulate the use of white-space in programs, may have been introduced by personal preference; others are meants to prevent very specific and unlikely types of error from eariler coding efforts within the same organization.\n효율적인 가이드라인이 되려면, rule의 개수는 적어야 하고, 쉽게 이해되고, 기억될 수 있을 만큼 명확해야 한다.\n규칙은 기계적으로 검사할 수 있을 만큼 구체적이어야 한다.\nRule 1 모든 코드는 매우 간단한 control flow를 가져야 한다. goto, setjmp, longjmp 그리고 직간접의 recursion은 사용하지 않는다.\n향상된 code clarity\nRule 2 All loops must have a fixed upper-bound Rule 3 Do not use dynamic memory allocation after initialization Memory allocator and garbage collectors often have unpredictable behavior that can significantly impact performance.\nRule 4 No function should be longer than what can be printed on a single sheet of paper 60 lines of code per function\nRule 5 The assertion density of the code should average to a minimum of two assertions per function Assertions must always be side-effect free and should be defined as Boolean tests. When an assertion fails, an explict recovery action must be taken(returning error condition to the caller of the function)\nRule 6. Data object must be declared at the smallest possible level of scope Prefer local and static rather than Global\nThe rule discourages the re-use of variables for multiple, incompatible purposes, which can complicated fault diagnosis.\nRule 7. The return value of non-void functions must be checked by each calling function, and the validity of parameters must be checked inside each function Rule 8. The use of preporcessor must be limited to the inclusion of header files and simple macro definitions. Token pasting, variable argument lists, and recursive macro calls are not allowed.\nThe use of conditional compilation directives is often also dubious, but cannot always be avoided. This means that there should rarely be justification for more than one or two conditional compilation directives even in large software development efforts, beyond the standard boilderplate that avoids multiple inclusion of the same header file.\n(boilerplate : Boilerplate (spaceflight), non-functional craft, system, or payload which is used to test various configurations and basic size, load, and handling characteristics)\nThe c preprocessor is a powerful obfuscation tool that can destroy code clarity and befubble many text based checkers.\n10 conditional compilation directives, there could be up to 2^10 possible versions of the code\nRule 9. The use of pointers should be restricted. Specifically, no more one level of dereference is allowed. Function pointers are not permitted. Rule 10. All code must be compiled, from the fist day of development, with all compiler warnings enabled at the compiler\u0026rsquo;s most pedantic settings. There simply is no excuse for any software development effort not to make use of this readily available technology. It should be considered routine practices, even for non-critical code development. Many devlopers have been caught in the assumption that a warning was surely invalid, only to realize much later that the message was in fact valid for less obvious reasons.\nRule 1~2 gurantees the creation of a clear and trasnparent control flow structure that is easier to build, test and anazyze\n","id":177,"section":"posts","summary":"from NASA/JPL(Jet Propulsion Laboratory) The result is that most existing guidelines contain well over a hundred rules, sometimes with questionable justification. Some rules especially those that try to stipulate the use of white-space in programs, may have been introduced by personal preference; others are meants to prevent very specific and unlikely types of error from eariler coding efforts within the same organization. 효율적인 가이드라","tags":[],"title":"The Power of Ten-Rules for Developing Safety Critical Code","uri":"https://cychong47.github.io/2015/07/the-power-of-ten-rules-for-developing-safety-critical-code/","year":"2015"},{"content":"p81  전문가라서 승진했더니 전문적인 일에서는 점점 더 멀어지고, 해보지 않은 일을 끊임없이 떠안기는 게 현대 기업의 문화다. 이 과정에서 효율이 떨어지기라도 한다면 기업은 \u0026lsquo;너는 쓸모없다\u0026rsquo;며 직원을 내친다.\n  중요한 것은 일을 제대로 해내는 능력을 갖춘 사람이다. 누구나 똑같은 말을 한다. 하지만 대기업은 최고의 능력을 갖춘 사람을 구하지 않는다. 조직 논리에 순적응할 수 있는 사람을 찾을 뿐이다. 따라서 결과적으로 대기업은 최고가 될 수 없다.\n 그래서 Steve Jobs가 Apple은 여전히 작은 venture들의 모임이라고 한 건가? 그러게 되길 원하고\np83  \u0026lsquo;초전문화(Hyper Specialization)\u0026rsquo;\n초전문화로 얼마나 품질이 개선될 지 가늠하려면, 지금 자신이 스스로의 전문성과 상관없는, 따라서 잘하지도 못하는 일에 개인적으로 얼마나 많은 시간을 쏟고 있는 지 생각해보라.\n p156  세상 모든 일이 그렇듯, 나이를 먹어서 뭔가 할 수 없는 사람은 젊은 시절에도 아무것도 할 수 없을 뿐이었다.\n ","id":178,"section":"posts","summary":"p81 전문가라서 승진했더니 전문적인 일에서는 점점 더 멀어지고, 해보지 않은 일을 끊임없이 떠안기는 게 현대 기업의 문화다. 이 과정에서 효율이 떨어지기라도 한다면 기","tags":["Book"],"title":"(책) 빅 스몰","uri":"https://cychong47.github.io/2015/07/caeg-big-seumol/","year":"2015"},{"content":"출처 : 관리의 기본 (Fundamental of management) #2 - 관리자/리더에게 필요한 역량\n 가장 중요한 것은 Communication 역량으로, 팀내 또는 팀간의 조율을 위해서는 반드시 필요한 능력이라고 생각한다. 두말할 필요가 없는 부분인데, 효과적인 커뮤니케이션 스킬을 가지기 위해서는 상호 존중이 바탕이 되어야 한다. 존중의 바탕이 없이는 명령이되고, 명령은 팀을 Push하는 모델을 만들지, 팀이 스스로 높은 성과를 낼 수 있도록 Pull (당기는 형태)의 리더쉽을 만들어내기는 어렵다.\n관리자로써 전체적인 계획을 만들고 이를 실행하려면, 팀원들을 코칭할 필요가 있다. 이것이 Coaching skill이고.\n팀 셋업이나 팀관리에 대한 스킬, 프로젝트 관리 능력들도 당연히 중요한 스킬이 된다.\n컴퓨터 스킬이 들어 있는데, 단순히 MS 오피스와 같은 컴퓨터 스킬만을 이야기 하는 것이 아니라, 근래에 들어서 협업 관리 툴이 많이 보급 되고 있다. Slack과 같은 메신져나 JIRA와 같은 이슈 트랙킹 도구, 드롭박스나 구글과 같은 문서 협업도구들은 이러한 능력을 가지고 있으냐 마느냐, 그리고 이를 얼마나 효과적으로 팀에 도입할 수 있느냐 여부에 따라서도 팀의 성과에 많은 영향을 준다.\n다음으로, 주목할만한 것이 Writing Skill (쓰기의 기술)이다. 전적으로 공감하는 부분인데, 문서를 작성하고 이메일을 작성할때 효과적인 문서화는 효과적인 커뮤니케이션을 불러오고 팀을 효율적으로 일할 수 있게 해준다. 많은 관리자, 아니 비단 관리자뿐만 아니라 많은 사람들이 문서화 또는 쓰기 기술에 약해서 의사 전달이 잘못되서 효율성이 떨어지는 경우가 많다.\n마지막으로 주목할 부분은 Resource management skill로, 리소스란 사람, 돈 등 가용할 수 있는 자원을 모두 리소스라고 한다. 결국 관리란, 이 리소스를 효과적인 시점에 효율적으로 투여 하는 것인데, 이 리소스에 대한 개념이 없으면 팀의 역량을 엉뚱한곳으로 투여되서, 팀의 역량이 낭비되는 결과를 초래한다.\n 가장 중요한 것이 communication skill임에도 불구하여, 여전히 조직에서 발생하는 문제점(버그) 수를 줄이는 것이 가장 중요하다고 생각하는 듯 하다. 실은 그렇게 그렇게 행동하길 원하는 분위기라서 그런 지도 모르지만, 그건 핑계인 듯 하고, 원래 그런 쪽에 대해서는 별 관심이 없어 보인다. 그러니 시간이 갈수록 조직이 이렇게 되지\u0026hellip;.\n","id":179,"section":"posts","summary":"출처 : 관리의 기본 (Fundamental of management) #2 - 관리자/리더에게 필요한 역량 가장 중요한 것은 Communication 역량으로, 팀내 또는 팀간의 조율을 위해서는 반드시 필요한 능력이라고 생각한다. 두","tags":["잡생각","조직관리","리더"],"title":"관리자 들도 공부 좀 합시다","uri":"https://cychong47.github.io/2015/07/gwanrija-deuldo-gongbu-jom-habsida/","year":"2015"},{"content":"그냥 누구나 생각하는 바람직한 방법과 목표 그리고 절차를 따라야 한다는 게 고작 결론인가? 그런 누구나 할 수 있는 이야기잖아. 저런 이야기를 돈을 내고 들어야 한다는 건가? 이해가 안된다.\n현재 불편한, 잘못된, 쓸데없는 일을 하게 만드는 절차를 감당해야 하는 사람들에게 솔직한 의견을 구하는 것이 더 나은 방법 아닐까?\n아무리 다른 곳의 일하는 체계나 조직을 분석해도 소용없다. 그 비교자료에는 없는 내용이 핵심이니까. 조직을 운영하는 사람들의 능력과 그 조직을 구성하는 사람들의 능력. 그리고 생각들. 그건 아무리 해도 표현할 수가 없다. 알 수도 없다. 그런데 그게 핵심이다. 아무리 좋은 툴을 갖다 줘도, 아무리 선진 일처리 방식을 가져와도 사람을 빼놓고 일해서는 소용없다.\n급한 일정에 문제가 생겨 지연이 발생했을 때 함께 지연을 최소화할 방안을 찾는 게 아니라 왜 그런 지연이 발생했는지, 누구 잘못인지를 찾으라고 하는게 올바른 management인지는 모르겠다. 그게 그렇게 중요한가? 다시 실수를 안하기 위해 필요한 일인것은 알지만, 그건 추후에 회고하면서 하면 안되는 걸까?\n","id":180,"section":"posts","summary":"그냥 누구나 생각하는 바람직한 방법과 목표 그리고 절차를 따라야 한다는 게 고작 결론인가? 그런 누구나 할 수 있는 이야기잖아. 저런 이야기를 돈을 내고 들어야 한다는 건","tags":["잡생각","관리능력","사람이 핵심"],"title":"열심히 비교한 결론이 고작 그건가?","uri":"https://cychong47.github.io/2015/06/yeolsimhi-bigyohan-gyeolroni-gojag-geugeonga/","year":"2015"},{"content":"출처 : http://m.news.naver.com/read.nhn?mode=LSD\u0026amp;sid1=001\u0026amp;oid=008\u0026amp;aid=0003492855\n 4.어려운 문제에 무턱대고 덤비지 마라\n어렵고 힘든 문제에 부딪히면 지레 겁을 먹기 쉽다. 아니면 무대포로 앞뒤 재지 않고 그냥 밀어붙인다. 그러나 구글과 페북에서 근무하며 얻은 지혜는 어렵고 덩치 큰 문제를 만나면 작게 쪼개서 각 부분별로 해결책을 찾는다는 것이다. 이렇게 부분별로 찾아진 해결책이 모아지면 원래의 덩치 큰 어려운 문제는 자연스럽게 풀리게 된다.\n 문제가 어려우면 어려울 수록 잘게 쪼개자. 잘게 쪼갠 문제를 해결하다 보면 전체 문제가 풀릴 수도 있다. 하지만 동시에 문제의 전체적인 모습을 보는 것도 게을리하면 안된다. 모순같지만 세상사 모든 게 그렇다. 절대적으로 맞는 말은 없다.\n 7.피드백을 사람에 겨냥하지 마라\n상대방이 해 준 피드백은 당신의 발전에 도움이 된다. 그런데 피드백을 할 때 사람이 아닌 이슈에 초점을 맞춰야 한다. 틀린 점을 끄집어내기 보다는 어떻게 하면 개선할 수 있는지에 초점을 맞추자. 이런 방식의 피드백은 긴장감을 누그러뜨릴 뿐만 아니라 더욱 효과적이고 긍정적인 결과를 낳게 된다.\n 피드백은 사람이 아니라, Thing을 향해야 한다. 좋은 의도라 해도 사람에 대한 비난은 결국 나쁜 결과를 만든다. 사람에 대한 언급이 아무리 가벼워도 듣는 사람은 그렇게 듣지 못한다.\n 8.현재의 순간에서 도망치려 하지 마라 경쟁이 심한 직장에서 근무하다 보면 겁먹을 일도 많고 스트레스 받는 일도 많다. 그래서 현재의 순간을 즐기지 못하고 도망치려 하기 쉽다. 하지만 그럴수록 현재의 상황을 받아들이며 사는 습관을 길러야 한다. 현재의 순간을 피하지 말고 소중히 여기자\n 도망치지 말자. 더 이상 무슨 말이 필요하겠나. 특히 나에게 필요한 거.\n","id":181,"section":"posts","summary":"출처 : http://m.news.naver.com/read.nhn?mode=LSD\u0026amp;sid1=001\u0026amp;oid=008\u0026amp;aid=0003492855 4.어려운 문제에 무턱대고 덤비지 마라 어렵고 힘든 문제에 부딪히면 지레 겁을 먹기 쉽다. 아니면 무대포로 앞뒤 재지 않고 그냥 밀어붙인다. 그러나 구글과 페","tags":["좋은글"],"title":"Divide \u0026 Conquer","uri":"https://cychong47.github.io/2015/06/divide-conquer/","year":"2015"},{"content":"(예를 들어) 분명 물리적으로 10개월이 필요한 일이 있다. 일정이 급하다고 6개월내 해 내라고 한다. 열심히 하지만 결국 6개월 기한은 넘어가고 겨우겨우 (담당자들이 개고생해서) 8개월 혹은 9개월내 일을 마친다.\n그리곤 말한다. (6개월을 요구했던 이들은) 처음에 6개월을 여구했으니까 8개월내 해낸거라고. 처음부터 10개월을 이야기했으면 못했을 거라고.\n하지만 경험상 저런 경우 8개월내 끝나기 보다 12개월이 걸리는 경우가 많다. 무리한 일정은 부실한 설계와 엉성한 구현을 만들어내고 버그로 인한 재작업을 유도한다. 이때 책임은 누가 져야 할까?\n","id":182,"section":"posts","summary":"(예를 들어) 분명 물리적으로 10개월이 필요한 일이 있다. 일정이 급하다고 6개월내 해 내라고 한다. 열심히 하지만 결국 6개월 기한은 넘어가고 겨우겨우 (담당자","tags":["잡생각"],"title":"의도된 마감효과?","uri":"https://cychong47.github.io/2015/06/magamhyogwareul-norineun-geonga/","year":"2015"},{"content":"스스로 잘한다고 공공연하게 말하는 친구의 말은 믿을 수가 없다. 자기가 잘하는 단 하나만 생각해서 잘한다고 말하지만, 그게 SW 개발자가 가져야 할 모든 건 아닌데. 그것도 깨닫지 못하는 걸 보면 잘한다고 자만하는 건 스스로의 착각.\n남들의 인정을 받는 지 의문.\n혹은 남들이 자신과 함께 일하고 싶어 하는 지 한번이라도 생각해 봤으면.\n또 저런 친구들의 착각은 남들이 자기랑 함께 일하기 싫어하는 이유를 자신이 너무 잘나서 라고 생각한다는\u0026hellip;\n","id":183,"section":"posts","summary":"스스로 잘한다고 공공연하게 말하는 친구의 말은 믿을 수가 없다. 자기가 잘하는 단 하나만 생각해서 잘한다고 말하지만, 그게 SW 개발자가 가져야 할 모든 건 아닌데. 그것","tags":["잡생각"],"title":"착각과 자만","uri":"https://cychong47.github.io/2015/05/cagga/","year":"2015"},{"content":" 대부분의 개발자는 현업에서 선배 개발자들이 작성한 코드를 유지보수하면서 코드 작성 방법을 배우게 됩니다. 회사에 따라 다르긴 하겠지만, 이렇게 접한 대부분의 코드는 겨우 겨우 동작만 하지, 코드의 가독성이나 유지보수를 거의 생각하지 않고 작성된 코드일 확률이 높습니다. 이런 코드를 읽고, 어떻게든 돌아가게 수정하는 훈련만 하다 보면 애시당초 코드를 잘 짠다는 게 무엇인지 알기가 어렵게 됩니다.\n 출처 : http://wp.me/p66O1q-3j\n평소 내가 가진 생각과 비슷하다. 코드는 작성하는 게 1이면 읽는 게 9라고 한다. 그 만큼 기계가 아닌 사람이 읽는 것의 대상이 되는 경우가 많으므로 읽는 작업에 도움이 되도록 coding style의 정리가 반드시 필요하다고 생각한다. 하지만 이걸 무시하는 경우가 너무 많다는.\n부서 내부 혹은 블록 내부 조차 coding style이 없는 상황이라 외부에 일을 맡기는 경우 받아온 코드는 기존 coding style(이라고 할 것도 없지만 그래도)과 또 다른 style이라, 이런 코드들이 누적되면 그야말로 누더기가 된다. 논리와 계산이 혼재된 것 뿐만 아니라 coding style이 혼재된 코드 역시 읽기에 쉽지 않다.\n","id":184,"section":"posts","summary":"대부분의 개발자는 현업에서 선배 개발자들이 작성한 코드를 유지보수하면서 코드 작성 방법을 배우게 됩니다. 회사에 따라 다르긴 하겠지만, 이렇게 접한 대부분의 코드","tags":["잡생각","Coding Style"],"title":"Coding Style의 중요성","uri":"https://cychong47.github.io/2015/05/coding-styleyi-jungyoseong/","year":"2015"},{"content":"출처 : DPDK mailing list\nCoding Style Description This document specifies the preferred style for source files in the DPDK source tree. It is based on the Linux Kernel coding guidelines and the FreeBSD 7.2 Kernel Developer\u0026rsquo;s Manual (see man style(9)), but was heavily modified for the needs of the DPDK.\nGeneral Guidelines The rules and guidelines given in this document cannot cover every situation, so the following general guidelines should be used as a fallback:\n The code style should be consistent within each individual file. In the case of creating new files, the style should be consistent within each file in a given directory or module. The primary reason for coding standards is to increase code readability and comprehensibility, therefore always use whatever option will make the code easiest to read.  Line length is recommended to be not more than 80 characters, including comments. [Tab stop size should be assumed to be 8-characters wide].\n note\nThe above is recommendation, and not a hard limit. However, it is expected that the recommendations should be followed in all but the rarest situations.\n C Comment Style Usual Comments These comments should be used in normal cases. To document a public API, a doxygen-like format must be used: refer to Doxygen Documentation.\n/* * VERY important single-line comments look like this. */ /* Most single-line comments look like this. */ /* * Multi-line comments look like this. Make them real sentences. Fill * them so they look like real paragraphs. */  License Header Each file should begin with a special comment containing the appropriate copyright and license for the file. Generally this is the BSD License, except for code for Linux Kernel modules. After any copyright header, a blank line should be left before any other contents, e.g. include statements in a C file.\nC Preprocessor Directives Header Includes In DPDK sources, the include files should be ordered as following:\n libc includes (system includes first) DPDK EAL includes DPDK misc libraries includes application-specific includes  Include files from the local application directory are included using quotes, while includes from other paths are included using angle brackets: \u0026ldquo;\u0026lt;\u0026gt;\u0026rdquo;.\nExample:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;rte_eal.h\u0026gt; #include \u0026lt;rte_ring.h\u0026gt; #include \u0026lt;rte_mempool.h\u0026gt; #include \u0026quot;application.h\u0026quot;  Header File Guards Headers should be protected against multiple inclusion with the usual:\n#ifndef _FILE_H_ #define _FILE_H_ /* Code */ #endif /* _FILE_H_ */  Macros Do not #define or declare names except with the standard DPDK prefix: RTE_. This is to ensure there are no collisions with definitions in the application itself.\nThe names of \u0026ldquo;unsafe\u0026rdquo; macros (ones that have side effects), and the names of macros for manifest constants, are all in uppercase.\nThe expansions of expression-like macros are either a single token or have outer parentheses. If a macro is an inline expansion of a function, the function name is all in lowercase and the macro has the same name all in uppercase. If the macro encapsulates a compound statement, enclose it in a do-while loop, so that it can be used safely in if statements. Any final statement-terminating semicolon should be supplied by the macro invocation rather than the macro, to make parsing easier for pretty-printers and editors.\nFor example:\n#define MACRO(x, y) do { \\ variable = (x) + (y); \\ (y) += 2; \\ } while(0)   note\nWherever possible, enums and inline functions should be preferred to macros, since they provide additional degrees of type-safety and can allow compilers to emit extra warnings about unsafe code.\n Conditional Compilation When code is conditionally compiled using #ifdef or #if, a comment may be added following the matching #endif or #else to permit the reader to easily discern where conditionally compiled code regions end. This comment should be used only for (subjectively) long regions, regions greater than 20 lines, or where a series of nested #ifdef's may be confusing to the reader. Exceptions may be made for cases where code is conditionally not compiled for the purposes of lint(1), or other tools, even though the uncompiled region may be small. The comment should be separated from the #endif or #else by a single space. For short conditionally compiled regions, a closing comment should not be used. The comment for #endif should match the expression used in the corresponding #if or #ifdef. The comment for #else and #elif should match the inverse of the expression(s) used in the preceding #if and/or #elif statements. In the comments, the subexpression defined(FOO) is abbreviated as \u0026ldquo;FOO\u0026rdquo;. For the purposes of comments, #ifndef FOO is treated as #if !defined(FOO).\n#ifdef KTRACE #include \u0026lt;sys/ktrace.h\u0026gt; #endif #ifdef COMPAT_43 /* A large region here, or other conditional code. */ #else /* !COMPAT_43 */ /* Or here. */ #endif /* COMPAT_43 */ #ifndef COMPAT_43 /* Yet another large region here, or other conditional code. */ #else /* COMPAT_43 */ /* Or here. */ #endif /* !COMPAT_43 */   note\nConditional compilation should be used only when absolutely necessary, as it increases the number of target binaries that need to be built and tested.\n C Types Integers For fixed/minimum-size integer values, the project uses the form uintXX_t (from stdint.h) instead of older BSD-style integer identifiers of the form u_intXX_t.\nEnumerations  Enumeration values are all uppercase.  enum enumtype { ONE, TWO } et;   Enum types should be used in preference to macros #defining a set of (sequential) values. Enum types should be prefixed with rte_ and the elements by a suitable prefix [generally starting RTE_\u0026lt;enum\u0026gt;_ - where \u0026lt;enum\u0026gt; is a shortname for the enum type] to avoid namespace collisions.  Bitfields The developer should group bitfields that are included in the same integer, as follows:\nstruct grehdr { uint16_t rec:3, srr:1, seq:1, key:1, routing:1, csum:1, version:3, reserved:4, ack:1; /* ... */ }  Variable Declarations In declarations, do not put any whitespace between asterisks and adjacent tokens, except for tokens that are identifiers related to types. (These identifiers are the names of basic types, type qualifiers, and typedef-names other than the one being declared.) Separate these identifiers from asterisks using a single space.\nFor example:\nint *x; /* no space after asterisk */ int * const x; /* space after asterisk when using a type qualifier */   All externally-visible variables should have an rte_ prefix in the name to avoid namespace collisions. Do not use uppercase letters - either in the form of ALL_UPPERCASE, or CamelCase - in variable names. Lower-case letters and underscores only.  Structure Declarations  In general, when declaring variables in new structures, declare them sorted by use, then by size (largest to smallest), and then in alphabetical order. Sorting by use means that commonly used variables are used together and that the structure layout makes logical sense. Ordering by size then ensures that as little padding is added to the structure as possible. For existing structures, additions to structures should be added to the end so for backward compatibility reasons. Each structure element gets its own line. Try to make the structure readable by aligning the member names using spaces as shown below. Names following extremely long types, which therefore cannot be easily aligned with the rest, should be separated by a single space.  struct foo { struct foo *next; /* List of active foo. */ struct mumble amumble; /* Comment for mumble. */ int bar; /* Try to align the comments. */ struct verylongtypename *baz; /* Won't fit with other members */ };   Major structures should be declared at the top of the file in which they are used, or in separate header files if they are used in multiple source files. Use of the structures should be by separate variable declarations and those declarations must be extern if they are declared in a header file. Externally visible structure definitions should have the structure name prefixed by rte_ to avoid namespace collisions.  Queues Use queue(3) macros rather than rolling your own lists, whenever possible. Thus, the previous example would be better written:\n#include \u0026lt;sys/queue.h\u0026gt; struct foo { LIST_ENTRY(foo) link; /* Use queue macros for foo lists. */ struct mumble amumble; /* Comment for mumble. */ int bar; /* Try to align the comments. */ struct verylongtypename *baz; /* Won't fit with other members */ }; LIST_HEAD(, foo) foohead; /* Head of global foo list. */  DPDK also provides an optimized way to store elements in lockless rings. This should be used in all data-path code, when there are several consumer and/or producers to avoid locking for concurrent access.\nTypedefs Avoid using typedefs for structure types.\nFor example, use:\nstruct my_struct_type { /* ... */ }; struct my_struct_type my_var;  rather than:\ntypedef struct my_struct_type { /* ... */ } my_struct_type; my_struct_type my_var  Typedefs are problematic because they do not properly hide their underlying type; for example, you need to know if the typedef is the structure itself, as shown above, or a pointer to the structure. In addition, they must be declared exactly once, whereas an incomplete structure type can be mentioned as many times as necessary. Typedefs are difficult to use in stand-alone header files. The header that defines the typedef must be included before the header that uses it, or by the header that uses it (which causes namespace pollution), or there must be a back-door mechanism for obtaining the typedef.\nNote that #defines used instead of typedefs also are problematic (since they do not propagate the pointer type correctly due to direct text replacement). For example, #define pint int * does not work as expected, while typedef int *pint does work. As stated when discussing macros, typedefs should be preferred to macros in cases like this.\nWhen convention requires a typedef; make its name match the struct tag. Avoid typedefs ending in _t, except as specified in Standard C or by POSIX.\n note\nIt is recommended to use typedefs to define function pointer types, for reasons of code readability. This is especially true when the function type is used as a parameter to another function.\n For example:\n/** * Definition of a remote launch function. */ typedef int (lcore_function_t)(void *); /* launch a function of lcore_function_t type */ int rte_eal_remote_launch(lcore_function_t *f, void *arg, unsigned slave_id);  C Indentation General  Indentation is a hard tab, that is, a tab character, not a sequence of spaces,   note\nGlobal whitespace rule in DPDK, use tabs for indentation, spaces for alignment.\n  Do not put any spaces before a tab for indentation. If you have to wrap a long statement, put the operator at the end of the line, and indent again. For control statements (if, while, etc.), continuation it is recommended that the next line be indented by two tabs, rather than one, to prevent confusion as to whether the second line of the control statement forms part of the statement body or not. Alternatively, the line continuation may use additional spaces to line up to an appropriately point on the preceding line, for example, to align to an opening brace.   note\nAs with all style guidelines, code should match style already in use in an existing file.\n while (really_long_variable_name_1 == really_long_variable_name_2 \u0026amp;\u0026amp; var3 == var4){ /* confusing to read as */ x = y + z; /* control stmt body lines up with second line of */ a = b + c; /* control statement itself if single indent used */ } if (really_long_variable_name_1 == really_long_variable_name_2 \u0026amp;\u0026amp; var3 == var4){ /* two tabs used */ x = y + z; /* statement body no longer lines up */ a = b + c; } z = a + really + long + statement + that + needs + two + lines + gets + indented + on + the + second + and + subsequent + lines;   Do not add whitespace at the end of a line. Do not add whitespace or a blank line at the end of a file.  Control Statements and Loops  Include a space after keywords (if, while, for, return, switch). Do not use braces ({ and }) for control statements with zero or just a single statement, unless that statement is more than a single line in which case the braces are permitted.  for (p = buf; *p != '\\0'; ++p) ; /* nothing */ for (;;) stmt; for (;;) { z = a + really + long + statement + that + needs + two + lines + gets + indented + on + the + second + and + subsequent + lines; } for (;;) { if (cond) stmt; } if (val != NULL) val = realloc(val, newsize);   Parts of a for loop may be left empty.  for (; cnt \u0026lt; 15; cnt++) { stmt1; stmt2; }   Closing and opening braces go on the same line as the else keyword. Braces that are not necessary should be left out.  if (test) stmt; else if (bar) { stmt; stmt; } else stmt;  Function Calls  Do not use spaces after function names. Commas should have a space after them. No spaces after ( or [ or preceding the ] or ) characters.  error = function(a1, a2); if (error != 0) exit(error);  Operators  Unary operators do not require spaces, binary operators do. Do not use parentheses unless they are required for precedence or unless the statement is confusing without them. However, remember that other people may be more easily confused than you.  Exit Exits should be 0 on success, or 1 on failure.\nexit(0); /* * Avoid obvious comments such as * \u0026quot;Exit 0 on success.\u0026quot; */   }\n Local Variables  Variables should be declared at the start of a block of code rather than in the middle. The exception to this is when the variable is const in which case the declaration must be at the point of first use/assignment. When declaring variables in functions, multiple variables per line are OK. However, if multiple declarations would cause the line to exceed a reasonable line length, begin a new set of declarations on the next line rather than using a line continuation. Be careful to not obfuscate the code by initializing variables in the declarations, only the last variable on a line should be initialized. If multiple variables are to be initialised when defined, put one per line. Do not use function calls in initializers, except for const variables.  int i = 0, j = 0, k = 0; /* bad, too many initializer */ char a = 0; /* OK, one variable per line with initializer */ char b = 0; float x, y = 0.0; /* OK, only last variable has initializer */  Casts and sizeof  Casts and sizeof statements are not followed by a space. Always write sizeof statements with parenthesis. The redundant parenthesis rules do not apply to sizeof(var) instances.  C Function Definition, Declaration and Use Prototypes  It is recommended (and generally required by the compiler) that all non-static functions are prototyped somewhere. Functions local to one source module should be declared static, and should not be prototyped unless absolutely necessary. Functions used from other parts of code (external API) must be prototyped in the relevant include file. Function prototypes should be listed in a logical order, preferably alphabetical unless there is a compelling reason to use a different ordering. Functions that are used locally in more than one module go into a separate header file, for example, \u0026ldquo;extern.h\u0026rdquo;. Do not use the __P macro. Functions that are part of an external API should be documented using Doxygen-like comments above declarations. See the Doxgen documentation topic for details. Functions that are part of the external API must have an rte_ prefix on the function name. Do not use uppercase letters - either in the form of ALL_UPPERCASE, or CamelCase - in function names. Lower-case letters and underscores only. When prototyping functions, associate names with parameter types, for example:  void function1(int fd); /* good */ void function2(int); /* bad */   Short function prototypes should be contained on a single line. Longer prototypes, e.g. those with many parameters, can be split across multiple lines. The second and subsequent lines should be further indented as for line statement continuations as described in the previous section.  static char *function1(int _arg, const char *_arg2, struct foo *_arg3, struct bar *_arg4, struct baz *_arg5); static void usage(void);   note\nUnlike function definitions, the function prototypes do not need to place the function return type on a separate line.\n Definitions  The function type should be on a line by itself preceding the function. The opening brace of the function body should be on a line by itself.  static char * function(int a1, int a2, float fl, int a4) {   Do not declare functions inside other functions. ANSI C states that such declarations have file scope regardless of the nesting of the declaration. Hiding file declarations in what appears to be a local scope is undesirable and will elicit complaints from a good compiler. Old-style (K\u0026amp;R) function declaration should not be used, use ANSI function declarations instead as shown below. Long argument lists should be wrapped as described above in the function prototypes section.  /* * All major routines should have a comment briefly describing what * they do. The comment before the \u0026quot;main\u0026quot; routine should describe * what the program does. */ int main(int argc, char *argv[]) { char *ep; long num; int ch;  C Statement Style and Conventions NULL Pointers  NULL is the preferred null pointer constant. Use NULL instead of (type *)0 or (type *)NULL, except where the compiler does not know the destination type e.g. for variadic args to a function. Test pointers against NULL, for example, use:  if (p == NULL) /* Good, compare pointer to NULL */ if (!p) /* Bad, using ! on pointer */   Do not use ! for tests unless it is a boolean, for example, use:  if (*p == '\\0') /* check character against (char)0 */  Return Value  Functions which create objects, or allocate memory, should return pointer types, and NULL on error. The error type should be indicated may setting the variable rte_errno appropriately. Functions which work on bursts of packets, such as RX-like or TX-like functions, should return the number of packets handled. Other functions returning int should generally behave like system calls: returning 0 on success and -1 on error, setting rte_errno to indicate the specific type of error. Where already standard in a given library, the alternative error approach may be used where the negative value is not -1 but is instead -errno if relevant, for example, -EINVAL. Note, however, to allow consistency across functions returning integer or pointer types, the previous approach is preferred for any new libraries. For functions where no error is possible, the function type should be void not int. Routines returning void * should not have their return values cast to any pointer type. (Typecasting can prevent the compiler from warning about missing prototypes as any implicit definition of a function returns int - which, unlike void * needs a typecast to assign to a pointer variable.)   note\nThe above rule about not typecasting void * applies to malloc, as well as to DPDK functions.\n  Values in return statements should not be enclosed in parentheses.  Logging and Errors In the DPDK environment, use the logging interface provided:\n#define RTE_LOGTYPE_TESTAPP1 RTE_LOGTYPE_USER1 #define RTE_LOGTYPE_TESTAPP2 RTE_LOGTYPE_USER2 /* enable these logs type */ rte_set_log_type(RTE_LOGTYPE_TESTAPP1, 1); rte_set_log_type(RTE_LOGTYPE_TESTAPP2, 1); /* log in debug level */ rte_set_log_level(RTE_LOG_DEBUG); RTE_LOG(DEBUG, TESTAPP1, \u0026quot;this is is a debug level message\\n\u0026quot;); RTE_LOG(INFO, TESTAPP1, \u0026quot;this is is a info level message\\n\u0026quot;); RTE_LOG(WARNING, TESTAPP1, \u0026quot;this is is a warning level message\\n\u0026quot;); /* log in info level */ rte_set_log_level(RTE_LOG_INFO); RTE_LOG(DEBUG, TESTAPP2, \u0026quot;debug level message (not displayed)\\n\u0026quot;);  Branch Prediction  When a test is done in a critical zone (called often or in a data path) the code made use the likely() and unlikely() macros to indicate the expected, or preferred fast path. They are expanded as a compiler builtin and allow the developer to indicate if the branch is likely to be taken or not. Example:  #include \u0026lt;rte_branch_prediction.h\u0026gt; if (likely(x \u0026gt; 1)) do_stuff();   note\nThe use of likely() and unlikely() should only be done in performance critical paths, and only when there is a clearly preferred path, or a measured performance increase gained from doing so. These macros should be avoided in non-performance-critical code.\n Static Variables and Functions  All functions and variables that are local to a file must be declared as static because it can often help the compiler to do some optimizations (such as, inlining the code). Functions that should be inlined should to be declared as static inline and can be defined in a .c or a .h file.   note\nStatic functions defined in a header file must be declared as static inline in order to prevent compiler warnings about the function being unused.\n Const Attribute The const attribute should be used as often as possible when a variable is read-only.\nInline ASM in C code The asm and volatile keywords do not have underscores. The AT\u0026amp;T syntax should be used. Input and output operands should be named to avoid confusion, as shown in the following example:\nasm volatile(\u0026quot;outb %[val], %[port]\u0026quot; : : [port] \u0026quot;dN\u0026quot; (port), [val] \u0026quot;a\u0026quot; (val));  Control Statements  Forever loops are done with for statements, not while statements. Elements in a switch statement that cascade should have a FALLTHROUGH comment. For example:  switch (ch) { /* Indent the switch. */ case 'a': /* Don't indent the case. */ aflag = 1; /* Indent case body one tab. */ /* FALLTHROUGH */ case 'b': bflag = 1; break; case '?': default: usage(); /* NOTREACHED */ }  Environment or Architecture-specific Sources In DPDK and DPDK applications, some code is specific to an architecture (i686, x86_64) or to an executive environment (bsdapp or linuxapp) and so on. As far as is possible, all such instances of architecture or env-specific code should be provided via standard APIs in the EAL.\nBy convention, a file is common if it is not located in a directory indicating that it is specific. For instance, a file located in a subdir of \u0026ldquo;x86_64\u0026rdquo; directory is specific to this architecture. A file located in a subdir of \u0026ldquo;linuxapp\u0026rdquo; is specific to this execution environment.\n note\nCode in DPDK libraries and applications should be generic. The correct location for architecture or executive environment specific code is in the EAL.\n When absolutely necessary, there are several ways to handle specific code:\n Use a #ifdef with the CONFIG option in the C code. This can be done when the differences are small and they can be embedded in the same C file:   Use the CONFIG option in the Makefile. This is done when the differences are more significant. In this case, the code is split into two separate files that are architecture or environment specific. This should only apply inside the EAL library.  Per Architecture Sources The following config options can be used:\n CONFIG_RTE_ARCH is a string that contains the name of the architecture. CONFIG_RTE_ARCH_I686, CONFIG_RTE_ARCH_X86_64, CONFIG_RTE_ARCH_X86_64_32 or CONFIG_RTE_ARCH_PPC_64 are defined only if we are building for those architectures.  Per Execution Environment Sources The following config options can be used:\n CONFIG_RTE_EXEC_ENV is a string that contains the name of the executive environment. CONFIG_RTE_EXEC_ENV_BSDAPP or CONFIG_RTE_EXEC_ENV_LINUXAPP are defined only if we are building for this execution environment.  Doxygen Documentation The API documentation is automatically generated in the DPDK framework. That is why all files that are part of the public API must be documented using Doxygen syntax.\nThe public API comprises functions of DPDK that can be used by an external application that will use the SDK. Only the Doxygen syntax described in the coding rules (this document) should be used in the code. All the Doxygen features are described in the Doxygen manual online.\nDocumenting a Function All public functions must be documented. The documentation is placed in the header file, above the declaration of the function. The definition of the function may be documented, but using standard comments (not in doxygen format). The following is an example of function documentation:\n/** * Summary here; one sentence on one line (should not exceed 80 chars). * * A more detailed description goes here. * * A blank line forms a paragraph. There should be no trailing white-space * anywhere. * * @param first * \u0026quot;@param\u0026quot; is a Doxygen directive to describe a function parameter. Like * some other directives, it takes a term/summary on the same line and a * description (this text) indented by 2 spaces on the next line. All * descriptive text should wrap at 80 chars, without going over. * Newlines are NOT supported within directives; if a newline would be * before this text, it would be appended to the general description above. * @param second * There should be no newline between multiple directives (of the same * type). * * @return * \u0026quot;@return\u0026quot; is a different Doxygen directive to describe the return value * of a function, if there is any. */ int rte_foo(int first, int second)  Documenting Files Each public file may start with a comment describing what the file does. For example:\n/** * @file * This file describes the coding rules of RTE. * * It contains the coding rules of C code, ASM code, reStructured * Text documentation, and of course how to use doxygen to document * public API. */  Documenting Constants and Variables Examples:\n/** * The definition of a funny TRUE. */ #define TRUE 0 #define TRUE 1 /**\u0026lt; another way to document a macro */ /** * Frequency of the HPET counter in Hz * * @see rte_eal_hpet_init() */ extern uint64_t eal_hpet_resolution_hz;  Documenting Structures Public structures should also be documented. The /**\u0026lt; sequence can be used to documented the fields of the structure, as shown in the following example:\n/** * Structure describing a memzone, which is a contiguous portions of * physical memory identified by a name. */ struct rte_memzone { #define MEMZONE_NAMESIZE 32 char name[MEMZONE_NAMESIZE]; /**\u0026lt; name of the memory zone */ phys_addr_t phys_addr; /**\u0026lt; start physical address */ void *addr; /**\u0026lt; start virtual address */ uint64_t len; /**\u0026lt; len of the memzone */ int socket_id; /**\u0026lt; NUMA socket id */ };  See Also Sections The @see keyword can be used to highlight a link to an existing function, file, or URL. This directive should be placed on one line, without anything else, at the bottom of the documentation header.\n/** * (documentation of function, file, ...) * * @see rte_foo() * @see eal_memzone.c */  ","id":185,"section":"posts","summary":"출처 : DPDK mailing list Coding Style Description This document specifies the preferred style for source files in the DPDK source tree. It is based on the Linux Kernel coding guidelines and the FreeBSD 7.2 Kernel Developer\u0026rsquo;s Manual (see man style(9)), but was heavily modified for the needs of the DPDK. General Guidelines The rules and guidelines given in this document cannot cover every situation, so the following general","tags":["DPDK","Coding Style","C"],"title":"DPDK Coding style","uri":"https://cychong47.github.io/2015/05/dpdk-coding-style/","year":"2015"},{"content":"출처 : Docker 무작정 따라하기\n참고 : 가장 빨리 배우는 Docker\n","id":186,"section":"posts","summary":"출처 : Docker 무작정 따라하기 참고 : 가장 빨리 배우는 Docker","tags":["docker"],"title":"Docker for dummies 정리","uri":"https://cychong47.github.io/2015/05/docker-for-dummies-jeongri/","year":"2015"},{"content":"p13  나는 사업을 하면서 수시로 수확체감의 법칙을 실감한다. 어떤 사업이든 일정 수준에 도달하면 노동이나 자본 등 생산 요소를 늘려도 결과물은 비례해서 증가하지 않는다.\n일과 성공 역시 마찬가지다. 들인 시관과 성과는 정비례하지 않는다. 6시간 일한다고 목표를 달성하지 못하는 것도 아니고 12시간 일한다고 두 배의 성과를 얻는 것도 아니다. 그런데도 여전히 많은 사람들이 50시간이 아니라 70시간을 일할 때 더 많은 일을 해낸다고 믿는다.\n p15  우리가 12시간씩 일하며 인생은 원래 고달픈 거라고 스스로를 위로하는 동안 누군가는 획기적인 아이디어로 3시간 일하고 9시간 동안 여유를 즐긴다.\n인간은 주당 30시간에서 60시간 정도 일할 때 \u0026lsquo;최대의 행복감\u0026rsquo;을 느낀다고 한다. 일하는 시간이 적으면 자신의 존재 가치를 증명하고 자아실현을 할 충분한 기회를 갖지 못하고, 일하는 시간이 너무 길면 체력이 떨어지면서 삶에 대한 의욕도 사라진다. 잘 살기 위해 일을 하는 것인데 일하는데 모든 에너지를 다 써서 정작 좋아하는 것을 즐기지 못하게 되는 것이다.\n p16  사람들은 인생에서 가장 중요한 게 무엇이냐는 질문을 받으면 가족, 친구, 건강이라고 주저 없이 말한다. 그러나 현실에서 선택하는 것은 그 세가지가 아니라 일이다. 씁쓸한 건 대부분의 사람들이 관계를 단절시키고 건강 악화를 초래하는 원인으로 가장 많이 꼽인 것이 바로 일이라는 사실이다.\n p26  다른 사람들이 정의한 성공을 무작정 따라가는 것은 아무 의미가 없다. 사실 남들과 똑같은 방법으로는 성공할 수도 없다. 때로는 위험을 감수하고 나만의 길을 창조해야 만족감도 있고 행복도 느끼는 성공을 할 수 있다.\n p45  최고가 아니라 유일함을 추구하라.\n1등은 시간이 지나면 잊여지지만 유일한 것은 시간이 갈수록 더 큰 의미를 갖는다.\n자기만의 특별함으로 잊히지 않는 존재가 되라.\n p48  지나가던 사람들이 뒤돌아볼 정도로 튀는 옷을 입었던 적이 있는가? 남들과 다른 자신의 생각을 당당하게 말한 적은 언제인가? 성공하고 싶다면 다른 사람의 발자국 위에 발을 올리지 마라. 항상 자기만의 독특한 방식을 고민하라. 자신의 삶을 더 나은 것으로 만들기 위해서는 어떻게 하면 창조적인 결과물을 얻을 수 있는 가를 생각해야 한다.\n p52  토니 세이 자포스 CEO. Collision \u0026amp; Co-learning \u0026amp; Connectedness\n마주치고, 서로 배우고, 연결되면 혁신이라는 기적은 저절로 일어난다.\n혼자 몰입하는 시간은 그 아이디어를 정리할 때 써도 충분하다.\n그러니 지금 하는 일에 효율성을 높이고 싶다면 자리에 앉아 일과 씨름하는 대신 나가서 사람들과 만나고 이야기를 주고받아라.\n p56  \u0026lsquo;무엇을 해 볼 생각이 있다\u0026rsquo;는 말은 성공하는 데 필요한 요소 가운데 1~5 퍼센트 정도의 비중밖에 차지하지 않는다. 성공의 나머지 95~99퍼센트는 실행에서 온다. 성공적으로 실행하기 위해서는 능숙하게 일을 처리하는 기술과 네트워크 구축 등 단기간 내에 습득할 수 없는 여러 요소들이 조화를 이뤄야 한다.\n p70  좋은 시절은 나이 때문에 사라지는 것이 아니라 체념하기 때문에 사라진다. 각자 자신이 좋아하는 일을 해서 성공을 쟁취하기에 늦은 나이란 없음을 깨닫기를 바란다. 좋은 시절이란 지금 현재 시점이며, 어떤 일이든 시작하기에 가장 좋은 날은 바로 오늘이다.\n p77  \u0026lsquo;뭐가 잘못됐을까\u0026rsquo; 걱정하며 애태우지 말고 \u0026lsquo;뭐가 잘됐을까\u0026rsquo;를 찾아 더 잘할 수 있는 방법을 고민하라.\n긍정적인 것이든 부정적인 것이든 삶은 스스로 에너지를 쏟고 주의를 기울이는 쪽으로 흘러간다.\n p82  실제 사용자가 되 사람들과 이야기를 나누고 그들이 선택하는 것과 선택하지 않는 것을 주의 깊게 살펴라.\n p92  확인해도 끝이 없는 일반적인 정보들의 흐름을 무작정 쫓아가 봤자 다른 사람들과 똑같은 것을 배우기 위해 시간을 썼을 뿐이다. 당신은 절대 그 어떤 이득도, 특별한 견문도, 세상에 도움이 될 만한 새로운 무언가를 얻지 못한다. 남들도 다 아는 것을 알기 위해 노력하는 것은 중요하지 않다. 우리가 해야 할 일은 다른 사람들과는 다른 무언가를 알기 위해 노력하는 것이다. 거기에서 기회가 발생하기 때문이다.\n p93  티모시 페리스 \u0026lsquo;4시간\u0026rsquo; 을 읽을 더 이상 흘러가는 소식을 쫓지 않겠다는 결단을 내렸다.\n오히려 놀랍게도 뉴스를 끊고 몇 달이 지나자 소설에 대한 흥미가 생겨났다. 그리고 공부를 하고 싶다는 마음도 들었다.\n우리가 알려고 노력해야 하는 것들은 바로 이런 지식들이다. 순수한 호기심이 마음을 움직여서 얻은 지식이 당신을 남들과 다르게 만들어 줄 것이다. 그러니 평소 의무감 때문에 지켜보던 뉴스 채널을 던져 버리고 새롭고 사람들이 잘 모르는 지식을 찾아 나서라. 더 적은 시간으로 더 많은 것들을 달성할 수 있고 재미도 배가 할 것이다.\n p96  전 직원이 같은 목표를 갖게 되자 기업 내에 목표지향적 환경이 만드러졌고 이를 바탕으로 자포스는 엄청난 능률과 더불어 행복까지 얻었다. 리더나 기업가들은 이따금씩 구성원들이 생각만큼 조직에 헌신하지 않는다고 불평한다. 그러면서 이를 바로잡기 위해 경영 관리를 더 철저하게 하고 더 엄격히 통제해야 한다고 결론을 내린다. 그러나 이것은 잘못된 판단이다. 근본저긴 원인은 리더나 기업가 자신에게 있다.\n한 조직의 리더로서 명확하게 흥미진진한 목표를 지닌 회사를 만들지 못했고, 회사의 계획에 진정으로 흥미를 느끼는 직원을 구하지 못했으며, 각각의 구성원들에게 공동체 속에서 자기 역할이 무엇인지 어떻게 공헌할 수 있는지를 확실히 말해 주지 않았기 때문이다. 다시 말해 직원들이 문제가 많은 게 아니라 스스로 준비 작업을 제대로 하지 않은 것에 대한 대가를 치르고 있는 것 뿐이다.\n이들에게 절실한 과제는 처음으로 돌아가 목표를 찾는 일이지, 조직이나 체계를 때려 고치는 일이 아니다.\n만약 당신이 아직 인생의 목표를 찾지 못했다면 이 책을 읽고 있는 지금 이 순간을 계기로 삼아 고민해 보길 바란다. 내 인생의 목표는 무엇인가. 목표도 없고 하고 싶은 일도 없다고 체념하지 말자. 즐겁게 했던 일을 따라가 보면 잘할 수 있는 일이 분명히 떠오를 것이다. 그 일이 직업으로 선택할 만한 것은 아닐지라도 신나게 뭔가에 열중했던 기억이 떠오른다면 목표를 세우는 데 큰 자극제가 된다.\n올해가 지나기 전에 1년 동안 달성할 목표를 세우고 뛰어들어라. 그러면 내년은 결코 나이만 한 살 더 먹은 덧없는 한 해가 되지 않을 것이다.\n p101  도대체 왜 많은 기업들은 단순함을 따르지 않고 자꾸 옆길로 새는 것일까? 답은 간단하다. 똑독하게 보이려는 사람들이 노력이 일을 그토록 복잡하게 만드는 것이다.\n p104  좋은 프로그램이란 원래의 목적을 가장 잘 구현할 수 있는 것이기 때문이다.\n그의 말처럼 시스템을 단순화할수록 일은 더 쉬워지고 효율은 올라간다. 그러니 그 무엇보다 먼저 간결함을 선택하라.\n p116  스티브 코비 컨설팅\n\u0026lsquo;진실로 중요한 일에만 집중하라\u0026rsquo;. 학교에 다닐 때부터 모든 숙제를 빠짐없이 해내야 \u0026lsquo;참 잘했어요\u0026rsquo; 도장을 받을 수 있었던 우리에게 이것은 쉽지 않았다. 그보다는 긴긴 업무 목록을 작성하고 하나씩 지워 나가는 게 훨씬 안전하게 보였다. 그러나 이 훈련을 하면서 어떤 프로젝트를 하든 정말 중요한 일은 한 가지뿐이거나 많아야 세 가지에 불과하다는 사실을 발견했다.\n사람들은 습관적으로 엄청나게 중요한 일보다 업무 목록에 있는 작고 쉬운 일부터 먼저 처리하려고 한다.\n p124  뼈 빠지게 일하면서도 성공을 거두지 못하는 그저 그런 리더와 별다른 희생을 치르지 않고도 어렵지 않게 놀라운 성과를 거두는 리더의 차이점은 무엇일까? 아마 적절한 인재를 고용하고 그들에게 동기와 영감을 부여하면서 올바른 문화를 조성하는 능력이 있느냐 없느냐의 차이일 것이다. 그러나 할 수 있는 대답이겠지만, 실제로 이 능력은 쉽게 얻을 수 있는 게 아니다.\n p126  \u0026lsquo;서로 다른 업무를 하고 있는 사람들을 조화롭게 이어 주고 직원들에게 긍정적인 비전을 주는 것이 바로 리더죠. 직원들의 일에 사사건건 개입하고 생각을 떠보기 위해 소통을 하는 것이 아닙니다. 오히려 직원들이 지금 하고 있는 일을 믿고 있고 그들의 능력을 인정하고 있다는 사실을 알리기 위해 대화를 합니다. 그리고 도움이 필요한 타이밍에 도움을 주기 위해서이기도 하고요. 일을 진행하는데 있어서 리더가 방해물이 되어서는 안 됩니다\u0026rsquo;\n p128  사람들은 자신의 말을 들어주는 사람에게 마음을 연다. 듣는다는 행동에는 당신을 존중하고 배려한다는 메시지가 담겨 있기 때문이다. 반면 비판과 평가를 받으면 마음의 문을 꽁꽁 닫아걸거나 논쟁을 벌인다. 서로 한 팀이 되지 않으면 어려움을 극복하는 일은 실패할 수 밖에 없다.\n리더란 자신의 성공이 아니라 평범한 다른 사람들이 뛰어난 성공을 거둘 수 있도록 돕기 위해 존재하는 것이다. 그러니 더 나은 미래를 만들고 싶다면 상대의 말에 비판과 평가보다는 경청을 하는 사람이 되라. 나와 DNA부터 다른 상대방의 관점을 진심으로 이해하고 그들의 마음을 움직이기 위해서는 먼저 귀를 기울여 들어야 한다는 사실을 잊지 말길 바란다.\n p134  \u0026lsquo;회사가 아주 작았을 때부터 매일 그날 끝내야 하거나 진행해야 하는 업무 목록을 기록해 오고 있습니다. 그 일들을 다 마치고 사무실을 나서면 오늘 하루 열심히 일했고, 내 역할을 잘 해냈다는 생각이 듭니다.\n p140  지칠 때까지 일하지 마라. 못한 일은 다음 날 다시 만회할 수 있지만 한번 말라붙은 열정을 복구하는 데는 몇 달 몇 년이 걸릴 수도 있다.\n p155  하루 24시간을 8:8:8로 나누어 일을 하는데 8시간, 잠을 자는데 8시간 그리고 나머지 8시간을 자신이 진짜 하고 싶은 일을 하는 시간으로 삼았다.\n p170  SAS\n\u0026ldquo;부모로서 아이가 아플 때 병원에 데려가고, 아이가 학교에서 하는 첫 연극이나 축구 경기를 보러 가는 일은 꼭 해야 하지 않을까요? 이런 것들을 포기하고 사무실에 앉아 일을 한다고 해서 대단한 제품이 개발될 거라고 생각하지 않습니다. 그래서 회사를 처음 세울 때부터 \u0026lsquo;일과 삶의 균형\u0026rsquo;을 1순위로 고려했습니다. \u0026quot;\n p173  사람들은 일과 삶의 균형이라고 하면 자기 자신을 먼저 생각한다. 하지만 자신의 인생을 즐기며 일도 잘하기 위해서는 팀 전체가 그렇게 되어야 한다. 그러니까 일을 잘한다고 또는 자기가 리더라고 혼자만 여유를 가져서는 안 된다는 말이다.\n직원 모두가 즐겁고 신나게 일하고 출근하게 회사, 그리고 그 경험을 다른 팀원들과 나눌 수 있는 회사에서는 그렇지 않은 회사에 비해 특별한 유대감이 생겨나고 서로를 훨씬 더 많이 배려하는 문화가 형성된다. 함께 일하는 동료들에게 배려를 베풀면 베풀수록 자신 또한 더욱 큰 힘을 얻고 서로를 위해 더 열심히 일하게 되며, 팀을 위한 충성심이 높아질수록 또는 팀원 간에 의리가 넘칠수록 능률은 더 오른다.\n p180  할아버지는 월요일을 실험일로 정했다. 그리고 어떻게 시간을 효율적으로 쓸 수 있는 지 공작기계를 이리저리 조정해서 최적화된 생상 방법을 찾아내려 애썼다. 다른 사람들과 달리 정신없이 바쁘게 일하지도 않았고 옆에 놓인 상자에 조립품을 채워 넣지도 않았다. 그저 생각하고 실험했다. 할아버지에게 월요일은 앞으로의 시간을 효율적으로 쓰기 위해 계획을 짜는 날이었던 것이다.\n p195  첫 이메일을 쓰고 수신자의 입장에서 생각해 본다. 상대방의 경험은 분명 당신과 다를 테니까\n이메일을 쓴 후 바로 보내지 않는다. 그 전에 다음의 안내를 따른다.\n 이 메일 대신 수신자와 직접 만나 이야기를 하는게 가능한 지 생각해 본다. 직접 만드는 게 불가능하다면 자신이 쓴 이메일을 다시 한번 읽어보고, 상대방의 감정을 자극하거나 자신을 치켜세우는 내용이 담긴 문구는 삭제한다. 중요한 이메일이라면 자신이 쓴 글을 다른 사람에게 읽게 하고 솔직한 견해를 구한다\n자신의 감정을 누그러뜨리고 최대한 침착하게 이메일을 보냈는데도 상대방에게서 화가 섞인 답장을 받았다면 더 이상 글로 소통하지 말고 전화로 연락을 하거나 직접 만나도록 한다   p206  인생에 가치를 더해 주지 못하는 활동들을 목록에서 지워라. 불필요한 일을 버리는 것이 좋은 활동을 채워 넣는 것보다 살믈 더 풍요롭게 만든다.\n ","id":187,"section":"posts","summary":"p13 나는 사업을 하면서 수시로 수확체감의 법칙을 실감한다. 어떤 사업이든 일정 수준에 도달하면 노동이나 자본 등 생산 요소를 늘려도 결과물은 비례해서 증가하지 않는다","tags":["Book"],"title":"(책) 죽어라 일만 하는 사람은 절대 모르는 스마트한 성공들","uri":"https://cychong47.github.io/2015/05/caeg-jugeora-ilman-haneun-sarameun-jeoldae-moreuneun-seumateuhan-seonggongdeul/","year":"2015"},{"content":"\u0026lsquo;\u0026lsquo;단의 공식\u0026rsquo;\u0026rsquo;  버려라 : 중요한 것을 위해 덜 중요한 것을 버리는 것. \u0026lsquo;더 많이\u0026rsquo;를 버리고 핵심에 집중 세워라 : 왜 일해야 하는 지 사명을 세우고, 내가 누구인지 정체성을 세우고, 어디로 가야 할 지 길을 세워야 한다. 지켜라 : 단순함의 핵심은 지속 가능에 달려 잇다.  p14  GE의 제프리 이멜트(Jeffrey Immelt) 회장은 2013년 10월 BBC와의 인터뷰에서 이렇게 설명했다. \u0026quot; 조직이 커지면서 중요하지 않은 일을 너무 많이 하고 있다. 단순화는 직원들이 중요하지 않은 일에 맞서 정말 중요한 일을 함께 하도록 돕는 도구다. 조직을 더 날렵하게 만들고, 관료주의를 없애고, 시장에 완전히 집중하는 것을 뜻한다\u0026rdquo;\n p24  현대인은 가슴이 두근거리지 않는 것들에 둘러싸여 너무 많은 에너지를 쏟는다. 주변을 찬찬히 살펴보고 자신을 두근거리게 하는 물건만 골라 남김으로써, 자신이 정말 하고 싶은 일에만 집중할 수 있게 된다.\n p48  직원의 동기부여다. 슈나르 회장은 \u0026ldquo;파타고니아 직원들이 열심히 일하는 이유는 일을 사랑할 뿐 아니라 그 일을 통해 세상에 기여할 수 있기 때문\u0026quot;이라며 \u0026ldquo;이 두가지가 결합되면 인간의 우수성을 이끌어내면서도 큰 사업적 성과를 거둔다는 두 가지 목표를 다 이룰 수 있다\u0026quot;고 설명했다.\n 우리가 만든 제품을 소비자가 어떻게 평가하느냐를 넘어 소비자가 우리 제품을 이용해서 어떤 가치를 만들어 내는지(소비자의 시장 점유율 증가나 새로운 서비스 혹은 가치 창출 등) 를 알려주는 것이 직원들의 동기부여에 도움이 되지 않을까? 단순히 품질을 높여라 라는 무미건조한 말 보다는 우리의 행동이 우리의 노력이 어떤 가치를 만들어 내는지를 체감하게 해 준다면 동기부여에 도움이 되지 않을까?\n\u0026lsquo;나만 아니면 돼\u0026rsquo; 라는 생각은 \u0026lsquo;우리 부서 문제만 아니면 돼\u0026rsquo;로 이어진다. 이건 발생한 문제를 우리가 함께 해결해야 할 문제로 보는 것이 아니라 그 부서를, 부서장을 평가하려는 목적으로 사용하기 때문에 모두 방어적으로 반응하게 만드는 것이다. 결국 이런 문화를 만든 것은 다름 아닌 바로 당신들\u0026hellip;\np50  \u0026lsquo;소비하지 않으면 안 되는 시스템\u0026rsquo;과 \u0026lsquo;늘어나지 않는 유효수요\u0026rsquo;가 빚어내는 모순이 임계점에 도달했다.\n p61  모든 것을 담기는 쉽다. 그러나 적게 담는 건 어렵다. 복잡하게 만들고 중언부언하기는 쉽다. 그러나 절제는 어렵다. 언젠가 마크 트웨인이 출판사에서 \u0026lsquo;이틀 내에 두 쪽짜리 단편 필요\u0026rsquo;라는 전보를 받았다. 트웨인은 이렇게 회신했다.\n\u0026lsquo;이틀 내에 두 쪽짜리는 불가. 30쪽 짜리는 가능. 두 쪽짜리는 30일 필요\u0026rsquo;\n p70  우리가 자신만의 가치, 새로운 가치를 세워야 하는 또다른 이유가 있다. \u0026lt;기계와의 전쟁\u0026gt;의 에릭 브린욜프슨(Erik Brynjolfson) 교수의 표현을 빌리자면, \u0026lsquo;어떻게 하면 더 빨리, 더 많이 만들 것인가\u0026rsquo;를 고민하면 기계가 인간 노동력을 대체할 수 밖에 없다.\n p72  \u0026ldquo;직원 교육에는 반드시 명심해야 할 두 가지가 있습니다. 첫째는 창의성을 길러 새로운 가치를 창출하는 한편, 단순 업무를 반복하지 않도록 가르치는 것입니다. 많은 구식 회사들은 \u0026lsquo;(회사와 관련된)\u0026rsquo; 모든 것을 하나하나 기억하고 단순 업무를 반복\u0026rsquo;하는 직원을 성실하다고 평가하지만, 생각해보세요. 이런 건 모두가 기계로 대체할 수 있습니다. 절대로 좋은 교육법이 아닙니다. 둘째는 인간과 인간 사이의 소통 능력을 개발하고 교육하는 겁니다. 예컨대 리더십, 팀워크, 협상력, 공감 능력, 가르치는 능력은 앞으로 점점 더 중요해질 겁니다. 기계는 이런 부분에서는 발전이 더디며 능숙하지 못하기 때문입니다.\u0026rdquo;\n p 83  \u0026ldquo;회사를 운영하는 사람들과 그 안에서 실무를 처리하는 사람들 사이에 너무나 많은 중간관리자가 있습니다 .열정적이고 창의적인 사람들이 자기가 옳다고 생각하는 일을 하기 위해 5단계의 경영층을 설득해야 하는 상황에 놓인 것입니다\u0026rdquo;\n p 112  \u0026ldquo;선택과 집중이 필요합니다. 아직 뇌 용량을 다 채우지 않은 어린이가 어떤 환경, 정보에 노출되는지가 그래서 중요하죠. 어릴 때는 뇌에 주입되는 관념, 개념, 정보가 신피질의 공간을 무섭게 채워가니까요\u0026rdquo;\n 뇌는 처음엔 매우 빠른 속도로 성장하다 어느 순간에 이르면 성인이 될 때까지 계속 줄어든다고 한다. 그럼에도 불구하고 그 크기가 작아질수록 뇌는 점점 더 영리해진다\np 116  베인앤컴퍼니의 제임스 앨런(James Allen) 글로벌전략부문 대표는 \u0026ldquo;기업의 규모가 커지고 행정적으로 복잡해지면서 의사결정 과정에서 고객 의견이나 일선의 목소리가 제대로 반영되지 않는다. 결국 기업은 점차적으로 사명감을 잃게 되고 성장 과정에서 파생된 복잡성으로 인해 서서히 쇠락한다\u0026quot;고 지적했다\u0026rdquo;\n\u0026ldquo;성장은 복잡성을 유발하며, 복잡성은 성장의 조용한 암살자\u0026quot;라고 말했다. 복잡성은 소리 없이 조직을 죽인다.\n p 118  뒤집어진 \u0026lsquo;U\u0026rsquo;자 형태의 복잡성과 성과 간의 관계는 2009년 데이비스(J. P. Davis)와 아이젠하트(K.M. Elsenhardt), 빙엄(C.B. Bingham)이 처음 제시했다. 그들은 팀 게임에서 규칙이 점점 많이 추가될수록 성과에 어떤 영향을 미치는지 측정했다. 처음에는 규칙이 증가할 수록 성과가 향상됐으나 나중엔 오히려 악화됐다. 단순히 표현하자면, 규칙을 너무 많이 늘리면 팀의 초점을 흐려 성과에 부정적인 영향을 미치는 것이다. 이를 \u0026lsquo;복잡성 곡선\u0026rsquo;이라 부른다.\n p 122  사람에 의해 초래되는 복잡성이란, 직원들이 마치 일부러 그러는 것처럼 간단한 일도 복잡하게 만드는 것을 말한다. 일 처리 프로세스와 조직구조, 커뮤니케이션, 제품 등 모든 것을 간단하게 처리할 수 있는데, 쓸데없이 복잡하게 만드는 것이다. 복잡성이 저절로 생겨날 리 없다. 우리 자신에 의해 생겨난다. 이런 의미에서 단순함의 기업문화를 심고 유지하는 것이야말로 관리자의 가장 중요한 사명이라 할 수 있다.\n요즘 기업 내부에서는 엄청난 경영 정보가 생산되지만, 전혀 사용되지 않거나 불필요한 정보가 많다. 만일 관리자들이 무너가를 측정하고 보고하는 데 너무 많은 시간을 쏟는다면 경계 신호다.\n p124  GE는 웹사이트에 직원 누구나 제안을 올릴 수 있게 하고, 우수 제안자의 얼굴과 이름을 게시\n 우리도 하지만, 요식행위에 그치는 경우가 많다.\np129  단순함이란 단어 뒤에 숨은 키워드는 효율성, 상식, 그리고 자연스럽게 일하는 것이다. 자연스럽게 일한다면, 복잡한 해결책을 피할 수 있다. 지켜야 할 규칙이 적고 지시사항이 짧을수록, 지키기 쉽고 자연스러워진다 자연스럽게 일한다면, 복잡한 해결책을 피할 수 있다. 설명이 단순할수록, 이해하고 실행하기 쉬워진다. 단지 \u0026lsquo;설명이 전혀 필요하지 않을 만큼 단순한 일은 없다\u0026rsquo;는 것과 \u0026lsquo;하려는 일을 적절히 이해하지 않는 한 누구도 일을 즐길 수 없다\u0026rsquo;는 사실을 잊지 말자\u0026rdquo;\n p166  \u0026lt;생각의 시대\u0026gt;라는 책을 쓴 인문학자 김용규는 \u0026ldquo;지식의 시대는 끝났다. 이제 생각의 시대\u0026quot;라고 강조했다.\n프랜시스 베이컨이 말한 \u0026ldquo;아는 것이 힘이다\u0026quot;라는 지식의 파워는 사라졌다. 이런 시대의 경쟁력은 그 많은 지식을 수시로 빼내 활용하면서 생각하는 능력에서 나온다고 김용규는 주장한다.\n p180  \u0026ldquo;저는 제 일을 \u0026lsquo;어떻게\u0026rsquo; 하는 지 알고 있었고 \u0026lsquo;무엇을 ' 하는 지도 알고 있었습니다. 그러나 \u0026lsquo;왜\u0026rsquo; 하는지는 몰랐던 겁니다.\n p187  선병원의 이야기는 \u0026lsquo;왜\u0026rsquo; 일해야 하는 지, 중요한 것이 무엇인지 알면 \u0026lsquo;어떻게\u0026rsquo; 해야 할지의 길은 자연스럽게 찾을 수 있음을 알려주는 사례다. \u0026lsquo;왜\u0026rsquo;를 모르는 조직은 복잡하다. 무엇을, 어떻게 해야 할지 모르기 때문이다. \u0026lsquo;왜\u0026rsquo;를 아는 조직은 단순하다. 무엇을, 어떻게 해야 할지가 분명하기 때문에 괜한 일에 힘을 빼거나 시간을 낭비할 필요가 없다. 이것이 단순해지기 위해서는 \u0026lsquo;왜\u0026rsquo;를 세워야 하는 이유다.\n p194  아버지는 항상 그녀와 오빠에게 이렇게 묻곤했다. \u0026ldquo;오늘은 무엇에 실패했니?\u0026rdquo; 실패한 게 없으면 아버지는 실망했다. 그녀의 아버지는 \u0026ldquo;실패란 성공하지 못하는 것이 아니라 아무것도 시도하지 않는 것\u0026quot;이라고 말하곤 했다. 그녀는 \u0026ldquo;이제 어른이 되어 내가 실패를 두려워하지 않는다는 사실에 대해 아버지에게 정말 감사하다\u0026rdquo; 고 말했다.\n p208  \u0026ldquo;남의 말은 죽음에 이르는 독약이 될 수 있다\u0026rdquo;\n\u0026ldquo;두려움에 사로잡힌 사람은 다른 사람들의 허락만을 기다리며, 원하는 것은 가질 수 없는 사람인 체한다.\u0026rdquo;\n\u0026ldquo;나는 끊임없이 누군가와 나 자신을 비교하는 내면의 비판적인 목소리에 굴복하는 대신 그 목소리를 관찰하면서 비로소 두려움을 통제할 수 있었다\u0026rdquo;\n p210  인상깊었던 대목은 한국 특유의 비교문화가 건전한 시민의식 형성을 저해한 요인 중의 하나라고 주장한 부분이다.\n\u0026ldquo;한국의 중산층이 가장 힘들게 여기는 일은 내 집 마련과 자녀 교육이다. 인생 전체를 놓고 봤을 때도 이 두 과제에 지나치게 에너지를 낭비하고 있다. 그러다보니 정작 민주사회의 주춧돌이 되어야 할 교양의 형성, 자기성찰과 반성의 문화는 발육부진을 겪고 있다.\n p214  \u0026ldquo;만약 가지지 못한 것을 욕망한다면 가진 것을 멸시할 것이고, 삶은 충만함도 매력도 없이 흘러갈 것이다. 그리고 돌연 죽음이 나타나 머리맡에 버티고 설 것이다\u0026rdquo;\n p226  \u0026ldquo;사람들은 실패를 피하려 한다. 하지만 실패가 생명이나 건강을 대가로 요구하는 경우는 많지 않다. 기껏해야 실패의 댓가는 조롱을 견디는 것이나 이미 실패를 경험한 이들이 침묵하며 동정하는 것을 견디는 정도다. 하지만 기껏해야 이 정도인 것이야말로 실패를 싫어하는 사람들이 어떤 시도조차 하지 않는 중요한 이유다\u0026rdquo;\n p230  피터 드러커가 늘 역설했듯 기업의 가치란 그 기업이 하는 일이 아니라 그 회사의 제품을 사는 고객에 의해 정의되기 때문이다.\n\u0026ldquo;경영진의 책무 중 하나는 이러한 \u0026lsquo;외부 지향성\u0026rsquo;을 구성원들에게 끊임없이 상기시키는 것\u0026rsquo;이다.\n이것이 중요한 이유는, 기업 내부에 있는 사람들은 늘 안에만 눈이 머물러 자신이 만드는 상품과 잣니이 가진 기술에만 집중하는 경향이 있기 때문이다. 그러나 고객은 어떤 제품을 만들기 위해 기업이 얼마나 열심히 노력했는지에는 전혀 관심이 없다. 그것이 자신이 가진 문제를 해결하는데 도움이 될 수 있는지, 자신도 모르던 새로운 편의를 줄 수 있는지에만 관심을 갖는다.\n제품은 고객에게 어떤 혜택을 제공하느냐로 정의해야 합니다. 그래서 우리는 \u0026lsquo;이 제품은 지금 당신이 일하는 시간을 50퍼센트 줄여줍니다\u0026rsquo;라는 식으로 말합니다.\u0026rdquo;\n p234  혁신이란 이처럼 다른 이의 결핍과 고통을 이해하고 공감하는데서 싹튼다.\n p248  이런 일은 거의 대부분의 대기업에서 일어난다. 관료주의가 창궐하고, 꼭 내려야 하는 결정은 늪에 빠진 듯 계속 보류 상태에 있으며 일반 관리비도 엄청나게 늘어난다. 더 무서운 것은, 이런 일이 되풀이 될수록 종업원의 의욕과 사기가 저하되며 혁신이 지체된다는 점이다.\n베인앤컴퍼니에 따르면, 기업 직원들은 가용 시간의 25퍼센트를 가치가 낮거나 비효율적인 일에 허비한다.\n p253  베인앤컴퍼니는 의사결정과 관련된 이런 다양한 역할을 \u0026lsquo;RAPID\u0026rsquo;란 말로 집약해 표현한다. Recommendation, Agree, Perform, Input, Decide의 머리글자를 딴 것이다.\n\u0026ldquo;어느 공동체나 기업에서 많은 사람이 함께 일하려면 규칙이 있어야 한다. 그러나 규칙이 복잡할수록 지키기가 어렵다. 복잡한 규칙은 마비를 부른다. 과거의 유산, 책임지는 데 대한 불안과 거부감은 관료주의의 온상이 된다. 우유부단은 더 많은 통계, 더 많은 조사, 더 많은 위원회, 더 많은 관료주의를 부른다. 관료주의는 조직을 복잡하게 하고 마비시킨다\u0026rdquo;\n p256  픽사에선 그룹별로 작은 영화방에 모여 전날의 업무 진척 상황(미완성 작품)을 발표한 뒤 상사와 동료의 피드백을 받는 일일 리뷰 회의를 한다. 소파에 반쯤 누워 커피와 과자를 즐기면서 하는 회의지만, 피드백은 칼날처럼 날카롭다. 영화 하나를 만들기까지 이런 회의를 꼬박 2년 동안 한다고 한다. 처음엔 다른 사람에게 매일 자신의 작품을 보여주는 게 부끄럽다고 한다. 하지만 받아들일 수밖에 없다. 피드백을 통해 문제의 원인을 발견하고 수백 번, 수천 번 수정을 거치면 명작이 나오기 때문이다.\n p260  현명한 기업들이 집중하는 다섯 가지. 전략의 집중. 고객에 대한 집중. 제품의 집중. 조직의 집중. 프로세스의 집중.\n p270  \u0026ldquo;빨리 만들어내는 게 중요하고, \u0026lsquo;빨리 만드는 게 최고\u0026rsquo;라고 한다면 맥도널드의 방식을 다르는 게 최선이겠지요. 그러나 그렇게 따라 하면 그 분야에서 세계 최고인 맥도널드를 이길 수가 없습니다\u0026rdquo;\n p289  피터 드러커가 말했듯 \u0026ldquo;애당초 할 필요가 없는 일을 지나치게 효율적으로 처리하는 것만큼 쓸데없는 일도 없다\u0026rdquo;\n p290  업무 스킬이나 노하우를 축적하는 구조가 없었기 때문에 담당자가 없어지면 다시 처음부터 기술을 구축해야 했던 것이다. 그런 식으로는 급변하는 비즈니스 환경에 적응할 수 없었다.\n p293  조직 구성원들에게 \u0026ldquo;지키자\u0026quot;고 독촉만 해서는 좋은 결과가 나올 수 없다는 것이다. 중요한 것은 지킬 수 있는 \u0026lsquo;구조\u0026rsquo;를 만드는 일이며, 그 책임의 대부분은 조직의 상층부에 있다.\n ","id":188,"section":"posts","summary":"\u0026lsquo;\u0026lsquo;단의 공식\u0026rsquo;\u0026rsquo; 버려라 : 중요한 것을 위해 덜 중요한 것을 버리는 것. \u0026lsquo;더 많이\u0026rsquo","tags":["Book"],"title":"(책) 단","uri":"https://cychong47.github.io/2015/05/dan/","year":"2015"},{"content":"Heavy Reading 2014 December\nhttp://contextream.com/media/docs/HR-ConteXtream-Fit-VNF-WP-12-8.pdf\nThe important Factors Driving NFV deployment is Service Agility \u0026amp; Flexibility\n In a virtual environment, where applications are extracted from hardware, VNF de- signers face different challenges and opportunities. If operators are to achieve a step change in service agility, it should be possible to provision VNFs on a quasi-on- demand basis. Fit VNFs can be dedicated to a single function and then connected together using traffic steering (or \u0026ldquo;chaining\u0026rdquo;) mechanisms to create services.\n  VNFs themselves should be designed for the cloud.\nThe base meaning is to take existing applications and transform (virtualize) them. This is not the wrong thing to do; indeed, it has potential benefits. However, experience from enterprise and Web services has shown that porting legacy functions to the cloud results in less than optimal architectures that are subject to disruption from \u0026ldquo;cloud native\u0026rdquo; services.\n VNF는 기존 Physical HW에서 동작하던 SW를 VM에서 동작시키는 것이므로, 기존 SW를 단순(?)히 VM에서 동작하도록 할 수도 있다. 그러나 이미 가상화를 먼저 겪은 enterprise나 web service에서 보듯 기존 기능을 포팅하는 것은 \u0026ldquo;cloud native\u0026rdquo; 하지 않아 최적화는 한계가 있다(구체적으로 어떤\u0026hellip; 한계)\n On-demand provisioning \u0026amp; shorter lifecycle 1+N with rapid instantiation of new VNFs in event of failure rather than 1+1 with state replication Distributed across infrastruture Automated scale out Agile   Our research is very clear that operators do not view \u0026ldquo;quick and dirty\u0026rdquo; ports of appliance software to a VM environment as satisfactory. They are concerned about the performance of \u0026ldquo;Frankenstein\u0026rdquo; applications running in the cloud and about their ability to manage such functions in an automated way.\n Operator는 가능한 빨라 가상화 환경에서 앱을 동작시키는 것에 만족하는 것이 아니라 Cloud에서 자동화된 방식으로 앱을 제어하길 원한다.\n\u0026lsquo;Fit VNF\u0026rsquo;  The idea is to pare back the VNF to its core function and remove extraneous capabilities no longer needed in the cloud\n  Removing redundant software modules. - 샤시 관리는 VNF에서 Cloud management layer로 이동 Simplifying the VNF networking stack - Legacy app을 포팅한 경우 복잡한 networking stack을 가지고 있을 수 있다. 그런 복잡한 건 network fabric에게 맡기고 VNF는 좀 더 가볍게 본연의 NF 처리에 집중 Deconstruct multi-function nodes - NE는 기능에 따라 여러 개의 NF로 나눠 SFC로 묶을 수 있게 모듈화 한다. Modular Scaling - NF 단위로 scaling in/out  Combination of Smarter NFVI and Slimmer VNF  Extract connectivity and management functions from the VNF and migrate them to the cloud platform\nIn this way, operator can create a generic NFV cloud that can support services composed of the appropriate \u0026ldquo;Fit VNFs\u0026rdquo; In this way, the \u0026ldquo;Fit VNF\u0026rdquo; and \u0026ldquo;Smart Platform\u0026rdquo; become important enablers of service agility.\nRedundant functions are extracted from the application and migrated to the NFV Infrastructure (NFVI) layer, with the result that the VNF becomes \u0026ldquo;fitter\u0026rdquo; and the platform becomes \u0026ldquo;smarter\u0026rdquo;\n Ultimately, VNFs could become library, or \u0026ldquo;catalog,\u0026rdquo; items that can be deployed on the NFV cloud platform, via instruction from the NFV service orchestrator, on an on- demand basis.\nWhat is migrated from VNF to NFVI  Dynamic Virtual Connectivity Scalability to run on multiple cores/servers Load balancing and health checks Internal SFC to connect sub-function instances Elasticity to change scale to needs Distribution to multiple data centers while maintaining state Analytics collection Service awareness Subscriber awareness High availability and redundancy  Open Platform NFV  Vendor-specific platform -\u0026gt; OPNFV for independency of VNFs  Carrier Grade Open Source NFVI reference platform Improve consistency and interoperability between NFV components NFVI, VIM and API to other NFV elements such as management and orchestration(MANO)    Interoperable NFVI  VNFI should be open platform to support VNFs from different vendors The more platform capability is available, VNFs can be simplified accordingly Where the NFVI is more capable (\u0026ldquo;intelligent\u0026rdquo;), and VNFs simpler, operators can more quickly deploy functions and provision services. By over-specifying the platform upfront, operators will lose the agility they desire and place undeliverable requirements on suppliers\n그렇다고 NFVI에 처음부터 과도한 smartness를 요구하면 operator가 원하는 agility를 얻지 못할 수 있다. 그러므로 점진적으로 NFVI의 기능을 추가해야 한다.   This will likely result in a situation where less demanding functions will be the first to surrender their autonomy to the platform.\n Mobile Core에서 간단한 기능들(Load balancer, video optimizer, HTTP proxies)는 Gi-LAN에서 지원하는 기능을 사용하는 것이 이 기능들을 포함하도록 EPC를 고치는 것보다 낫다.(?)\nProgrammable Networking requirements  Programmable, dynamic connectivity between VNFs is, therefore, valuable. If an NFV service orchestrator can push rules to a platform that can quickly provision the VNFs need to support a service, and the associated service function paths, operators will move a big step closer to the agility they desire from NFV. This capability is a large component of what makes an NFV platform \u0026ldquo;smart\u0026rdquo; and is why SDN and network virtualization are important. DC의 경우보다 telecom의 경우 다른 점은 distributed VNFs and need to manage \u0026ldquo;subscriber aware\u0026rdquo; traffic flows at scale. In telecom networks, where there is likely to be distributed VNFs (placed according to performance requirements), the argument for a specialist SDN solution for NFV is stronger because the need to man- age application and subscriber state across locations.  In summary  Legacy app을 cloud 상황을 고려하지 않고 단순히 가상화 환경으로 porting하는 것은 Operator가 원하는 on-demand provisioning에 맞지 않고 성능 측면에서 최적화된 형태가 아니다 NFV 환경은 open platform이어야 operator가 원하는 agility를 얻을 수 있다. 다양한 업체의 VNF와 VNFI를 활용 VNF는 PNF와 달리 networking stack이나 HW 관리 등의 기능을 제거해서 NF 에 집중해야 한다. 이런 기능들을 cloud management platform 으로 옮겨 VNF를 가볍게 해야 한다. \u0026ldquo;Fit VNF\u0026rdquo; On-demand Provisioning가 SDN을 결합해야 operator가 원하는 service agility를 얻을 수 있다.  ","id":189,"section":"posts","summary":"Heavy Reading 2014 December http://contextream.com/media/docs/HR-ConteXtream-Fit-VNF-WP-12-8.pdf The important Factors Driving NFV deployment is Service Agility \u0026amp; Flexibility In a virtual environment, where applications are extracted from hardware, VNF de- signers face different challenges and opportunities. If operators are to achieve a step change in service agility, it should be possible to provision VNFs on a quasi-on- demand basis. Fit VNFs can be dedicated to a single function and then connected together","tags":["Service Agility","nfv"],"title":"Designing for Service Agility","uri":"https://cychong47.github.io/2015/01/wp-designing-for-service-agility/","year":"2015"},{"content":"Small Cell  Big Cell 256 user 이하를 small cell로 정의 mini-CRAN Paris Hill SOC을 이용하는 경우 RRH에서 LTE/3G DSP+DFE 까지 처리하고 Ethernet으로 IA core로 전달. Altiostar 구조와 유사한 듯  Wifi 와 3G/4G까지 지원하는 차세대 SOC 2/4/8 core까지 지원   Aricent와 협업하여 L1/L2/L3 Protocol stack 개발  ONP  Red Rock Canyon  Las Vegas에서 30분 가량 걸리는 거리   Switch와 NIC 통합 PCI-e를 지원해서 NIC없이 Xeon을 직접 연결할 수 있음. 150page 가량의 report ONP 1.1 버전. 1.2 버전은 각 OSS 버전을 업데이트할 계획  OpenStack Juno OpenDayLight Helium DPDK v1.8 Haswell 2600 v3 Ethernet Controller Fortvillle XL710   NTT lagopus SDN Controller  OpenFlow 1.3 http://lagopus.github.io 2 RX, 4 Processing, 2 Tx cores   Juniper Virtual NX - DPDK based router  vMX can run in the most popular hypervisors, including: KVM, VMware, and Xen. The vMX can even run in Docker containers and on bare metal. Buyers will be able to buy either license in increments based on capacity, for example in 100M, 1G, or 10G sizes, or any combination thereof. http://www.juniper.net/us/en/products-services/routing/mx-series/vmx/    WindRiver  CIE(Contents Inspection Engine)  Intel Hyperscan 사용 http://www.intel.com/content/dam/www/public/us/en/documents/presentation/wind-river-intelligent-network-platform-presentation.pdf   Titanium Server  OPNFV 와 유사하게 OSS들의 조합으로 구성 Carrier Grade 요구에 맞게 hardening  Carrier Grade Linux Carrier grade high-performance Kernel-based Virtual Machine (KVM) virtualization Carrier grade accelerated vSwitch - 20Gbps on 2 cores Carrier grade OpenStack Carrier grade middleware Lifecycle development tools   http://www.windriver.com/products/titanium-server/ 1초내 VM 복구 등 Live migration in 200ms    Communication Infrastructure Platform  Broadwell-DE  10G 2개 포함    Intel Software Platform Solution  Intel System Studio 3Ghz CPU에서 10Gbps를 지원하려면 201cycle. Spin lock에 60-90 cycle, task switch에 300 cycle Haswell은 20 core/CPU 지원. HT 켜고 QPI 연결하면 80개 logical core OVS 2.4에서 공식적으로 DPDK 지원 포함 Linux UIO is replaced by VFIO  DPDK 1.7.0부터 VFIO 지원 Safe device assignment with VFIO VFIO PCI device assignment breaks free of KVM Documentation / vfio.txt VFIO : A User\u0026rsquo;s perspective    ","id":190,"section":"posts","summary":"Small Cell Big Cell 256 user 이하를 small cell로 정의 mini-CRAN Paris Hill SOC을 이용하는 경우 RRH에서 LTE/3G DSP+DFE 까지 처리하고 Ethernet으로 IA core로 전달. Altiostar 구조와 유사한 듯","tags":["DPDK","SDN","Intel","ONP","vSwitch","vRouter","nfv"],"title":"Intel Embedded Tech Forum 2014","uri":"https://cychong47.github.io/2014/12/intel-embedded-tech-forum-2014/","year":"2014"},{"content":"며칠 밖에 보지 않았지만, 그래도 내용을 분석해 보려고 했던 OVDK인데, 오늘 기사를 보니 Intel에서 공식적으로 OVDK의 개발 중단을 발표했단다.\nIntel Dead-Ends Its Fork of Open vSwitch\nData path(Fast path)를 커널 모듈에서 처리하는 OVS를 fork해서 DPDK를 이용해서 user space에 Fast Path를 만들려고 했는데 그러다 보니 역시 계속해서 발전하는 OVS의 기능을 수용하기 부담스러웠나 보다. 더군다나 OVS에서도 experimental feature이긴 하지만 DPDK를 이용하는 코드도 있다고 하니.\n내년 초에 나올 다음 버전 OVS에 공식 기능으로 들어가길 기대한다고.\n Intel’s new, mainstream-OVS code goes under the name DPDK-netdev and has been on Github since March. It’s available as an “experimental feature” in OVS version 2.3, according to an Intel message on the dpdk-ovs mailing list. Intel hopes to include the code officially in OVS 2.4, which OVS’ committers are hoping to release early next year.\n 그나저나 OVDK를 사용하던 Ericsson과 NEC는 고민이 좀 되겠다.\n He cites Ericsson and NEC as two companies that were following the OVDK path. Ericsson acknowledged being aware of the situation but declined to comment; NEC experts did not respond to a request for comment.\n 6Wind는 별도로 자체 개발한 듯 하고\n 6WIND has been showing its Open vSwitch acceleration since ONS 2013. 6WIND wasn’t involved in Intel’s new OVS work, Eraltan says, although the companies have worked together on DPDK in general.\n ","id":191,"section":"posts","summary":"며칠 밖에 보지 않았지만, 그래도 내용을 분석해 보려고 했던 OVDK인데, 오늘 기사를 보니 Intel에서 공식적으로 OVDK의 개발 중단을 발표했단다. Intel Dead-Ends Its","tags":["DPDK","OVS","Intel","OVDK","nfv"],"title":"R.I.P OVDK","uri":"https://cychong47.github.io/2014/11/r-i-p-ovdk/","year":"2014"},{"content":" Cavium Demonstrates Multiple OpenDataPlane Applications at Linaro Connect USA 2014 Cavium ThunderX 48 Core 2.5Ghz ARM Server SoC   Cavium ThunderX 48 Core 2.5Ghz ARM Server SoC Cavium ThunderX is the world\u0026rsquo;s fastest ARM Processor, featuring 48 ARMv8 64bit cores at 2.5Ghz each, with two SoC\u0026rsquo;s possible per motherboard, this means 240Ghz of compuete power per Server Board. Providing extremely high performance at much lower power, much lower cost, much more optimized than any x86 server system. Cavium is shipping samples of their Server product by the end of this year with mass production scheduled for next year. http://armdevices.net/2014/06/06/cavium-thunderx-48-core-2-5ghz-arm-server-soc/\n   Linaro: ODL controlling: ODP-Open vSwitch\n  Download ODP docs from http://opendataplane.org\nwget http://www.opendataplane.org/wp-content/uploads/2014/01/ODPIntroductionandOverview-2014Jan29.pdf wget http://www.opendataplane.org/wp-content/uploads/2013/12/ODPLaunchOverview1.pdf git clone https://git.linaro.org/lng/odp-architecture.git git clone https://git.linaro.org/lng/odp.git git clone https://git.linaro.org/lng/odp-apps.git git clone https://git.linaro.org/lng/odp-keystone2.git git clone https://git.linaro.org/lng/odp-netmap.git git clone http://git.linaro.org/lng/odp-dpdk.git\n  ","id":192,"section":"posts","summary":"Cavium Demonstrates Multiple OpenDataPlane Applications at Linaro Connect USA 2014 Cavium ThunderX 48 Core 2.5Ghz ARM Server SoC   Cavium ThunderX 48 Core 2.5Ghz ARM Server SoC Cavium ThunderX is the world\u0026rsquo;s fastest ARM Processor, featuring 48 ARMv8 64bit cores at 2.5Ghz each, with two SoC\u0026rsquo;s possible per motherboard, this means 240Ghz of compuete power per Server Board. Providing extremely high performance at much lower power, much lower cost, much more optimized than any x86 server system.","tags":["odp"],"title":"ODP","uri":"https://cychong47.github.io/2014/11/odp/","year":"2014"},{"content":" Application Performance Tuning and Future Optimizations in DPDK by Venky Venkatesan DPDK in a Virtual World by Bhavesh Davda Rashmin Patel High Performance Networking Leveraging the DPDK and the Growing Community by Thomas Monj alon Multi Socket Ferrari for NFV by Laszlo Vadkerti Andras Kovacs Lightning Fast IO with PacketDirect by Gabriel Silva A High Performance vSwitch of the User by the User for the User by Yoshihiro Nakajima Is It Time to Revisit the IP Stack in the Linux Kernel and KVM by Jun Xu Closing Remarks by Tim ODriscoll  ","id":193,"section":"posts","summary":" Application Performance Tuning and Future Optimizations in DPDK by Venky Venkatesan DPDK in a Virtual World by Bhavesh Davda Rashmin Patel High Performance Networking Leveraging the DPDK and the Growing Community by Thomas Monj alon Multi Socket Ferrari for NFV by Laszlo Vadkerti Andras Kovacs Lightning Fast IO with PacketDirect by Gabriel Silva A High Performance vSwitch of the User by the User for the User by Yoshihiro Nakajima Is It Time to Revisit the IP Stack in the Linux Kernel and KVM by Jun Xu Closing Remarks by Tim ODriscoll  ","tags":["DPDK"],"title":"DPDK Summit 2014 Videos","uri":"https://cychong47.github.io/2014/11/dpdk-summit-2014-videos/","year":"2014"},{"content":"정말 하나같이 핵심적인 내용인데 정작 이걸 알아야 하는 사람은 이런 데 관심이 없겠지.\n출처 : 부실한 공유문화를 지배하는 개발자의 심리\n 전반적으로 공유문화가 부실하게 된 것은 현재 개발자들의 책임은 아니다. 원래 문화라는게 우리의 선조, 선배들이 만들어 놓은 것을 따르면서 아주 약간씩 바뀌는 것이다. 개발문화도 그렇다. 지금까지 선배들이 그런 환경에서 그렇게 일해 왔기 때문에 그런 문화가 형성되었고 우리도 거기에 적응해서 일하고 있는 것이다.\n 문화가 바뀌기 어려운 이유는 나 혼자 노력해서는 안되기 때문이다. 다른 사람들은 공유를 위해서 노력하지 않고 나 혼자 애를 쓰면 나만 두배로 손해를 본다. 이는 ‘죄수 딜레마’와 비슷하다.\n \u0026hellip;\n둘째, 과도한 프로세스는 오히려 독약이다.\n 대기업에서 많이 벌어지는 일인데, 현재 역량이나 문화수준을 훨씬 뛰어넘는 과도한 시스템과 프로세스를 도입해서 강요하곤 한다. 이런 경우 겉으로는 규칙을 지키고 비싼 시스템을 착실히 쓰는 것 같지만 속을 보면 형식적으로 따르고 흉내만 내서 효율은 오히려 더 떨어진다. 이런 일이 벌어지는 이유는 스스로의 역량이나 문화 수준을 과대평가 하기 때문이기도 하다.\n  제대로 된 CTO의 부재도 한몫 한다. 실전 경험이 부족한 SW 프로세스팀은 밑져야 본전 식으로 프로세스를 복잡하게 만들고 많은 문서를 요구하곤 한다. SW 프로세스팀도 이렇게 밖에 할 수 없는 많은 고충이 있다. 많은 문서 중에서 프로젝트에 실질적으로 필요한 문서는 한두개에 불과한 경우가 대부분이지만 회사에서는 나머지를 쉽게 포기하지 못한다. 이러다 보니 개발자들은 문서 따로 개발 따로 진행을 하고 문서는 개발에 별 도움도 안되고 공유의 목적으로도 의미가 없게 된다. 이런 식으로 문제가 발생하면 프로세스를 더 복잡하게 만드는 악순환이 진행된다.\n 셋째, 개발자 보고 알아서 잘 해보라고 하면 안된다.\n 풀뿌리식으로 개선이 될 수 있는 사안이 아니다. 시스템과 프로세스도 필요하고 경영진의 의지와 후원이 절대적이다. 가장 중요한 것은 공유문화를 이끌 리더가 필요하다는 것이다. CTO급의 인물이 있어서 흐지부지 되기 쉬운 공유 문화 개혁에 꾸준한 추진력을 실어줄 수 있어야 한다. 역량 수준에 따라서 여러가지 시스템도 필요하다.\n 넷째, 나중에 몰아서 공유하면 실패한다.\n 일기를 몰아서 쓰듯이 공유도 몰아서 하면 실패한다. 공유를 위해서 문서를 만들고 시스템에 기록을 하는 것이 목적이 되면 안된다. 이것들은 소프트웨어를 개발하는 과정이고 이렇게 개발을 해야 가장 빨리 효율적으로 개발할 수 있기 때문에 문서를 만들고 공유를 하는 것이다.\n  공유를 위해서 숙제를 하듯이 정리를 해서 시스템에 지식을 올리고 공유하는 것보다 매 순간 필요한 것들을 즉시 등록하는 것이 좋다. 공유할 것, 물어 볼 것, 의논해야 할 것들을 일단 적당한 시스템에 올려 놓고 진행을 하는 것이다. 그러면 자연스럽게 과정이 공유가 된다. 즉, 공유는 개발의 과정이고 일부이지 산출물, 부산물들이 아니다.\n  공유를 위해서 산출물을 만들어야 한다고 생각하는 순간 공유는 실패하고 산출물도 제대로 만들어 질리가 만무하다. 이렇게 만들어진 문서는 나중에 유지보수 시에도 활용도가 뚝 떨어진다. 공유목적으로도 실패한 것이다. 개발과정이 자연스러운 공유의 과정이 되도록 해야 한다.\n 다섯째, 모든 사람이 다 너무 바쁘면 안된다.\n 모든 개발자가 호떡집에 불난 것 같이 바쁜 회사가 많다. 가끔은 신입 개발자는 한가하고 고참들이 더 바쁜 경우도 있다. 이런 회사는 대부분 공유에 실패한다. 불 끄느라고 정신이 없어서 나머지는 눈에 들어오지도 않는다. 시니어 엔지니어가 될수록 시야도 넓어지고 생각도 많이 하고 여기저기 관여도 많이 해야 하기 때문에 정신없이 바쁘면 안된다.\n 여섯째, 보안보다 공유가 우선이다.\n 소프트웨어는 설계도면이 핵심이 아니다. 구성원들의 지식 공동체가 핵심이며 문서, 시스템, 경험, 지식의 복합체가 소프트웨어 회사 기술의 실체이다. 대부분의 SW회사는 HW분야에서 설계도면 빼돌리 듯 기술을 빼돌릴 수가 없다. 우리나라에서는 빈약한 공유문화 속에서 소수의 개발자가 거의 모든 정보를 독점하기 때문에 종종 기술을 빼돌리는 일이 벌어진다. 이런 상황에서는 보안을 아무리 강조해도 기술이 새나가는 것을 막을 수는 없다.\n 드물게 보안이 더 중요한 SW회사도 있기는 하지만 극소수에 불과하다. 보안에 대한 과도한 우려 때문에 공유를 너무 불편하게 하는 회사가 의외로 많다. 보안이 별 이슈도 아닌 회사도 공유에 거부감이 있는 직원의 주장에 넘어가서 공유를 포기한 회사도 많다. 훌륭한 오픈소스가 판치는 마당에 소프트웨어 회사에서는 숨길 것이 그렇게 많지 않다. 특수한 분야의 몇몇 회사를 제외하고는 모든 직원에게 모든 정보를 오픈해도 별 문제가 안된다. 보안을 과도하게 강조하여 공유에 제약을 가하기 시작하면 공유는 반쪽짜리가 되어서 효율은 엄청나게 떨어지게 된다.\n ","id":194,"section":"posts","summary":"정말 하나같이 핵심적인 내용인데 정작 이걸 알아야 하는 사람은 이런 데 관심이 없겠지. 출처 : 부실한 공유문화를 지배하는 개발자의 심리 전반적으로 공유문화가 부실하","tags":["SW 개발 문화"],"title":"(펌) 부실한 공유문화를 지배하는 개발자의 심리","uri":"https://cychong47.github.io/2014/11/peom-busilhan-gongyumunhwareul-jibaehaneun-gaebaljayi-simri/","year":"2014"},{"content":"Cuckoo 알고리즘을 사용하여 Flow lookup과 flow update 성능을 높힌 것과 DPDK를 이용하여 패킷 처리 성능을 높힌 것\n출처 : Scalable, High Performance Ethernet Forwarding with CuckooSwitch\nDPDK  DPDK를 이용한 IO 성능 개선한 것 외에 특이한 것은 없음.  Cuckoo hashing   대개 FIB update를 위해 RCU(Read Copy Update)를 사용함. 이 경우 완전한 정보를 갖는 additional entry가 필요\n 수정된 cuckoo algorithm을 기반으로 한 flow table 사용    Basic Cuckoo hashing\n ensures 50% table space utilization    4-way associative hash table has 95% utilization\n \u0026lsquo;A cool and practical alternative to traditional hash tables\u0026rsquo; Only two cache-sized parallel memory accesses are required for lookup What means \u0026lsquo;4-way\u0026rsquo;? Each hash bucket has 4 entries??? - FIXME Check the paper    메모리 사용량 감소 및 multiple reader와 single writer가 동시에 접근할 수 있게 하여 lock 사용없이 FIB update 성능 개선\n Compact and concurrent memcache with dumber caching and smarter hashing \u0026lsquo;Optimitic concurrent cuckoo hashing\u0026rsquo; More optimization for \u0026hellip;. FIXME    Compiler reorerding barriers\n \u0026lsquo;a sequence of memory writes at one core are guaranteed to appear in the same order at all remote CPUs\u0026rsquo; If one cores write W1,W2 and W3 and the R1 from some core observes the effect of W3, then the R2 and R3 which is issued after R1 also observed the same effect Check the words \u0026ldquo;compiler reordering barriers\u0026rdquo; ensure the compiler does not reorder the store and read instructions using a compiler reordering barrier between the read operations which should keep the instruction order __asm__ __volatile__(\u0026quot;\u0026quot; ::: \u0026quot;memory\u0026quot;) in gcc mark volatile for the fields to access    Batch Hash table lookup\n If the size of the hash table cannot fit the fast CPU cache size, then performance drops dramatically. For this, batching 16 packets for one lookup Combine all the packets in the buffers as a single batch and perform hash table lookup at the same time FIXME - How to batch lookups    Prefetch\n FIXME    Performance  10^9 entries 350M lookups/second 0.5M updates/second  etc.  RouteBricks(2009) - 35Gbps https://github.com/efficient/libcuckoo  http://efficient.github.io/libcuckoo/   https://github.com/efficient/libcuckoo-c  ","id":195,"section":"posts","summary":"Cuckoo 알고리즘을 사용하여 Flow lookup과 flow update 성능을 높힌 것과 DPDK를 이용하여 패킷 처리 성능을 높힌 것 출처 : Scalable, High Performance Ethernet Forwarding with CuckooSwitch DPDK DPDK를 이용한 IO 성능 개선","tags":["논문","Algorithm"],"title":"Cuckoo Switch","uri":"https://cychong47.github.io/2014/11/cuckoo-switch/","year":"2014"},{"content":"원제 : The year without pants\np42  방송에서 IDEO가 \u0026ldquo;Deep Dive\u0026quot;라는 아이디어 개발 기법을 써서 닷새 만에 쇼핑카트를 개선하는 과정을 보여주었다. 곧이어 수 많은 기업이 Deep Dive 기법을 어설프게 따라 했지만, 놀랍게도 결과는 그들의 기대에 못 미쳤다. IDEO의 회의 단계와 규칙을 그대로 따라 하고 아무리 노력한들 한 가지가 빠진 상태에서는 방송에서 본 것과 같은 결과가 나올 리 없었다. 문제의 누락된 요소이자 가장 중요한 요소는 바로 거기에 참여한 사람들이었다 나이트라인을 시청한 다른 기업들의 경우 IDEO처럼 디자인에 재능이 뛰어난 직원들이 근무하는 환경이 아니었다. 화면에서는 드러나지 않았지만, 이런 재능보다도 더 중요한 것은 IDEO 직원들이 공유하는 가치관과 태도였다. 이렇게 겉모양만 흉내 내는 것을 인류학 용어로는 \u0026lsquo;화물 숭배 Cargo cult\u0026rsquo;라고 하는데 원주민들이 유용한 화물을 실어다 주던 비행기가 다시 오기를 기원하면서 활주로를 꾸며놓고 의식을 거행하는 것을 가리킨다.\n p43  아무리 기법이 훌륭해도 어리석은 직원을 현명한 직원으로 바꿔주지는 않는다. 또 불신이 형성될 수 밖에 없는 환경이라면 그 어떤 기법을 가져다 쓴다 해도 동료 간에 신뢰가 형성되는 마법을 부리지는 못한다.\n\u0026hellip; 가장 좋은 전략, 어쩌면 유일한 전략은 성공기업의 문화를 있는 그대도 살피는 것이다. 하지만 문화를 이해하는 일은 회의 기법이나 창의적 기법을 이해하기보다 훨씬 어렵다. 후자의 경우는 모두 논리에 기초하지만, 문화는 정서에 기초하기 때문에 문화를 다루는 것은 사뭇 두려운 일이기도 하다. 문화를 평가할 수 있는 역량을 지닌 사람도 드물지만, 용기를 내어 조직문화를 바꾸려는 시도를 한다 해도 그 변화가 미미한 수준에 그치는 경우가 태반이다\n p46  뮬렌웨그는 대규모 프로젝트를 수행할 역량이 자신에게 있을지도 모른다고 생각했고, 이를 확인하려면 한번 도전해 보는 수밖에 없다고 판단했다.\n p48  같은 곳에서 십 년이나 머물게 되면 영영 그곳을 떠나지 못할 거라는 두렴움이 들었다.\n한 기업에서 십 년 이상 일하면 인생의 재미를 발견하는 데 전혀 도움이 안 될 거라는 확신이 있었다.\n p56  어느 기업이나 마찬가지겠지만, 특히 혁신을 표방하는 기업이라면 제품을 창작하는 이들이야말로 핵심 인재다. 이 외에 다른 역할을 맡은 이들을 제품 개발자들을 돕기 위해 존재한다고 봐도 무방하다. 이 같은 개념을 위반하는 대표적인 사례로는 정보통신 부서에서 자기네 업무의 효율성을 높이려고 제품 개발자들이 사용할 수 있는 장비에 대해 제한을 두는 행위 등이 있다. 만약 경영관리 및 지원부서와 제작부서 중에 효율성을 부서를 선택하야 한다면 그 대상은 지원업무를 담당하는 부서여야 한다. 경영진을 비롯해 지원업무를 담당하는 이들이 업무의 흐름을 좌지우지하면 제품의 품질만 떨어뜨릴 뿐이다.\n p58  오토매틱 고용 계약서\n 나는 배움을 중단하지 않을 것이다. 나는 내 앞으로 할당된 업무만 하는 사람이 되지 않을 것이다. 결코 현상유지에 만족하지 않을 것이다. 나는 열정적이고 충직한 고객들을 통해 지속 가능한 방식으로 우리 사업을 구축할 것이다. 동료를 도울 수 있는 기회를 절대 지나치지 않을 것이며, 개구리 올챙이 적 생각을 못하는 우를 범하지 않을 것이다. 나를 움직이는 것은 돈이 아니라 사람들에게 끼치는 영향력이다.\n  p62  회의에 대한 내 지론은 간단하다. 논의중인 내용이 중요하면 사람들은 집중한다는 것이다.\n p86  수 많은 기업에서 단합대회를 기획하면서 승부수를 띄우는 지점은 \u0026lsquo;장소\u0026rsquo;다. 숲 속의 리조트나 특별한 도시로 여행을 가면 쳇바퀴 같은 일상에서 벗어나 직원들이 몸과 마음을 쇄신하고 새로운 방식으로 사고하게 될 거라고 기대한다. 하지만 그들은 장소가 바뀌어도 변하지 않는 제일 중요한 한 가지를 망각했다. 바로 기업문화다. 어디를 가든 일하는 방식을 은연중에 규정하는 가치관이나 태도 역시 함께 따라다니기 때문이다. 경영진들이 이런 행사를 주도할수록 혁신에서는 멀어지고 현상유지는 강화될 뿐 이다.\n p101  중요한 것은 우리가 시장에 내놓은 제품의 품질이었다. 벨피오레는 또한 우리가 출시한 제품이 호평을 받는다면 그것은 순전히 개발자들 덕분이라고 말했다. 개발자들이 제일 중요했다. 개발자들은 단순히 생산부 직원이 아니라 장인들이다. 소프트웨어를 만드는 회사 내에서도 심장부에 해당하는 창의력 엔진이다.\n p106  시사이드 워크숍 마지막 날, 모든 팀은 전 직원이 보는 앞에서 결과물을 선보였다. 팀원들과 함께 모두가 보는 앞에서 우리가 만든 결과물을 보여주는 기분은 짜릿했다. 내 기억에 가장 선명하게 남는 것은 오오~ 와~ 하고 내지르던 사람들의 감탄사였다. 오랫동안 일했던 전 직장에서 팀원들과 소프트웨어를 만드는 동안에는 들어보지 못했던 감탄사였다.\n p110  우리는 오늘날의 기업들에게 미래지향적인 관점에서 의문을 제기해야 한다. 직원들에게 쓸데없이 짐만 되고 있는 불필요한 문화가 직장 내에 얼마나 많은가? 우리는 합리적으로 설명하지 못할 수많은 관행을 충실히 따르고 있다. \u0026hellip; 우리가 이러한 관행을 따르는 이유는 직장에 들어온 순간부터 그렇게 하도록 강요받았기 때문이고, 시간이 흐르면서 너무 익숙해진 탓에 이 관행들이 만들어진 전통이라는 사실조차 잊은 것이다.\n오토매틱의 기업문화를 결정짓는 핵심 요소는 전통보다 성과를 우선시한다는 것이다. .. 근로자의 실적을 평가하는 일차적인 잣대가 노동의 품질인 것은 너무나 당연하지 않은가? 그렇다면 방해가 되는 전통을 제거하고 도움이 되는 방법을 새로운 전통으로 마스는 것이 좋지 않는가?\n p101  불필요한 전통을 제거하는 관리자는 진보한다. 제약을 걷어내 업무성과가 향상되어도 좋은 일이고, 업무성과에 변화가 없더라도 사기가 진작된다면 모두에게 좋은 일이다.\n아무것도 바뀌지 않는 조직이라면 박물관이지 살아 숨 쉬는 일터라고 볼 수 없다.\n  뮬렌웨그는 이를 통해 새로운 것을 배우는 가장 좋은 방법은 자신의 신념을 실행에 옮기는 것이라는 믿음을 가지게 되었다.\n그는 몇 주씩 같은 문제를 논의하고 정교한 전략을 수립하는 데 골몰할 이유가 없다고 생각했다. 뮬렌웨그는 실험하고 데이터를 수집하고, 그리고 이 과정을 반복하는 편이 더 좋았다.\n p102  새로운 것을 가장 빨리 배우는 길은 듬직한 사원에게 중요한 역할을 맡겨 그들 스스로 실험을 진행하도록 하는 것이었다.\n p116  Tracy Kidder \u0026lsquo;\u0026lsquo;새로운 기계의 영혼(The soul of a new machine)\u0026rsquo;\n p129  내가 스카이프로 누군가에게 \u0026ldquo;어떻게 지내요?\u0026ldquo;라고 물었을 때 상대가 \u0026ldquo;좋아요\u0026quot;라고 대답하면 나는 다시 \u0026ldquo;아니 정말로 어떻게 지내요?\u0026rdquo; 라고 묻곤 한다. 이 경우 더 많은 정보를 얻었다 해도 그것은 내가 억지로 얻어낸 답변이었고, 그들 가까이에서 내가 자연스럽게 관찰하면서 얻은 정보와는 달랐다. 오토매틱인들은 먼저 자기 자신을 잘 알고 온라인에서 적극적으로 자신을 표출할 필요가 있었다.\n  모든 사람은 일대일로 만나면 사람이 달라진다. 개인적으로 만나면 그들은 대화에 온전히 집중한다. 회의에서 모든 결정이 이루어진다고 생각한다면 참으로 순진한 바보다. 회의실에 있는 모든 직원을 단 한 차례 연설로 설득할 수 있는 사람은 거의 없다. 그런 일은 영화에서나 가능하다. 두 사람 이상이 내 말을 듣고 있다면 반드시 하지 못하는 말이 있고 들리지 않는 말이 있다.\n p136  프로그램을 직접 짜지 못하면서 어떻게 개발자들을 관리할 수 있느냐는 것이다. 나는 두 가지가 해결된다면 어떤 것을 만들든 사람들을 관리할 수 있다고 믿는다. 그 두 가지는 명확성과 신뢰다. 목표와 평가 기준을 서로가 명확하게 한다면, 목표에 도달하기 위해 수행하는 업무에 관해 동일한 언어를 구사할 수 있다. 내가 잘 모르는 기술적 사안이 문제가 될 때 나를 항상 구해 준 질문은 \u0026ldquo;그 문제가 사용자 경험에 어떤 영향을 미치나요?\u0026rdquo; \u0026hellip; 하지만 사용자 관점에서 사고하는 것은 자신이 잘 모르는 기술적 문제가 실제로 미칠 영향력을 이해할 수 있는 멋진 방법이다.\n사용자 경험에 관한 질문을 던지는 것은 개발 업무의 우선순위를 정하는 가장 중요한 방법이다.\n p141  사람들의 민낯을 보고 싶다면 불을 질러보아야 한다. 만사가 잘 돌아가고 있을 때 우리는 사람들의 제일 좋은 면만 보게 딘다. 뭔가 불에 타야만 사람들의 진면모를 볼 수 있다.\n p144  오토매틱은 \u0026lsquo;\u0026lsquo;깨진창 이론\u0026rsquo;을 믿었다. 정기적으로 사소한 문제들을 고쳐나가면 더 큰 문제들을 에방할 수 있다는 의미이다.\n p151  선도적인 소프트웨어 기업인 IBM이 1970년대에 근로자들의 생산성을 평가하면서 이런 방법을 썼다는 우스개소리가 있다. 개발자들이 얼마나 많은 코드를 작성했는지 코드 줄 수를 추적하기로 했다. \u0026hellip; 하지만 프로그래밍은 양적으로 측정할 수 있다는 전제는 틀렸다. 뛰어난 개발자일수록 프로그램을 완성하는데 필요한 코드는 더 늘어나는 것이 아니라 더 줄어든다. 프로그래밍의 속성에 무지한 사람만이 생각할 수 있었던 시대착오적인 평가 방법이었다.\n 하지만 지금도 이 이론을 신봉하는 좀비들이 넘쳐난다. 당장 주위를 둘러보자.\n 현대의 수많은 관리자들이 신봉하는 말이 있다. \u0026ldquo;평가한 대로 거둔다\u0026rdquo; 구굴을 비롯한 여러 기업에서는 모든 의사결정과 목표, 활동에 영향을 주는 요소를 측정하는 지표를 만들어야 한다고 주장한다. 현대의 기업들은 이 같은 평가지표를 널리 추종하지만, 나아갈 바를 알아내려고 마련한 바로 그 평가지표 때문에 길을 잃기도 쉬다.\n관리자들이 모든 사람이 볼 수 있도록 점수판을 걸어놓으면 그때부터 예기치 않은 일이 벌어진다. 근로자들은 자기도 모르게 매시간 그 점수판을 확인하고, 그 점수를 높이는 방향으로 일을 진행하고, 점수판에 드러나지 않는 다른 요소를 희생하는 일도 감수한다.\n\u0026hellip;\n평가지표상 좋은 점수를 받으려고 정도를 벗어나게 되면 제품이나 서비스 품질에 오히려 부정적 영향을 미칠 것이고, 이는 소비자들이 본능적으로 알아차리기 마련이다. 핵심성과지표를 도입하고 숫자 중심으로 사고하는 경영진들은 일이 잘못되면 으레 더 정교한 성과지표, 더 많은 성과지표를 만들어야 문제를 해결할 수 있다고 믿는다. 그런 식으로 성과지표가 하나둘 늘어난다. 처음에는 반짝하고 효괄ㄹ 낼지 모르지만, 머지않아 똑같은 일이 반복되고 문제는 증폭된다. 모든 평가지표는 우리를 유횩한다. 명석한 사람들이 아무리 좋은 의도로 만든 평가지표라도 거기에 시선을 고정하면 어리석은 결정을 하게 되고, 점점 더 빨리 자멸의 길로 달려간다. 데이터가 사람을 대신해 결정을 내려주지는 않는다. 데이터는 적절하게 사용하면 문제를 더 명확하게 인식하는 데 도움이 되지만, 데이터가 곧 의사결정 전부는 아니다. 조언의 역실이 존재하는 것처럼 \u0026lsquo;데이터의 역설\u0026rsquo;도 존재한다. 아무리 많은 데이터를 갖고 있어도 그 데이터를 어떻게 해석하고 적용할 것인지를 결정하려면 결국 우리 직관에 의지해야 한다는 것이다.\n다시 말해, 핵심성과지표(KPI)를 평가하기 위한 좋은 핵심성과지표는 존재하지 않는다.\n p160  혹시 생길지 모를 나쁜 일들을 예방할 목적으로 공정관리를 하는 것을 나는 방어적인 관리라고 부른다. 방어적으로 프로젝트를 관리하는 경우에는 나쁜 일들을 예방하는 데 집착한 나머지 좋은 일들이 일어나는 것까지 막게 된다. 더러는 아무 일도 일어나지 못하게 막는다는 사실을 인식하지 못한다.\n p161  대개의 프로젝트는 확정된 종합 계획에 따라 움직이지만, 오토매틱에서는 이 같은 일정이 없었기 때문에 직원들은 기간 내에 일을 끝내지 못할까 봐 전전긍긍하는 마음 없이 작게나마 늘 서비스를 개선하고 있다는 성취감을 맛봤다.\n p177  건축가들은 설계를 마치고 나면 사라져서 다시 현장에서 보기 힘들다는 비난을 자주 받곤 한다. 자신들의 선택이 ㅇ적절했는지 아닌지 건물이 개장한 후에 확인해야 하는데, 그 같은 관리를 하지 않는 경우가 많기 때문이다. 여직원을 표 파는 로봇처럼 취급하지 말고 사소한 사안이라도 변화를 줄 수 있는 재량권을 주었다면 어땠을까? 만약 그랬다면 날마다 지겹도록 듣는 질문을 분석해 표지판이나 안내책자를 개선하고, 자신의 도움 없이도 더 많은 사람이 편하게 길을 찾을 수 있도록 시스템을 개선할 수도 있을 것이다.\n가령, 오토매틱처럼 아테네 교통국의 모든 신임 경영진이 일선에서 3주간 현장 업무를 체험한다면, 고객 관점에서 매표소 업무를 새롭게 규정하고 역무원들에게 재량권을 허용해 서비스를 개선할 수도 있지 않을까?\n p187  성당식 비전을 수립한 다음에 그것들을 시장식 개발 방법으로 구현할 수 있음을 회사에 증명하고 싶었다.\n p188  핵심서비스보다 주변 서비스에 더 투자하는 일은 없어야 한다고 판단했다. 그렇게 되면 과감하게 전략을 펼치지 못하고 늘 방어직인 경영 기조로 흐르게 된다.\n Wordpress 댓글 시스템으로 인수한 시스템과 자체 개발 시스템 중 어디에 투자할 것 인가를 두고 고민.\np197  품질관리를 전담하는 팀이 없기 때문에 직원들 모두가 품질에 책임을 지는 분위기였다. 품질관리 전담팀이 있는 기업에서는 쉽게 찾아볼 수 없는 모습이다. 신생기업이나 소규모 팀 체제에서는 모두가 서로 돕기 때문이다. \u0026hellip; 과게 MS에서는 게으름을 피우거나 자기 일에 책임지지 않고 허튼 핑계를 대는 부작용을 방지하는 차원에서 ㅇ리부러 인원ㅇ르 줄여 소규모로 팀을 유지하곤 했다. 인원 부족이 심각하면 불행한 사태가 발생하지만, 적당히 줄이되 재량권을 부여하면 직원들의 사기와 생산성이 진작된다. 열정적인 사람들은 어려운 과제를 오히려 즐길 줄 안다.\n p207  만약 가족이든 회사든 어떤 조직이 왜 현재와 같은 모습인지 알고 싶다면 먼저 윗사람을 살펴보라. 그 조직에서 가장 힘이 쎈 사람이 날마다 어떻게 행동하느냐에 따라 그 조직의 문화가 달라진다. 만약 당신이 다니는 직장에서 직원들이 서로 언성을 높이는 일이 잦다면, 그 원인은 조직에서 힘이 제일 센 사람에게 찾아야 한다. 동료에게 언성을 높이는 사람을 바로 그 사람이 채용했고, 그 직원의 행동을 도중에 제지하거나 따로 불러서 주의를 시키지 않았기 때문이다. 그 사람을 해고하는 극단적인 결정을 내릴 수도 있겠고, 어쨌거나 최고 의사결정권자가 어떤 조치를 했다면 그런 다툼은 사라졌을 것이다.\n불량한 태도로 회의를 하는 직원들이 있다면 반드시 그곳에는 누가 됐든 어떤 조치를 할 수 있는 결정권자가 있기 마련이다. 한 조직의 문화는 그 사람이 어떻게 행동하느냐에 달렸다. 의사결정권자가 침묵했다면 지금 일어난 일을 용인한다는 신호를 보낸 것이나 마찬가지다. 그 대신에 \u0026ldquo;좋은 아이디어입니다\u0026quot;라든가 \u0026ldquo;핵심을 찌르는 질문을 주셔서 감사합니다\u0026quot;라고 의견을 표명할 경우에는 모두가 그 뜻을 알아차리고 그 같은 행동이 강화될 가능성이 크다. 윗사람의 태도를 보고 자신의 행동을 결정하는 것은 인간의 본능이다. 대화하는 장소가 어디든 그곳에는 평판이나 영향력이 가장 높은 사람이 있기 마련이다. 그리고 그 사람이 하는 선택이 하나둘 쌓여서 조직문화라는 것이 만들어진다.\n  팀장으로서 충분한 권한과 재량권을 보장받았기 때문에 우리 팀이 나중에 실패한다면 그것은 어디까지나 내 책임이었다.\n p212  우리는 제품에 포함할 수많은 기능 중에 가장 간단하고, 가장 쉽고, 가장 가치 있는 기능만 추려내 먼저 배포하기로 했다(흔히들 Minimum Visible Product라고 한다.\n p224  \u0026lsquo;어떤 방법이 업무 생산성을 높이는지 판단하는 것은 일하는 종업원의 몫이다\u0026rsquo;\n p229  사내 정치는 이메일을 불필요하게 양산하는 원인이 되기도 한다.\n이메일은 발신자에게 권한이 있다\n이메일은 닫힌 채널이다\n이메일은 시간이 흐르면 사라진다\n p234  내가 작성한 글에 근본적인 문제를 제기하는 것으로 포문을 여는 바람에 몇 차례 소득 없는 논쟁을 벌인 적이 있다.\n p236  내가 이해하지 못하는 부분에 대해서는 늘 상사에게 설명을 요구했다. 이때 내가 원하는 것은 지시가 아니라 가르침이다. 상대가 내 주장이 틀렸다고 입증하든 내가 논쟁에서 패하든 내가 무언가를 배울 수 있다면 나는 개의치 않는다. 하지만 시키는 대로 하는 일에는 소질이 없다. 상사가 아랫사람을 설득하기 위해 얼마나 노력하는 사람이냐에 따라 나는 훌륭한 직원이 될 수도 있고 형편없는 직원이 될 수도 있다.\n p241  조직에 정말로 필요한 관리자는 일주일에 80시간 근무를 요구하며 직원들을 다그치는 사람이 아니라, 좋은 인재를 알아보고 건전한 갈등을 촉진하며 직원들을 방해하지 않는 사람을 경영진이 알게 될 수도 있다.\n p242  P2에 올라오는 글이나 작업 코드는 누구나 볼 수 있기 때문에 정탐하려고 마음만 먹는다면 게으름을 피우는 직원들을 쉽게 찾아낼 수 있었다. 그러나 그런 걸 정탐하고 다니는 사람은 없었고, 따라서 얼마든지 게으름을 피울 수 있는 상황이었지만 그런 사람들은 극소수였다. 내가 본 그 어떤 회사보다도 오토매틱인들은 생산성 면에세 탁월했다.\n p248  같은 시공간에 함게 있으면서 신규 기능을 세상에 내보내는 일은 정말이지 짜릿한 경험이다.\n p250  일정에 심각한 문제가 생겼다. 위기관리가 필요한 전형적인 상황에서\n 직접 문제를 진단한다. 다른 개발자에게 부탁해 문제를 진단한다. 변화를 준다. 프로젝트를 더 단순하게 만들면 도움이 되기도 한다. 요구사항 단순화 프로젝트를 폐기한다. 계속 진행한다. 추가 일정으로 해결   p252  관리자가 자신이 고용한 인재보다 일련의 규칙을 더 신뢰할 때 방법론은 불필요하게 갈등을 유발하는 도구로 전락하는 수가 많다. 나는 형편없는 팀을 이끌고 위대한 방법론을 실행하느니 훌륭한 팀을 이끌고 형편없는 방법론을 실행하는 편을 택하겠다.\n p258  우리는 개발자들이 독립적으로 작업할 수 있도록 업무를 할당했는데, 지나고 보니 이 단순한 방식이 사실은 가장 생산성이 떨어지는 방식이었다.\n p265  \u0026ldquo;XX 프로젝트는 무척 중요합니다\u0026quot;라고 말하는 상사가 그냥 헛소리를 지껄인 것인지 아닌지는 자원을 얼마나 공급하는지를 보면 쉽게 확인할 수 있다. 리더가 자신이 한 말에 상응한 자원을 제공하지 않는다면 무능한 사람이거나 가식적인 사람, 아니면 두 가지 모두에 해당하는 사람이다. 하고자 하는 일이 중요하다면 그것을 입증해야 하고,중요성은 늘 다른 프로젝트에 대한 상대적인 의미를 지닌다. 지원들을 움직이려고 공약을 남발하듯이 매번 중요성을 강조하면 안 된다.\n p266  내가 신경 쓰는 부분은 일정을 수립하는 것보다다도 작업을 세분화하는 것이었고, 그래야 작업 단계를 설정할 수 있었다. 우수한 프로젝트 관리자라면 누구나 그렇듯이 나는 항상 작업 일람표를 요구했고, 그것들을 우선순위에 따라 정리했다.\n p300  얼마든지 위험을 무릅쓸 수 있는 자유가 주어졌는데 정작 위험을 기피하는 문화라니, 나로서는 이해가 가지 않았다.\n p345  노동에 관해 여러 가지 관념이 있지만, 그중에서도 가장 위험한 생각은 노동에서 재미와 의미를 찾으려 들지 말라는 것이다. 현대인들은 우리가 일하면서 돈을 받는 것은 그 만큼 재미도 없고 의미도 없는 일을 해서 받는 보상이라고 여긴다. \u0026hellip; 마음 깊은 곳에서는 자기가 하는 일이 자신을 위해서나 남을 위해서나 무의미하다는 사실을 알기 때문이다. 돈은 지위를 부여하지만, 지위가 삶의 의미를 부여하지 는 않는다. 사람들은 자신의 영혼을 가혹하게 홀대한 만큼 많은 돈을 번다.\n p346  노동의 역사는 기본적으로 생존의 문제에서부터 시작되었다. 인간은 살아남기 위해 사냥을 하고 채집을 했다. 그 시절에는 노동과 노동 이외의 삶을 이분법적으로 나누는 일은 거의 없었다. 일과 생활의 구분이 없어서 삶이 비참했디기보다는 오히려 의미 있었을 가능성이 큰다. 아무리 고된 활동이라도 모든 활동은 개인에게 의미가 있었다.\n  Richard Donkin 에서 1903년에 처음 세상에 알려진 호주 원주민 요론트 족에 대해 쓰고 있다. 이들 부족은 이전까지 현대인들과 접촉이 전혀 없었는데, 노동과 놀이를 전혀 구분하지 않는 오랜 전통을 지니고 있었다.\n 요론트 족이 쓰는 말에는 \u0026lsquo;워크woq\u0026rsquo;라는 낱말이 있는데, 이는 여러 가지 잡다한 일과 허드렛일을 지칭한다. 하지만 이 허드렛일 - 즉 \u0026lsquo;워크\u0026rsquo; - 에는 사냥이 포함되지 않는다. 수렵채집 사회에서 생존에 가장 중요한 활동인 사냥은 노동으로 여기지 않은 것이다. 이 원시 부족에게 노동은 어쩔 수 없이 해야 하는 어떤 일로 보인다. 이 개념 - 하고 싶지 않은 일이 노동이다 - 은 우리 현대인에게도 매우 익숙한 노동의 개념 중 하나다\n  reference  코드 수로 생산성을 판단하는 경우 문제점  ","id":196,"section":"posts","summary":"원제 : The year without pants p42 방송에서 IDEO가 \u0026ldquo;Deep Dive\u0026quot;라는 아이디어 개발 기법을 써서 닷새 만에 쇼핑카트를 개선하는 과정을 보여주었다. 곧이어 수 많은 기","tags":["Book"],"title":"(책) 바지 벗고 일하면 안되나요?","uri":"https://cychong47.github.io/2014/10/caeg-baji-beosgo-ilhamyeon-andoenayo/","year":"2014"},{"content":" 우선 할 것은 모든 과제의 진행상황을 투명하게 볼 수 있는 시스템만들기 엑셀로 관리하고 있는 정보에 대해 최적의 대안을 찾아 엑셀 사용을 최소화 하기 파일 서버에 단순히 모으고 있는 자료를 DB화. 적어도 하나의 과제에 관련된 문서를 한눈에 볼 수 있게 하고, 검색이 가능하도록 변경 File based DB 시스템 대체 방안. 필요하다면 기존 요구사항만 기존 담당자들로부터 받고, 새로운 생각을 가진 사람들에게 대안을 제안하도록 Code Coverage 100% 같은 비효율적인 업무 없애기 Inventory 정보 투명화. 어떤 실험 자산을 어떻게 사용하고 있는지, 부서간 공유. 분야별 정보 공유할 수 있는 공간 만들고, 정보 공유 독려. 무슨무슨 TF니 WG를 만들기 보다 스스로 정보를 공유하도록 만들기(보다 구체적인 방안 필요) 메일을 통한 정보 공유 최소화. 메일과 같은 휘발성 매체가 아닌(적어도 사내에서는 휘발성이 높음) CMS에 기록해서 이력 관리가 쉽도록 모든 공유 정보는 CMS에 기록(위키 등) Unit Test 강화. 불필요한 코드 삭제 유도 비현실적이고, 불합리한 무리한 패키지 개발 계획 조정. 1년에 최대 2개만 개발 SIT단계 이후 진행되는 pre-SIT 같은 바보같은 업무 없앰 TC 개수 관리 같은 의미없는 숫자기반 관리 지양 아침 8시 회의 같은 어이없는 회의 금지 SE Lab 강화. 모 부서와의 전쟁. 미개하고, 무례하고, 개념없는 놈들. 비효율적인 문서 작성 기반의 업무 보고 대안 강구. 부서 혹은 부문 별 wish list 관리. 각 부서는 제기된 요청사항에 대해 검토 후 선정된 결과에 대해 기능 구현/개선. 단 선정 내용에 대해 필히 공유(그렇지 않으면 의미 있는 것보다는 쉬운 것을 선정할 수 있으므로)  ","id":197,"section":"posts","summary":"우선 할 것은 모든 과제의 진행상황을 투명하게 볼 수 있는 시스템만들기 엑셀로 관리하고 있는 정보에 대해 최적의 대안을 찾아 엑셀 사용을 최소화 하기 파일 서버에 단순히 모","tags":["잡생각"],"title":"내게 권한이 있다면","uri":"https://cychong47.github.io/2014/10/naege-gweonhani-issdamyeon/","year":"2014"},{"content":" 창의적인 아이디어를 만들기가 쉽지 않을 텐데, 나름의 노하우가 있다면? 후배들에게 ‘아이디어를 좀 내봐, 너 좋은 아이디어 없냐?’ 하는 회의는 의미 없다. 아이디어가 있으면 이미 이야기했을 것이다. 내가 중요하게 생각하는 것은 회의에 참석한 캐릭터의 특성을 파악하는 것이다. ‘저 친구는 어떤 성향인지, 뭘 좋아하고 싫어하는지, 편견이 심한지 그렇지 않은지, 판단은 믿을 만한지’ 등등. 스태프들의 캐릭터를 파악하고 있어야 한다.\n 멋진데. 이런 게 진정한 관리자의 덕목이 아닐까\n PD로 일하는 데 도움이 되었던 경험이 있다면? 아무래도 대학 다닐 때 연극했던 경험이 제일 소중하다. 마음 맞는 사람들이 모여서 공통의 목표를 향해 진짜 미친 듯이, 자기의 모든 것을 포기하면서 비등점을 향해 달려 나간다. 그리고 공연이 딱 끝나고 나면 모두 운다. 수십명이 함께. 그 일이 진짜 짜릿하다. ‘내가 하고 싶은 일이 이런 일이구나’라는 걸 그때 처음 느꼈고, 이 비슷한 일이면 아무거나 상관없다는 생각이 들었다. 그래서 시트콤 작가 모집 광고를 보고 지원하기도 했고, 영화사에 조연출로 들어가기도 했다.\n 요즘 너무너무 재미가 없는데 이런 게 없어 그런 것 같다. 뭔가를 위해 함께 일하고, 함께 그 성과를 즐기는 거. 1년에 수 많은 패키지를 개발하지만 \u0026ldquo;뭔가를 이뤘다\u0026quot;라고 할 만한 것이 없다. 도전이라고 할만한 것도 없지만, 그냥 공장에서 찍어내는 듯한 일을 하고 있으니 성취감은 찾아볼 수 없다. 그래서 점점 매너리즘에 빠지고 있는 듯 한데 위에서도 SW를 공장 일처럼 만들고 있는듯한 느낌이다. 그냥 문제 없는 코드 만들면 최고라는 분위기.\nhttp://m.sisainlive.com/news/articleView.html?idxno=21316\n","id":198,"section":"posts","summary":"창의적인 아이디어를 만들기가 쉽지 않을 텐데, 나름의 노하우가 있다면? 후배들에게 ‘아이디어를 좀 내봐, 너 좋은 아이디어 없냐?’ 하는 회의는 의미 없다. 아이디","tags":["매너리즘"],"title":"나영석 PD","uri":"https://cychong47.github.io/2014/10/nayeongseog-pd/","year":"2014"},{"content":"근태를 처리하지 못해 하루 최소 근무시간인 4시간을 채우고 포럼 장소인 리츠칼튼 호텔로 달려(버스타고) 감. 다행히 오후 세션 시작 시간인 1시 10분 전에 도착했지만 덕분에 점심도 못 먹고 끝날 때까지 있어야 했다. 먹은 거라곤 사탕 몇 개.\n트랙 2개인데, 다른 쪽 트랙에서도 듣고 싶은 게 있었지만 트랙 1을 끝까지 들었다.\nQuanta  Taiwan Company CPU와 switch 를 상호 선택할 수 있도록 함.  상용 스위치 칩 사용  Intel Alta and RRC(w/ Aricent OS)  Intel ONS   Broadcom Trident and Tomahawk Cavium Xpliant  다양한 CPU 사용 가능  Intel, Freescale, Cavium, Broadcom(XLP)  OCE, ONIE(Open Network Install Environment)  Fetch Network OS from the booter(boot loader -\u0026gt; ONIE -\u0026gt; fetch network OS) Similar to loadable OS 표준 I/F가 있다고 하네. http://opencompute.org ONIE Slideshare  Open Network Linux  Linux distribution for \u0026ldquo;bare metal\u0026rdquo; switches Quanta Ubuntu ONL is sponsored by BigSwitch homepage  North Bound I/F  OpenFlow RestFul OpEN API ???  Restful API in switch  Switch provide RestFul API directly. Baremetal OS  64-bit OS for x86-64 based computers Written in Assembly   Puppet, Chef  Puppet is a tool designed to manage the configuration of Unix-like and MS systems. The user describe system resources and their state, either using Puppet\u0026rsquo;s declarative language or a Ruby DSL. Puppet Puppet-openstack Chef Chef-openstack Chef for OpenStack Chef is a systems and clouds infrastructure automation framework that makes it easy servers and applications to any physical, virtual, or cloud location, no matter the size of the infrastructure.   MLAG(Multi-Chassis Link Aggregation)  Extension of LAG up to node-level. Not covered by IEEE 802.1AX-2008 Vendor-specific implementation   Support OF 1.3 One customer build their hypersclae datacenter with qunata\u0026rsquo;s h/W and their inhouse OS, but still use ONIE  Advantech  For Enterprise and Telecom market All QuickAssist Accelerator support Netronome as I/O processor  FlowNIC acceleration card Flow Processor as Accelerated switch NFP-6840 for high-end   Use 6wind solution  NEC NFV Commercial Ready solution NEC  R\u0026amp;D on Virtualization from 2009 National POC 500K Subscribers POC(VoLTE) 투자 비용은 mobile network이 가장 크게 증가함. 동시에 data revenue의 증가도 가장 큼.  How to reduce TCO  virtualization based resource utilization Programmable scalable reliable network Flexible automated configuration centralized control \u0026amp; management Average 39%(CAPEX + OPEX)  CAPEX 28% - New feature OPEX System Upgrade 89% reduction OPEX Floor Site rental 66%    Component  Redhat or HP for OS and hypervisor HP or Dell Intel DPDK, NIC OpenStack Shift from ATCA NF to COTS NF M2M Service Platform over NFV  CONNEXIVE Platofrm(virtualized platform) for M2M Services    Pluribus  http://pluribusnetworks.com Startup from 2010 Pretty interesting Netvisor and Server-switch architecture H/W is from advantech for some product Utilize many open-sources  ISC Internet Switch consortium Quagga   Convert legacy designed switch to server based based design  Legacy switch use proprietary chip and small control processor Server use powerful CPU for control processor and commercial NIC Switch chip is used to replace NIC Switch chip을 PCIe를 통해 CPU에 직접 연결. DMA를 통해 직접 스위치 내부 테이블을 제어.   Netvisor cover multiple boxes - illumos container???  illumos is a free and open-source Unix OS derived from the OpenSolaris http://illumos.org or wiki.illumos.org   Bhyve hypervisor - 30x faster than KVM?  BSD hypervisor http://hbyve.org Runs FreeBSD 9+, OpenBSD and Linux guests   Fabric Cluster - build standard based ethernet fabric as ONE logical switch Time Machine analytics  Can track of flows on a specific time period in the past   Netvisor Fabric-Connect  Brocade  Last night(14/9/23), announce brocade controller AWS 계정을 이용하면 demo를 직접 사용해 볼 수 있다고 Linear performance as the number of cores are increased while other\u0026rsquo;s performance is saturated Yahoo Japan use Brocade VCS fabric for hadoop environment.  ","id":199,"section":"posts","summary":"근태를 처리하지 못해 하루 최소 근무시간인 4시간을 채우고 포럼 장소인 리츠칼튼 호텔로 달려(버스타고) 감. 다행히 오후 세션 시작 시간인 1시 10분 전에 도착했지","tags":["SDN","Intel","ONP","Brocade","Quanta","NEC","Pluribus","Cavium","OVDK","nfv"],"title":"Intel SDN/NFV Forum Korea 2014","uri":"https://cychong47.github.io/2014/09/intel-sdnnfv-forum-korea-2014/","year":"2014"},{"content":"오래만에 재밌는 책을 봤다.\n해커를 위한 책이라고 하지만, 해킹에 관한 기법보다는 network application을 작성하는데 유용한 scapy, dpkt 그리고 정규식에 대한 설명이 유용하다. 마침 요 근래 업무용으로 Python을 이용해서 패킷 만들고, 송/수신하는 유틸리티를 만들고 있어 Impacket 모듈을 많이 사용했는데 그것보다 scapy 가 훨씬 편해 보인다.\n새 책을 사긴 그렇고 중고책을 하나 구할 까 했는데 알라딘에서 중고책 매입가가 4천원 대. 작년 초에 나온 책인데 너무 싸게 매입하는 게 아닌가\n일단 책 보면서 유용하다 싶은 내용을 몇 가지 주제로 나눠 정리했다.\n소스 코드를 받을 수 있는 곳은  github COMPANION MATERIALS  예제를 하나하나 보면 참 배울게 많아 보인다.\nSemaphore  screenLock = Semaphore(value = 1) screenLock.acquire() screeLock.release(()  pxssh library  s = pxssh.pxssh() s.login(host, user, password) s.sendline(xxx) s.prompt()  scapy   haslayer() is powerful to check if packet has known protocol\nfrom scapy.all import *\n if pkt.haslayer(IP) if pkt.haslayer(TCP) if pkt.haslayer(ICMP)    To see the file name use scapy\n $ scapy Welcome to Scapy \u0026gt;\u0026gt;\u0026gt; ls(IP) ...    CH4, 7-testFastFlux.py - pcap 파일을 읽어 특정 데이터를 가진 경우 확인\n def handlePkt(pkt): if pkt.haslayer(DNSRR): rrname = pkt.getlayer(DNSRR).rrname rdata = pkt.getlayer(DNSRR).rdata pkts = rdpcap('fastFlux.pcap') for pkt in pkts: handlePkt(pkt)    CH4, 6-spoofDetect.py - sniff해서 특정 데이터를 가진 패킷 확인\n def testTTL(pkt): try: if pkt.haslayer(IP): ipsrc = pkt.getlayer(IP).src ttl = str(pkt.ttl) conf.iface = 'eth0' sniff(filter=\u0026quot;tcp port 21\u0026quot;, prn=testTTL, store=0) # filter is optional    Make a packet easily\n IPlayer = IP(src=\u0026quot;1.1.1.1\u0026quot;, dst=\u0026quot;2.2.2.2\u0026quot;) TCPlayer = TCP(sport=123, dport=456) pkt = IPlayer / TCPlayer send(pkt)    or pkt = IP(src=\u0026quot;1.1.1.1\u0026rdquo;, dst=\u0026quot;2.2.2.2\u0026rdquo;) / TCP(dport=456) / Raw(load=\u0026quot;^\\xB0\\x02\\x89\\x06\\xFE\\xC8\\x89F\\x04\\xB0\\x06\\x89F\u0026rdquo;) send(pkt, iface=\u0026quot;eth0\u0026rdquo;, count=10)\n pkt = IP(src=\u0026quot;1.1.1.1\u0026quot;, dst=\u0026quot;2.2.2.2\u0026quot;) / TCP(dport=456) / Raw(load=\u0026quot;Amanda\u0026quot;) send(pkt, iface=\u0026quot;eth0\u0026quot;, count=10)    Too see the packet has string XXX=YYY and get YYY\n raw = raw.sprintf(\u0026quot;%Raw.load%\u0026quot;) name=re.findall(\u0026quot;(?i)XXX=(.*)\u0026amp;\u0026quot;, raw)    Too see the string \u0026ldquo;Amanda\u0026rdquo; with tcpdump, use -A option which means ASCII\n  CH5, 7-uavSniff.py - good example of using Class\n  DPKT module p144   CH4, 4-googleEarthPcap.py\n  IP 주소를 이용해 IP의 물리적인 위치 정보를 찾고, 이를 이용해 google earth에 표시하기 위해 KML 파일 생성\n  dpkt를 이용한 패킷 분석\n  dpkt는 pip로 설치 불가\n for ts, buf in pcap: ethernet = dpkt.ethernet.Ethernet(buf) ip = eth.data src = socket.ntoa(ip.src)    p147   dpkt을 이용한 HTTP 분석\n  상위 protocol header를 가리킬 때 x.data 사용\n  5-findDDoS.py\n tcp = ip.data http = dpkt.http.Request(tcp.data) if http.method == 'GET': uri = http.uri.lower() if '.zip' in uri: print \u0026quot;bingo\u0026quot;    p149  tcp = ip.data sport = tcp.sport dport = tcp.dport if '!lazor' in tcp.data.lower(): print \u0026quot;bingo\u0026quot;    except KeyboardInterrupt:\n try: foobar() except KeyboardInterrupt: sys.exit(0)    Regular Expression  \u0026gt;\u0026gt;\u0026gt; print re.findall(\u0026quot;(?i)XXX=(.*)\u0026quot;, \u0026quot;!#ASFDASFASDFAS#$%$#XXX=YYY\u0026quot;) ['YYY'] \u0026gt;\u0026gt;\u0026gt; print re.findall(\u0026quot;XXX=(.*)\u0026quot;, \u0026quot;!#ASFDASFASDFAS#$%$#XXX=YYY\u0026quot;) ['YYY'] 왜 `(?i)`를 사용하는 걸까? \u0026gt;\u0026gt;\u0026gt; re.findall(r'[0-9a-zA-Z]{3}', \u0026quot;123 2314 13\u0026quot;) ['123', '231']  Mechanize module  # -*- coding: utf-8 -*- import mechanize def viewPage(url): browser = mechanize.Browser() page = browser.open(url) source_code = page.read() print source_code viewPage('http://www.syngress.com/')  Twitter API  CH6, 9-twitterInterests.py  Template  #!/usr/bin/python # -*- coding: utf-8 -*- def main(): parser = optparse.OptionParser('usage %prog -i \u0026lt;interface\u0026gt;') parser.add_option('-i', dest='interface', type='string', help='specify interface to listen on') (options, args) = parser.parse_args() if options.interface == None: print parser.usage exit(0) else: conf.iface = options.interface try: print '[*] Starting Credit Card Sniffer.' sniff(filter='tcp', prn=findCreditCard, store=0) except KeyboardInterrupt: exit(0) if __name__ == '__main__': main()  Template(Class)  #!/usr/bin/python # -*- coding: utf-8 -*- class testThread(threading.Thread): def __init__(self): threading.Thread.__init__(self) # add intialize variables or initialization functions def run(self): # main function of this class def main(): testInstance = testThread() testInstance.start()  ","id":200,"section":"posts","summary":"오래만에 재밌는 책을 봤다. 해커를 위한 책이라고 하지만, 해킹에 관한 기법보다는 network application을 작성하는데 유용한 scapy, dpkt 그리고 정규식에 대한 설명이","tags":["Python","dpkt","scapy","Book"],"title":"(책) Violent Python","uri":"https://cychong47.github.io/2014/09/caeg-violent-python/","year":"2014"},{"content":"p230  OKR(Objectives and Key Results) 는 원래 인텔의 앤디 그로브(Andy Grove)가 고안한 경영기법이다. \u0026hellip; 무었을 하고 싶어하는지만 정하는 것이 아니라, 측정 가능하게 업무(핵심결과)를 나눠야 한다는 내용이었다.\nOKR은 구글문화의 핵심이 되었다. 모든 직원이 나름의 OKR을 분기별로, 연도별로 세워서 승인을 받아야 한다. 그 뿐만이 아니라 팀 수준, 부서 수준, 심지어 회사 수준의 OKR도 구축했다(회사 수준의 OKR은 중요한 구상이나 시래를 만회하려 할 때 구축했다) 1년에 네 차례씩 구글 직원 모두 멈춰 서서 부서별 회의를 갖고 OKR 진전상황을 확인한다.\n이러한 제도를 구글이 관료제화 되어가는 신호가 아닐까 생각하는 사람도 있을 것이다. 실제 업무를 못하게 될 정도로 잡일 프로젝트를 도입한 것이 아닌가 궁금할지도 모른다. 하지만 구글 직원들은 그렇게 생각하지 않는다. 그들은 OKR을 하나의 데이터로 여긴다. 성과를 측정하는 수단으로 계량화가 가능한 방식이기 때문이다. OKR은 측정이 가능하다는 점, 거기에 핵심이었다. \u0026lsquo;지메일을 성공시키겠다\u0026rsquo;가 아니라 \u0026lsquo;지메일을 9월에 발족하여 11월까지 사용자 수를 100만 명으로 늘리겠다\u0026rsquo;라고 계획하는 것이다. 마리아 메이어는 이렇게 말한다. \u0026ldquo;수치가 없으면 핵심결과가 아니죠\u0026rdquo; OKR은 야망을 구체화시킨다. 도어는 위험을 받아들일 수 있도록 허용해 주기도 합니다.\u0026rdquo; OKR은 목표를 도달하지 못한다는 것보다 초과 달성했을 경우에 더 문제가 된다. 미리 목표를 편안하게 설정해서 편안하게 업무를 했다는 뜻이 되기 때문이다. 구글은 목표치를 초과달성한 직원을 도전적이지 않다고 여긴다.\nOKR은 목표를 달성한 것을 1로 보며 가장 적절한 성적은 0.7~0.8점이다. 분기마다 다음 분기의 OKR을 설정하며 6주일 후 관리자에게 진행상황을 보고한다. 이때의 실적은 교통신호체계로 표시된다. 분기 말로 갈수록 OKR은 자체평가하고, 1점을 얻는 경우, 즉 100퍼센트 달성을 하는 경우에는 다른 평가자가 다시 한번 점검한다.\nOKR은 단순히 개인의 성과를 관리하기 위한 도구가 아니다. OKR은 개개인의 임무가 무엇인지 공개하는 수단이기도 하다. 구글의 모든 직원은 인트라넷 MOMA의 직원정보에 OKR을 공개한다. 심지어 래리와 세르게이의 OKR도 공개된다. \u0026ldquo;우리는 회사를 합리적인 조직으로 운영하고 싶었어요. 투명성이 높으면 더욱 좋죠. 분기마다 무엇을 이루고 싶은지 한두 페이지로 모두 함께 소통할 수 있다면 얼마나 좋겠습니까?\u0026rdquo; 대기업에는 보통 고질적인 탈개성화가 일어난다. OKR 공유 또한 대기업화를 막기 위한 고육지책 중 하나다. 처음 기업을 시작할 때는 모두 서로 알며 무엇을 하는지도 안다. 직원 수가 2만 명이 넘는 지금도 여전히 구글은 직원간의 친화성을 높이기 위해 노력한다. MOMA 외에도 구글 직원이라면 누구나 프로젝트 데이터베이스에 접속하여 현재 회사가 엔지니어링과 제품관리자, 제품, 엔지니어링 등을 어떻게 나눴는지 알아볼 수 있다. 새로운 멋진 프로젝트를 찾는 직원은 \u0026lsquo;아이디어\u0026rsquo;라고 하는 섹션에 접속하여 동료들이 어떤 일손을 구하는 지 알 수 있다.\n  OKR template This Is The Internal Grading System Google Uses For Its Employees — And You Should Use It Too How Google Set Goals:OKRs   OKRs are about the company’s goals and how each employee contributes to those goals. Performance evaluations – which are entirely about evaluating how an employee performed in a given period – should be independent from their OKRs\n p280  \u0026ldquo;아마 정부를 포함해서 세계 어느 곳보다도 대규모로 redundant network을 연결시켜 놓은 곳이 구글일 겁니다\u0026rdquo;\n p364  우리는 구글이이게, 절감도 다르게 할 겁니다. 우리가 GM이나 엑손이었다면 넥타이를 맨 사람으로 가득 찬 위원회를 하나 만들어서 외부 컨설턴트를 고용해가지고는 \u0026lsquo;해결책\u0026rsquo;이라고 쓴 메모를 돌리겠죠. 구글에서는 우리 직원에게 이렇게 말합니다.\u0026lsquo;낭비 요소가 있는지 당싱이 알려주세요\u0026rsquo; 구글은 그 작업을 위해 따로 인력을 고용하고 웹기반의 툴을 만들어서 데이터위주로 만든 낭비요소 분석기를 만들었다. \u0026hellip; 모든 카페의 소비량과 사용량에 대한 데이터를 모으고, 사무실 내 부엌 사용패턴을 측정한 다음에 스프레드시트에 데이터를 집어 넣어 피봇 테이블 기능을 써서 사용빈도가 낮은 카페를 발견했다.\n p370  구글 인사팀은 직원의 지위에 대해 9가지의 단계로 이뤄진 시스템을 만들었다. \u0026hellip; 구글은 직원들이 현재 사다리에서 어느 정도 단계에 올라있는지조차 알려주지 않는데, 이는 통상적인 구글의 내부적인 투명성을 생각해본다면 이례적인 일이다. 보크는 이런 비밀주의가 \u0026lsquo;인지적 휴리스틱(Cognitive Heuristic)때문이라고 설명할 터였다. 인지적 휴리스틱이란 사람들이 자신보다 직급이 높은 상관의 말을 따라야 한다고 생각하게 만드는 무의식적인 사고 과정을 말한다. \u0026ldquo;대초원에 있거나 대기업에 있으면 도움이 될 테지만 구글에서는 도움이 안 됩니다. 에릭이나 래리는 어느 누구라도 어떤 이에게 \u0026lsquo;당신 말이 틀렸어요\u0026rsquo;라고 말하고 왜 틀렸는지 10가지 이유를 말할 수 있는 관계가 되어야 한다고 생각합니다\u0026rdquo; 이 과정에서 직급은 거추장스러울 뿐이다.\n 혁신을 바란다면 가장 먼저 해야 할 게 이게 아닌가 싶다. 호칭이 뭐 대수냐고? 하지만 그 호칭이 들어가는 순간 상대방의 의견에 반하는 말을 하려면 수 배의 용기가 필요하다. 그런 용기를 가진 사람을 오히려 골라내야 한다고? 필요한 것이 뭔가? 용기를 가진 뛰어난 인재인가? 아니면 좋은 의견/생각 그 자체인가? 답은 명확하지 않나?\np385  보안이 중요하지만 구글은 직원을 신뢰할 수 없다는 생각을 참을 수가 없었다. \u0026hellip; 회사가 당신을 좀도둑으로 취급하고, 회사문을 나설 때마다 가방을 뒤지는 곳에서 진정한 구글 직원이 될 리 있겠는가?\n 자연스럽게 회사나 자신을 분리한다. 이 회사는 그저 직장일 뿐이라고. 그걸 원한다면야\n","id":201,"section":"posts","summary":"p230 OKR(Objectives and Key Results) 는 원래 인텔의 앤디 그로브(Andy Grove)가 고안한 경영기법이다. \u0026hellip; 무었을 하고 싶어하는지만 정하는 것이 아니라, 측정 가능하게 업무(핵심","tags":["Book"],"title":"(책) 0과 1로 세상을 바꾸는 구글 그 모든 이야기(In the Flex)","uri":"https://cychong47.github.io/2014/09/0gwa-1ro-sesangeul-bagguneun-gugeul-geu-modeun-iyagiin-the-flex/","year":"2014"},{"content":"혼창통by 이지훈\n8p  혼 : 가슴 벅차게 하는 비전이 사람을 움직인다.\n창 : 끊임없이 \u0026ldquo;왜\u0026quot;라고 물어라, 그러면 열린다. 통 : 만나라, 또 만나라. 들어라 잘 들어라.\n 16p  IBM, P\u0026amp;G, Cisco, CEMEX 이 기없들의 공통점은 무엇일까? 그렇다 공룡처럼 몸집이 큰 기업들이다. 공룡인데도 민첩하다. 한가지 공통점은 회사 전체가 보다 큰 가치, 가슴을 울렁이게 하는 원대한 비전을 공유한다는 사실이다. 하버드경영대학원의 로자베스모스 캔터 교수(Rosabeth Moss Kanter) \u0026ldquo;모든 직원이 보다 큰 가치를 공유하게 되면 일선에서 어떤 문제가 부딛쳐도, 혹은 본사로부터 아무리 떨어진 곳에서 일하더라도 자발적으로 문제의 해결을 주도하게 된다\u0026rdquo;\n 17p  손정의 소프트뱅크 회장은 비전의 중요성을 강조하면서 이렇게 말했다. \u0026ldquo;눈앞을 보기 때문에 멀미를 느끼는 것이다. 몇백 킬로미터 앞을 보라. 그곳은 잔잔한 물결처럼 평온하다. 나는 그런 장소에 서서 오늘을 지켜보고 사업을 하고 있기 때문에 전혀 걱정하지 않는다\u0026rdquo;\n 18p  현실에 만족하고 안주하는 순간, 창은 시들고 만다. 다른 사람들이 선택한 쉬운 길을 거부하고, 늘 \u0026ldquo;왜\u0026quot;라고 물으며 새롭고 어려운 길을 갈 때에야 비로소 창이 싹튼다. 창은 손이 진흙으로 더러워지는 것을 두려워하지 않는 실험정신이고, 실패를 찬양하는 도전정신이다.\n 33p  무언가 디지털화할 수 있는 것은 결국 공짜 버전이 나오고 만다. 결국 당신의 숙제는 어떻게 공짜와 경쟁할 수 있느냐는 것이다. 공짜 버전이 제공하지 못하는 것을 제공하라. \u0026lsquo;아이튠즈\u0026rsquo;가 제공한 것은 편리함이었다. 제품을 파는 시대에서 서비스를 파는 시대로 바뀌고 있다.\n 43p  많은 리더들이 \u0026lsquo;어떻게 하면 구성원들에게 동기를 부여해 스스로 일하게 만들 수 있을까?\u0026rsquo; 라는 문제를 고민한다. 돈은 결코 정답이 아니다. 물론 누구나 돈이 필요하긴 하지만, 돈으로 사람을 움직이는 데는 한계가 있는 법이다. 경영자라면 이해득실을 전부 버려도 포기해서는 안 되는 죽어도 지키고 싶은 무엇을 최소한 한 가지는 마음속 깊이 갖고 있어야 한다. 그래야 사람의 마음을 움직일 수 있다. 그것이 바로 철학이고 혼일 것이다. 혼은 \u0026lsquo;사람을 움직이는 힘\u0026rsquo;이다.\n 46p  나는 사람들이 어떻게 그렇게 사는 지 상상을 할 수 없어요. 내가 보기에 정말 미친 것 같거든요. 아무리 높은 연봉이라도 일상생활의 일부로서 즐거움이 없는 삶을 나는 살 수 없습니다. 자본주의 체계란 놀라울 정도로 못돼먹은 겁니다. 80%이상의 사람들이, 생계를 위해 하는 일에서 아무런 즐거움을 엊지 못한다고 합니다. 대부분 사람들의 인생이 그렇습니다. 정말 미쳤어요.\n 49p  케네디 토머스 \u0026lt;열정과 몰입의 방법, Intrinsic Motivation at work\u0026gt; 사람들은 4가지 조건이 충족될 경우 일에서 재미와 열정을 느낀다. 1. 자신이 가치있는 일을 하고 있다고 느낄 때 2. 그 일을 할 때 자신에게 선택권이 있다고 느낄 때 3. 그 일을 할 만한 기술과 지식이 있다고 느낄 때 4. 실제로 진보하고 있다고 느낄 때\n 51p  세계와 경쟁한다는 것이 진정 어떤 의미인지 알고 있는 지\u0026hellip;66p다른 사람들의 생각에 얽매이지 마십시오. 타인의 소리들이 여러분 내면의 진정한 목소리를 방해하지 못하게 하십시오. 그리고 가장 중요한 것은 여러분의 심장과 직관이 이끄는 대로 살아갈 수 있는 용기를 가지는 것입니다. 이미 여러분의 심장과 직관은 당신이 진짜로 원하는 것이 무엇인지를 알고 있습니다. 나머지는 다 부차적인 것입니다.\n 70p  나는 만약 어떤 일에서 재미와 즐거움을 더 이상 찾을 수 없다면 드디어 다른 일을 찾아야 할 때가 된 것이라고 믿는다. 행복하지 않게 시간을 보내기에는 인생이 너무 짧다. 아침에 일어나면서부터 스트레스를 견뎌야 하고, 비참한 기분으로 일터로 나간다면 삶에 대한 올바른 태도가 아니다.\n 72p  좋아하지 않는 직장이지만 그래도 계쏙 남아 일해야만 하는 사람에게는. 인생은 긍정적으로 바라보는 사람에게 문을 열어준다. 일을 하면서 만나게 되는 사람들과 함께 즐거움을 찾아야 한다.\n 73p  \u0026lsquo;나는 골치 아프고 힘든 일이 잔쯕 있을 때는 그 일이 해결되었을 때의 기쁨을 생각하면서 출근합니다\u0026rdquo; 개인은 일의 주인이 되어야 한다. 그래야 진정한 성공을 맛볼 수 있다. 기업은 조직원을 일의 주인으로 만들어야 한다. 그것이 조직원과 기업이 함께 성장하는 길이다.\n 84p  돈으로는 사람을 움직일 수 없습니다. 사람을 움직이려면 마음 깊은 곳에서 타오르는 동기를 부여해야 합니다. 이를 위해서는 이윤을 뛰어넘는 숭고한 경영철학과 경영자의 인격이 필요합니다.\n 90p  중요한 사실은 내발적 동기가 외발적 동기보다 더 지속성이 있고, 더 좋은 결과를 가져오며, 더 큰 심리적 안정을 가져온다는 점이다. 내발적 동기의 경우, 활동에 집중하는 것 자체가 보상이 되므로 언제까지나 높은 동기가 부여될 수 있고, 활동이 계쏙 유지돼 자연스럽게 좋은 성과를 내게 된다.\n 92p  \u0026lsquo;당근과 채찍\u0026rsquo; 전략으로 상징되는 전통적인 기업의 보상 시스템은 종업원이 스스로 일하려는 동기, 즉 내발적 동기를 오히려 꺾을 수 있다는 점이다.\n 95p  천이유천 이란 중국 속담을 새기기 다닌다고 했다. 하늘 위에 또 하늘이 있다는 뜻이다. \u0026ldquo;제 성격에는 자만의 DNA가 흐르고 있습니다. 조금만 방심해도 우쭐해지기 쉬운 성격이죠. 그래서 늘 자만하지 않도록 스스로를 일깨우고 조심하고 있습니다\u0026rdquo;\n 96p  첫째가 중국의 개혁 개방 둘째가 높은 목표를 세우고 그것을 실현하기 위해 늘 노력한 갓 셋째가 언제나 공부하는 것\n 96p  간부는 큰 엔진이고, 그 밖의 모든 직원들은 큰 엔진과 함께 돌아가는 작은 엔진이 되어야 합니다. 밑의 직원들이 엔진에 따라 움직이는 기어가 되어서는 절대로 안됩니다. 어떻게 하면 일을 더 잘할 수 있을 지 스스로 생각하게 만들어야 합니다. 이렇게 해야 원동력이 더 커지게 됩니다.\n 99p  마케팅 1.0 소비자 머리에 호소 2.0 감성에 호소 3.0 영혼에 호소. 환경에 신경 쓰고 사회에 좋은 일도 하는 회사라면 내게 특별히 무엇을 주지 않더라도 그냥 좋다.\n 104p  혼은 \u0026lsquo;사람을 움직이는 힘\u0026rsquo;이며 \u0026lsquo;내가 여기에 있어야 하는 이유\u0026rsquo;이고 \u0026lsquo;개인을 뛰어넘는 대의\u0026rsquo;이다. 혼은 우리를 움직이게 하고, 버티게 하고, 극복하게 하는 근본적인 힘.\n 119p  사람들의 태도와 정신을 바꾸는 것이 중요합니다. 처음에는 불편해도 스스로에게 강제하고 단계적으로 반복 훈련을 하면 습관이 됩니다. 습관은 들이기는 어렵지만 나중에는 자연스럽고 편안해지죠. 개인뿐 아니라 조직이나 기관도 이런 식으로 변해야 합니다.\n 127p  끊임없이 노력해야 하고 아주 작은 디테일까지 세심한 주의를 기울여야 하며, 리스크를 감수하더라도 실행에 옮겨야 한다.\n 129p  다니엘 핑크 우리가 왜 새로워지고 창조적이지 않으면 안되는 지. 1. 아시아 - 아시아의 신흥시장 인력이 급성장한 경우, 루틴한 업무는 일상재가 될 것이다. 남들이 하지 않는 창조적인 일을 하지 않으면 안 된다. 2. 자동화 - 기계와 소프트웨어가 인간의 노동과 두뇌를 대신해가고 있다. 컴퓨터가 대체할 수 없는 인간의 우뇌만이 할 수 있는 창조적인 일을 하지 않으면 안된다. 3. 풍요 - 생활이 풍족해지면서 사람들의 새로운 욕구를 충족시키는 창의성 있는 인재가 날로 중요해진다. 당장은 사람들이 필요하다고 느끼지 못하지만, 사람들의 잠재된 욕구를 충족시킬 수 있는 상품을 개발하는 역량이 중요하다.\n 136p  다니엘 핑크 이제 우리에게는 펙트들이 너무나 넘쳐난다. 그런 팩트들을 스토리로, 문맥으로 엮어내지 못하면 팩트는 증발된다.\n 139p  마에다 총장은 권위적 리더쉽고, 창조적 리더쉽을 제시 권위적 리더쉽 - 채찍 중시, 위계질서 중시, \u0026lsquo;예스 혹은 노\u0026rsquo;의 명쾌함 중시, 옳은 판단인지 따지기, 장군처럼 생각하기, 실수 회피, 제한된 피드백만의 허용 창조적 리더쉽 - 당근 중시, 네트워크 중시, \u0026lsquo;아마도\u0026rsquo;와 같은 모호함 인정, 현실적 판단인지 따지기, 예술가처럼 생각하기, 실수로부터의 학습 환영, 무제한적 비판 허용\n 144p  이처럼 창을 얻기 위해서는 마음이 열려 있어야 한다. 우리는 어떤 결정을 내리면 자신의 생각이 틀릴 수도 있다는 생각에에 대해 개방적으로 되기 어렵다. 자신의 결정의 근거를 부정하는 모든 사실에 대해 마음을 닫기 쉽다. 그러나 창을 얻기 위해서는 다른 사람의 충고와 비판에 열려 있어야 한다.\n 145p  소설가 베르나르 베르베르 \u0026lsquo;풍부하고 다양한 호기심은 타고 나는 것이지만, 그 이후에는 끊임없이 정보와 지식을 습득하는 노력이 필요합니다. 나는 날마다 배웁니다. 뭔가 새로운 것을 하지 않은 날에는 \u0026lsquo;시간을 잃어버렸다\u0026rsquo;고 여깁니다.\n 161p  아마존 베조스의 선택 기준 Regret minimization framework 자신이 여든 살이 되었을 때를 가정해서 인생을 뒤돌아 보았을 때 후회할 일을 가장 줄이는 방법을 생각.\n 164p  큰 생각을 하려면 자신을 색다른 경험에 수없이 노출시켜보라.\n 164p  무용가 트와일라 타프는 사전에서 단어를 찾을 때, 그 단어 바로 앞, 뒷 단어도 함께 읽는 다고. 다음 번에 좋은 아이디어가 어디에서 올지 모르기 때문에. 한 번에 성격이 다른 여러 작품을 동시에 하고, 한 작품이 끝나면 그와 전혀 성격이 다른 작품에 도전하는 것도 창조성을 유지하는 그녀만의 노하우\n 165p  우뇌형 인간의 5가지 조건. 다니엘 핑크 1. 디자인이란 언어를 익히라. 2. 스토리를 만들라 3. 큰 그림으로 생각하라 4. 공감하라 5. Play하라168p미국 속담 에 \u0026lsquo;평소 알고 있던 악마가 낫다\u0026rsquo;. 그만큼 사람들은 변화를 싫어하는 보수적 본성이 있다.\n 174p  지식 e 시즌 4. 경로 의존성(Path Dependency) 한 번 일정한 경로에 의존하기 시작하면 나중에 그 경로가 비효율적이라는 것을 알고도 여전히 그 경로를 벗어나지 못한다는 사고의 관습\n 190p  실패한 사람이 무엇을 해야 할 지 생각하지 않으면, 실패를 반복할 수 밖에 없다. 실패의 원인과 과정을 깊이 있게 생각하지 않으면, 실패는 실패의 어머니일 뿐이다. 실패는 도전과 발전을 위해 그 원잉늘 분석하고 거기서 창조적인 아이디어를 도출해낼 때, 비로소 가치가 있는 것이다. 부주의아 오판으로 똑같은 실수를 연발하는 것은 절대 용서받을 수 없는 실패다.\n 195p  창은 혼을 노력과 근성으로 치환하는 과정이며 매일 새로워지는 일이고 익숙한 것과의 싸움이다. 어느 날 갑자기 찾아오는 것이 아니라 노력하고 도전하는 하루하루가 쌓여야 비로소 발현되는 것이 창이다.\n 239p  호리바 마사오 \u0026lt;남의 말을 듣기 마라\u0026gt; 나와 같이 일하는 사람은 나와 다른 생각을 갖고 있어야만 존재 가치가 있는 법이다. 나와 똑같은 생각을 가지고 있다면 차라리 그 월급을 내게 달라\n 244p  조직 내의 진정한 소통은 위에서 아래로 흐르는 탑다운의 일방적 방식으로는 결코 이룰 수 없다. 진정한 소통은 아래에서 위로, 오른쪽에서 왼쪽으로 360도 어느 쪽에서든 자유롭게 흐르는 것이다. 톱다운 커뮤니케이션은 조직 전체를 톱, 한 사람의 능력 안에 머물게 한다. 그러나 360도 커뮤니케이션은 구성원 모두가 아이디어와 능력을 발휘할 수 있게 함으로써 조직 역량에 한계가 없어진다.\n 245p  가와시마 기요시 혼다 전 사장 최근 2~3년간 내가 말한 사항들이 사내에서 8할이나 통과됐다. 6할이 넘으면 원맨 경영의 폐해가 나타나는 위험신호라고 하는데, 그렇다면 지금 혼다가 위험하다는 얘기가 아닌가?\n 246p  지난 20년간 조사한 수백 명의 관리자 중 70%는 보스의 일이 실패하리라는 것을 알면서도 피드백이나 충고를 하지 않은 것으로 나탔다. 직원이 경영자에게 문제를 제기할 정도면 가볍게 하는 말이 결코 아닐 것이기 때문이다. 물이 흐르지 못하면 고여서 썩기 마련이듯, 소통이 원할하지 못한 조직은 결국 문제가 발생하기 마련이다. 이것이 경영자가 직원들이 자유롭게 말할 수 있는 환경과 분위기를 조성해야 하는 이유다. 직원 또한 소신껏 자신의 의견을 개진해야 하는 이유다.\n 252p  포스코 정준양 회장 리더는 VIP가 되어야 한다. 리더라면 Vision을 제시할 수 있어야 하고, Insight 통찰력과 철학 Philosophy를 갖고 있어야 한다고 주장했다.\n 254p  1977년부터 1997년 사이에 태어난 N세대의 특징은 - 선택의 자유를 최고의 가치로 여기고 - 협업에 익숙하며 - 사실 여부를 늘 검증하려고 하고 - 재미와 스피드를 추구한다.\n 258p  사일로(Silo) 바이오기업 몬산토 휴 그랜트 사장 무엇보다 연구 인력과 경영 관리 파트의 직원들이 함께 모여 일을 하기 시작했어요. 많은 기술 중심 회사들은 연구 인력과 경영 인력이 따로 근무하고, 별로 교류하지 않습니다. 그리고 위계 서열이 뚜렷하죠(경영 관리 인력이 주도권을 잡는다는 의미)\n 269p  SAS 좋은 복지 프로그램을 제공하면 직원들 스스로 회사를 다니는 일에 가치를 느끼고 만족해가기 때문이에요. 회사가 직원을 만족시키면 직원들은 좋은 제품을 개발해 외부 소비자를 만족시킨다. 고객을 행복하게 하려면 고객과 만나는 쌔스의 직원들이 행복해야 합니다.\n 271p  직원이 행복해야 고객이 행복할 수 있다는 점만은 어떤 조직에나 통용된다는 점이다. 직원이 행복하지 않은데, 어떻게 동기를 부여받을 거이며, 어떻게 스스로 열심히 일해 좋은 제품과 서비스를 창출할 것인가? 조직의 통은 조직원들의 만족과 행복을 끌어내고, 이것은 다시 고객의 만족과 행복으로 이어진다. 만족과 행복은 끊임없이 확대재생산되는 것이다.\n 273p  그렇다면 어떻게 해야 조직원이 위에서 내려오는 과업에 대해서도 마치 내발적 동기에 의해 하는 일처럼 스스로 신이 나서 열심히 하게 만들 수 있을가? 이와 관련해 에드워드 데시 교수를 비롯한 자기 결정성 이론 심리학자들이 개발한 개념이 내재화 Internalization이다. 즉 외부 요인에 의해 자극되거나 통제되는 행동의 경우에도 조직이 인간의 3가지 기본적 욕구를 충복만이 환경을 구축해 지원할 경우, 사람들은 일을 스스로의 것으로 내재화하고 통홥하게 된다는 것이다.275p데시 교수는 일견 재미없는 일일지라도 그것을 왜 해야 하는 지 근본적인 이유를 제시하고, 그 일에 대한 상대방의 관점과 느낌을 존중해주며, 스스로 선택하는 경험을 많이 할 수 있게 하고, 일에 대한 압력을 최소화하라고 조언한다.\n 277p  20세기 초반 이후로 관리자들의 임무란 \u0026lsquo;어떻게 하면 웬만한 실력의 기술자들을 데려와서 같은 일을 빠르고 정확히 반복하게 만들까\u0026quot;였죠. 기업의 경영 구조 자체가 혁신을 생상하도록 설계된 것이 아니라 같은 일을 반복하도록 설계돼 있기 때문입니다.\n 278p  리더의 역할은 직원 저마다가 가진 재능과 지식을 효율적으로 한데 모으는 것이지, 그들이 무작정 일을 더 열심히 하도록 만드는 게 아닙니다. 똑똑한 사람들이 일을 많이 하도록 하는 게 결코 중요한 문제가 아닌 거죠.\n 279p  피터 센게 교수 내가 보기에 아무도 도발하지 않는 조직은 가장 위험한 조직입니다. 깊은 곳에 문제점이 있는데도 자칫 계속 문제를 썩힐 수 도 있으니까요. 건강한 조직은 서로 속을 터놓고 애기하기 때문에 문제를 실시간으로 파악하고 해결할 수 있습니다. \u0026lsquo;내가 이런 말을 해서 일자리를 잃으면 어떻게 하지?', \u0026lsquo;이 얘기를 했는데 누군가 나를 비웃으면?\u0026rsquo; 이라는 걱정들로 가득 찬 조직은 희망이 없는 조직이죠. 겉으로는 통제가 잘 되는 것처럼 보이기 때문에 CEO를 흐뭇하게 만들 수도 있지만, 수면 아래엔 문제점들이 그득할 것입니다. 센게 교수에 따르면 두려움으로 경영되는 조직은 방어직 사고에 의해 억압된 조직이라고 표현할 수 있다. 이런 조직 속에선 모든 사람들이 항상 다른 사람에게 \u0026lsquo;내가 그 문제에 대한 답을 갖고 있다\u0026rsquo;는 확신을 주기 위해 노력한다. 그렇기 때문에 어떤 상황에서도 자심감 찬 모습만을 보이기 위해 분투한다. 뿐만 아니라 자기 자신이나 다른 사람을 \u0026lsquo;부끄럽게 만드는\u0026rsquo; 이슈들을 제기하는 것을 매우 꺼리게 된다. 중요한 이슈이긴 하지만 어렵거나 당황스러운 주제에 대해 얘기하는 것을 피하는 것이다. 이런 폐해를 없애기 위해서는 모든 구성원이 비전을 공유하고, 같이 머리를 맞대=고, 함께 살아남기 위해 노력한다는 정신을 심어야 한다는 것이 그의 주장이다.\n 282p  Gore사 상사나 부하가 없는 완전한 수평 조직이어서 모두가 동료(Associate)로 불리운다. 빌 고어는 더글러스 맥그리거 Douglas McGregors의 Y이론에 대한 믿음을 바탕으로 독특한 조직을 만들었다. Y이론이란 성선설로 인간은 오락이나 휴식뿐 아니라 자존과 헌신에 대해서도 본성적으로 욕구가 있으므로, 자발적으로 일할 마음을 갖게 하면 능력의 극대화가 가능하다는 분석이다.\n 288p  리더의 책무는 매일 회사를 빠져나가는 그 90%의 중요 자산이 내일 다시 회사로 돌아와서 재미있게 일하도록 하는 것이다.\n ","id":202,"section":"posts","summary":"혼창통by 이지훈 8p 혼 : 가슴 벅차게 하는 비전이 사람을 움직인다. 창 : 끊임없이 \u0026ldquo;왜\u0026quot;라고 물어라, 그러면 열린다. 통 : 만나라, 또 만","tags":["Book"],"title":"(책) 혼. 창. 통.","uri":"https://cychong47.github.io/2014/09/caeg-hon-cang-tong/","year":"2014"},{"content":"VirtualBox에 DPDK 설치하기 참고\nVirtualBox 설치하기 통상적인 절차대로 VirtualBox를 설치하고, Ubuntu 14.04 LTS 설치한다. DPDK는 32bit와 64bit를 모두 지원하지만 64비트를 사용하는 것이 좋다. Application에 따라 많은 양의 Memory를 사용할 수도 있으므로.\nNIC 카드 추가 VirtualBox가 지원하는 NIC에 Intel 82540EM과 82545EM이 있다. 둘 다 DPDK에서 지원하는 1G NIC이다. 이 중에서 82545EM 카드를 2개 추가한다.\nVirtualBox의 Guest OS를 종료시킨 상태에서 환경 설정에서 Network \u0026gt; Adapter 항목에서 Adapter 2, Adapter 3를 활성화시킨다.\n그 결과 총 3개의 NIC이 설치되었다.\n그리고 interface 속성을 Bridged Adapter 형태로 설정한다.(Bridged Adapter는 NAT 없이 외부(Host OS를 통해)와 통신할 수 있는 방식이다. NAT를 사용하지 않으므로 Bridged Adapter에는 외부와 직접 통신할 수 있도록 고유한 IP를 할당하거나, 외부에서 IP 할당을 해야 한다)\nSSE 사용하기 근래 버전의 DPDK는 SSE가 필수다(hash 라이브러리등에서) SSE를 사용하려면 아래와 같이 설정한다. 괄호 안의 Ubuntu 14.04는 VM 이름이다.\nmini-2011:~ cychong$ VBoxManage setextradata \u0026quot;Ubuntu 14.04\u0026quot; VBoxInternal/CPUM/SSE4.1 1 mini-2011:~ cychong$ VBoxManage setextradata \u0026quot;Ubuntu 14.04\u0026quot; VBoxInternal/CPUM/SSE4.2 1  DPDK 설치 git clone git://dpdk.org/dpdk  DPDK 빌드 export RTE_SDK=/home/cychong/dpdk export RTE_ARCH=x86_64 export RTE_TARGET=x86_64-native-linuxapp-gcc make config T=x86_64-native-linuxapp-gcc  l2fwd 실행하기 Build cychong@ubuntu:~/dpdk/examples/l2fwd$ make CC main.o LD l2fwd INSTALL-APP l2fwd INSTALL-MAP l2fwd.map  igb_uio 커널 모듈 설치 DPDK application은 User-level application으로 PCI를 통해 연결된 NIC에 접근하기 위해 User-Space IO(1, 2 참고)를 이용하므로 커널 모듈을 설치해야 한다.\ncychong@ubuntu:~/dpdk$ sudo insmod /lib/modules/4.13.0-32-generic/kernel/drivers/uio/uio.ko cychong@ubuntu:~/dpdk$ sudo insmod x86_64-native-linuxapp-gcc/kmod/igb_uio.ko  lspci 명령을 보면 Virtualbox에는 총 3개의 NIC가 존재하고, 이중 PCI ID 00:03.0은 Host OS와의 통신에 사용되는 Adapter 1이므로 이를 제외한 나머지 2개 00:08.0과 00:09.0을 DPDK용으로 사용한다.\ncychong@ubuntu:~$ lspci |grep Intel |grep 8254 00:03.0 Ethernet controller: Intel Corporation 82540EM Gigabit Ethernet Controller (rev 02) 00:08.0 Ethernet controller: Intel Corporation 82545EM Gigabit Ethernet Controller (Copper) (rev 02) 00:09.0 Ethernet controller: Intel Corporation 82545EM Gigabit Ethernet Controller (Copper) (rev 02)  Kernel에 포함된 device driver igb에 연결되어 있는 어댑터를 뺏어온다.\ncychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py --status Network devices using DPDK-compatible driver ============================================ \u0026lt;none\u0026gt; Network devices using kernel driver =================================== 0000:00:03.0 '82540EM Gigabit Ethernet Controller' if=eth0 drv=e1000 unused=igb_uio *Active* 0000:00:08.0 '82545EM Gigabit Ethernet Controller (Copper)' if=eth1 drv=e1000 unused=igb_uio 0000:00:09.0 '82545EM Gigabit Ethernet Controller (Copper)' if=eth2 drv=e1000 unused=igb_uio Other network devices ===================== \u0026lt;none\u0026gt;  위에서 eth1, eth2를 DPDK용으로 사용하기 위해 아래와 같이 우선 unbind하고 igb_uio에 bind한다.\ncychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py -u 0000:00:08.0 cychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py -u 0000:00:09.0 cychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py --bind=igb_uio 0000:00:08.0 cychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py --bind=igb_uio 0000:00:09.0  L2fwd 실행하기 cychong@ubuntu:~/dpdk$sudo examples/l2fwd/build/l2fwd -c 0x2 --no-huge -w 00:0:08.0 -w 00:0:09.0 -n1 -- -q 8 -p 3 cychong@ubuntu:~/dpdk$ sudo examples/l2fwd/build/l2fwd -c 0x2 --no-huge -w 00:0:08.0 -w 00:0:09.0 -n1 -- -q 8 -p 3 EAL: Detected lcore 0 as core 0 on socket 0 EAL: Detected lcore 1 as core 1 on socket 0 EAL: Support maximum 64 logical core(s) by configuration. EAL: Detected 2 lcore(s) EAL: cannot open VFIO container, error 2 (No such file or directory) EAL: VFIO support could not be initialized EAL: Setting up memory... EAL: TSC frequency is ~2321680 KHz EAL: WARNING: cpu flags constant_tsc=yes nonstop_tsc=no -\u0026gt; using unreliable clock cycles ! EAL: WARNING: Master core has no memory on local socket! EAL: Master core 1 is ready (tid=ef771840) EAL: PCI device 0000:00:08.0 on NUMA socket -1 EAL: probe driver: 8086:100f rte_em_pmd EAL: PCI memory mapped at 0x7fd5ef71b000 PMD: eth_em_dev_init(): port_id 0 vendorID=0x8086 deviceID=0x100f EAL: PCI device 0000:00:09.0 on NUMA socket -1 EAL: probe driver: 8086:100f rte_em_pmd EAL: PCI memory mapped at 0x7fd5ef6fb000 PMD: eth_em_dev_init(): port_id 1 vendorID=0x8086 deviceID=0x100f Lcore 1: RX port 0 Lcore 1: RX port 1 Initializing port 0... PMD: eth_em_rx_queue_setup(): sw_ring=0x7fd5eb358c80 hw_ring=0x7fd5ed71eb00 dma_addr=0x7fd5ed71eb00 PMD: eth_em_tx_queue_setup(): sw_ring=0x7fd5eb356b80 hw_ring=0x7fd5ed72eb00 dma_addr=0x7fd5ed72eb00 PMD: eth_em_start(): \u0026lt;\u0026lt; done: Port 0, MAC address: 08:00:27:41:5F:94 Initializing port 1... PMD: eth_em_rx_queue_setup(): sw_ring=0x7fd5eb356580 hw_ring=0x7fd5ed73eb00 dma_addr=0x7fd5ed73eb00 PMD: eth_em_tx_queue_setup(): sw_ring=0x7fd5eb354480 hw_ring=0x7fd5ed74eb00 dma_addr=0x7fd5ed74eb00 PMD: eth_em_start(): \u0026lt;\u0026lt; done: Port 1, MAC address: 08:00:27:2B:31:74 Checking link statusdone Port 0 Link Up - speed 1000 Mbps - full-duplex Port 1 Link Up - speed 1000 Mbps - full-duplex L2FWD: entering main loop on lcore 1 L2FWD: -- lcoreid=1 portid=0 L2FWD: -- lcoreid=1 portid=1 Port statistics ==================================== Statistics for port 0 ------------------------------ Packets sent: 0 Packets received: 0 Packets dropped: 0 Statistics for port 1 ------------------------------ Packets sent: 0 Packets received: 0 Packets dropped: 0 Aggregate statistics =============================== Total packets sent: 0 Total packets received: 0 Total packets dropped: 0 ====================================================  다음에는 패킷 송수신 관련 기능을 실제로 시험해 본다. DPDK와 같은 user-mode IO를 사용하는 경우의 핵심인 PMD(Poll Mode Driver)를 이용해서 외부에서 수신되는 패킷을 처리하는 것과, DPDK 1.7에 추가된 Pcap 파일 혹은 ring을 이용해서 패킷을 받는 경우를 알아본다.\n참고 ","id":203,"section":"posts","summary":"VirtualBox에 DPDK 설치하기 참고 VirtualBox 설치하기 통상적인 절차대로 VirtualBox를 설치하고, Ubuntu 14.04 LTS 설치한다. DPDK는 32bit와 64bi","tags":["DPDK","Virtualbox"],"title":"DPDK on VirtualBox","uri":"https://cychong47.github.io/2014/09/dpdk-on-virtualbox/","year":"2014"},{"content":"p24  만약 직원이 자신이 하려는 도전에 따르는 책임을 받아들이려고 한다면, 많은 조직이 책임을 더 부여하려고 할 것이다.\n p32 Rolf Dobelli 스마트한 생각들, 스마트한 선택들  \u0026lsquo;확증 편향\u0026rsquo;. 사람은 자신이 확실하는 일에 대해 옳다고 증명해주는 증거들만 철석같이 믿지요.\n\u0026lsquo;사회적 검증\u0026rsquo;도 대단히 안 좋고 위험한 행동 오류.\n권력이나 권위 있는 사람들의 말을 무조건 믿는 \u0026lsquo;권위자 편향\u0026rsquo; 또한 위험. 전 세계적으로 경제학자 수는 100만 명이 넘지만 단 1명도 2008년 금융 위기를 정확히 예측하지 못했다. 당장 눈앞에 펼쳐진 자료들을 과신하는 \u0026lsquo;가용성 편형\u0026rsquo;\n p34  확증 편향에 빠지는 것은 경계해야 합니다. 몇 차례 옳은 결정을 내렸다고 해서 차츰 자기 결정을 과신하는 확증 편향에 빠지기 쉽지요. 큰 권력을 가진 리더일수록 직언을 하는 참모가 반드시 2~3명은 있어야 합니다. 결정을 내리기 전 이 사람들에게 의견을 묻고 일부러 반대 의견을 내달라고 하십시오. CEO들은 사실 매우 외롭습니다. 누군가 자기 의견에 반대해주길 바라지요. 자기 관점과 다른 관점에서 의견을 듣고 싶어합니다.\n p35  나쁜 리더의 가장 흔한 공통점은 \u0026lsquo;사회적 검증\u0026rsquo; 오류를 자주 범한다는 것입니다. 경쟁사의 특정 제품이 성공을 거두면 나쁜 리더들은 자기 부하들에게 \u0026lsquo;왜 저런 걸 못 만드느냐\u0026rsquo;고 질책합니다. 그 원인이 자신한테 있을지 도 모르는데. 그러다가 결국 복제 제품을 내 놓는 겁니다. 이는 곧 업계에서 한 걸음 뒤처지는 것을 의미하지요.\n또 다른 공통점은 나쁜 리더 대부분이 마이크로 매니저라는 점입니다. 회사의 사소한 일이나 직원 개개인의 일거수일투족까지 관리 감독하려 들지요. 그러나 돌이켜보면 한 회사가 성공을 거두려면 올바른 산업에 진출했는가가 더 결정적입니다. 즉 당신이 노를 잘 젓는것도 중요하지만, 그보다 애당초 좋은 배에 타는 게 훨씬 낫다는 겁니다.\n p86 Sam Horn  텅 후(Tongue-Fu) 의 핵심은 한마디로 요약하자면 \u0026lsquo;선택\u0026rsquo;입니다. 남들의 도발에 어떻게 대응할지, 무시할 지 등. \u0026hellip;\n선택 1 \u0026ldquo;상대를 바꾼다\u0026rdquo; 불가능 선택 2 \u0026ldquo;상황을 바꾼다\u0026rdquo; 요청, 부탁 등\n선택 3 \u0026quot; 나를 바꾼다\u0026rdquo; \u0026lsquo;세상을 바꿀 수 없으니 내가 바꿔어야겠다\u0026quot;고 마음먹고 행동 패턴을 바꾸는 것\n p89  예를 들어 업무가 너무 많아 야근이 잦은 게 문제라면 지난 주 당신의 출퇴근 및 업무 시간을 정확히 적어둔 차트를 보여주세요. 상사가 시킨 일을 처리하는 데 정확히 몇 시간씩 걸렸는지 보여주세요.\n절대로 \u0026lsquo;일이 너무 많아요\u0026rsquo;하고 투정부리지 마세요.\n p90 Howard Stevenson 명예 교수  부하를 질책할 때는 \u0026lsquo;~했어야지\u0026rsquo;라는 표현을 피하세요. \u0026lsquo;지각할 것 같으면 전화했어야지!\u0026rsquo; 이런 문장은 말의 톤은 상대에 대한 존중이 없고 짜증을 부릅니다. 부하는 자기가 잘못했어요 \u0026lsquo;이미 지나간 일을 지금 와서 어쩌라는 거야\u0026rsquo;하며 반감을 갖지요. \u0026lsquo;~했어야지\u0026rsquo;대신 미래 지향적 단어 \u0026lsquo;다음부터는~'을 쓰도록 하세요. 이 한마디로 상사는 비판자에서 조언자로 바뀝니다.\n p97  전환점이란 지금까지 달려오던 것과 전혀 다른 쪽으로 완전히 방향을 트는 것을 말합니다. 단지 살짝 변화만 주는 차원이 아니에요. 중요한 것은 그 전환점에 우리의 잠재력을 이끌어낼 엄청한 힘이 있다는 겁니다. 미셸은 회사가 조직을 개편하고 자신에게 어떤 기회를 주는지에 따라 행동하기로 결정했어요. 그러나 그냥 좋은 방향으로 풀리기만 기다렸지요. 저는 그냥 기다리지 말고 주도적으로 회사에 자기 목소리를 내야 한다고 조언했어요. 이런 게 바로 인생의 전환점입니다.\n p98  경주마는 단순히 골인 지점만 보고 달립니다. 반면에 야생마는 가야 할 곳이 어딘지 피할 곳이 어딘지 끊임없이 생각하고 때로는 천천히 달리기도 하지요. 경주마는 달리기 위해 생각을 멈추지만 야생마는 생각하기 위해 달기리를 멈춥니다.\n p126 Daniel Pink  고객 스스로도 모르는 문제를 발견하기 위해서는 고객에게 적절한 질문을 던저야 한다는 것이다. 그는 과거에 최고의 세일즈맨은 고객의 질문에 대답하는 데 능통했다면, 요즘 최고의 세일즈맨은 고객에게 좋은 질문을 하는 사람이라고 한다. 좋은 질문을 하려면, 질문 리스트를 만든 뒤 각 질문의 장단점을 생각하며 질문의 우선순위를 정하는 연습을 하라고 그는 조언했다.\n p148  한국도 조직 위계질서가 세계에서 아주 강한 곳 중 하나라고 생각합니다. 사람들이 창의적인 생각을 자유롭게 표현하고 실현할 기회가 주어지지 않은 상태에서 창의적 인재가 나오기 어려울 것이라고 생각합니다.\n p250 Olivia Lum, Hyflux CEO  우리는 개별 연구원들이 시장 가치가 없는 연구 분야에 매몰되지 않도록 물산업 시장 전문가들을 연구에 투입합니다. 연구원들에게 시장이 필요로 하는 상품이 무엇인지 교육시키고 분야 간 소통을 원활하게 해 통합적 사고를 하도록 합니다.\n p253  어떤 꿈이든 지 꿈을 가지셍. 꿈을 갖고 노력하다보면 기회가 찾아옵니다. 기회는 당신이 만드는 것입니다. 그리고 그 기회를 잡으세요. 꿈이 없으면 당신의 모든 것이 끝납니다. 꿈꾸는 것을 멈추지 마세요.\n p262 자오위핑, 백가강단(CCTV)  업무나 시장 상황이 비교적 단순한 기업에서는 조조의 방식이 성공하기 쉽습니다. 반면 업무가 복잡하고 변화가 급할수록 유비형 방식이 성공하기 쉽습니다. 간단하고 단순한 업계는 통제해야만 잘 돌아가고, 복잡한 쪽은 전문가들이 능력을 잘 발휘할 수 있도록 지지해야 조직이 잘 돌아가게 마련이니가요. 지금까지는 조조형 리더가 많았지만, 앞으로는 기업 문화가 바뀌면서 유비의 방식이 더 중요해질 것입니다.\n이상작 중간 관리자로는 제갈량, 이상적 일선 직원으로는 조자룡을 들었다. 제갈량은 만사 일처리가 착실하고 디테일을 잘보면서도 큰 그림을 놓치지 않았습니다. 위로는 보스의 신임을 얻고 아래로는 병사들의 존경을 받았지요. 조자룡은 능력이 뛰어나고 충성심이 강했습니다.\n p265  구성원들의 능력에 따라 각기 다른 비전을 제시해야 합니다. 비교적 능력이 약하고 평범한 집단에는 편안함과 만족을 보장해주면 족합니다. 하지만 능력이 뛰어나고 자존감이 강한 구성원이 모인 집단에서는 그런 만족감만으로는 직원들을 붙들어둘 수 없습니다. 이상이나 이념, 가치관을 실현해줄 수 있어야 합니다. 이들이 자아를 실현하고 꿈을 이룰 수 있도록 비전을 줘야 합니다.\n p277 John Rice GE 부회장  GE는 늘 배우는 문화를 가진 회사입니다. 오늘의 나는 작년의 나보다 더 나은 리더가 돼야 합니다. 또한 내년에는 올해보다 더 성장해야 하고요. 이는 실수에서 배우고, 새로운 나라와 문화, 시장, 제품에서 늘 배우려는 문화가 있어야만 가능합니다.\n p278  뭔가 하나라도 남달리 잘하는 게 있는 사람인가입니다. \u0026hellip; 요즘 같은 세상에서 직장을 가지려면 처음엔 뭔가 하나라도 남들보다 잘하는 게 있어야 합니다. 일단 뭔가 하나에 강한 상태로 출발하고, 다른 일반적인 기술들은 승진을 해가면서 배우면 됩니다.\n p322 Teresa Amabile  성과를 높이기 위한 가장 좋은 방법은 직원들에게 긍정적 기분을 만들어주는 것이다. 사람이 기뻐할 때 자신의 업무 환경에 대해 긍정적으로 인식하고, 자신의 업무에 강력한 동기 부여를 받을 때 가장 창의적이 된다는 것이다. 최고의 기분을 유지하는 하루를 만드는 방법은 매일 사소한 업무라도 의미 있는 작은 성공을 맛보게 해주는 것 입니다.\n p326  인정을 받은 안 받는 일에서 성과를 내는 것 자체가 더 중요한 겁니다. 의미 있는 일을 하고 거기서 뭔가 진전을 이뤄낸다면 사람은 긍정적 감정을 갖게 됩니다. 동료와 사이가 좋아지고, 강력한 동기 부여가 됩니다. 게다가 뭔가 인정을 받기 위해선 업무에서 어떤 형태로든 작은 성공을 맛봐야 해요. 실제로 성과를 내지 않았는데 인정을 받는다면 직원은 매우 냉소적으로 바뀝니다.\n p328  직원이 업무에게 진전하게 하려면 관리자는 어떻게 해야 할까? 첫째, 일단 명확한 목표를 심어준다. 둘째, 명확한 목표를 심은 뒤에는 자율성을 부여해야 한다. 사소한 일에 간섭하고 시시콜콜한 내용까지 지시하는 것은 최악이다. 심리적 안정감을 주는 기업 문화가 필요하다. 실패했다고 부하직원을 억누르고 비난하고 비판하고 처벌하는 행위를 멈춰야 한다.\n ","id":204,"section":"posts","summary":"p24 만약 직원이 자신이 하려는 도전에 따르는 책임을 받아들이려고 한다면, 많은 조직이 책임을 더 부여하려고 할 것이다. p32 Rolf Dobelli 스마트한 생각들, 스마트한 선택들 \u0026l","tags":["Book"],"title":"(책) 더 인터뷰","uri":"https://cychong47.github.io/2014/09/caeg-deo-inteobyu/","year":"2014"},{"content":"김진애\np32  뒤를 돌아보면, \u0026ldquo;1년 동안 공부만 할 거야!\u0026ldquo;하고 결단하고 그 결단을 독하게 지켰던 체험을 통해 얻은 가장 큰 자산은 \u0026lsquo;독해야 할 때 독해질 수 있다;는 자신감이다. 이 자신감은 내 일생 내내 큰 자산이 되었다. \u0026lsquo;필요하다면 유혹을 끊어낼 수 있다. 잔가지들에 연연해하지 않을 수 있다. 내 온 자신을 던질 수 있다. 몰입할 수 있다\u0026rsquo;는 믿음은 중요하다. 한번 독해지기를 경험해보면 언제나 독해질 수 있는 것이다.\n p77  무시당하는 느낌이 없어졌다. 조롱당하는 느낌, 모욕당하는 느낌도 없어졌다. 기대를 받는다는 느낌도 생겼다. \u0026ldquo;이거 해도 되나?\u0026rdquo; 자문하던 주저감이 줄어들었다. \u0026ldquo;이거 말해도 되나? 이런 거 물어봐도 되나?\u0026rdquo; 같은 자기검열도 사라졌다.\n\u0026hellip;\n사람 대접받는다는 느낌, 같은 사람으로 대할 수 있고 대해질 수 있다는 느낌이었다. 서로의 차이는 있지만 가능성은 누구에게나 열려 있고 역할은 누구에게나 주어질 수 있다는 분위기였다.\n새로 얻은 중요한 깨달음이 있다. \u0026lsquo;말해야 한다\u0026rsquo;는 것이다. 말하지 않으면 아는 것도 아는 게 아니며, 자신의 의견을 말해야 비로소 상대와 통할 수 있고, 말로 표현되어야 생각이 정제되고 발전되며, 말하는 행위 자체가 상대에 대한 존중이라는 분위기였다. 얼마나 큰 변화이랴. \u0026lsquo;말을 하면 상처만 커진다\u0026rsquo;는 생각 때문에 어릴 적에 입을 닫고 답답해했고, 자라면서는 \u0026lsquo;말하면 다친다. 말조심해야 한다\u0026rsquo;는 압박 때문에 갑갑했던 \u0026lsquo;말의 족쇄\u0026rsquo;가 드디어 풀렸다.\n p113  그 파워는 바로 \u0026lsquo;통찰력\u0026rsquo;에서 나온다. 핵심 개념을 세우고 개념을 스토리로 전개하는 파워. 어떻게 90분 동안 이렇게 마음을 흔들어놓을 수 있나? 통찰력이란 그렇게 중요하다. 전체를 통찰하는 힘, 구조를 파악하는 힘, 핵심을 파악하는 힘, 개념을 세우는 힘, 전체와 부분의 연관성을 이해하는 힘, 이런 지적 \u0026lsquo;통찰력\u0026rsquo;은 우리 모두 지향해야 할 파워다.\n p141  창업하면서 꼭 각오해야 할 것이 있다. \u0026lsquo;세상은 별로 당신에게 관심이 없다\u0026rsquo;는 냉정한 사실이다. 다른 사람들의 성공적 창업 스토리를 주목해주는 것은 TV나 강연회에서나 일어나는 일이다. 현실에서는 \u0026lsquo;당신은 대체재로 보일 것이다. 당신은 도구로 보일 것이다. 당신은 소모재로 보일 것이다\u0026rsquo;라는 엄연한 사실이 기다린다. 이 냉정한 현실을 냉철하게 받아들이자. 그리고 실망과 좌절과 손해와 분노를 딛고 살아남자. 또 새로운 가능성을 모색해보자.\n p158  하기 싫어도 해야 하는 일을 할 때, 나는 배울 것 한 가지를 아예 미리 정해놓는다. 사실 아무리 하기 싫더라도 배울 것 하나 없는 일은 이 세상에 없다. 게다가 아무리 하기 싫은 일이라도 열심히 하다 보면 일 자체에 빠지게 되기도 한다. 인간의 본능 중 하나인 성실성이 작동하는 것이다. 여기에 긍정적인 동기 한 가지만 곁들이면 속으로 회심의 미소 하나 지을 게 생긴다.\n p186  언어의 기본은 듣기가 먼저인 것이다. 언어의 순수함, 아름다움, 세련됨을 즐기게 되고 또한 조악하고 천박하고 비논리적인 언어를 분별하게 되는 이점과 함께, 많이 들을 수록 이야기하는 능력도 따라서 자란다. 사람들은 누구나 이야기를 잘하고 싶어 한다. 이야기를 잘하려면 먼저 잘 듣자.\n p229  가장 근사한 팀이란, 위아래 가리지 않고, 왜 이 일을 하는지에 대한 가치를 공유하고, 일하자고 만났으면 5분 만에 일로 돌입하고, 서로의 시간을 아껴주고, 서로의 특성을 독려하고, 서로의 능력을 키워주며, 소모적인 실적 경쟁이 아니라 일의 대승적인 퍼포먼스를 위하여 생산적인 경쟁 협력을 하는 팀이다. 그런 팀워크가 가동된다면 얼마나 좋을까\n좋은 팀워크에 필요한 것은 수도 없이 많다. 그중 팀장의 리더십 역할에 대해서는 아무리 강조해도 지나치지 않다. 팀에 기원을 불어넣어주고 힘을 키워주는 것이 팀장의 역할이다. 그렇다고 팀워크의 리더십에 하나의 정답만이 있는 것은 아니다. 때로는 카리스마가 필요하고, 때로는 헌신이 필요하며, 당근과 채직을 적절히 구사해야 하기도 하고, 왜 이 일을 하는지에 대한 가치를 공유할 수 있도록 해야 하며, 밀고 당기는 리듬도 필요하고, 에너지의 높낮이를 조절하는 호흡도 필요하다.\n p243  거대한 수레바퀴가 돌아가는 이런 사회에서 자신만은 살아남을 수 있다고 생각하는가? 자신만은 살아남아야 한다고 생각하는가? 이렇게 생각하기 시작하는 순간, 과잉 경쟁의 잔혹한 수레바쿠에 치이는 대가를 감수해야 할 것이다. 자본과 권력이란 워낙 잔혹하다. 당신이 아무리 우수하고 탁월하더라도 이용당하며, 시시때때로 밟히고, 어느 시점에는 배신을 당할 것이다. 그 자리에 연연할수록 잔혹한 수레바퀴 사이에 끼어서 으스러질 위험만 커진다. 조직의 논리 속에서 개인의 능력이란 아주 미미한 변수가 될 뿐이다.\n p245  사회의 유연성을 높이는 과제는 별도로 하더라도, 우리 자신의 유연성을 높이는 것은 우리 자신이 해야 할 일이다. 당신의 유연성을 높여라. 다양한 옵션에 눈을 열어라. 한 분야에서 오랫동안 일을 하더라도 일하는 환경은 끊임없이 바뀌는 것이 정상이다. 일하는 프로젝트가 바귀고, 주제도 바뀌고, 직책도 바뀌고, 일하는 조직도 바뀐다. 특정한 일을 통해 그 어떤가를 배웠으면, 그 다음 단계를 생각하고, 관련되는 다른 일을 구상하라. 아직 변화를 실천으로 옮기지 못했다 하더라도 머릿속에 시나리오를 계속 만들어두라. 실천으로 옮길 \u0026lsquo;때\u0026rsquo;는 반드시 올 것이다.\n매너리즘에 빠지기 전에 떠나자. \u0026lsquo;숙련된 조교\u0026rsquo;라는 말이 있다. 일에 숙달되는 것은 좋은 일이지만 계속해서 숙달된 조교만 하다가는 매너리즘에 빠지고야 만다. 지금 하는 일에 숙달되었다고 생각되면 이제 떠날 때가 되었고 다른 일을 찾을 때가 되었다. 변화란 항상 위험을 동반하는지라, 주변에서 말리고 가족들이 말리고 또 주저하는 자신을 느끼게 될 것이다. 그러나 위험이 다가오기 전에 주체적인 선택을 하는 것일 뿐이다. 잘리기 전에 먼저 떠나자. 정체하기 전에 먼저 새 길을 찾자. 떠나기를 강요받기 전에 자신이 선택해서 새로운 길을 찾아 나서는 것이 길게 보면 훨씬 더 좋다.\n p249  바로 지금, 지금과는 다른 삶의 옵션을 준비해두자. 어차피 우리 인생은 제2, 제3의 인생을 살아야 할 만큼 길기도 하다. 5년 후에 어디에서 어떠한 일을 할 것인가? 10년 후에는 또 어디에서 어떠한 역할을 할 것인가? 오직 한 가지 일만 들이파는 것으로써만 인생이 완성될 수는 없다. 주제는 하나이되 수없는 변주를 해나가야 자신의 음악이 완성되는 것이다.\n관건은 타이밍이다. 언제 어떻게 새로운 일감을 찾아서 자신의 일로 만드느냐 하는 것이다. 인생의 티이밍은 참으로 중요하다. 평생을 생각하고 타이밍을 고민해보자.\n p250  공부하고 일하는 방식은 변하지 않는다. 말하자면, 고기 잡는 방식은 크게 바뀌지 않는다. 다만 잡는 고기와 배 띄우는 바다가 달라지는 것뿐이다. 당신이 학교와 프로 생활에서 배우는 공부와 일하기 방식은 큰 흐름 속에서 하나의 단계일 뿐이다. 그 어느 자리에서 그 어느 일을 통해 잘 배우고 깨달음을 얻었다면, 이제 다음 과정을 생각해 보라. 새로운 도전과 모험을 향하여!\n p256  어떻게 세종 시대, 정조 시대에는 그렇게 탁월한 인물들이 많이 나왔을까? 서구의 르네상스 시대에는 그렇게 근사한 인물들이 쏟아졌을가? 라는 화두다. \u0026hellip; 인물을 발탁하고 좋은 일들을 발굴하는 \u0026lsquo;리더\u0026rsquo;의 역할도 분명 클 것이다. 당시의 정치 리더들은 강력한 혁신 리더들어었으니 말이다. 그런데 아마 그 시대에 일어났음직한 수순은, \u0026lsquo;개인의 리더\u0026rsquo;에서 \u0026lsquo;그룹 리더십\u0026rsquo;으로 발전되었을 것 아닐까? 좋은 사람은 좋은 사람들을 끌어들이고, 인물은 인물을 알아본다. 탁워할 일은 시기와 질투의 대상이 아니라 더욱 탁월한 일들을 자극하게 되는 것이다. 사람들은 이런 선순환 구조에 더욱 자극을 받고 더욱 노력하고 모색했던 상태였을 것이다. 탁월한 공부생태계가 자연적으로 만들어졌던 행복한 상황이었을 것이다.\n p258  우리가 리더를 인정하는 것은 어떤 경우에나 총괄 지휘가 필요하다는 것을 알기 때문이다. 우리가 리더의 리더십을 인정하는 것은 그 리더가 꼭 특출하거나 훌륭해서만은 아니다. 리더십이 흔들리면 플레이가 당장 깨질 위험이 높기 때문에 인정하는 것뿐이다. 리더란 잠시 잠깐 책임과 권한을 가지는 것일 뿐이다. 리더가 진정한 리더십을 똑독하게 고민한다면, 자신의 리더십으로 어떻게 그룹의 리더십을 끌어낼 수 있을까 고민해야 한다. 리더는 자신이 그 자리에 있는 이유는 바로 그 때문이고, 자신이 물러난 이후에도 사회의 리더십이 뿌리내리는 것의 중요성을 알아야 한다.\n p268  21세기적으로 착하려면 도덕성만으로는 안된다. 마음만으로는 안 된다. 아주 영리해야 한다. 머리를 써야 하고, 시간을 들여 정보를 파악해야 하고, 거짓말을 분별해내야 하고, 왜 착한 소비가 결국 나와 우리를 위해 좋은 지 논리를 펼칠 수 있어야 한다. 그리고 그것을 개인의 착한 행위에 그치는 것이 아니라 동료와 친구와 이웃과 사회에 전파하는 설득력까지 가져야 한다.\n p269  \u0026lsquo;장금아, 너의 선의를 믿는다. 그러나 선의를 가지고도 능력이 없으면 사람을 상하게 할 수 있다. 너는 할 수 있겠느냐?\u0026rsquo;\n p270  세상은 항상 착한 사람, 착한 동기를 가진 사람을 속이려 들고 무시하려 든다. 성실함과 부지런한과 배려심을 악용하려 든다. \u0026hellip; 경제 감각은 필수다. 어떤 경우에나 돈 감각, 경영 감각, 산업 감각, 거시경제 감각을 갖고 있어야 설득력 있는 대안을 만들어낼 수 있다. 사회의 많은 대안들은 이익을 어떻게 만드느냐, 누구에게 이익이 가느냐, 누가 일할 수 있게 만드느냐, 어떻게 안정을 꾀하느냐에 대한 대안이 포함되어야 설득력을 가지며 그래야 통한다.\n ","id":205,"section":"posts","summary":"김진애 p32 뒤를 돌아보면, \u0026ldquo;1년 동안 공부만 할 거야!\u0026ldquo;하고 결단하고 그 결단을 독하게 지켰던 체험을 통해 얻은 가장 큰 자산은 \u0026lsqu","tags":["Book"],"title":"(책) 왜 공부하는가","uri":"https://cychong47.github.io/2014/09/caeg-wae-gongbuhaneunga/","year":"2014"},{"content":" 휴식을 취하라 다양한 활동에 대해 각각의 컴퓨터 모니터를 설치하라. 종이로 된 할 일 목록을 사용하라 한 이메일을 복수의 카테고리로 분류하라. 필요할 때는 통째로 없애라. 간단한 업무와 장기 프로젝트를 위한 시간을 따로 지정하라. 결정을 내릴 때 그 가치보다 더 많은 시간을 들이지 말라 잠을 자라. 직장에서 낮잠을 자라. 지나치게 정리하지 말라 일은 직장에 두고 와라.  출처 : 정보 과다의 시대, 머릿속 정리법 10가지\n","id":206,"section":"posts","summary":"휴식을 취하라 다양한 활동에 대해 각각의 컴퓨터 모니터를 설치하라. 종이로 된 할 일 목록을 사용하라 한 이메일을 복수의 카테고리로 분류하라. 필요할 때는 통째로 없애","tags":["lifehack"],"title":"(펌) 머리속 정리법 10가지","uri":"https://cychong47.github.io/2014/09/peom-meorisog-jeongribeob-10gaji/","year":"2014"},{"content":"추가 해야 할 내용\n MovingCastle에 대한 추가 백업? 혹은 Mini 2011을 이중 백업. Wordpress Blog 내용만 추가로 백업 필요. Ghost Blog 추가 백업  ","id":207,"section":"posts","summary":"추가 해야 할 내용 MovingCastle에 대한 추가 백업? 혹은 Mini 2011을 이중 백업. Wordpress Blog 내용만 추가로 백업 필요. Ghost Blog 추가 백업","tags":["Time Machine","mac"],"title":"Time Machine backup","uri":"https://cychong47.github.io/2014/09/time-machine-backup/","year":"2014"},{"content":"(책) 빅데이터 승리의 과학\nTechnology 팀  오바마 2012년 선거 당시 2008년 당시의 SNS를 활용하는 수준을 넘어서 통합적인 선거 지원을 위해 빅데이터 기술 활용. 선거 특성에 맞는 AWS 를 이용해서 인프라를 구축하고, R 언어를 활용. 하둡은 실시간성이 부족하여 제한적으로 사용. 디지털 팀의 CDS(Chief Digital Strategist)는 31살 Joe Rosparse, CTO는 하퍼 리드(33)등을 고용.\n벤처기업 엔지니어 출신. 혁신을 좋아하고, 기존 틀과 문화에 얽매이지 않고 오직 해결책에만 관심을 둠. 리드는 50명에 이르는 Technology 팀 멤버를 구성. Twitter, Google, Facebook, Craiglist, Quora, orbits, IBM, MS 등에서 일하는 인력들이 합류. \u0026ldquo;외뿔고래(Narwhal)\u0026ldquo;라고 불린 IT 통합 프로젝트 . 하나의 애플리케이션이나 서비스가 아니라 아키텍쳐였으며 전체를 아우르는 API의 집합 서로 다른 형태의 DB를 통합하여 하나처럼 작동하는 시스템 구축. RestFul API를 이용해서 구축 모든 애플리케이션이 오직 외뿔고래 API를 통해서만 DB에 접근할 수 있게 함. 외뿔고래 API를 이용해서 각각의 앱들을 모두 분리시킴으로써 각각의 앱들을 개별적으로 확장할 수 있게 하고, 앱들 간의 데이터를 공유하게 함.  이전 선거 실패에 대한 반성  2000년에 이어 2004년 선거까지 연거푸 패배의 쓴 잔을 마신 민주당 케리 후보 캠프에서 활동했던 사람들과 진보진영의 시민사회단체 활동가 20여 명이 2004년 대선이 끝난 후 2박3일간의 모임을 가졌다. 그 자리에서 그들은 민주당과 진보진영의 문제점과 개선방안에 대해서 치열하게 토론을 갖고, 그 동안 민주당과 시민사회단체들이 너무 선언적인 활동에만 치우치고 자기들끼리만 연대하여 활동하였으며 선거운동은 대부분 상층 정치전략가들에 의해서 좌우되었다고 반성하였다. 그들은 민주당이 선거에서 승리하기 위해서는 대중 속으로 더 파고들어야 하고 더 효율적이고 실질적인 조직활동을 해야 한다고 결론 내렸다.\n Hadoop system 하둡 = HDFS(분산 데이터 저장) + MapReduce(분산 데이터 처리)\nMapReduce\n 파일들이 각기 어디에 위치하고 있는지 기록학 파악하는 지도(맵)를 간소화(reduce)하여 보다 신속하게 파일들의 색인을 구축하고 검색을 용이하게 해주는 색인 체계  Hadoop\n 최소 3군데에 동일 데이터를 저장하여 H/W 오류 시에도 동작할 수 있게 함. 데이터를 소프트웨어가 있는 서버로 옮기는 것보다 데이터가 있는 서버로 소프트웨어를 보내 처리하고 그 결과만 원래 소프트웨어가 있던 서버로 보내서 통합 확장성이 커서 한번에 다룰 수 있는 파일의 양이 매우 많다. 기가/테라 바이트 크기의 파일 처리도 가능. 하나의 클러스터에 수천 개의 노드(컴퓨터)를 둘 수 있고, 하나의 인스턴스(작업)에 수천만 개의 파일을 지원 이식성 및 호환성이 뛰어남  단점\n Hadoop과 MapReduce는 파일을 대규모로 저장하고 처리하는 데에는 큰 장점을 갖지만, 실시간 분석에는 단점이 있다. 배치 처리를 기본으로 함으로 처리 지연 발생 특수한 목적의 데이터 분석을 위해서 비정형적인 Ad-hoc query를 만들고 처리하려면 개발자들의 노력이 많이 필요함. 구글도 몇 년 전부터 Hadoop은 데이터의 저장과 처리에 주로 사용하고, 데이터의 query와 분석을 위해서는 Dremell이라는 플랫폼을 갭라하여 함께 사용하는 중  오바마 캠프는 HP Vertica라는 SQL 기반의 대용량병렬 처리(Massively Parallel Processing) database platform 선택\n행동 심리학  Craig Fox 교수를 중심으로 행동과학가 컨소시엄(Consortium of Behavioral Scientists) - Nudge, 설득의 심리학 등의 작가. 왜곡된 루머에 대처하는 가장 좋은 전략은 자신에 대한 공격을 부정하는 것이 아니라 그것을 이길 수 있는 다른 긍정적 표현을 강하게 하는 것. \u0026ldquo;아바마와 무슬림\u0026rdquo; -\u0026gt; \u0026ldquo;나는 무슬람이 아니다\u0026rdquo;(X) \u0026ldquo;오바마는 기독교도다\u0026rdquo;(O)   한 사람이 어떤 일을 하기 위해서 간단한 계획을 세운다면 그런 계획이 없었을 때보다 그 일을 실제로 하게 될 가능성이 높아진다\n ","id":208,"section":"posts","summary":"(책) 빅데이터 승리의 과학 Technology 팀 오바마 2012년 선거 당시 2008년 당시의 SNS를 활용하는 수준을 넘어서 통합적인 선거 지원을 위해 빅데이터 기술 활용. 선거","tags":["Book"],"title":"(책) 빅데이터 승리의 과학","uri":"https://cychong47.github.io/2014/09/caeg-bigdeiteo-seungriyi-gwahag/","year":"2014"},{"content":"초보적인 실수를 반복한다고 구박하지만,\n자기들은 기본적인 패키지 운영도 못하면서 누굴 구박하는지. 조직간 알력 해결도 못하면서. 같은 일을 서로 더 힘들게 하는 문화를 만들어 놓고서.\n매일 같이 비상이다 위기다 라고 협박만 하면서.\n잘못된 일정 따위는 사과하지 않으면서.\n특정 부서의 오기로 만들어진 과제 일정 차질에 대해서는 아무 말도 안하면서.\n뭐가 잘났다고.\n","id":209,"section":"posts","summary":"초보적인 실수를 반복한다고 구박하지만, 자기들은 기본적인 패키지 운영도 못하면서 누굴 구박하는지. 조직간 알력 해결도 못하면서. 같은 일을 서로 더 힘들게 하는 문","tags":[],"title":"초보적인 실수를 반복한다고 구박하지만","uri":"https://cychong47.github.io/2014/09/cobojeogin-silsureul-banboghandago-gubaghajiman/","year":"2014"},{"content":"TPP 3. Provide Options, Don\u0026rsquo;t make Lame excuses 검토 결과 부정적일 때, 그냥 안된다고 하지말고 대안을 같이 제시하자. \u0026ldquo;이거 해 봤어?\u0026rdquo; \u0026ldquo;이거 고려했어\u0026rdquo; 같이 나올 수 있는 질문에 대해 미리 고민하고 대응할 것. 여기서 대응이란 질문에 대한 답을 제시할 수 있도록 미리 준비하라는 것. 실제로 고려해 보고, 실제로 시도해보고 나서 할 수 있으면 최고.\n무조건 안된다고 하지 말고, 대안을 제시하자. 안된다고 말하기 보다는 그 문제를 해결하기 위해 뭘 할 수 있는 지 제시하자.\nTPP 4. Don\u0026rsquo;t live with broken windows 잘못된 디자인, 잘못된 결정, 허접한 코드를 고치지 않은 형태로 두지 말아라. 발견했으면 반드시 조치를 해라. 필요하면 해당 코드를 코멘트로 막아버리고, 지원되지 않는다는 출력문을 내라. 차라리 그게 문제를 더 일으키는 것 보다 낫다.\n이런 \u0026ldquo;깨진 유리창\u0026quot;이 있으면 코드를 개선할 생각을 안하기 마련이다. \u0026ldquo;어차피 이런 코드인데 뭐, 대충 작성하지 뭐\u0026quot;라는 생각을 갖게 한다.\n반대로 잘 작성된 코드가 있으면 그 코드에 대해서는 신경을 쓰게 마련이다. 좋은 코드로 남도록 잘 다듬으려고.\nTPP 4. Be a catalyst for change 돌 스프 혹은 개구리.\n마을의 모든 사람들이 즐길 수 있도록 한 병사와 같은 촉매 역할을 할 것. 결국 모두가 승리하는 결과를 얻을 수 있다.\n뭔가를 하려는데 사람들의 동의가 필요하고, 예산도 한정되어 있고, 복잡한 이해관계가 엮여있다. 이럴때는 우선 작은 걸 잘 만들어서 보여준다. 그리고 \u0026ldquo;여기에 이런 기능이 있으면 더 좋을 듯 한데\u0026quot;라며 별로 중요하지 않은 것처럼 말한다. 그리고는 그 기능을 해야 할 사람이나 예산을 가진 사람이 참여하고 싶어하는 걸 기다린다.\n사람들은 성공하는 것에는 쉽게 참여한다(People find it easier to join on ongoing success)\nTPP 6. Remember the big picture 마을 사람들 입장에서 보면 결과론적으로 모두 즐거운 식사를 했겠지만, 간과해서는 안되는 것은 작은 것(재료들)이 하나씩 투자되었다는 것을 눈치채지 못했다는 것이다.\n때로는 작은 것들이 모여 morale과 팀을 깬다.\n개구리가 되지 마라. 항상 큰 그림에 집중해야 한다. 꾸준히 내가 하는 것뿐만 아니라 주변에서 일어나는 것들을 검토해야 한다.\n지나치게 완벽한 프로그램을 만들기 위해 노력하지 말라. 그럴 수도 없다. It may not be perfect. Don’t worry : I could never be perfect\n","id":210,"section":"posts","summary":"TPP 3. Provide Options, Don\u0026rsquo;t make Lame excuses 검토 결과 부정적일 때, 그냥 안된다고 하지말고 대안을 같이 제시하자. \u0026ldquo;이거 해 봤어?\u0026rdquo; \u0026ldquo;이거 고려했","tags":["The Pragmatic Programmer"],"title":"The Pragmatic Programmer","uri":"https://cychong47.github.io/2014/09/the-pragmatic-programmer/","year":"2014"},{"content":"우선 Synology NAS에서 webdav를 켜는 건 기본이고\nDevonthink의 Sync tab에서 타입을 webdav로 하면 아래와 같은 입력 창이 나오는데 여기에 서버 주소 등 필요한 정보를 적으면 된다. 이때 path는 user name으로 로그인했을 때 기준으로 하면 됨. 즉 Full path를 적으면 되는데 처음 입력할 때는 /home/Documents/Devonthink로 입력했는데 나중에 다시 보면 저렇게 바뀌어 있다.\n이제 두 대의 맥을 이렇게 운영하련다.\n동기화 관련 참고자료\n Dropbox를 사용할 때 동시에 여러 Mac에서 동기화된 DB를 열지 않도록 하는 applescript Devonthink DB가 깨졌을 때 복구하는 방법 웹페이지 일부만 스크랩하는 방법  ","id":211,"section":"posts","summary":"우선 Synology NAS에서 webdav를 켜는 건 기본이고 Devonthink의 Sync tab에서 타입을 webdav로 하면 아래와 같은 입력 창이 나오는데 여기에 서버 주","tags":["synology","webdav","devnothink"],"title":"Synology + Webdav + Devonthink","uri":"https://cychong47.github.io/2014/09/synology-webdav-devonthink/","year":"2014"},{"content":" \u0026lt;인생의 목적\u0026gt;\n우리는 살기 위해, 그리고 경험하기 위해 태어났습니다.\n바쁜 일정 속에서도 스스로에게 되뇌이곤 합니다.\n인간은 일하기 위해 태어난 것이 아니라, 인생이라는 선물을 즐기기 위해 태어났다고. 우리는 일하기 위해 존재하는 것이 아니라, 조금 더 세상을 나아지게 하기 위해 여기 있다고.\n당신이 당신의 인생을 일에 올인하고 있다면, 분명 후회의 순간이 찾아옵니다.\n당신이 직장에서 성공하고 있다면 더더욱 항상 기억해야합니다. 우리는 삶을 위해 삽니다. 그리고 일은 절대 삶보다 중요할 수 없습니다.\n 인생의 목적은 삶을 사는 것이지 일하는 게 아니다. 일도 삶의 일부로 해석해야지, 일이 목적이 되어서는 안된다는\n \u0026lt;불평과 불만\u0026gt;\n절대 불평과 불만을 습관으로 만들지 마십시오.\n가끔 하는 불평은 괜찮습니다. 그러나 만약 습관적으로 불평하고 있다면, 주의하세요. 불평은 술과 같습니다. 더 마실수록 더 목말라집니다.\n성공으로 가는 길목에서 당신은 깨닫게 될 것입니다. 성공한 사람들은 투덜대지 않고, 자주 불평하지 않습니다.\n세상은 당신이 한 말은 기억하지 않습니다. 그러나 당신이 이룬 것은 기억합니다.\n 불평과 불만을 습관으로 만들지 말라\u0026hellip;\n \u0026lt;명심해야 할 두 가지\u0026gt;\n당신의 태도는 당신의 능력보다 중요합니다. 당신의 결정이 당신의 역량보다 결정적입니다.\n 태도!!!\n출처 : 일과 인생에서 성공하고 싶은 청년들이 꼭 읽어야 할 글\n","id":212,"section":"posts","summary":"\u0026lt;인생의 목적\u0026gt; 우리는 살기 위해, 그리고 경험하기 위해 태어났습니다. 바쁜 일정 속에서도 스스로에게 되뇌이곤 합니다. 인간은 일하기 위해 태어난 것","tags":["인용"],"title":"(펌) 삶의 목적","uri":"https://cychong47.github.io/2014/09/peom-salmyi-mogjeog/","year":"2014"},{"content":" 나는 매주 금요일 오후가 되면 구글이라는 회사의 위력을 다시금 실감한다. 알려진 대로 구글은 매주 금요일마다 전 직원이 모이는 TGIF라는 행사가 있다.\n 정말 지금도 이걸 하고 있다니 놀랍기만 하다. 회사 규모가 커져서 못할 줄 알았는데.\n과연 우리 회사의 임원들은 같은 시간에 뭘 하고 있을까? 구글보다 비즈니스의 폭이 넓어서 더 많은 회의가 필요해서?\n 이들 두 창업자의 가장 큰 관심사는 구글 비즈니스가 아니라, 구글러들의 행복과 문화를 어떻게 하면 좀 더 발전시켜나갈 것인가에 있다. 이들은 직원들이 진정으로 행복한 삶을 살면서 사명감을 갖고 일할 수 있는 비전을 제시한다. 우리 스스로가 행복해야, 우리가 세상을 바꾸고 행복하게 만들 수 있다는 경영 철학 때문이다. 나는 \u0026lsquo;행복하게 일해야 행복한 제품을 만들고, 세상 사람들이 다 같이 행복할 수 있다\u0026rsquo;는 아름다운 이야기를 매주 들으면서 나 스스로도 그렇게 바뀌어가고 있다.\n 아직도 이런 말을 들을 때마다 반신반의한다. 정말 저 큰 회사의 대표가 회사보다 직원들의 행복을 먼저 생각한다라는 말. 정말?\n 구글은 5만 명의 직원이 거대한 목표 아래 일사불란하게 달려가는 조직이 아니다. 올해의 매출목표 따위의 말은 존재하지도 않는다.\n 정말? 정말 정말 정말??\n 2011년 구글 부사장인 Matt Cutts는 TED 강연에서 \u0026lsquo;30일 동안 새로운 것에 도전하기. Try something new for 30days\u0026rsquo;란 주제로 강연을 한 적이 있다. 대략적인 내용은 다음과 같다.\n\u0026ldquo;정말 뭔가를 간절하게 원한다면 30일이면 충분히 그 일을 해낼 수 있습니다. 좋든 싫든 어차피 이 한 달은 흘러가는 시간입니다. 한 번 시험 삼아 실행에 옮겨본 들 손해 볼 일은 없지요. 작지만 지속적으로 실행에 옮길 수 있는 변화들은 오래가는 법입니다\u0026rdquo;\n 내가 가장 필요한 거. Just Do It\n 어느 한 분야에 흥미와 관심을 갖고 인터넷상에서 그 지식을 끝없이 흡수하고 싶다면 영어 독해 능력을 키우는데 힘써야 한다. 늘 필요한 정보를 찾아 나의 지식창고에 쌓아가는 훈련을 해야 한다. \u0026lsquo;시간 죽이기\u0026rsquo;식의 게임하기와 영화나 만화 보는 시간, 카톡 하는 시간은 나에게 살이 되고 피가 되는 지식과 정보를 내다버리고 있는 \u0026lsquo;헛된\u0026rsquo; 시간일 수 있다.\n 흐흠\u0026hellip;..\n 소프트웨어 엔지니어는 누구든지 작성하는 프로그램 코드에 리뷰를 받아야 한다. 그게 코드가 아니라 단 한 줄의 코멘트라 할지라도 마찬가지다. 코드가 틀렸거나, 덜 효과적인 방법을 사용했거나, 주석문에 영어 오자가 있다면 다른 구글의 리뷰어들에 의해서 다듬어진다. 이러한 과정을 통해 구글러들은 점점 더 효율적인 프로그래밍을 할 수 있도록 키워진다. MIT를 수석으로 졸헙한 사람이라도 마찬가지다.\n모난 돌들이 서로 부딛히면서 다듬어지는 과정을 겪는 것처럼, 구글의 모든 소프트웨어 엔지니어들은 서로의 결과물을 리뷰해주고, 때로는 서로의 논리와 지식을 내세워 논쟁하면서 문제를 해결해나간다. 프로그램뿐만 아니고 생각하는 방법, 문제를 푸는 방법, 프로젝트를 바라보는 관점까지 서로 리뷰를 주고받으면서 부족한 생각이나 지식을 발전시켜 나간다. 그 결과 \u0026lsquo;100의 능력을 가지고 구글에 들어온 엔지니어들은 시간이 지나면서 그 이상의 능력을 가지게 된다.\n 그렇다. 리뷰는 그 사람의 코드에 틀린 점이 있는 지를 보는 것 이상으로 그 코드의 수준을 높이는 작업이어야 한다. 지금 하고 있는 게 그런지\u0026hellip; 그런 생각으로 다른 사람의 코드를 보고, 다른 사람 역시 그런 마음으로 코드 리뷰어의 코멘트를 바라보는 지. 혹시 공격과 수비로 생각하는 건 아닌 지.\n 캘린더나 스케줄러 앱을 이용해서 시간을 30분 단위로 쪼개고 그 시간대로 움직이는 연습을 하면 된다.\n 시간 관리의 중요성을 다시금 생각하게 한다.\n 모든 구글러는 면접에 참여해야 하는 의무를 가지고 있다. 누들러의 티를 벗고 구글에 익숙해질 때 쯤이면 면접 교육을 받는다.\n 의무가 아니라서 그런지. 면접위원을 해 본적은 있지만, 한번도 어떻게 해야 하는 지 교육을 받는 적이 없다. 교육은 커녕 기준도 들은 적이 없다는\u0026hellip;.\n 어느 구글러와 일의 삶의 균형에 대해 얘기를 나눈 적이 있다. 그는 정시에 칼퇴근하고 그 이후에는 전혀 업무에 관심을 갖지 않는 것을 일과 삶의 균형이라고 보지는 않았다. 아무리 바쁘게 일을 하고 업무량이 많더라도, 내가 정말 하고 싶거나 해야 하는 것들을 자유롭게 할 수 있는 것, 그것이 바로 일과 삶의 균형이라는 결론을 내렸다. 구글러들은 일과 삶의 밸런스를 시간 개념으로 구별하는 것이 아니라, 자유로움과 자기 결정력에 따라 구분한다.\n 시간이나 장소의 관점이 아닌 자유도 측면에서 바라봐야 진정으로 일과 삶의 균형이 된다는 말인데\u0026hellip;\n","id":213,"section":"posts","summary":"나는 매주 금요일 오후가 되면 구글이라는 회사의 위력을 다시금 실감한다. 알려진 대로 구글은 매주 금요일마다 전 직원이 모이는 TGIF라는 행사가 있다. 정말 지금도","tags":["Book"],"title":"(책) 구글은 SKY를 모른다","uri":"https://cychong47.github.io/2014/08/caeg-gugeuleun-skyreul-moreunda/","year":"2014"},{"content":"출처 : 20 Life Lessons Everyone Can Master By The Age 40\n1. Everything will be okay, and if it’s not, it’s certainly not the end of the world. 내가 포기할 때 실패한 끝난 거다.\n2. Find what you love and own it! 3. Don’t fear mistakes. 4. You deserve respect. 5. Romance is NOT the same as love. 6. It’s never too late to live a life that makes you proud. 7. Remain calm in all situations. 8. You win some, you lose some. 9. The term ‘Overnight Success’ really means 2 to 10 years.  Everything takes time and the best things in life are earned through consistency and patience. This doesn’t necessarily mean that if you just work hard, you’ll have everything you ever wanted. There’s definitely such a thing as working smarter. In order to discover ways to work ‘smarter’ it takes years of experience.\n 10. Maintain your focus.  Having good focus is directly connected to self-discipline. There will always be distractions, especially in the digital age. Making every single party and social event just isn’t as important now. Use your experience, wisdom and instincts to focus on what’s truly important in life.\n 11. Not everyone is always going to like you. 12. You simply cannot control everything and everyone. 13. Energy is everywhere and you can use yours to either work for you, or against you.  Disliking, not forgiving and trying to change others takes more energy then just letting it go and minding your own business. Now that you’ve mastered this, you can choose wisely where to expend energy to create the ideal life for you.\n 14. Don’t sweat the small stuff.  It’s not that you condone everything that happens, or everything that people do and say. It has more to do with accepting people and places exactly as is and still being able to thrive among them.\n 작은 거에 집착하지 말라는\n15. Money is not the measure of success. 16. It’s not about what you have. It’s about what you do with what you have. 17. You really do reap what you sow. 18. Happiness doesn’t just come to you automatically. You make it with your thoughts and actions. 제목 그대로.\n19. The past has passed for a reason. So let it go. Let it go. 과거로부터는 잘한 점이건 잘못한 점이건 교훈만 기억하고, 과거의 성공, 실패 모두 잊자.\n20. Life is short and can end in an instant. Live it to the fullest. 한 순간에 인생이 끝날 수도 있다. 매 순간 후회없이 살자.\n","id":214,"section":"posts","summary":"출처 : 20 Life Lessons Everyone Can Master By The Age 40 1. Everything will be okay, and if it’s not, it’s certainly not the end of the world. 내가 포기할 때 실패한 끝난 거다. 2. Find what you love and own it! 3. Don’t fear mistakes. 4. You deserve respect.","tags":["life","lifehack"],"title":"(펌) 20 Life Lessons Everyone Can Master By The Age 40","uri":"https://cychong47.github.io/2014/08/peom-20-life-lessons-everyone-can-master-by-the-age-40/","year":"2014"},{"content":"어떻게 하면 더 나은 소프트웨어를 만들 수 있을까? – 인터뷰 시리즈 part 1, Fernando Jimenez Moreno와 함께\n출처 : http://hacks.mozilla.or.kr/2014/08/how-can-we-write-better-software-interview-series-part-1/\n영문 원본 : https://hacks.mozilla.org/2014/07/how-can-we-write-better-software-interview-series-part-1/\nTelefonica에서 근무하고 있으면서 MozillaOS 개발에 참여하고 있는 사람의 인터뷰 기사\nCode Reviewer 업무를 함에 있어 참고할 만한 좋은 내용이 많아 옮겨 본다.\n 우리가 모질라와 함께 일한 것은 2011년으로 거슬러 올라갑니다. 두 회사 모두에게 잘 맞는 공통된 작업 절차를 찾기까지 꽤 많은 시간이 걸렸습니다. 제말은, 우리는 텔코(telco) 문화에서 일하던 사람입니다. 텔코 문화에서는 대부분의 작업들이 폐쇄적이고 비밀입니다. 이것은 모질라의 공개적이고 투명한 문화와는 반대죠.\n Telco 문화가 왜 폐쇄적이어야 할까? Telco 문화가 폐쇄적이라기 보다 Mozilla와 같은 Web 기반 기술을 사용하는 회사나 조직의 문화가 공개적이고 투명한 게 아닐까 싶다. Telco가 아니라 자동차 산업도 폐쇄적일 거라고 생각\n 우리는 텔레포니카에서 애자일 방법론을 쓰고 있었는데, 당시 모질라는 애자일 방법론을 쓰고 있지 않았습니다. 우리는 양쪽 모두에게 맞는 작업 절차를 찾아야 했습니다. 그러기 위해 꽤 많은 시간이 필요했습니다. 작업 절차에 대해 의논하기 위해 아주 많이 만났고, 아주 많이 토론했습니다. 다른 텔코 회사들과 일하는 것의 경우는 지금까지 무척 만족합니다. 특히 텔레노르와 잘 협조하고 있습니다. 아직까지 우리는 그들(텔레노르)과 정보를 공유할 때 조심합니다. 왜냐하면 궁극적으로 그들은 우리의 경쟁사니까요. 하지만 그렇다고 해서 파이어폭스 계정 시스템 개발 같은 공동의 목표를 위해 협조 못한다는 말은 아닙니다.\n Telefonica가 Agile을 사용하고, Mozilla가 그렇지 않다는 게 의외네. 반대가 아닐까 싶었는데 NFV관련 내용을 봐도 그렇고 Telefonia가 상당해 개발 지향적인 듯\n 많은 원칙이 적용되고, 많은 회사가 참여하는 프로젝트의 경우 스타일가이드, 도구, 프로세스 등의 공통 표준이 얼마나 중요한가요?\n글쎄요, 나는 소프트웨어 엔지니어링에 대해 일반적으로 말할 때 표준이 중요하다고 합니다. 하지만, 나는 그것을 SCRUM이라고 부르던, KANBAN이라고 부르던, SCRUMBAN이라고 부런던 상관하지 않습니다. 마찬가지로 Git 워크플로우를 따르던, Mercurial 워크플로우를 따르던, 아니면 구글의 자바스크립트 스타일가이드를 따르던, 모질라의 자바스크립트 스타일가이드를 따르던 상관하지 않습니다. 어떤 공통의 프로세스와 표준은 반드시 필요합니다. 특히 대규모의 엔지니어링 그룹의 경우는 더욱 그렇습니다. 오픈소스 프로젝트나 모질라 프로젝트가 이에 해당합니다. 공통 표준에 대해 말하자면, 규칙은 매우 간단합니다. 보통의 경우 이런 표준과 공통 프로세스들을 정의하고 토론하는데 너무 많은 시간을 소비하는 나머진 진정한 개발 목표를 잃어버리는 수가 있습니다. 나는 이런 공통 표준이 결국은 도구일뿐이라는 사실을 잊으면 안된다고 생각합니다. 우리 개발자들과 우리 매니저들을 돕는 도구지요. 공통 표준에 대해 유연하게 접근하는 지혜가 필요합니다.\n우리는 코드를 리뷰할 때 코딩 스타일을 많이 보곤합니다. 하지만 결과적으로 우리가 원하는 것은 코드를 수정해서 문제를 해결하는 것입니다. 만약 코딩 스타일에 문제가 있다면 고치면 됩니다. 연습삼아 패치를 남기는 상황이라면 일단 패치 코드를 버그 시스템에 기록으로 남겨 두세요. 그러면 코드 리뷰어가 기회 있을 때 코멘트할 것입니다.\n 다소 모호한 답변인 듯. 표준이 필요하다는 듯 한데 또 그 표준에 대해서는 유연하게 접근하자는 말. 모호하다. 동시에 여러 style을 사용해도 문제가 없다는 건지\n당연히 코딩 스타일보다 동작을 보는 게 중요하지. 코딩 스타일에 문제가 있으면 고치면 된다는 말은 코드도 문제가 있으면 고치면 된다는 거랑 뭐가 다른 걸까?\n 코드를 리뷰할 때 무엇을 살펴보나요?\n일반적으로 제가 가장 먼저 확인하는 것은 정확성입니다. 그러니까, 패치 코드는 원래 의도했던 문제를 실제로 해결해야 합니다. 그리고 당연히 부가적인 문제를 일으켜서는 안됩니다. 어떤 회귀적 문제도 일으켜서는 안됩니다. 시간이 허락되면 패치 코드를 제가 직접 테스트합니다. 패치 코드가 어떻게 동작하는지 알고 싶어서 이기도 하고, 아주 중요한 패치 코드일 경우 제대로 동작하는지 회귀적 문제를 일으키지는 않는지 확인하고 싶어서 이기도 합니다. 또 코드가 효율적으로 동작하는지 안전한지 살펴봅니다. 패치 코드에 대한 테스트 슈트 작성이 가능해 보이면 거의 언제나 테스트 슈트 작성을 요구합니다. 마지막으로 전반적인 코드의 품질, 문서, 코딩스타일, 기여정도, 프로세스의 정확성 등을 살펴봅니다\n 직접 리뷰어가 테스트까지 한다는 게 의외(?). 가능하면 언제나 테스트 슈트 작성을 요구한다는 것이 인상적이다.\n 당신은 지금까지 제가 겪은 다른 어떤 리뷰어보다 더 일관성을 강조했습니다. 다른 어떤 리뷰어보다 말이죠.\n글쎄요. 일관성은 코드의 전반적인 품질을 향상시킵니다. 리뷰할 때, 나는 종종 “nit:”라는 코멘트를 남깁니다. 이건 모질라에서 아주 일반적인 코멘트인데, “이 코드를 수정하면 좋겠습니다. 만약 수정하지 않더라도 리뷰 결과는 긍정적입니다. 하지만 이 코드가 조금 더 수정되기를 희망합니다.”라는 뜻입니다.\n 동작은 하겠지만, 수정했으면 좋겠다라는 의미. 나도 이런 코멘트를 많이 하는 편인데 사람에 따라 받아들이는 게 달라서 고민. 물론 이렇게 의켠을 주는 거슨 받아들이는 사람이 판단하라는 의미이긴 하지만\u0026hellip;\n 개발자로서 당신은 엄격한 리뷰를 배우는 기회로 삼으려 했단 말이지요? 그렇다면 리뷰어로서 리뷰를 가르치는 수단으로 사용하기도 했나요?\n예, 물론입니다. 그러니까 패치 코드를 리뷰하는 것은 가르치는 일입니다. 리뷰어는 코드를 작성한 사람에게 옳다고 생각하는 것을 말하는 것입니다. 때때로 코멘트를 뒷받침할만한 이론이나 이유가 불분명할 때도 있지만, 리뷰어는 자기 주장을 해야 합니다. 리뷰어는 가능한 최선의 이유를 설명해야 하고 최선의 진보를 이뤄내야 합니다.\n 코드 리뷰어의 의견은 코드 리뷰어의 생각을 말하는 것. 당연히 잘못된 생각이 있을 수 있으므로. 다만 위 글처럼 근거가 부족한 경우 설득하기 어렵다. 개발자들은 누구보다 자존심이 강하고 자신만의 스타일을 가지고 있는 것들이라.\n","id":215,"section":"posts","summary":"어떻게 하면 더 나은 소프트웨어를 만들 수 있을까? – 인터뷰 시리즈 part 1, Fernando Jimenez Moreno와 함께 출처 : http://hacks.mozilla.or.kr/2014/08/how-can-we-write-better-software-interview-series-part-1/ 영문 원본 : https://hacks.mozilla.org/2014/07/how-can-we-write-better-software-interview-series-part-1/ Telefonica에서 근무하고 있으면","tags":["코드리뷰"],"title":"(펌) 어떻게 하면 더 나은 소프트웨어를 만들 수 있을까?","uri":"https://cychong47.github.io/2014/08/peom-eoddeohge-hamyeon-deo-naeun-sopeuteuweeoreul-mandeul-su-isseulgga/","year":"2014"},{"content":"세미나 내용  Controller \u0026ndash;(OpenFlow)\u0026ndash; ovs-switchd \u0026ndash;(netlink)\u0026ndash; Datapath Datapath is in the kernel space OVDK move the kernel based OVS to user space.  ovs-switched talk to OVDK with UDP   기존 OVDK는 port별 task handler(각각 별도의 core에서 동작)  그 결과 많은 core 필요 WR 이야기처럼 VM간 혹은 VM과 외부와의 통신을 담당하는 OVS용으로 많은 core를 사용하면 실제로 VM이 사용할 수 있는 core 개수가 줄어들어 문제   virtIO 사용시 VM에서 동작하는 application이 kernel stack의 필요한 경우 결국 OVDK와 VM내 커널 space간 copy가 필요함  최신 버전에서는 VM에서도 KNI based virtIO를 이용하도록 개선함. 확인 필요   Rainbow platform  DPDK의 log library를 이용해서 외부 log server로 실시간으로 메시지 보냄. sFlow나 netFlow는 실시간이 아니라고. 음.. log library에 대한 확인 필요. 쓸만하면 log library를 별도로 만들지 말고 이걸 사용하는 것도 좋을 듯. log server는 NoSQL을 이용한 분석 서버라고 분석 서버에서 실시간 분석해서 의심되는 패킷을 받으면 OVS들에 명령을 내려 별도 DPI 서버로 경유하도록 해서 쉽게 Service Chaining 을 구현할 수 있다.    DPDK를 접한 지는 오래 되었지만 초반에 한번 플랫폼이 정리된 후 크게 개선하지 못했다. 딱히 요구사항이 없어서 나름 안정된 걸 건드릴 이유를 찾지 못한 것이 표면적인 이유지만, 실은 기능 혹은 성능 개선을 해서 얻는 실질적인 장점이 별로 없어서.\n대신 DPDK가 나올 때마나 계속해서 새 버전을 이용할 수 있도록 미리미리 준비는 했지만.\nDPDK 내부를 공부하는 것도 흐지부지 하고, 그렇다고 가상화를 제대로 한 것도 아니고. 쩝.\n","id":216,"section":"posts","summary":"세미나 내용 Controller \u0026ndash;(OpenFlow)\u0026ndash; ovs-switchd \u0026ndash;(netlink)\u0026ndash; Datapath Datapath is in the kernel space OVDK move the kernel based OVS to user space. ovs-switched talk to OVDK with UDP 기존 OVDK는 port별 task handler(각각 별도의 core에서 동작) 그 결과 많","tags":["DPDK","OVS","OVDK","Naim"],"title":"SDN expert group 세미나 - Play with DPDK","uri":"https://cychong47.github.io/2014/08/sdn-expert-group-semina-play-with-dpdk/","year":"2014"},{"content":" 그러나 생각하기 위한 시간을 내는 것으로는 부족해 보인다. 자신의 믿음에 부합되는 정보만을 찾는 편향이 인간에게는 있다고 했다. 혼자 생각한다고 그런 편향에서 벗어날 수 있을 것 같지는 않다.\n▶그렇다. 아파트 가격이 오를 것이라고 믿으면 그에 부합되는 증거만을 보려고 한다. 반대되는 증거는 보려 하지 않는다. 그렇기 때문에 우리는 우리 곁에 \u0026lsquo;최고 이의 제기자(chief challenger officer)\u0026lsquo;를 둬야 한다. 내 의견에 이의를 제기하는 사람 말이다. 리더일수록 더욱 그래야 한다.\n에릭 슈밋 구글 회장의 회의 진행 방식도 좋다. 그는 회의에서 미심쩍은 얼굴을 하고 있는 사람을 찾는다. 그리고는 “당신의 견해는 무엇이냐”고 묻는다. 이는 자신과 다른 의견을 청취하기 위해서다.\n 자신의 의견에 대해 동의하는 사람들의 의견만 듣고자 하는 리더는 갖다 버려야. 자신의 생각의 잘못된 점에 대해 기꺼히 지적할 수 있는 사람과 그런 문화를 만들지 못한 리더는 잘못된 결정의 모든 책임을 스스로 져야 한다. 듣기 싫은 소리를 듣지 못하게 만든 사람은 바로 본인이므로.\n차라리 혼자 생각할 시간 가져라\n","id":217,"section":"posts","summary":"그러나 생각하기 위한 시간을 내는 것으로는 부족해 보인다. 자신의 믿음에 부합되는 정보만을 찾는 편향이 인간에게는 있다고 했다. 혼자 생각한다고 그런 편향에서 벗어","tags":["잡생각"],"title":"차라리 혼자 생각할 시간 가져라","uri":"https://cychong47.github.io/2014/08/carari-honja-saenggaghal-sigan-gajyeora/","year":"2014"},{"content":"p19\n \u0026lsquo;인생은 해석\u0026rsquo;이라는 말이 있다. 인생을 살면서 많은 사건을 겪게 되는데, 그 사건들을 어떻게 해석하느냐에 따라 삶의 방향이 달라진다는 뜻이다. 마찬가지로 우리가 살고 있는 시대를 명확하게 바라보고 해석할 필요가 있다. 그에 다라 우리가 삶을 사는 방식과 이 사회가 문제에 대처해나가는 방향은 완전히 달라진다.\n 해석에 따라 어떻게 나에게 의미를 갖는 지가 달라진다.\np109\n 문제는 목표과 자세다. 성공의 지름길만 걸어가는 왕도는 없다. 오히려 외도를 하면서도, 전혀 다른 커뮤니티에 참여하면서 기회를 포착하기도 한다. 도전을 통해 얻은 시행착오오 처절한 조절도 커리어에는 오히려 큰 도움이 된다.\n p109\n  여러분들은 앞날을 내다보면서 점들을 연결할 수는 없습니다. 여러분들은 단지 과거를 돌이켜보는 와중에 그것들을 연결할 수 있을 뿐입니다. 그러니 여러분은 그 점들이 미래에 어떤 식으로든 연결된다는 사실을 믿어야만 합니다. 여러분의 배짱, 운명, 인생, 업, 그게 무엇이든 간에 여러분은 믿음을 가져야만 합니다. 이런 방식은 절대로 저를 실망시키지 않았습니다. 그리고 제 인생에 힘이 되었습니다.\n  스티브 잡스의 말. 미래를 예측할 수는 없지만 현재가 반드시 미래에 중요한 영향을 준다는 점은 분명하다는\n 그런 점의 조합을 축적된 커리어로 만드는 것은 본인에게 달려 있다. 똑같은 일을 하더라도 그것을 돈만 받으면 된다는 소모적인 시간 때우기로 볼것이냐, 미래를 위한 발판으로 삶을 것이냐에 따라 미래는 전혀 다르게 다가올 것이다. 누군가에게는 없어져버리는 비용이요, 또 다른 누군가에게는 장래를 위한 투자다.\n p113\n  꿈? 그게 어떻게 네 꿈이야? 움직이질 않는데? 그건 별이지. 하늘에 떠 있는, 가질 수도 없는, 시도조차 못 하는 쳐다만 봐야 하는 별. 네가 뭔가를 해야 될 거 아냐. 조금이라도 부딪치고 애를 쓰고 하다못해 계획이라도 세워봐야 거기에 네 냄새든 색깔이든 발라지는 거 아냐!\n  p121\n 제품 기획자는 나름대로 차별화 전략을 마련해서 만반의 준비를 한다. 그런데 사람들이 흔히 범하는 오류 중 하나는 \u0026lsquo;왜\u0026rsquo;라는 근본적인 질문을 던지지 않는 것이다.\n 단순히 고객이 원해서가 아니라 고객의 왜 원하는 지를 생각해야 한다.\np123\n 결국 \u0026ldquo;왜\u0026quot;라는 질문을 던지고, 그것을 실험해서 구현한 기업이 승자가 되었다.\n p127\n Emmanuel Pastreich교수(페스트라이쉬)는 창의적인 생각에 대해 다음과 같이 정의한다. \u0026ldquo;창의적인 생각은 새로운 무엇인가를 창조하는 것이 아닌, 우리 주변의 것을 다르게 보고 생각함으로써 그것에 또 다른 생명을 부여하는 것이다.\u0026rdquo;\n p129\n 산업화 시대에는 어느 한 분야만 잘해도 조직의 일원으로서 공헌할 수 있었다. 그러나 융합의 시대에는 개인의 총제적 역량이 중요하다. 자기 자신의 강점을 살릴 수 있는 열린 교육이 필요하다. 젊은 시절부터 비좁은 공간으로 밀어 넣은 상태에서 사회에 진출한 후 열린 마인드를 가지라고 하는 것은 앞뒤가 맞지 않는다. 절반의 지식만 가지고 사회에 나온 젊은이들은 다가올 미래 사회에 적응하기가 힘들다.\n p192\n 자기 기술을 가진 기업은 사업의 주도권을 쥐게 된다. 자기 기술이 없다면 사업 협력 자체를 할 수 없다. 또한 기술이 없다면 문제를 해결할 능력도 없고, 아예 대화에 끼어들 수도 없다. 물론 그 기술은 경쟁력 있는 기술을 의미한다.\n ","id":218,"section":"posts","summary":"p19 \u0026lsquo;인생은 해석\u0026rsquo;이라는 말이 있다. 인생을 살면서 많은 사건을 겪게 되는데, 그 사건들을 어떻게 해석하느냐에 따라 삶의 방향이 달라진다","tags":["Book"],"title":"(책) 누가 미래를 가질 것인가?","uri":"https://cychong47.github.io/2014/08/nuga-miraereul-gajil-geosinga/","year":"2014"},{"content":"회사라고 치자. 계열사에 회장이 떴다. 회장이 계열사 직원들로부터 소원수리를 받았다. 심각한 문제다. 그런데 사장들이 뻔히 문제점을 알고 있으면서 무시하고 아무 일도 안하고 있는 거다. 그러면 어떻게 될까?\n당장 질책이 떨어지고, 문제의 경중의 따라 사장이 짤릴 수도 있다.\n지금 교황이 방한한 일을 그렇게 보면 과대해석일까?\n교황은 와서 세월호 등을 포함해 대한민국에서 소외되고 있는 많은 사람들을 만난다. 바쁜 그 며칠간의 일정이 그렇다. 하지만 일년 내내 대한민국에 있는 추기경이라는 사람은 뭐가 그리 바쁜 지 힘없고 고통받는 이들을 외면해 왔다. 도대체 뭐에 써먹는 추기경인지. 자기가 챙겨야 할 고통받는 사람들은 최소한 재산이 넉넉하거나 권력이 있어야 하나보다.\n교황이 온다고 반대 집회하는 기독교(일부겠지만 설마)인 들은 뭐 논할 가치가 없는 것들이니 입을 가치도 없고\n교황이 온다고 경제가 살아난다고 기사 쓰는 쓰레기 언론. 참 천박하다 천박해.\n","id":219,"section":"posts","summary":"회사라고 치자. 계열사에 회장이 떴다. 회장이 계열사 직원들로부터 소원수리를 받았다. 심각한 문제다. 그런데 사장들이 뻔히 문제점을 알고 있으면서 무시하고 아무","tags":["life","tag"],"title":"종교의 차별된 사랑","uri":"https://cychong47.github.io/2014/08/jonggyoyi-cabyeoldoen-sarang/","year":"2014"},{"content":"p76  이 아이디어를 MIT 경영대학원 교수인 Glen Urban에게 가져갔을 때 그는 \u0026ldquo;이 아이디어는 당신이 생각하는 것보다 훨씬 스케일이 크다. 두 배의 속도로 움직이고, 두 배 크게 생각해야 한다\u0026quot;고 조언했다.\n \u0026ldquo;이 아이디어는 당신이 생각하는 것보다 훨씬 스케일이 크다. 그러므로 도전하지 말아라\u0026rdquo; 라고 말할 줄 알았는데\u0026hellip;\np85  자포스 CEO 토니. 회사를 판매한 경우 그 돈을 가지고 할 수 있는 일을 나열해 봤더니 대부분의 것들이 회사를 팔지 않고도 할 수 있는 일이 대부분이었다고. 시간이 부족할 뿐. 그래서 회사를 판매하지 않기로 결심했다고\n Exit하는 것이 목적이 아니라 자신이 하고 싶은 일을 하는 것이 목적이었으므로 가능한 생각. 그 덕분에 처음 제안받는 것 보다 훨씬 큰 금액으로 회사를 넘길 수 있긴 했지만\np92  짐 : 지금까지 스탠퍼드 학생을 많이 채용했는데, 사람을 채용할 때는 무엇을 가장 중점점으로 보았나요?\n마크 : 첫째는 지능(raw intelligence)입니다. 10년의 경력을 가진 사람을 뽑을 수도 있습니다. 그런 사람은 필요한 걸 금방 만들어내겟지요. 그러나 경험이 없더라도 똑똑한 사람은 순식간에 필요한 걸 다 배운 후, 결국은 10년 경력자가 해결하지 못하는 문제를 해결해냅니다. 둘째는 우리가 추구하는 것과 얼마나 잘 맞는지를 봅니다. 똑똑하고 기술이 있다 하더라도 우리의 비전을 믿지 않는다면 열심히 일하지 않겠죠.\n마크는 회삭의 비전을 공유한 유능한 인재들이 자신의 일에 집중할 수 있도록 배려하는 것을 그 무엇보다 중요하게 생각하고, 실제로 그것을 운영 방침으로 실천하고 있는 것이다.\n CEO의 생각이 돈을 버는 것 보다는 자신이 생각하는 것을 이루는 것이고, 그걸 위해 노력하는 인재들이 불편을 겪지 않도록 하는 것을 최우선으로 한다. 멋지지 않나? 과연 그런 회사가 얼마나 될까? 자신의 목숨을 부지하기 위해 일하는 사람도 있을 것이고, 주주들이나 이사회의 요구를 만족시키기 위해 하는 사람도 있을 텐데.\np98  파괴적 기술(Disruptive Technology). Clayton M. Christensen 교수의 저서 \u0026lt;혁신 기업의 딜레마, Innovator\u0026rsquo;s Dilemma\u0026gt;\n p101  넷플릭스가 끊임없이 새로운 골리앗과 다윗들의 도전을 받으면서도 지속적으로 성장할 수 있었던 요인은 무엇일까? 나는 그 답을 넷플릭스의 파괴적 혁신과 기업문화 속에서 찾았다.\n 자신의 기존 cash cow를 과감하게 포기하지 않으면 쉽게 레드오션이 되는 것을 피할 수 없다. 물론 경우에 따라서는 확실한 시장 지배력을 가졌다면 그 시장을 손쉽게 포기하는 것은 어려울 것이다. 그만한 새로운 시장을 만들어 내는 것도 쉬운 일은 아니니. 하지만, 시장 지배력이 낮은 회사라면 과감히 그 시장을 포기하고 새로운 시장을 만들어내는 것도 고려해야 한다. 얼마 안되는 그리고 점점 경쟁이 심해지고, 점점 작아지는 시장 점유율을 유지하기 위해 들이는 노력은 점점 그 성과가 줄어들 것이다.\np108 넷플릭스의 기업문화  Values are what we value(우리의 가치는 우리가 가치있게 여기는 것) High Performance Free \u0026amp; Responsibility Context, not Control Highly Aligned, Loosely Coupled Pay Top of Market Promotions \u0026amp; Development  Netflix Culture\np108 Values are what we value  대부분의 회사들이 내세우는 가치는 실제와 거리가 먼 경우가 많다. 어떤 회사가 내세우는 가치 중 하나가 \u0026lsquo;용기\u0026rsquo;였다고 하자. 옳지 않은 방향으로 갈 때 바른말을 할 수 있는 용기 말이다. 하지만 실제로는 바른말을 하지 않은 사람이 보상을 받거나 승진한다면, 회사의 가치는 그저 공허한 말에 불과할 뿐이고, 직원들은 더 깊은 좌절에 빠질 것이다. 회사의 승진 원칙은 매우 중요하다. 직원들은 대개 회사에서 승진한 사람이 추구하는 것이 회사가 중요하게 여기는 가치라고 생각한다. 엉뚱한 사람이 승진하면, 직원들은 \u0026lsquo;아, 이 회사에서 중요하게 생각하는 것은 도덕성, 전문성, 팀워크가 아니라 상사에게 얼마나 잘 보이느냐구나\u0026rsquo;라고 생각하게 된다.\n 책에서는 미국 회사 \u0026lsquo;엔론\u0026rsquo;의 예를 들었지만, 내 생각에는 이명박네 가훈이 \u0026lsquo;정직\u0026rsquo;이라고 하는 걸 드는게 더 쉽게 이해가 될 듯 하다.(웃기고 자빠졌네)\n 넷플릭스가 정의하는 멋진 일터는 \u0026lsquo;끝내주는 동료들이 있는 곳이다\u0026rsquo;. 최고의 동료들을 끌어오는 데 효과적인 일들만 한다는 것을 명시해놓앗다.\n\u0026hellip; 회사에서 자신에게 영감을 주고 함께 있으면 기분 좋은 사람들이 줄어든다면, 그 조직은 곧 떠나고 싶어진다. \u0026lsquo;끝내주는 사람들\u0026rsquo;이 회사에 많다는 것은 아주 중요하다. 끝내주는 사람이 많다면 그들은 또 다른 끝내주는 사람을 데려올 것이고, 그들은 다른 끝내주는 사람들 때문에 조직에 남게 된다.\n그런데 회사 규모가 커지면 할 일은 많고 사람은 부족해진다. 그래서 평범한 사람들을 채용하기 시작한다. 처음에는 괜찮다. 그러나 평범한 사람이 많아지면 회사 분위기가 이상하게 흘러간다. 끝내주는 사람들은 평범한 사람들에게 둘러싸야 좌절감을 느끼고 회사를 떠난다. 결국 평범한 사람들만 남은 회사는 내리막길을 걷기 마련이다.\n 이 부분에 대해서는 조금 이해하기 어렵다. 그럼 평범한 사람은 좋은 문화를 가진 회사에 들어가지도 말라는 것인지? 왜 평범한 사람들이 많아지만 회사 분위기가 이상하게 흘러간다고 단정하는 걸까? 평범한 사람들을 데리고 좋은 문화나 제품을 만들 수 있는 능력을 가진 \u0026ldquo;끝내주는 사람\u0026quot;은 없다는 건가? 오직 자기와 수준이 비슷한 끝내주는 사람들하고만 일을 해야 끝내주는 결과를 낸다는 건 지나친 비약이 아닐까?\np109 넷플릭스 - 자유와 책임  넷플릭스는 \u0026lsquo;책임감 있는 사람은 자유가 있을 때 더 큰 성과를 내고, 그 자유를 누릴 자격이 있다\u0026quot;고 말한다.\n대부분의 회사는 규모가 커질수록 자유를 제약한다. 실수를 방지하기 위해서다. 실수로 인한 피해가 커지면 성과가 좋은 직원들의 비율이 낮아지고, 결국은 시장 상황이 바뀌면서 회사가 망하기 때문이다.\n그들은 복잡성이 증가하는 것보다 빠른 속도로 인재의 비율을 높여갓다. 즉 사업의 복잡성이 높아짐에 따라 그 보다 빨리 우수한 직원의 비율을 늘려나간 것이다.\n이를 달성하는 구체적인 방법은 업계 최고의 보상을 해주고, 가치가 높은 사람들을 끌어오고, 높은 성과를 내는 문화를 계속해서 발전시켜 나가는 것이다. 또한 자유의 정도를 높이기 위해 프로세스를 끊임없이 개선해 나간다. 단 실수를 방지한다는 명목으로 자꾸 새로운 규칙을 만들지는 않는다.\n 마지막 문장은 절대 동감. 다만 위 글에서 설명한 것처럼 넷플릭스는 \u0026lsquo;끝내주는 사람\u0026rsquo;들로 구성된 조직이라 저게 가능한 것인지? \u0026lsquo;평범한\u0026rsquo; 사람들이 더 많은 조직에는 적용할 수 없는 것인지 궁금하다. 그래서 그렇게 일반 회사에는 쓸데없는 프로세스가 많고, 체크리스트가 시간이 갈수록 계속해서 늘어나는 것인지.\np110 - 넷플릭스에 가장 유리한 방향으로 할 것  \u0026lsquo;마치 자신의 돈인 것처럼 쓰기\u0026rsquo;\n p111  능력계발에 관해서도, 높은 성과를 내는 사람들은 그들이 뛰어난 사람들과 큰 도전에 둘러써야 있는 한 경험과 관찰, 토론 등을 통해 스스로 성장한다고 믿는다. 즉 교육이나 멘토링 등의 형식적인 프로그램은 능력계발에 거의 효과가 없다고 생각한다.\n우수한 인재들은 회사가 별도로 교육을 하지 않아도 스스로 기회를 찾아 배우고 성장한다. 그것이 그들에게 즐거움을 주기 때문이다. 단 그들은 회사에 성장하고 배울 기회가 없다고 느끼면 주저없이 떠날 것이다.\n 125 Dropbox  투자자들은 미팅을 할 때마다 시장이 이미 기존 제품들로 포화상태고, 그 제품들 중 돈을 많이 버는 회사는 없으며, 그 회사들이 해결하려는 문제도 사람들에게는 그다지 중요하지 않다고 했다. 드루는 물었다. \u0026ldquo;그 다른 제품들을 써봤냐요?\u0026rdquo; \u0026ldquo;예\u0026quot;라고 대답하면 그는 또 물었다. \u0026ldquo;부드럽게 동작하던가요?\u0026rdquo; 그 대답은 항상 \u0026ldquo;아니오\u0026quot;였다. 그렇지만 벤처케피털리스트들은 드루의 비전을 이해할 수 없었다. 드루는 소프트웨어가 \u0026lsquo;마법처럼 동작하면\u0026rsquo; 사람들이 몰려들 것이라고 믿었다.\n 이미 많은 솔류션이 존재해도, 그 솔류션이 문제를 우아하게 해결하고 있지 못한다면 분명 시장은 아직 있는 것이다.\n149  \u0026lsquo;성장\u0026rsquo;이 빠른 회사에서 정보는 한 달만 지나도 모두 무의미한 것이 되어버리기 때문이다.\n 성장이 빠르지 않은 회사에서도 정보는 금방 썩게 된다. 인정하지 않을 뿐이지.\n","id":220,"section":"posts","summary":"p76 이 아이디어를 MIT 경영대학원 교수인 Glen Urban에게 가져갔을 때 그는 \u0026ldquo;이 아이디어는 당신이 생각하는 것보다 훨씬 스케일이 크다. 두 배의 속도로 움","tags":["Book"],"title":"(책) 스핀 잇","uri":"https://cychong47.github.io/2014/08/seupin-is/","year":"2014"},{"content":"SDN이 주로 operator 입장에서 비용 절감, 관리 용이, 혁신 용이, 자동화(programmable)의 장점을 이야기하는데 NTT DOCOMO는 실제로 이런 방법을 통해 사용자에게 제공할 수 있는 가치(end-user value)에 대해 이야기한다.\n조금 과장하면 앞 선 장점 나열은 비-애플인 듯하고, 후자는 애플의 발표인 듯. 단순히 Operator에게 비용뿐만 아니라 인지도를 올릴 수 있는 방법을 제시한다는 면에서 참 느낌이 다르다.\nSDN: Helping Real People in a Real Crisis | 6WIND Blog\n","id":221,"section":"posts","summary":"SDN이 주로 operator 입장에서 비용 절감, 관리 용이, 혁신 용이, 자동화(programmable)의 장점을 이야기하는데 NTT DOCOMO는 실제로 이런 방법을 통","tags":["SDN","nfv"],"title":"SDN의 진정한 가치","uri":"https://cychong47.github.io/2014/08/sdnyi-jinjeonghan-gaci/","year":"2014"},{"content":"화웨이가 어떻게 지금과 같이 세계 2위의 통신업체가 될 수 있었는지 CEO인 런정페이를 중심으로 그 비결을 설명한 책.\n늙지 않는 조직을 만들기 위해 끊임없이 노력하고 일괄 사퇴 후 재취업과 같은 극단적인 선택도 마다하지 않은 화웨이. 시스코가 괜히 건드려 무료 홍보해주고(마치 애플이 삼성을 고소해 홍보해 줬다는 것과 유사) 모토롤라가 CEO가 바뀌지 않았으면 화웨이의 시스템 사업을 인수해서 지금의 화웨이가 없었을 텐데. 만일 모토로라가 화웨이의 사업을 인수했다 해도 모토로라의 시스템 사업은 망했을 거라고 생각. 화웨이는 런정페이가 없으면, 혹은 그가 만들어 놓은 문화와 시스템이 동작하지 않으면 다른 회사와 다름이 없으므로.\n전체적으로 중국인 입장에서 쓴 글이라 칭찬 일변도라는 점이 거슬리지만 결과론적으로 지금과 같은 거대업체가 된 것을 부정할 수 없으므로 배는 아프지만 인정할 수 밖에…\n \u0026ldquo;무릇 발전은 다른 사람이 아닌 내 손으로 쥐어야 합니다.\u0026rdquo;\n 아웃 소싱을 폄하하는 것은 결코 아니지만 결국 핵심 기술은 내재화하지 않으면 의미가 없다. 핵심 기술이 아닌 부분을 아웃소싱한 후 그 위에 나만의 핵심 기술을 이용한 부가가치를 추가하지 않으면\u0026hellip;\n \u0026ldquo;제도와 문화가 신은 아니지만 그 힘은 실로 거대합니다\u0026rdquo;\n 주먹구구식으로 운영되는 조직은 커질 수 없다. 문화의 중요성을 강조.\n 모토로라는 고객 니즈에 더디게 반응한 것은 물론, 자신이 만든 틀 안에 갇혀 고객을 무시하고 상식을 외면한 채 오로지 기술 제일주의를 고집했다.\n 이리듐 프로젝트. 모토로라가 몰락하게 된 직접적인 계기가 된. 성공했으면 어떻게 되었을까 싶기도 하다. 지금처럼 3GPP 그런 스펙 다 무시하고 있지 않았을까?\n 화웨이가 지난 20여 년 동안 \u0026lsquo;유성\u0026rsquo;이라는 명단에 들어가지 않을 수 있었던 가장 중요한 요소 중 하나는, 자본의 유횩과 지배에서 벗어나려고 발버둥쳤다는 점이다.\n 오직 ROI만 논하는 자본주의가 위대한 기업을 절름발이로 만든 것을 보고 이렇게 생각했다고\n \u0026ldquo;단시간 안에 매주 40시간씩 일한다고 산업 전환이나 업그레이드가 그렇게 쉽게 진행될 수 있을까요? 매주 40시간씩 일하면 일반 노동자를 생산할 수는 있겠지만 음악가, 무용가, 과학자, 프로그래머, 상인 등은 만들어낼 수 없습니다.\u0026rdquo;\n 아프다. 그리고 두렵다.\n \u0026ldquo;기업이 발전하려면 낭과 패의 세 가지 특징을 모두 지니고 있어야 합니다.\n첫째, 민감함 후각,\n둘째, 불굴의 진취성,\n셋째, 팀플레이 정신.\u0026rdquo;\n 앞다리가 길고 뒷다리가 짧은 늑대가 \u0026lsquo;낭\u0026rsquo;, 반대인 늑대가 \u0026lsquo;패\u0026rsquo;란다. 그래서 두 짐승이 같이 나란히 걷다가 사이가 벌어지면 순간 균형을 잃고 넘어져 당황하게 되는 것을 가리켜 낭패라고 한단다.\n IT기업에게 가장 중요한 건 재능 있는 사람이죠. 꿈을 가진 사람들이 함께 모여 일하도록 하려면, 이들을 더욱 단단히 묶어놓고 생사고락을 함께하는 운명 공동체로 만들어야 합니다.\n 인재가 제일 중요한 건 어느 분야나 똑같다. 인재를 특별히 대우하는 것은 적어도 바라지 않더라도 홀대하지는 말아야 .\n 2011년 말 현재, 14만 6000명에 달하는 화웨이 직원 중에 6망 5596명이 자사 지분을 보유하고 있다. 상장사 중에서 주주가 가장 많이 분산되어 있고, 직원의 자사 지분 보유율이 가장 높은 유일한 사례라 하겠다.\n 정말 특이한 형태의 회사\n 미국의 클린턴 정부는 National Information Infrastructure(Information Super Highway) 프로젝트를 본격적으로 추진하면서 국가적 차원에서 아이디어가 중심이 되는 시대, 동시에 파괴를 수반한 창조의 시대가 도래했다고 선포했다. 요컨대 구제도의 산물에 대한 철저한 파괴라는 대가를 치르며 공격적으로 아이디어와 혁신을 추진했다.\n 과거의 부정을 포함한 혁신\n \u0026ldquo;장기적으로 개방 정책을 추진한 화웨이의 전략은 단 한 번도 흔들린 적이 없습니다. 어떠한 순간에도 굴하지 말고 세상을 향해 문을 활짝 열어놓으십시오. 문을 닫은 상태에서 외부 에너지를 흡수하지 못한다면 결국 자신만 성장하지 못합니다. 그리고 자신에게는 항상 엄격하십시오. 정확하고 객관적으로 자신을 대할 줄 알아야 합니다. 그렇지 않으면 개방은 지속될 수 없습니다\u0026rdquo;\n ","id":222,"section":"posts","summary":"화웨이가 어떻게 지금과 같이 세계 2위의 통신업체가 될 수 있었는지 CEO인 런정페이를 중심으로 그 비결을 설명한 책. 늙지 않는 조직을 만들기 위해 끊임없이 노력하고","tags":["Book"],"title":"(책) 화웨이의 위대한 늑대문화","uri":"https://cychong47.github.io/2014/08/hwaweiyi-widaehan-neugdaemunhwa/","year":"2014"},{"content":"출처  Heavy-ReadingQosmosDPI-SDN-NFVWhite-PaperJan2014.pdf 2014년 1월  전반적인 내용  The largest use case (by number of vendors citing it) is service assurance for QoS/QoE; the second largest is policy control (PCEF), which we believe is the largest use case by volume Half of respondents said that encryption of protocols is reducing the effectiveness of DPI . Packet metric analysis (heuristics) was identified as the main remedy - packet size, spacing, frequency  DPI 용도  Service Awarence (QoS, QoE)가 가장 높음(60%) Policy Control(PCEF)도 비슷 3GPP TDF 기능. 표준 내용 확인 필요 Service Analystics system도 높은 관심  가입자 수준에서 분석하려는 의도가 많아짐. Customer prefrences and load/characteristics Real-time analytics Real-time subscriber data analysis and RAN congenstion control at cell level Pose hard challenge to engineers. Accurate real-time detection of application and protocols is essential.   대부분의 대형 벤더가 자체 DPI 솔류션 확보. 작은 업체일 수록 third-party solution 사용  대략 응답자의 30%가 third-party solution 사용하나, 대형 벤더의 응답율이 높아 실제 사용률은 더 높을 듯   암호화된 패킷 때문에 Packet Metric analysis(size, spacing, frequency) 등 DPI 이상의 기술로 해결해 가야 함. NFV는 새로운 제품 개발의 H/W 및 S/W 설계에 영향을 줄거라는 의견이 92%로 지배적.  그렇지만, 가상화 할때 고려하는 H/W platform으로는 COTS만큼 자체 H/W를 고려하고 있음 아직 어떤 것이 H/W platform인지 맞는 것인지 확신이 없기 때문에 그만큼 보수적으로 자체 플랫폼을 고려하는 것으로 분석됨. 그렇지만 appliance-selling(H/W) 모델에서 usage-selling(Software license) 모델로 이동할 거라는 예상 NFV와 표준화된 third-party component의 출현은 점점 outsouring 비율을 높일 거라는 예상.    NFV/SDN을 고려한 DPI  DPI는 Switch node의 Hypervisor(OVS), VM 내(DPI VNFC-Virtual Network Function) 그리고 Controller에 위치할 것으로 보임  VM내 DPI(DPI VNFC)는 ETSI ISG(July 2013)에서 정리한 공식 use case중 하나.    ","id":223,"section":"posts","summary":"출처 Heavy-ReadingQosmosDPI-SDN-NFVWhite-PaperJan2014.pdf 2014년 1월 전반적인 내용 The largest use case (by number of vendors citing it) is service assurance for QoS/QoE; the second largest is policy control (PCEF), which we believe is the largest use case by volume Half of respondents said that encryption of protocols is reducing the effectiveness of DPI . Packet metric analysis (heuristics) was identified as","tags":["dpi","SDN","nfv"],"title":"DPI \u0026 Traffic analysis in networks based on NFV and SDN","uri":"https://cychong47.github.io/2014/08/dpi-traffic-analysis-in-networks-based-on-nfv-and-sdn/","year":"2014"},{"content":"Network 장비를 만드는 방법 중 가장 흔한 방법이 Networking에 최적화된 processor를 제공하는 업체로부터 processor를 구입하고, 그 processor와 함께 제공되는 SDK를 사용하는 것이다. 그러다보니 특정 업체의 processor를 위해 만든 S/W를 다른 processor로 포팅하는 경우 많은 부분을 수정해야 하는 경우가 많다.\n당연한 이야기지만, 특정 processor에 종속적인 부분은 해당 processor가 제공하는 H/W accelerator 를 이용하는 코드나 해당 processor의 특성에 맞게 설계된 구조 등이다. 다른 processor로 포팅하는 경우 \u001c전자의 경우는 새로운 processor에서 대응되는 API등이 제공되면 비교적 쉽게 변경할 수 있다. 후자의 경우는 좀 더 근본적인 문제라 다른 차원의 문제가 되지만. 예를 들어 특정 업체는 processor 차원에서 packet ordering을 제공하는 경우가 있다. 그러므로 이 경우 multi-core 환경에서 여러 core들은 서로 다른 core가 같은 flow(순서가 보장되어야 하는 패킷들의 흐름)에 속하는 패킷을 처리하는 지 신경 쓸 필요없이 패킷을 처리하고, 패킷을 최종적으로 전송할 때만 순서를 맞추는 작업을 H/W 기능을 이용해서 수행하면 된다. 반면 이런 H/W 기능이 없는 경우 근본적으로 flow별로 서로 다른 core에게 전달되도록 하는 등의 고려가 필요할 수 있다.\n아무튼 특정 processor 하나만 사용하는 경우가 아니라 동시에 여러 가지 processor를 이용하거나, 특정 processor가 단종되거나 성능이나 기능상의 이유로 다른 processor로 대체되는 경우 기존에 해당 processor를 위해 작성한 S/W를 포팅해야 하는 고통을 피할 수 없다.\n통상 이렇게 processor의 H/W 기능을 활용하여 고속으로 패킷을 처리하는 부분을 Data Plane이라고 하고, Data Plane의 동작에 필요한 작업이 수행하는 부분을 Control Plane이라고 한다. 예를 들면 패킷 처리에 필요한 라우팅 테이블 설정 등이 Control Plane이 수행하는 대표적인 업무 중 하나다.\nOpenDataPlane은 각 processor에서 제공하는 SDK와 이를 이용해 개발한 S/W간의 의존성을 제공할 수 있도록 abstraction layer를 하나 정의한 것이다.\n  그림 출처 : http://www.opendataplane.org/\n그러므로 ODP의 성공은 SDK를 제공하는 업체의 협력이 핵심이다. 만일 업체의 협력이 없다면 누군가는 매번 업체의 SDK가 나올 때마다 해당 업체의 SDK를 ODP API에 맞게 수정하는 작업을 해야 할 것이다.\n현재 ODP는 다음과 같은 업체 들이 지원하고 있다. 주로 Silicon vendor가 핵심이고, 이를 이용할 업체도 몇 몇 있다.\n  applied micro\n  ARM\n  Broadcom (XLP processor를 개발한 RMI를 현재 보유)\n  Cavium (Multi-Core 환경에서 많이 사용하는 Octeon Processor 개발)\n  Freescale\n  Texas Instruments\n  Linaro (ARM의 확대를 위한 다양 분야에서의 S/W를 ARM 으로 포팅하기 위해 노력하고 있는 open source community. Linux Kernel 3.14 기준으로 3번째 Contributor라고. ARM을 이용한 가상화 역시 Linaro가 주축으로 밀고 있다.)\n  LSI\n  Montavista(Cavium에서 인수했으므로 당연히 Octeon Processor의 M/S 확대를 위해서라도 열심히 할 듯)\n  NSN\n  CISCO\n  참고로 Intel DPDK는 없다.\n재밌는(?) 건 openDataplane.org도 wordpress를 기반으로 하고 있다는. 정말 WP가 blog가 아니라 CMS 계를 평정했다고 들었는데 실감된다.\n참고로 홈페이지가 접속되지 않는 곳을 위해 소스 코드나 문서등은 git repository를 통해 접근할 수 있다.\n https://git.linaro.org/lng/odp.git https://git.linaro.org/lng/odp-architecture.git https://git.linaro.org/lng/odp-apps.git  [1] http://www.opendataplane.org/supporters/\n[2] https://wiki.linaro.org/LEG/Engineering/Virtualization\n[3] http://www.linaro.org/projects/\n","id":224,"section":"posts","summary":"Network 장비를 만드는 방법 중 가장 흔한 방법이 Networking에 최적화된 processor를 제공하는 업체로부터 processor를 구입하고, 그 pro","tags":["odp"],"title":"OpenDataPlane","uri":"https://cychong47.github.io/2014/05/opendataplane/","year":"2014"},{"content":"You\u0026rsquo;re live! Nice. We\u0026rsquo;ve put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at \u0026lt;your blog URL\u0026gt;/ghost/. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!\nGetting Started Ghost uses something called Markdown for writing. Essentially, it\u0026rsquo;s a shorthand way to manage your post formatting as you write!\nWriting in Markdown is really easy. In the left hand panel of Ghost, you simply write as you normally would. Where appropriate, you can use shortcuts to style your content. For example, a list:\n Item number one Item number two  A nested item   A final item  or with numbers!\n Remember to buy some milk Drink the milk Tweet that I remembered to buy the milk, and drank it  Links Want to link to a source? No problem. If you paste in url, like http://ghost.org - it\u0026rsquo;ll automatically be linked up. But if you want to customise your anchor text, you can do that too! Here\u0026rsquo;s a link to the Ghost website. Neat.\nWhat about Images? Images work too! Already know the URL of the image you want to include in your article? Simply paste it in like this to make it show up:\nNot sure which image you want to use yet? That\u0026rsquo;s ok too. Leave yourself a descriptive placeholder and keep writing. Come back later and drag and drop the image in to upload:\n![A bowl of bananas]\nQuoting Sometimes a link isn\u0026rsquo;t enough, you want to quote someone on what they\u0026rsquo;ve said. It was probably very wisdomous. Is wisdomous a word? Find out in a future release when we introduce spellcheck! For now - it\u0026rsquo;s definitely a word.\n Wisdomous - it\u0026rsquo;s definitely a word.\n Working with Code Got a streak of geek? We\u0026rsquo;ve got you covered there, too. You can write inline \u0026lt;code\u0026gt; blocks really easily with back ticks. Want to show off something more comprehensive? 4 spaces of indentation gets you there.\n.awesome-thing { display: block; width: 100%; }  Ready for a Break? Throw 3 or more dashes down on any new line and you\u0026rsquo;ve got yourself a fancy new divider. Aw yeah.\n Advanced Usage There\u0026rsquo;s one fantastic secret about Markdown. If you want, you can write plain old HTML and it\u0026rsquo;ll still work! Very flexible.\nThat should be enough to get you started. Have fun - and let us know what you think :)\n","id":225,"section":"posts","summary":"You\u0026rsquo;re live! Nice. We\u0026rsquo;ve put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at \u0026lt;your blog URL\u0026gt;/ghost/. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!","tags":["Getting Started"],"title":"Welcome to Ghost","uri":"https://cychong47.github.io/2014/05/welcome-to-ghost-2/","year":"2014"}],"tags":[{"title":"2015","uri":"https://cychong47.github.io/tags/2015/"},{"title":"5g","uri":"https://cychong47.github.io/tags/5g/"},{"title":"agile","uri":"https://cychong47.github.io/tags/agile/"},{"title":"aic","uri":"https://cychong47.github.io/tags/aic/"},{"title":"Algorithm","uri":"https://cychong47.github.io/tags/algorithm/"},{"title":"amazon","uri":"https://cychong47.github.io/tags/amazon/"},{"title":"amdocs","uri":"https://cychong47.github.io/tags/amdocs/"},{"title":"Amsterdam release","uri":"https://cychong47.github.io/tags/amsterdam-release/"},{"title":"andromeda","uri":"https://cychong47.github.io/tags/andromeda/"},{"title":"ansible","uri":"https://cychong47.github.io/tags/ansible/"},{"title":"ansible-playbook","uri":"https://cychong47.github.io/tags/ansible-playbook/"},{"title":"anti-work pattern","uri":"https://cychong47.github.io/tags/anti-work-pattern/"},{"title":"ATT","uri":"https://cychong47.github.io/tags/att/"},{"title":"automation","uri":"https://cychong47.github.io/tags/automation/"},{"title":"b4","uri":"https://cychong47.github.io/tags/b4/"},{"title":"backup","uri":"https://cychong47.github.io/tags/backup/"},{"title":"barometer","uri":"https://cychong47.github.io/tags/barometer/"},{"title":"blog","uri":"https://cychong47.github.io/tags/blog/"},{"title":"Book","uri":"https://cychong47.github.io/tags/book/"},{"title":"brew","uri":"https://cychong47.github.io/tags/brew/"},{"title":"Brocade","uri":"https://cychong47.github.io/tags/brocade/"},{"title":"C","uri":"https://cychong47.github.io/tags/c/"},{"title":"calico","uri":"https://cychong47.github.io/tags/calico/"},{"title":"Cavium","uri":"https://cychong47.github.io/tags/cavium/"},{"title":"cisco","uri":"https://cychong47.github.io/tags/cisco/"},{"title":"click","uri":"https://cychong47.github.io/tags/click/"},{"title":"cncf","uri":"https://cychong47.github.io/tags/cncf/"},{"title":"cni","uri":"https://cychong47.github.io/tags/cni/"},{"title":"Coding Style","uri":"https://cychong47.github.io/tags/coding-style/"},{"title":"collaboration","uri":"https://cychong47.github.io/tags/collaboration/"},{"title":"collectd","uri":"https://cychong47.github.io/tags/collectd/"},{"title":"connectX-5","uri":"https://cychong47.github.io/tags/connectx-5/"},{"title":"container","uri":"https://cychong47.github.io/tags/container/"},{"title":"continuous deployment","uri":"https://cychong47.github.io/tags/continuous-deployment/"},{"title":"cpu","uri":"https://cychong47.github.io/tags/cpu/"},{"title":"cran","uri":"https://cychong47.github.io/tags/cran/"},{"title":"crond","uri":"https://cychong47.github.io/tags/crond/"},{"title":"cubb","uri":"https://cychong47.github.io/tags/cubb/"},{"title":"culture","uri":"https://cychong47.github.io/tags/culture/"},{"title":"cuphy","uri":"https://cychong47.github.io/tags/cuphy/"},{"title":"cuvnf","uri":"https://cychong47.github.io/tags/cuvnf/"},{"title":"database","uri":"https://cychong47.github.io/tags/database/"},{"title":"dev culture","uri":"https://cychong47.github.io/tags/dev-culture/"},{"title":"devnothink","uri":"https://cychong47.github.io/tags/devnothink/"},{"title":"docker","uri":"https://cychong47.github.io/tags/docker/"},{"title":"docker-compose","uri":"https://cychong47.github.io/tags/docker-compose/"},{"title":"DPDK","uri":"https://cychong47.github.io/tags/dpdk/"},{"title":"dpi","uri":"https://cychong47.github.io/tags/dpi/"},{"title":"dpkt","uri":"https://cychong47.github.io/tags/dpkt/"},{"title":"edge","uri":"https://cychong47.github.io/tags/edge/"},{"title":"elasticsearch","uri":"https://cychong47.github.io/tags/elasticsearch/"},{"title":"elk","uri":"https://cychong47.github.io/tags/elk/"},{"title":"english","uri":"https://cychong47.github.io/tags/english/"},{"title":"espresso","uri":"https://cychong47.github.io/tags/espresso/"},{"title":"fapi","uri":"https://cychong47.github.io/tags/fapi/"},{"title":"feature flag driven development","uri":"https://cychong47.github.io/tags/feature-flag-driven-development/"},{"title":"feedback","uri":"https://cychong47.github.io/tags/feedback/"},{"title":"ffmpeg","uri":"https://cychong47.github.io/tags/ffmpeg/"},{"title":"finder","uri":"https://cychong47.github.io/tags/finder/"},{"title":"Flask","uri":"https://cychong47.github.io/tags/flask/"},{"title":"fragment","uri":"https://cychong47.github.io/tags/fragment/"},{"title":"ftp","uri":"https://cychong47.github.io/tags/ftp/"},{"title":"Getting Started","uri":"https://cychong47.github.io/tags/getting-started/"},{"title":"ghost","uri":"https://cychong47.github.io/tags/ghost/"},{"title":"ghost-theme","uri":"https://cychong47.github.io/tags/ghost-theme/"},{"title":"git","uri":"https://cychong47.github.io/tags/git/"},{"title":"github","uri":"https://cychong47.github.io/tags/github/"},{"title":"go","uri":"https://cychong47.github.io/tags/go/"},{"title":"golang","uri":"https://cychong47.github.io/tags/golang/"},{"title":"google","uri":"https://cychong47.github.io/tags/google/"},{"title":"gpb","uri":"https://cychong47.github.io/tags/gpb/"},{"title":"gpu","uri":"https://cychong47.github.io/tags/gpu/"},{"title":"grafana","uri":"https://cychong47.github.io/tags/grafana/"},{"title":"grpc","uri":"https://cychong47.github.io/tags/grpc/"},{"title":"HBR","uri":"https://cychong47.github.io/tags/hbr/"},{"title":"helm","uri":"https://cychong47.github.io/tags/helm/"},{"title":"homebrew","uri":"https://cychong47.github.io/tags/homebrew/"},{"title":"http","uri":"https://cychong47.github.io/tags/http/"},{"title":"hugo","uri":"https://cychong47.github.io/tags/hugo/"},{"title":"influxdb","uri":"https://cychong47.github.io/tags/influxdb/"},{"title":"inspiration","uri":"https://cychong47.github.io/tags/inspiration/"},{"title":"Intel","uri":"https://cychong47.github.io/tags/intel/"},{"title":"IPsec","uri":"https://cychong47.github.io/tags/ipsec/"},{"title":"ipv4","uri":"https://cychong47.github.io/tags/ipv4/"},{"title":"istio","uri":"https://cychong47.github.io/tags/istio/"},{"title":"jetpack","uri":"https://cychong47.github.io/tags/jetpack/"},{"title":"json","uri":"https://cychong47.github.io/tags/json/"},{"title":"jtbc","uri":"https://cychong47.github.io/tags/jtbc/"},{"title":"jupiter","uri":"https://cychong47.github.io/tags/jupiter/"},{"title":"kafka","uri":"https://cychong47.github.io/tags/kafka/"},{"title":"kni","uri":"https://cychong47.github.io/tags/kni/"},{"title":"kubelet","uri":"https://cychong47.github.io/tags/kubelet/"},{"title":"kubernetes","uri":"https://cychong47.github.io/tags/kubernetes/"},{"title":"launchd","uri":"https://cychong47.github.io/tags/launchd/"},{"title":"lb","uri":"https://cychong47.github.io/tags/lb/"},{"title":"life","uri":"https://cychong47.github.io/tags/life/"},{"title":"lifehack","uri":"https://cychong47.github.io/tags/lifehack/"},{"title":"linux","uri":"https://cychong47.github.io/tags/linux/"},{"title":"load balancer","uri":"https://cychong47.github.io/tags/load-balancer/"},{"title":"lte","uri":"https://cychong47.github.io/tags/lte/"},{"title":"mac","uri":"https://cychong47.github.io/tags/mac/"},{"title":"Mac mini 2009","uri":"https://cychong47.github.io/tags/mac-mini-2009/"},{"title":"maglev","uri":"https://cychong47.github.io/tags/maglev/"},{"title":"manager","uri":"https://cychong47.github.io/tags/manager/"},{"title":"markdown","uri":"https://cychong47.github.io/tags/markdown/"},{"title":"mbuf","uri":"https://cychong47.github.io/tags/mbuf/"},{"title":"mec","uri":"https://cychong47.github.io/tags/mec/"},{"title":"mediawiki","uri":"https://cychong47.github.io/tags/mediawiki/"},{"title":"meetup","uri":"https://cychong47.github.io/tags/meetup/"},{"title":"message queue","uri":"https://cychong47.github.io/tags/message-queue/"},{"title":"metricbeat","uri":"https://cychong47.github.io/tags/metricbeat/"},{"title":"microk8s","uri":"https://cychong47.github.io/tags/microk8s/"},{"title":"microservice","uri":"https://cychong47.github.io/tags/microservice/"},{"title":"mindmap","uri":"https://cychong47.github.io/tags/mindmap/"},{"title":"model-driven","uri":"https://cychong47.github.io/tags/model-driven/"},{"title":"monitoring","uri":"https://cychong47.github.io/tags/monitoring/"},{"title":"multipass","uri":"https://cychong47.github.io/tags/multipass/"},{"title":"mysql","uri":"https://cychong47.github.io/tags/mysql/"},{"title":"Naim","uri":"https://cychong47.github.io/tags/naim/"},{"title":"nas","uri":"https://cychong47.github.io/tags/nas/"},{"title":"nasa","uri":"https://cychong47.github.io/tags/nasa/"},{"title":"NEC","uri":"https://cychong47.github.io/tags/nec/"},{"title":"nested-chart","uri":"https://cychong47.github.io/tags/nested-chart/"},{"title":"netconf","uri":"https://cychong47.github.io/tags/netconf/"},{"title":"network","uri":"https://cychong47.github.io/tags/network/"},{"title":"neuron","uri":"https://cychong47.github.io/tags/neuron/"},{"title":"nfv","uri":"https://cychong47.github.io/tags/nfv/"},{"title":"nginmesh","uri":"https://cychong47.github.io/tags/nginmesh/"},{"title":"nginx","uri":"https://cychong47.github.io/tags/nginx/"},{"title":"NHN","uri":"https://cychong47.github.io/tags/nhn/"},{"title":"NIC","uri":"https://cychong47.github.io/tags/nic/"},{"title":"Nokia","uri":"https://cychong47.github.io/tags/nokia/"},{"title":"nvidia","uri":"https://cychong47.github.io/tags/nvidia/"},{"title":"odp","uri":"https://cychong47.github.io/tags/odp/"},{"title":"OFP","uri":"https://cychong47.github.io/tags/ofp/"},{"title":"onap","uri":"https://cychong47.github.io/tags/onap/"},{"title":"ONP","uri":"https://cychong47.github.io/tags/onp/"},{"title":"OpenFastPath","uri":"https://cychong47.github.io/tags/openfastpath/"},{"title":"opensource","uri":"https://cychong47.github.io/tags/opensource/"},{"title":"openstack","uri":"https://cychong47.github.io/tags/openstack/"},{"title":"opnfv","uri":"https://cychong47.github.io/tags/opnfv/"},{"title":"osx","uri":"https://cychong47.github.io/tags/osx/"},{"title":"OVDK","uri":"https://cychong47.github.io/tags/ovdk/"},{"title":"OVS","uri":"https://cychong47.github.io/tags/ovs/"},{"title":"p4","uri":"https://cychong47.github.io/tags/p4/"},{"title":"patch","uri":"https://cychong47.github.io/tags/patch/"},{"title":"perl","uri":"https://cychong47.github.io/tags/perl/"},{"title":"photo","uri":"https://cychong47.github.io/tags/photo/"},{"title":"pinpoint","uri":"https://cychong47.github.io/tags/pinpoint/"},{"title":"plist","uri":"https://cychong47.github.io/tags/plist/"},{"title":"Pluribus","uri":"https://cychong47.github.io/tags/pluribus/"},{"title":"prediction","uri":"https://cychong47.github.io/tags/prediction/"},{"title":"programming","uri":"https://cychong47.github.io/tags/programming/"},{"title":"prometheus","uri":"https://cychong47.github.io/tags/prometheus/"},{"title":"protobufs","uri":"https://cychong47.github.io/tags/protobufs/"},{"title":"protocol buffer","uri":"https://cychong47.github.io/tags/protocol-buffer/"},{"title":"pyftplib","uri":"https://cychong47.github.io/tags/pyftplib/"},{"title":"Python","uri":"https://cychong47.github.io/tags/python/"},{"title":"QAT","uri":"https://cychong47.github.io/tags/qat/"},{"title":"Quality","uri":"https://cychong47.github.io/tags/quality/"},{"title":"Quanta","uri":"https://cychong47.github.io/tags/quanta/"},{"title":"quicklook","uri":"https://cychong47.github.io/tags/quicklook/"},{"title":"R210","uri":"https://cychong47.github.io/tags/r210/"},{"title":"reassembly","uri":"https://cychong47.github.io/tags/reassembly/"},{"title":"recovery","uri":"https://cychong47.github.io/tags/recovery/"},{"title":"resources","uri":"https://cychong47.github.io/tags/resources/"},{"title":"RESTful","uri":"https://cychong47.github.io/tags/restful/"},{"title":"RMDA","uri":"https://cychong47.github.io/tags/rmda/"},{"title":"scapy","uri":"https://cychong47.github.io/tags/scapy/"},{"title":"sci","uri":"https://cychong47.github.io/tags/sci/"},{"title":"scrum","uri":"https://cychong47.github.io/tags/scrum/"},{"title":"sctp","uri":"https://cychong47.github.io/tags/sctp/"},{"title":"SDN","uri":"https://cychong47.github.io/tags/sdn/"},{"title":"Service Agility","uri":"https://cychong47.github.io/tags/service-agility/"},{"title":"service mesh","uri":"https://cychong47.github.io/tags/service-mesh/"},{"title":"setup","uri":"https://cychong47.github.io/tags/setup/"},{"title":"slack","uri":"https://cychong47.github.io/tags/slack/"},{"title":"snmp","uri":"https://cychong47.github.io/tags/snmp/"},{"title":"soft-skill","uri":"https://cychong47.github.io/tags/soft-skill/"},{"title":"sqlite","uri":"https://cychong47.github.io/tags/sqlite/"},{"title":"SRIOV","uri":"https://cychong47.github.io/tags/sriov/"},{"title":"startup","uri":"https://cychong47.github.io/tags/startup/"},{"title":"storage","uri":"https://cychong47.github.io/tags/storage/"},{"title":"study","uri":"https://cychong47.github.io/tags/study/"},{"title":"subchart","uri":"https://cychong47.github.io/tags/subchart/"},{"title":"SW Quality","uri":"https://cychong47.github.io/tags/sw-quality/"},{"title":"SW 개발 문화","uri":"https://cychong47.github.io/tags/sw-%EA%B0%9C%EB%B0%9C-%EB%AC%B8%ED%99%94/"},{"title":"swarm","uri":"https://cychong47.github.io/tags/swarm/"},{"title":"synology","uri":"https://cychong47.github.io/tags/synology/"},{"title":"tag","uri":"https://cychong47.github.io/tags/tag/"},{"title":"tcp","uri":"https://cychong47.github.io/tags/tcp/"},{"title":"team","uri":"https://cychong47.github.io/tags/team/"},{"title":"telemetry","uri":"https://cychong47.github.io/tags/telemetry/"},{"title":"The Pragmatic Programmer","uri":"https://cychong47.github.io/tags/the-pragmatic-programmer/"},{"title":"theme","uri":"https://cychong47.github.io/tags/theme/"},{"title":"til","uri":"https://cychong47.github.io/tags/til/"},{"title":"Time Machine","uri":"https://cychong47.github.io/tags/time-machine/"},{"title":"troubleshooting","uri":"https://cychong47.github.io/tags/troubleshooting/"},{"title":"tutorial","uri":"https://cychong47.github.io/tags/tutorial/"},{"title":"ubuntu","uri":"https://cychong47.github.io/tags/ubuntu/"},{"title":"vagrant","uri":"https://cychong47.github.io/tags/vagrant/"},{"title":"ves","uri":"https://cychong47.github.io/tags/ves/"},{"title":"Virtualbox","uri":"https://cychong47.github.io/tags/virtualbox/"},{"title":"virtualenv","uri":"https://cychong47.github.io/tags/virtualenv/"},{"title":"virtualization","uri":"https://cychong47.github.io/tags/virtualization/"},{"title":"Vmware","uri":"https://cychong47.github.io/tags/vmware/"},{"title":"VNF","uri":"https://cychong47.github.io/tags/vnf/"},{"title":"vran","uri":"https://cychong47.github.io/tags/vran/"},{"title":"vRouter","uri":"https://cychong47.github.io/tags/vrouter/"},{"title":"vSwitch","uri":"https://cychong47.github.io/tags/vswitch/"},{"title":"web-scrapping","uri":"https://cychong47.github.io/tags/web-scrapping/"},{"title":"webdav","uri":"https://cychong47.github.io/tags/webdav/"},{"title":"wiki","uri":"https://cychong47.github.io/tags/wiki/"},{"title":"windows10","uri":"https://cychong47.github.io/tags/windows10/"},{"title":"wordpress","uri":"https://cychong47.github.io/tags/wordpress/"},{"title":"work_rules","uri":"https://cychong47.github.io/tags/work_rules/"},{"title":"writing","uri":"https://cychong47.github.io/tags/writing/"},{"title":"xcrun","uri":"https://cychong47.github.io/tags/xcrun/"},{"title":"yang","uri":"https://cychong47.github.io/tags/yang/"},{"title":"개발이야기","uri":"https://cychong47.github.io/tags/%EA%B0%9C%EB%B0%9C%EC%9D%B4%EC%95%BC%EA%B8%B0/"},{"title":"경쟁","uri":"https://cychong47.github.io/tags/%EA%B2%BD%EC%9F%81/"},{"title":"공부","uri":"https://cychong47.github.io/tags/%EA%B3%B5%EB%B6%80/"},{"title":"공유","uri":"https://cychong47.github.io/tags/%EA%B3%B5%EC%9C%A0/"},{"title":"관리능력","uri":"https://cychong47.github.io/tags/%EA%B4%80%EB%A6%AC%EB%8A%A5%EB%A0%A5/"},{"title":"기록","uri":"https://cychong47.github.io/tags/%EA%B8%B0%EB%A1%9D/"},{"title":"논문","uri":"https://cychong47.github.io/tags/%EB%85%BC%EB%AC%B8/"},{"title":"리더","uri":"https://cychong47.github.io/tags/%EB%A6%AC%EB%8D%94/"},{"title":"매너리즘","uri":"https://cychong47.github.io/tags/%EB%A7%A4%EB%84%88%EB%A6%AC%EC%A6%98/"},{"title":"문화","uri":"https://cychong47.github.io/tags/%EB%AC%B8%ED%99%94/"},{"title":"사람이 핵심","uri":"https://cychong47.github.io/tags/%EC%82%AC%EB%9E%8C%EC%9D%B4-%ED%95%B5%EC%8B%AC/"},{"title":"생각","uri":"https://cychong47.github.io/tags/%EC%83%9D%EA%B0%81/"},{"title":"생산성","uri":"https://cychong47.github.io/tags/%EC%83%9D%EC%82%B0%EC%84%B1/"},{"title":"윤식당","uri":"https://cychong47.github.io/tags/%EC%9C%A4%EC%8B%9D%EB%8B%B9/"},{"title":"인용","uri":"https://cychong47.github.io/tags/%EC%9D%B8%EC%9A%A9/"},{"title":"임백준","uri":"https://cychong47.github.io/tags/%EC%9E%84%EB%B0%B1%EC%A4%80/"},{"title":"잡생각","uri":"https://cychong47.github.io/tags/%EC%9E%A1%EC%83%9D%EA%B0%81/"},{"title":"조직관리","uri":"https://cychong47.github.io/tags/%EC%A1%B0%EC%A7%81%EA%B4%80%EB%A6%AC/"},{"title":"조직문화","uri":"https://cychong47.github.io/tags/%EC%A1%B0%EC%A7%81%EB%AC%B8%ED%99%94/"},{"title":"좋은글","uri":"https://cychong47.github.io/tags/%EC%A2%8B%EC%9D%80%EA%B8%80/"},{"title":"착각하는 CEO","uri":"https://cychong47.github.io/tags/%EC%B0%A9%EA%B0%81%ED%95%98%EB%8A%94-ceo/"},{"title":"코드리뷰","uri":"https://cychong47.github.io/tags/%EC%BD%94%EB%93%9C%EB%A6%AC%EB%B7%B0/"},{"title":"회의","uri":"https://cychong47.github.io/tags/%ED%9A%8C%EC%9D%98/"}]}