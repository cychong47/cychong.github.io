<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Keep calm and write something"><meta property="og:type" content="article"><meta property="og:image" content="https://cychong47.github.io/images/another_blog_bg.jpg"><meta property="twitter:image" content="https://cychong47.github.io/images/another_blog_bg.jpg"><meta name=title content="Install kubernetes on mini3"><meta property="og:title" content="Install kubernetes on mini3"><meta property="twitter:title" content="Install kubernetes on mini3"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content="Blog, cychong, Kubernetes, dpdk"><link rel="shortcut icon" href=/img/favicon.ico><title>Install kubernetes on mini3-another blog</title><link rel=canonical href=/post/2021/2021-04-13-install-kubernetes-on-mini3/><link rel=stylesheet href=/css/iDisqus.min.css><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hux-blog.min.css><link rel=stylesheet href=/css/zanshang.css><link href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css rel=stylesheet type=text/css><link rel=stylesheet href=https://cychong47.github.io/css/custom-cleanwhite.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button>
<a class=navbar-brand href=/>Keep calm and write something</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>Home</a></li><li><a href=/categories/book>book</a></li><li><a href=/categories/gadget>gadget</a></li><li><a href=/categories/homelab>homelab</a></li><li><a href=/categories/hugo>hugo</a></li><li><a href=/categories/life>life</a></li><li><a href=/categories/note>note</a></li><li><a href=/categories/til>til</a></li><li><a href=/search>SEARCH <img src=/img/search.png height=15 style=cursor:pointer alt=Search></a></li></ul></div></div></div></nav><script>var $body=document.body;var $toggle=document.querySelector('.navbar-toggle');var $navbar=document.querySelector('#huxblog_navbar');var $collapse=document.querySelector('.navbar-collapse');$toggle.addEventListener('click',handleMagic)
function handleMagic(e){if($navbar.className.indexOf('in')>0){$navbar.className=" ";setTimeout(function(){if($navbar.className.indexOf('in')<0){$collapse.style.height="0px"}},400)}else{$collapse.style.height="auto"
$navbar.className+=" in";}}</script><style type=text/css>header.intro-header{background-image:url(/images/another_blog_bg.jpg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/kubernetes title=kubernetes>kubernetes</a>
<a class=tag href=/tags/containerd title=“containerd”>“containerd”</a></div><h1>Install kubernetes on mini3</h1><h2 class=subheading></h2><span class=meta>Posted by
Keep calm and write something
on
Tuesday, April 13, 2021</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-11 col-lg-offset-1
col-md-10 col-md-offset-1
post-container"><header><h2>TOC</h2></header><nav id=TableOfContents><ul><li><a href=#install-containerd-as-a-container-runtime>Install Containerd as a Container Runtime</a></li><li><a href=#install-kubeadm-kubelet-and-kubectl>Install kubeadm, kubelet and kubectl</a></li><li><a href=#disable-swap>Disable swap</a></li><li><a href=#setup-cluster>Setup Cluster</a></li><li><a href=#install-calico>Install Calico</a></li></ul></nav><p>mini1에서 mini3로의 이전을 준비 중.
기존에 mini3에는 재미삼아 k3s를 설치해 놓았는데 왠지 새로운 설정 방식을 알아야 할 필요가 있나 하는 생각이 들어 이전처럼 다시 vanilla kubernetes 를 설치하기로 했다. minkkube처럼 VM을 만들어야 설치가 되는 것도 아니고 그냥 host OS에 설치하면 되니까 설치도 간단하고(물론 바이너리 하나 설치하면 되는 k3s와는 비교하기 어렵지만) 부하를 감당하기 어려운 정도의 CPU도 아니라서.</p><p><a href=https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/>Installing kubeadm | Kubernetes</a></p><pre><code># /etc/modules-load.d/k8s.conf
br_netfilter
</code></pre><pre><code># /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
</code></pre><pre><code>$ sudo sysctl —system
</code></pre><h1 id=install-containerd-as-a-container-runtime>Install Containerd as a Container Runtime</h1><p>docker를 CRI로 사용하는 것은 곧 deprecated예정이니까 containerd를 사용해 보자.</p><p><a href=https://kubernetes.io/docs/setup/production-environment/container-runtimes>https://kubernetes.io/docs/setup/production-environment/container-runtimes</a></p><p>하지만 위 문서에서는 containerd 자체에 대한 내용은 없고, 별도 문서에서 설치 과정을 언급하고 있지만, docker를 사용하여 설치하는 것으로 기술하고 있어 별도의 링크를 참고하여 설치 중</p><p><a href=https://www.techrepublic.com/article/how-to-install-kubernetes-on-ubuntu-server-without-docker>https://www.techrepublic.com/article/how-to-install-kubernetes-on-ubuntu-server-without-docker</a></p><pre><code># /etc/modules-load.d/containerd.conf 
overlay
br_netfilter
</code></pre><pre><code># /etc/sysctl.d/99-kubernetes-cri.conf 
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
</code></pre><pre><code>$ sudo sysctl —system
</code></pre><p>이제 Containerd 를 패키지로 설치. github에 있는 Containerd는 최신 버전이 1.4.4지만 아직 Ubuntu repository에 있는 버전은 1.3.3라 좀 아쉽지만 일단 설치를 해 보자. 아니면 직접 빌드해서 설치하면 되긴한데, 그러면 앞으로 업데이트도 매번 빌드를 해야 할 것 같아서.</p><pre><code>$ sudo apt search containerd
...
containerd/focal-updates,focal-security,now 1.3.3-0ubuntu2.3 amd64 
  daemon to control runC
</code></pre><pre><code>$ sudo apt install containerd -y
</code></pre><pre><code>$ sudo mkdir -p /etc/containerd
$ containerd config default | sudo tee /etc/containerd/config.toml
</code></pre><pre><code>$ sudo systemctl restart containerd
</code></pre><h1 id=install-kubeadm-kubelet-and-kubectl>Install kubeadm, kubelet and kubectl</h1><p>kubeadm 등 k8s 관련 앱 들을 설치를 하기 위해 repo 추가</p><pre><code>$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add
OK

$ sudo apt-add-repository ‘deb http://apt.kubernetes.io/ kubernetes-xenial main’

Hit:2 http://kr.archive.ubuntu.com/ubuntu focal InRelease
Get:3 http://kr.archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]
Get:4 http://kr.archive.ubuntu.com/ubuntu focal-backports InRelease [101 kB]
Get:5 http://kr.archive.ubuntu.com/ubuntu focal-security InRelease [109 kB]
Get:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [9,383 B]
Get:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [45.5 kB]
Fetched 378 kB in 5s (77.5 kB/s)   
Reading package lists... Done
</code></pre><pre><code>$ sudo apt-get install kubeadm kubelet kubectl -y
</code></pre><h1 id=disable-swap>Disable swap</h1><p>Reboot후에도 swap을 만들지 않도록 조치하고</p><pre><code># /etc/fstab
...
#/swap.img
</code></pre><p>현재 활성화된 swap도 끄고</p><pre><code>$ free -h
              total        used        free      shared  buff/cache   available
Mem:           15Gi       292Mi       2.7Gi       2.0Mi        12Gi        14Gi
Swap:         4.0Gi       0.0Ki       4.0Gi

$ sudo swapoff -a

$ free -h
              total        used        free      shared  buff/cache   available
Mem:           15Gi       282Mi       2.7Gi       2.0Mi        12Gi        14Gi
Swap:            0B          0B          0B
</code></pre><h1 id=setup-cluster>Setup Cluster</h1><p>이제 준비가 되었으니 kubeadm으로 설치 시작.
mini1에 k8s 설치할 때 kubeadm을 사용해서 이번에는 다른 방법으로 해 보려고 찾아봤는데 딱히 마음에 드는 게 없어서 그냥 이번에도 kubeadm으로 진행. Terraform으로 어떻게 할 수 있지 않을까 했는데 자료를 찾지 못했다는. Public cloud 환경에 cluster를 구성하거나, 이미 구성되어 있는 cluster에 namespace를 추가하고, 툴을 설치하는 등의 예제는 많은데 내가 원하는 on-premise 환경에 kubernetes cluster를 구성하는 내용에 대한 자료는 의의로 많이 없었다는. 그래서 k8s홈페이지에서도 여전히 kubeadm, Kubespray, kops 정도만 소개하고 있는 걸까?</p><pre><code>$ sudo kubeadm config images pull
[config/images] Pulled k8s.gcr.io/kube-apiserver:v1.21.0
[config/images] Pulled k8s.gcr.io/kube-controller-manager:v1.21.0
[config/images] Pulled k8s.gcr.io/kube-scheduler:v1.21.0
[config/images] Pulled k8s.gcr.io/kube-proxy:v1.21.0
[config/images] Pulled k8s.gcr.io/pause:3.4.1
[config/images] Pulled k8s.gcr.io/etcd:3.4.13-0
[config/images] Pulled k8s.gcr.io/coredns/coredns:v1.8.0
</code></pre><pre><code>$ sudo kubeadm init --pod-network-cidr=10.245.0.0/16
[init] Using Kubernetes version: v1.21.0
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;
[certs] Generating &quot;ca&quot; certificate and key
[certs] Generating &quot;apiserver&quot; certificate and key
[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local mini3] and IPs [10.96.0.1 192.168.0.101][certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key
[certs] Generating &quot;front-proxy-ca&quot; certificate and key
[certs] Generating &quot;front-proxy-client&quot; certificate and key
[certs] Generating &quot;etcd/ca&quot; certificate and key
[certs] Generating &quot;etcd/server&quot; certificate and key
[certs] etcd/server serving cert is signed for DNS names [localhost mini3] and IPs [192.168.0.101 127.0.0.1 ::1]
[certs] Generating &quot;etcd/peer&quot; certificate and key
[certs] etcd/peer serving cert is signed for DNS names [localhost mini3] and IPs [192.168.0.101 127.0.0.1 ::1]
[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key
[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key
[certs] Generating &quot;sa&quot; key and public key
[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;
[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file
[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;
[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;
[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;
[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;
[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s
</code></pre><p>1분 정도(아래 로그를 보니 73초) 아무런 진행이 없다 다시 설치가 진행되고, 마지막에 성공했다는 메시지가 짠. 언제나 설치 성공은 기쁜 일이지.</p><pre><code>        [kubelet-check] Initial timeout of 40s passed.
[apiclient] All control plane components are healthy after 73.009593 seconds
[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace
[kubelet] Creating a ConfigMap &quot;kubelet-config-1.21&quot; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node mini3 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node mini3 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: rc93da.7cseyuwmnfvhgyyx
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace
[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.0.101:6443 --token qs9eij.pm7l5jzihbk2rmvs \
        --discovery-token-ca-cert-hash sha256:754b224773ada603d486d3e6652437539a847323dee6fa011ae472e85b3bcdbc 
</code></pre><p>시키는 대로 kube configuration 파일을 홈 디렉토리에 복사해주고. 이 파일만 있으면 어느 머신에서든 kubectl이나 k9s같은 툴을 이용해서 cluster의 상태를 확인하고, 변경할 수 있다는.</p><pre><code>$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre><p>Cluster 접근에 필요한 certificate등의 정보가 저장되어 있는 파일이라 파일 퍼미션은 저렇게 600으로 되어 있는 듯.</p><pre><code>$ ls -al $HOME/.kube/config
-rw------- 1 cychong cychong 5597 Apr 12 14:02 /home/cychong/.kube/config
</code></pre><h1 id=install-calico>Install Calico</h1><p>기본 CNI인 flannel을 사용해도 되지만, 이번에도 익숙한(?) Calico를 굳이 설치.</p><p>이전(v3.8) 설치 때와 달리 지금 Calico버전은 Operator를 이용해서 설치
<a href=https://docs.projectcalico.org/getting-started/kubernetes/quickstart>https://docs.projectcalico.org/getting-started/kubernetes/quickstart</a></p><pre><code>$ kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/
kubecontrollersconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/imagesets.operator.tigera.io created
customresourcedefinition.apiextensions.k8s.io/installations.operator.tigera.io created
customresourcedefinition.apiextensions.k8s.io/tigerastatuses.operator.tigera.io created
namespace/tigera-operator created
Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
podsecuritypolicy.policy/tigera-operator created
serviceaccount/tigera-operator created
clusterrole.rbac.authorization.k8s.io/tigera-operator created
clusterrolebinding.rbac.authorization.k8s.io/tigera-operator created
deployment.apps/tigera-operator created
</code></pre><p><code>tigera-operator</code> 라는 namespace가 생성되고, 거기에 tigera-operator pod가 하나 실행된다.</p><pre><code>$ kubectl get pods --all-namespaces
NAMESPACE         NAME                               READY   STATUS    RESTARTS   AGE
kube-system       coredns-558bd4d5db-7qm2n           0/1     Pending   0          7m3s
kube-system       coredns-558bd4d5db-vrhmk           0/1     Pending   0          7m3s
kube-system       etcd-mini3                         1/1     Running   0          7m7s
kube-system       kube-apiserver-mini3               1/1     Running   0          7m7s
kube-system       kube-controller-manager-mini3      1/1     Running   0          7m7s
kube-system       kube-proxy-ll97z                   1/1     Running   0          7m3s
kube-system       kube-scheduler-mini3               1/1     Running   0          7m7s
tigera-operator   tigera-operator-675ccbb69c-fg4k9   1/1     Running   0          2m27s
</code></pre><p>이제 나머지 Calico를 설치하는데, IP subnet을 변경했으니 설정파일을 받아서 수정한 후 설치하는 걸로.</p><pre><code>$ wget https://docs.projectcalico.org/manifests/custom-resources.yaml
--2021-04-12 14:20:49--  https://docs.projectcalico.org/manifests/custom-resources.yaml
Resolving docs.projectcalico.org (docs.projectcalico.org)... 3.0.239.142, 104.248.158.121, 2406:da18:880:3802:371c:4bf1:923b:fc30, ...
Connecting to docs.projectcalico.org (docs.projectcalico.org)|3.0.239.142|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 545 [text/yaml]
Saving to: ‘custom-resources.yaml’

custom-resources.yaml   100%[============================&gt;]     545  --.-KB/s    in 0s      

2021-04-12 14:20:50 (3.36 MB/s) - ‘custom-resources.yaml’ saved [545/545]
</code></pre><p>파일에서 “CIDR” 필드 값을 변경한다.</p><pre><code>$ vi custom-resource.yaml
</code></pre><p>앞에서 <code>kubeadm init</code>할때 사용했던 subnet과 같은 값으로 변경.</p><pre><code>$ grep cidr custom-resources.yaml 
      cidr: 10.245.0.0/16
</code></pre><pre><code>$ kubectl apply -f custom-resources.yaml 
installation.operator.tigera.io/default created
</code></pre><p>Wait for all Calico pods are in <code>RUNNING</code> state</p><pre><code># watch -n2 kubectl get pods -n calico-system 
Every 2.0s: kubectl get pods -n calico-system

NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-5cbf59cb6f-lg9xq   1/1     Running   0          3m7s
calico-node-dglfb                          1/1     Running   0          3m8s
calico-typha-d798686b4-hf6bb               1/1     Running   0          3m8s
</code></pre><p>이제 모든 namespaces 해 보면,</p><pre><code>$ kubectl get pods --all-namespaces
NAMESPACE         NAME                                       READY   STATUS    RESTARTS   AGEcalico-system     calico-kube-controllers-5cbf59cb6f-lg9xq   1/1     Running   0          8m18s
calico-system     calico-node-dglfb                          1/1     Running   0          8m19s
calico-system     calico-typha-d798686b4-hf6bb               1/1     Running   0          8m19s
kube-system       coredns-558bd4d5db-2wgvk                   1/1     Running   0          18mkube-system       coredns-558bd4d5db-sxmnq                   1/1     Running   0          18mkube-system       etcd-mini3                                 1/1     Running   0          18mkube-system       kube-apiserver-mini3                       1/1     Running   0          18m
kube-system       kube-controller-manager-mini3              1/1     Running   0          18mkube-system       kube-proxy-bnsv7                           1/1     Running   0          18m
kube-system       kube-scheduler-mini3                       1/1     Running   0          18m
tigera-operator   tigera-operator-675ccbb69c-z9hrz           1/1     Running   0          11m
</code></pre><p>Single node cluster 로 사용하기 위해</p><pre><code>$ kubectl taint nodes --all node-role.kubernetes.io/master-
node/mini3 untainted
$ kubectl get nodes -o wide
NAME    STATUS   ROLES                  AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME
mini3   Ready    control-plane,master   14m   v1.21.0   192.168.0.101   &lt;none&gt;        Ubuntu 20.04.2 LTS   5.4.0-66-generic   containerd://1.3.3-0ubuntu2.3
</code></pre><p>이전과 달리 <code>CONTAINER-RUNTIME</code> 에 <code>docker</code>가 아닌 <code>containerd</code>가 표시된 걸 보니 Containerd 설치가 제대로 된 듯</p><pre><code>$ kubectl describe node mini3
Name:               mini3
Roles:              control-plane,master
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=mini3
                    kubernetes.io/os=linux
                    node-role.kubernetes.io/control-plane=
                    node-role.kubernetes.io/master=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /run/containerd/containerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    projectcalico.org/IPv4Address: 192.168.0.101/24
                    projectcalico.org/IPv4VXLANTunnelAddr: 10.245.211.0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Mon, 12 Apr 2021 14:12:49 +0900
Taints:             &lt;none&gt;
Unschedulable:      false
Lease:
  HolderIdentity:  mini3
  AcquireTime:     &lt;unset&gt;
  RenewTime:       Mon, 12 Apr 2021 14:32:28 +0900
Conditions:
  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----                 ------  -----------------                 ------------------                ------                       -------
  NetworkUnavailable   False   Mon, 12 Apr 2021 14:24:14 +0900   Mon, 12 Apr 2021 14:24:14 +0900   CalicoIsUp                   Calico is running on this node
  MemoryPressure       False   Mon, 12 Apr 2021 14:30:07 +0900   Mon, 12 Apr 2021 14:12:47 +0900   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure         False   Mon, 12 Apr 2021 14:30:07 +0900   Mon, 12 Apr 2021 14:12:47 +0900   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure          False   Mon, 12 Apr 2021 14:30:07 +0900   Mon, 12 Apr 2021 14:12:47 +0900   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready                True    Mon, 12 Apr 2021 14:30:07 +0900   Mon, 12 Apr 2021 14:23:56 +0900   KubeletReady                 kubelet is posting ready status. AppArmor enabled
Addresses:
  InternalIP:  192.168.0.101
  Hostname:    mini3
Capacity:
  cpu:                2
  ephemeral-storage:  114336932Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             16311204Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  105372916357
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             16208804Ki
  pods:               110
System Info:
  Machine ID:                 7369831895a5443e9806a29d674b929b
  System UUID:                a61d4c15-ad23-4b7c-9f11-c07cd13f6216
  Boot ID:                    7bbad4d9-72fc-4bdf-8604-26cb6fb2bc99
  Kernel Version:             5.4.0-66-generic
  OS Image:                   Ubuntu 20.04.2 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  containerd://1.3.3-0ubuntu2.3
  Kubelet Version:            v1.21.0
  Kube-Proxy Version:         v1.21.0
PodCIDR:                      10.245.0.0/24
PodCIDRs:                     10.245.0.0/24
Non-terminated Pods:          (11 in total)
  Namespace                   Name                                        CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                        ------------  ----------  ---------------  -------------  ---
  calico-system               calico-kube-controllers-5cbf59cb6f-lg9xq    0 (0%)        0 (0%)      0 (0%)           0 (0%)         9m14s
  calico-system               calico-node-dglfb                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         9m15s
  calico-system               calico-typha-d798686b4-hf6bb                0 (0%)        0 (0%)      0 (0%)           0 (0%)         9m15s
  kube-system                 coredns-558bd4d5db-2wgvk                    100m (5%)     0 (0%)      70Mi (0%)        170Mi (1%)     19m
  kube-system                 coredns-558bd4d5db-sxmnq                    100m (5%)     0 (0%)      70Mi (0%)        170Mi (1%)     19m
  kube-system                 etcd-mini3                                  100m (5%)     0 (0%)      100Mi (0%)       0 (0%)         19m
  kube-system                 kube-apiserver-mini3                        250m (12%)    0 (0%)      0 (0%)           0 (0%)         19m
  kube-system                 kube-controller-manager-mini3               200m (10%)    0 (0%)      0 (0%)           0 (0%)         19m
  kube-system                 kube-proxy-bnsv7                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         19m
  kube-system                 kube-scheduler-mini3                        100m (5%)     0 (0%)      0 (0%)           0 (0%)         19m
  tigera-operator             tigera-operator-675ccbb69c-z9hrz            0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (42%)  0 (0%)
  memory             240Mi (1%)  340Mi (2%)
  ephemeral-storage  100Mi (0%)  0 (0%)
  hugepages-1Gi      0 (0%)      0 (0%)
  hugepages-2Mi      0 (0%)      0 (0%)
Events:
  Type     Reason                   Age                From        Message
  ----     ------                   ----               ----        -------
  Normal   NodeHasNoDiskPressure    21m (x5 over 21m)  kubelet     Node mini3 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     21m (x5 over 21m)  kubelet     Node mini3 status is now: NodeHasSufficientPID
  Normal   NodeHasSufficientMemory  20m (x6 over 21m)  kubelet     Node mini3 status is now: NodeHasSufficientMemory
  Normal   Starting                 19m                kubelet     Starting kubelet.
  Warning  InvalidDiskCapacity      19m                kubelet     invalid capacity 0 on image filesystem
  Normal   NodeHasSufficientMemory  19m                kubelet     Node mini3 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    19m                kubelet     Node mini3 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     19m                kubelet     Node mini3 status is now: NodeHasSufficientPID
  Normal   NodeAllocatableEnforced  19m                kubelet     Updated Node Allocatable limit across pods
  Normal   Starting                 19m                kube-proxy  Starting kube-proxy.
  Normal   NodeReady                8m40s              kubelet     Node mini3 status is now: NodeReady
</code></pre><p>기본 설치 끝.</p><p>그런데 docker를 설치하지 않았으니 docker 명령어를 사용할 수 없네. 흠.. podman을 설치할까 그냥 docker를 설치할까. podman으로 docker-compose를 사용할 수 있던가&mldr;</p><hr><ul class=pager><li class=previous><a href=/post/2021/2021-03-31-change-nodeport-to-clusterip/ data-toggle=tooltip data-placement=top title="Replace NodePort with ClsuterIP - Thx to Traefik">&larr;
Previous Post</a></li></ul><div id=disqus-comment></div></div><div class="col-lg-11 col-lg-offset-1
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/agile title=agile>agile</a>
<a href=/tags/amazon title=amazon>amazon</a>
<a href=/tags/amdocs title=amdocs>amdocs</a>
<a href=/tags/ansible title=ansible>ansible</a>
<a href=/tags/ansible-playbook title=ansible-playbook>ansible-playbook</a>
<a href=/tags/anti-work-pattern title=anti-work-pattern>anti-work-pattern</a>
<a href=/tags/apple title=apple>apple</a>
<a href=/tags/automation title=automation>automation</a>
<a href=/tags/backup title=backup>backup</a>
<a href=/tags/book title=book>book</a>
<a href=/tags/brew title=brew>brew</a>
<a href=/tags/calico title=calico>calico</a>
<a href=/tags/cisco title=cisco>cisco</a>
<a href=/tags/cni title=cni>cni</a>
<a href=/tags/coding-style title=coding-style>coding-style</a>
<a href=/tags/container title=container>container</a>
<a href=/tags/cron title=cron>cron</a>
<a href=/tags/cronjob title=cronjob>cronjob</a>
<a href=/tags/cuda title=cuda>cuda</a>
<a href=/tags/culture title=culture>culture</a>
<a href=/tags/dev-culture title=dev-culture>dev-culture</a>
<a href=/tags/devonthink title=devonthink>devonthink</a>
<a href=/tags/docker title=docker>docker</a>
<a href=/tags/docker-compose title=docker-compose>docker-compose</a>
<a href=/tags/dpdk title=dpdk>dpdk</a>
<a href=/tags/elk title=elk>elk</a>
<a href=/tags/english title=english>english</a>
<a href=/tags/getting-started title=getting-started>getting-started</a>
<a href=/tags/ghost title=ghost>ghost</a>
<a href=/tags/git title=git>git</a>
<a href=/tags/github title=github>github</a>
<a href=/tags/golang title=golang>golang</a>
<a href=/tags/google title=google>google</a>
<a href=/tags/gpu title=gpu>gpu</a>
<a href=/tags/grafana title=grafana>grafana</a>
<a href=/tags/helm title=helm>helm</a>
<a href=/tags/homebrew title=homebrew>homebrew</a>
<a href=/tags/http title=http>http</a>
<a href=/tags/hugo title=hugo>hugo</a>
<a href=/tags/influxdb title=influxdb>influxdb</a>
<a href=/tags/intel title=intel>intel</a>
<a href=/tags/ipad title=ipad>ipad</a>
<a href=/tags/iphone title=iphone>iphone</a>
<a href=/tags/ipsec title=ipsec>ipsec</a>
<a href=/tags/json title=json>json</a>
<a href=/tags/kubernetes title=kubernetes>kubernetes</a>
<a href=/tags/life title=life>life</a>
<a href=/tags/lifehack title=lifehack>lifehack</a>
<a href=/tags/mac-mini-2009 title=mac-mini-2009>mac-mini-2009</a>
<a href=/tags/manager title=manager>manager</a>
<a href=/tags/monitoring title=monitoring>monitoring</a>
<a href=/tags/mysql title=mysql>mysql</a>
<a href=/tags/nfv title=nfv>nfv</a>
<a href=/tags/nginx title=nginx>nginx</a>
<a href=/tags/note title=note>note</a>
<a href=/tags/odp title=odp>odp</a>
<a href=/tags/onap title=onap>onap</a>
<a href=/tags/onp title=onp>onp</a>
<a href=/tags/openstack title=openstack>openstack</a>
<a href=/tags/opnfv title=opnfv>opnfv</a>
<a href=/tags/osx title=osx>osx</a>
<a href=/tags/ovdk title=ovdk>ovdk</a>
<a href=/tags/ovs title=ovs>ovs</a>
<a href=/tags/photo title=photo>photo</a>
<a href=/tags/podcast title=podcast>podcast</a>
<a href=/tags/programming title=programming>programming</a>
<a href=/tags/protocol-buffer title=protocol-buffer>protocol-buffer</a>
<a href=/tags/python title=python>python</a>
<a href=/tags/scapy title=scapy>scapy</a>
<a href=/tags/sdn title=sdn>sdn</a>
<a href=/tags/slack title=slack>slack</a>
<a href=/tags/sw-%EA%B0%9C%EB%B0%9C-%EB%AC%B8%ED%99%94 title=sw-개발-문화>sw-개발-문화</a>
<a href=/tags/team title=team>team</a>
<a href=/tags/telemetry title=telemetry>telemetry</a>
<a href=/tags/til title=til>til</a>
<a href=/tags/traefik title=traefik>traefik</a>
<a href=/tags/troubleshooting title=troubleshooting>troubleshooting</a>
<a href=/tags/ubuntu title=ubuntu>ubuntu</a>
<a href=/tags/vagrant title=vagrant>vagrant</a>
<a href=/tags/virtualization title=virtualization>virtualization</a>
<a href=/tags/vmware title=vmware>vmware</a>
<a href=/tags/vnf title=vnf>vnf</a>
<a href=/tags/vran title=vran>vran</a>
<a href=/tags/wordpress title=wordpress>wordpress</a>
<a href=/tags/%EA%B3%B5%EB%B6%80 title=공부>공부</a>
<a href=/tags/%EA%B4%80%EB%A6%AC%EB%8A%A5%EB%A0%A5 title=관리능력>관리능력</a>
<a href=/tags/%EA%B8%B0%EB%A1%9D title=기록>기록</a>
<a href=/tags/%EB%A6%AC%EB%8D%94 title=리더>리더</a>
<a href=/tags/%EB%AC%B8%ED%99%94 title=문화>문화</a>
<a href=/tags/%EC%83%9D%EC%82%B0%EC%84%B1 title=생산성>생산성</a>
<a href=/tags/%EC%9E%A1%EC%83%9D%EA%B0%81 title=잡생각>잡생각</a>
<a href=/tags/%EC%A1%B0%EC%A7%81%EA%B4%80%EB%A6%AC title=조직관리>조직관리</a>
<a href=/tags/%ED%9A%8C%EC%9D%98 title=회의>회의</a></div></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href rel=alternate type=application/rss+xml title="Keep calm and write something"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-rss fa-stack-1x fa-inverse"></i></span></a></li><li><a href=mailto:cychong@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Keep calm and write something 2021<br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function async(u,c){var d=document,t='script',o=d.createElement(t),s=d.getElementsByTagName(t)[0];o.src=u;if(c){o.addEventListener('load',function(e){c(null,e);},false);}
s.parentNode.insertBefore(o,s);}</script><script>if($('#tag_cloud').length!==0){async("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:'#bbbbee',end:'#0085a1'},};$('#tag_cloud a').tagcloud();})}</script><script>async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js",function(){var $nav=document.querySelector("nav");if($nav)FastClick.attach($nav);})</script></body></html>